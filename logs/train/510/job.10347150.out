Starting at Thu May 26 11:07:49 CEST 2022
Running on hosts: res-hpc-lkeb05
Running on 1 nodes.
Running 1 tasks.
CPUs on node: 8.
Account: div2-lkeb
Job ID: 10347150
Job name: PancreasTrain
Node running script: res-hpc-lkeb05
Submit host: res-hpc-lo02.researchlumc.nl
GPUS: 0 or 
Thu May 26 14:08:47 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     Off  | 00000000:3B:00.0 Off |                  Off |
| 33%   50C    P0    71W / 260W |      0MiB / 24220MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Current working directory is /home/smaijer
Load all modules..
Done with loading all modules. Modules:
Activate conda env nnunet..
Verifying environment variables:
nnUNet_raw_data_base = /exports/lkeb-hpc/smaijer/data/nnUNet_raw_data_base
nnUNet_preprocessed = /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed
RESULTS_FOLDER = /exports/lkeb-hpc/smaijer/results
OUTPUT = /exports/lkeb-hpc/smaijer/output
Installing nnU-net..
Obtaining file:///home/smaijer/code/nnUNet
Requirement already satisfied: torch>1.10.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.11.0)
Requirement already satisfied: tqdm in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (4.64.0)
Requirement already satisfied: dicom2nifti in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2.3.2)
Requirement already satisfied: scikit-image>=0.14 in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.19.2)
Requirement already satisfied: medpy in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.4.0)
Requirement already satisfied: scipy in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.8.0)
Requirement already satisfied: batchgenerators>=0.23 in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.23)
Requirement already satisfied: numpy in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.21.2)
Requirement already satisfied: sklearn in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.0)
Requirement already satisfied: SimpleITK in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2.1.1)
Requirement already satisfied: pandas in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.4.2)
Requirement already satisfied: requests in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2.27.1)
Requirement already satisfied: nibabel in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (3.2.2)
Requirement already satisfied: tifffile in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2022.4.8)
Requirement already satisfied: matplotlib in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (3.5.1)
Requirement already satisfied: pillow>=7.1.2 in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (9.0.1)
Requirement already satisfied: unittest2 in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)
Requirement already satisfied: future in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (0.18.2)
Requirement already satisfied: threadpoolctl in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (3.1.0)
Requirement already satisfied: scikit-learn in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.0.2)
Requirement already satisfied: networkx>=2.2 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.8)
Requirement already satisfied: PyWavelets>=1.1.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (1.3.0)
Requirement already satisfied: packaging>=20.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (21.3)
Requirement already satisfied: imageio>=2.4.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.16.2)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.conda/envs/nn/lib/python3.9/site-packages (from packaging>=20.0->scikit-image>=0.14->nnunet==1.7.0) (3.0.8)
Requirement already satisfied: typing_extensions in ./.conda/envs/nn/lib/python3.9/site-packages (from torch>1.10.0->nnunet==1.7.0) (4.1.1)
Requirement already satisfied: pydicom>=1.3.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from dicom2nifti->nnunet==1.7.0) (2.3.0)
Requirement already satisfied: fonttools>=4.22.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (4.32.0)
Requirement already satisfied: cycler>=0.10 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (0.11.0)
Requirement already satisfied: kiwisolver>=1.0.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (1.4.2)
Requirement already satisfied: python-dateutil>=2.7 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (2.8.2)
Requirement already satisfied: six>=1.5 in ./.conda/envs/nn/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->nnunet==1.7.0) (1.16.0)
Requirement already satisfied: setuptools in ./.conda/envs/nn/lib/python3.9/site-packages (from nibabel->nnunet==1.7.0) (58.0.4)
Requirement already satisfied: pytz>=2020.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from pandas->nnunet==1.7.0) (2022.1)
Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (3.3)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (1.26.8)
Requirement already satisfied: charset-normalizer~=2.0.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (2.0.4)
Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (2021.10.8)
Requirement already satisfied: joblib>=0.11 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-learn->batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)
Requirement already satisfied: traceback2 in ./.conda/envs/nn/lib/python3.9/site-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.4.0)
Collecting argparse
  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)
Requirement already satisfied: linecache2 in ./.conda/envs/nn/lib/python3.9/site-packages (from traceback2->unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.0.0)
Installing collected packages: argparse, nnunet
  Attempting uninstall: nnunet
    Found existing installation: nnunet 1.7.0
    Uninstalling nnunet-1.7.0:
      Successfully uninstalled nnunet-1.7.0
  Running setup.py develop for nnunet
Successfully installed argparse-1.4.0 nnunet-1.7.0
Train all the folds..


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_lowres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 93, 318, 318]), 'current_spacing': array([2.5757525 , 1.29418872, 1.29418872]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 40, 224, 224]), 'median_patient_size_in_voxels': array([ 96, 512, 512]), 'current_spacing': array([2.5       , 0.80273402, 0.80273402]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-05-26 14:09:26.341674: Creating new 5-fold cross-validation split...
2022-05-26 14:09:26.362171: Desired fold for training: 0
2022-05-26 14:09:26.365481: This split has 191 training and 48 validation cases.
unpacking dataset
done
Susy hier
Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-26 14:10:37.294095: lr: 0.01
using pin_memory on device 0
using pin_memory on device 0
2022-05-26 14:10:42.370751: Unable to plot network architecture:
2022-05-26 14:10:42.375059: No module named 'hiddenlayer'
2022-05-26 14:10:42.377485: 
printing the network instead:

2022-05-26 14:10:42.379619: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-26 14:10:42.403359: 

2022-05-26 14:10:42.411540: 
epoch:  0
2022-05-26 14:12:33.757531: train loss : -0.0273
2022-05-26 14:12:43.650132: validation loss: -0.2729
2022-05-26 14:12:43.655103: Average global foreground Dice: [0.3881]
2022-05-26 14:12:43.658762: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:12:44.646139: lr: 0.009982
2022-05-26 14:12:44.650154: This epoch took 122.235394 s

2022-05-26 14:12:44.652920: 
epoch:  1
2022-05-26 14:14:18.089960: train loss : -0.2146
2022-05-26 14:14:29.113940: validation loss: -0.3235
2022-05-26 14:14:29.117618: Average global foreground Dice: [0.4361]
2022-05-26 14:14:29.120775: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:14:29.543949: lr: 0.009964
2022-05-26 14:14:29.594332: saving checkpoint...
2022-05-26 14:14:30.767117: done, saving took 1.22 seconds
2022-05-26 14:14:30.785488: This epoch took 106.130223 s

2022-05-26 14:14:30.788354: 
epoch:  2
2022-05-26 14:16:01.876240: train loss : -0.2995
2022-05-26 14:16:09.823127: validation loss: -0.3711
2022-05-26 14:16:09.828339: Average global foreground Dice: [0.4667]
2022-05-26 14:16:09.831793: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:16:10.290098: lr: 0.009946
2022-05-26 14:16:10.346428: saving checkpoint...
2022-05-26 14:16:11.467729: done, saving took 1.17 seconds
2022-05-26 14:16:11.485961: This epoch took 100.695243 s

2022-05-26 14:16:11.489710: 
epoch:  3
2022-05-26 14:17:42.843026: train loss : -0.3607
2022-05-26 14:17:52.416630: validation loss: -0.4731
2022-05-26 14:17:52.420288: Average global foreground Dice: [0.5587]
2022-05-26 14:17:52.422723: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:17:52.852936: lr: 0.009928
2022-05-26 14:17:52.904889: saving checkpoint...
2022-05-26 14:17:53.886993: done, saving took 1.03 seconds
2022-05-26 14:17:53.904461: This epoch took 102.412623 s

2022-05-26 14:17:53.907230: 
epoch:  4
2022-05-26 14:19:29.202330: train loss : -0.4021
2022-05-26 14:19:40.957240: validation loss: -0.5012
2022-05-26 14:19:40.961390: Average global foreground Dice: [0.5868]
2022-05-26 14:19:40.963704: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:19:41.402354: lr: 0.00991
2022-05-26 14:19:41.454680: saving checkpoint...
2022-05-26 14:19:42.387643: done, saving took 0.98 seconds
2022-05-26 14:19:42.402529: This epoch took 108.492944 s

2022-05-26 14:19:42.404771: 
epoch:  5
2022-05-26 14:21:13.995015: train loss : -0.4127
2022-05-26 14:21:22.176111: validation loss: -0.5606
2022-05-26 14:21:22.179626: Average global foreground Dice: [0.6343]
2022-05-26 14:21:22.181985: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:21:22.602199: lr: 0.009892
2022-05-26 14:21:22.646046: saving checkpoint...
2022-05-26 14:21:23.626973: done, saving took 1.02 seconds
2022-05-26 14:21:23.642715: This epoch took 101.235606 s

2022-05-26 14:21:23.644942: 
epoch:  6
2022-05-26 14:22:54.278940: train loss : -0.4895
2022-05-26 14:23:02.861953: validation loss: -0.5655
2022-05-26 14:23:02.867192: Average global foreground Dice: [0.6339]
2022-05-26 14:23:02.869991: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:23:03.292906: lr: 0.009874
2022-05-26 14:23:03.334955: saving checkpoint...
2022-05-26 14:23:04.379123: done, saving took 1.08 seconds
2022-05-26 14:23:04.395283: This epoch took 100.747986 s

2022-05-26 14:23:04.397704: 
epoch:  7
2022-05-26 14:24:35.571453: train loss : -0.4797
2022-05-26 14:24:44.166834: validation loss: -0.6082
2022-05-26 14:24:44.171468: Average global foreground Dice: [0.6794]
2022-05-26 14:24:44.174662: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:24:44.781250: lr: 0.009856
2022-05-26 14:24:44.826124: saving checkpoint...
2022-05-26 14:24:45.995512: done, saving took 1.21 seconds
2022-05-26 14:24:46.010188: This epoch took 101.610364 s

2022-05-26 14:24:46.012636: 
epoch:  8
2022-05-26 14:26:20.035843: train loss : -0.5306
2022-05-26 14:26:29.257461: validation loss: -0.5797
2022-05-26 14:26:29.266551: Average global foreground Dice: [0.6528]
2022-05-26 14:26:29.277747: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:26:29.818523: lr: 0.009838
2022-05-26 14:26:29.848012: saving checkpoint...
2022-05-26 14:26:30.837294: done, saving took 1.02 seconds
2022-05-26 14:26:30.851406: This epoch took 104.836506 s

2022-05-26 14:26:30.853663: 
epoch:  9
2022-05-26 14:28:02.012879: train loss : -0.5334
2022-05-26 14:28:11.196248: validation loss: -0.6224
2022-05-26 14:28:11.200287: Average global foreground Dice: [0.6908]
2022-05-26 14:28:11.203004: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:28:11.624587: lr: 0.00982
2022-05-26 14:28:11.660820: saving checkpoint...
2022-05-26 14:28:12.619363: done, saving took 0.99 seconds
2022-05-26 14:28:12.633142: This epoch took 101.777493 s

2022-05-26 14:28:12.635498: 
epoch:  10
2022-05-26 14:29:46.886802: train loss : -0.5355
2022-05-26 14:30:01.528304: validation loss: -0.6184
2022-05-26 14:30:01.533958: Average global foreground Dice: [0.6957]
2022-05-26 14:30:01.536950: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:30:01.983219: lr: 0.009802
2022-05-26 14:30:02.014155: saving checkpoint...
2022-05-26 14:30:02.959964: done, saving took 0.97 seconds
2022-05-26 14:30:02.974464: This epoch took 110.336964 s

2022-05-26 14:30:02.976716: 
epoch:  11
2022-05-26 14:31:46.037249: train loss : -0.5601
2022-05-26 14:31:55.849634: validation loss: -0.6407
2022-05-26 14:31:55.854013: Average global foreground Dice: [0.7085]
2022-05-26 14:31:55.856195: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:31:56.304656: lr: 0.009784
2022-05-26 14:31:56.336826: saving checkpoint...
2022-05-26 14:31:57.327546: done, saving took 1.02 seconds
2022-05-26 14:31:57.342364: This epoch took 114.363249 s

2022-05-26 14:31:57.345143: 
epoch:  12
2022-05-26 14:33:30.151571: train loss : -0.5634
2022-05-26 14:33:46.030555: validation loss: -0.6004
2022-05-26 14:33:46.034663: Average global foreground Dice: [0.6848]
2022-05-26 14:33:46.037776: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:33:46.477047: lr: 0.009766
2022-05-26 14:33:46.510506: saving checkpoint...
2022-05-26 14:33:47.515128: done, saving took 1.03 seconds
2022-05-26 14:33:47.529369: This epoch took 110.181896 s

2022-05-26 14:33:47.531833: 
epoch:  13
2022-05-26 14:35:20.892261: train loss : -0.5659
2022-05-26 14:35:30.812517: validation loss: -0.6315
2022-05-26 14:35:30.816043: Average global foreground Dice: [0.7112]
2022-05-26 14:35:30.818622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:35:31.246839: lr: 0.009748
2022-05-26 14:35:31.279591: saving checkpoint...
2022-05-26 14:35:32.284176: done, saving took 1.03 seconds
2022-05-26 14:35:32.301368: This epoch took 104.767257 s

2022-05-26 14:35:32.303866: 
epoch:  14
2022-05-26 14:37:03.421878: train loss : -0.5785
2022-05-26 14:37:12.408641: validation loss: -0.6459
2022-05-26 14:37:12.412101: Average global foreground Dice: [0.7037]
2022-05-26 14:37:12.414368: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:37:12.877416: lr: 0.00973
2022-05-26 14:37:12.924994: saving checkpoint...
2022-05-26 14:37:14.019067: done, saving took 1.14 seconds
2022-05-26 14:37:14.036255: This epoch took 101.729809 s

2022-05-26 14:37:14.038805: 
epoch:  15
2022-05-26 14:38:45.031920: train loss : -0.5838
2022-05-26 14:38:52.134123: validation loss: -0.6390
2022-05-26 14:38:52.137981: Average global foreground Dice: [0.7063]
2022-05-26 14:38:52.140281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:38:52.570015: lr: 0.009712
2022-05-26 14:38:52.615842: saving checkpoint...
2022-05-26 14:38:53.702130: done, saving took 1.13 seconds
2022-05-26 14:38:53.718772: This epoch took 99.677806 s

2022-05-26 14:38:53.721354: 
epoch:  16
2022-05-26 14:40:30.902231: train loss : -0.6125
2022-05-26 14:40:42.614684: validation loss: -0.6432
2022-05-26 14:40:42.618213: Average global foreground Dice: [0.7203]
2022-05-26 14:40:42.620681: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:40:43.044301: lr: 0.009693
2022-05-26 14:40:43.076746: saving checkpoint...
2022-05-26 14:40:44.005234: done, saving took 0.96 seconds
2022-05-26 14:40:44.018297: This epoch took 110.294772 s

2022-05-26 14:40:44.020637: 
epoch:  17
2022-05-26 14:42:18.423624: train loss : -0.6197
2022-05-26 14:42:30.704072: validation loss: -0.6674
2022-05-26 14:42:30.707396: Average global foreground Dice: [0.7328]
2022-05-26 14:42:30.709689: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:42:31.149297: lr: 0.009675
2022-05-26 14:42:31.180231: saving checkpoint...
2022-05-26 14:42:32.133843: done, saving took 0.98 seconds
2022-05-26 14:42:32.149027: This epoch took 108.125902 s

2022-05-26 14:42:32.151270: 
epoch:  18
2022-05-26 14:44:02.528985: train loss : -0.6109
2022-05-26 14:44:09.412529: validation loss: -0.6553
2022-05-26 14:44:09.415907: Average global foreground Dice: [0.7098]
2022-05-26 14:44:09.418445: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:44:09.846754: lr: 0.009657
2022-05-26 14:44:09.877524: saving checkpoint...
2022-05-26 14:44:11.013361: done, saving took 1.16 seconds
2022-05-26 14:44:11.027241: This epoch took 98.873962 s

2022-05-26 14:44:11.029666: 
epoch:  19
2022-05-26 14:45:41.971662: train loss : -0.6324
2022-05-26 14:45:49.895299: validation loss: -0.7182
2022-05-26 14:45:49.898749: Average global foreground Dice: [0.766]
2022-05-26 14:45:49.901076: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:45:50.331239: lr: 0.009639
2022-05-26 14:45:50.361824: saving checkpoint...
2022-05-26 14:45:51.394485: done, saving took 1.06 seconds
2022-05-26 14:45:51.409568: This epoch took 100.377830 s

2022-05-26 14:45:51.412085: 
epoch:  20
2022-05-26 14:47:26.309488: train loss : -0.6164
2022-05-26 14:47:37.818251: validation loss: -0.6745
2022-05-26 14:47:37.821711: Average global foreground Dice: [0.7445]
2022-05-26 14:47:37.823902: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:47:38.274228: lr: 0.009621
2022-05-26 14:47:38.305877: saving checkpoint...
2022-05-26 14:47:39.251807: done, saving took 0.98 seconds
2022-05-26 14:47:39.334904: This epoch took 107.919978 s

2022-05-26 14:47:39.337677: 
epoch:  21
2022-05-26 14:49:09.379054: train loss : -0.6229
2022-05-26 14:49:20.914300: validation loss: -0.7115
2022-05-26 14:49:20.918598: Average global foreground Dice: [0.7674]
2022-05-26 14:49:20.921002: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:49:21.386466: lr: 0.009603
2022-05-26 14:49:21.421052: saving checkpoint...
2022-05-26 14:49:22.527249: done, saving took 1.14 seconds
2022-05-26 14:49:22.542930: This epoch took 103.202664 s

2022-05-26 14:49:22.545365: 
epoch:  22
2022-05-26 14:50:53.136772: train loss : -0.6195
2022-05-26 14:50:59.908237: validation loss: -0.6486
2022-05-26 14:50:59.911503: Average global foreground Dice: [0.7137]
2022-05-26 14:50:59.913548: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:51:00.355832: lr: 0.009585
2022-05-26 14:51:00.386953: saving checkpoint...
2022-05-26 14:51:01.390200: done, saving took 1.03 seconds
2022-05-26 14:51:01.404163: This epoch took 98.856359 s

2022-05-26 14:51:01.406640: 
epoch:  23
2022-05-26 14:52:33.300352: train loss : -0.6166
2022-05-26 14:52:41.827714: validation loss: -0.6873
2022-05-26 14:52:41.831095: Average global foreground Dice: [0.7484]
2022-05-26 14:52:41.833563: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:52:42.267031: lr: 0.009567
2022-05-26 14:52:42.297532: saving checkpoint...
2022-05-26 14:52:43.236799: done, saving took 0.97 seconds
2022-05-26 14:52:43.251437: This epoch took 101.842514 s

2022-05-26 14:52:43.253775: 
epoch:  24
2022-05-26 14:54:13.997193: train loss : -0.6341
2022-05-26 14:54:25.694432: validation loss: -0.6892
2022-05-26 14:54:25.698380: Average global foreground Dice: [0.7452]
2022-05-26 14:54:25.700547: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:54:26.139958: lr: 0.009549
2022-05-26 14:54:26.170205: saving checkpoint...
2022-05-26 14:54:27.081197: done, saving took 0.94 seconds
2022-05-26 14:54:27.096061: This epoch took 103.840197 s

2022-05-26 14:54:27.098566: 
epoch:  25
2022-05-26 14:55:58.354337: train loss : -0.6403
2022-05-26 14:56:07.763014: validation loss: -0.7176
2022-05-26 14:56:07.768472: Average global foreground Dice: [0.7822]
2022-05-26 14:56:07.770800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:56:08.209623: lr: 0.009531
2022-05-26 14:56:08.241396: saving checkpoint...
2022-05-26 14:56:09.274085: done, saving took 1.06 seconds
2022-05-26 14:56:09.288252: This epoch took 102.187186 s

2022-05-26 14:56:09.290744: 
epoch:  26
2022-05-26 14:57:40.005953: train loss : -0.6535
2022-05-26 14:57:46.810657: validation loss: -0.7127
2022-05-26 14:57:46.813946: Average global foreground Dice: [0.7693]
2022-05-26 14:57:46.815970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:57:47.287234: lr: 0.009513
2022-05-26 14:57:47.320622: saving checkpoint...
2022-05-26 14:57:48.239699: done, saving took 0.95 seconds
2022-05-26 14:57:48.254620: This epoch took 98.961781 s

2022-05-26 14:57:48.256607: 
epoch:  27
2022-05-26 14:59:23.273826: train loss : -0.6451
2022-05-26 14:59:39.746263: validation loss: -0.7029
2022-05-26 14:59:39.750210: Average global foreground Dice: [0.7607]
2022-05-26 14:59:39.752519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 14:59:40.326386: lr: 0.009495
2022-05-26 14:59:40.355515: saving checkpoint...
2022-05-26 14:59:41.328644: done, saving took 1.00 seconds
2022-05-26 14:59:41.342541: This epoch took 113.083937 s

2022-05-26 14:59:41.344935: 
epoch:  28
2022-05-26 15:01:13.846253: train loss : -0.6543
2022-05-26 15:01:25.899053: validation loss: -0.7064
2022-05-26 15:01:25.902538: Average global foreground Dice: [0.7552]
2022-05-26 15:01:25.904820: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:01:26.343565: lr: 0.009476
2022-05-26 15:01:26.375964: saving checkpoint...
2022-05-26 15:01:27.313690: done, saving took 0.97 seconds
2022-05-26 15:01:27.327255: This epoch took 105.979840 s

2022-05-26 15:01:27.329518: 
epoch:  29
2022-05-26 15:02:58.080465: train loss : -0.6585
2022-05-26 15:03:05.112122: validation loss: -0.6586
2022-05-26 15:03:05.115848: Average global foreground Dice: [0.7221]
2022-05-26 15:03:05.118190: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:03:05.551324: lr: 0.009458
2022-05-26 15:03:05.583416: saving checkpoint...
2022-05-26 15:03:06.549452: done, saving took 1.00 seconds
2022-05-26 15:03:06.562831: This epoch took 99.231065 s

2022-05-26 15:03:06.565074: 
epoch:  30
2022-05-26 15:04:42.640588: train loss : -0.6370
2022-05-26 15:04:53.663548: validation loss: -0.7281
2022-05-26 15:04:53.667561: Average global foreground Dice: [0.7857]
2022-05-26 15:04:53.670184: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:04:54.098426: lr: 0.00944
2022-05-26 15:04:54.129078: saving checkpoint...
2022-05-26 15:04:55.068347: done, saving took 0.97 seconds
2022-05-26 15:04:55.081674: This epoch took 108.514221 s

2022-05-26 15:04:55.084057: 
epoch:  31
2022-05-26 15:06:26.740331: train loss : -0.6607
2022-05-26 15:06:38.278080: validation loss: -0.6292
2022-05-26 15:06:38.282274: Average global foreground Dice: [0.7225]
2022-05-26 15:06:38.285045: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:06:38.718872: lr: 0.009422
2022-05-26 15:06:38.721409: This epoch took 103.635229 s

2022-05-26 15:06:38.723477: 
epoch:  32
2022-05-26 15:08:10.113782: train loss : -0.6472
2022-05-26 15:08:17.763805: validation loss: -0.6927
2022-05-26 15:08:17.766965: Average global foreground Dice: [0.7508]
2022-05-26 15:08:17.769133: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:08:18.199768: lr: 0.009404
2022-05-26 15:08:18.234971: saving checkpoint...
2022-05-26 15:08:19.150736: done, saving took 0.95 seconds
2022-05-26 15:08:19.165163: This epoch took 100.439537 s

2022-05-26 15:08:19.167901: 
epoch:  33
2022-05-26 15:09:52.189704: train loss : -0.6457
2022-05-26 15:10:01.386840: validation loss: -0.6953
2022-05-26 15:10:01.391675: Average global foreground Dice: [0.7531]
2022-05-26 15:10:01.400286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:10:01.934690: lr: 0.009386
2022-05-26 15:10:01.980058: saving checkpoint...
2022-05-26 15:10:03.018336: done, saving took 1.08 seconds
2022-05-26 15:10:03.033134: This epoch took 103.863096 s

2022-05-26 15:10:03.035281: 
epoch:  34
2022-05-26 15:11:34.442382: train loss : -0.6767
2022-05-26 15:11:43.460591: validation loss: -0.7259
2022-05-26 15:11:43.464558: Average global foreground Dice: [0.7847]
2022-05-26 15:11:43.467603: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:11:44.041625: lr: 0.009368
2022-05-26 15:11:44.074184: saving checkpoint...
2022-05-26 15:11:45.045154: done, saving took 1.00 seconds
2022-05-26 15:11:45.060639: This epoch took 102.023265 s

2022-05-26 15:11:45.064186: 
epoch:  35
2022-05-26 15:13:15.798388: train loss : -0.6736
2022-05-26 15:13:23.920726: validation loss: -0.7096
2022-05-26 15:13:23.924798: Average global foreground Dice: [0.7772]
2022-05-26 15:13:23.927175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:13:24.369647: lr: 0.00935
2022-05-26 15:13:24.403139: saving checkpoint...
2022-05-26 15:13:25.320548: done, saving took 0.95 seconds
2022-05-26 15:13:25.334108: This epoch took 100.267600 s

2022-05-26 15:13:25.336423: 
epoch:  36
2022-05-26 15:15:03.488999: train loss : -0.6600
2022-05-26 15:15:13.839529: validation loss: -0.6839
2022-05-26 15:15:13.843483: Average global foreground Dice: [0.7483]
2022-05-26 15:15:13.845781: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:15:14.312144: lr: 0.009331
2022-05-26 15:15:14.345412: saving checkpoint...
2022-05-26 15:15:15.369423: done, saving took 1.05 seconds
2022-05-26 15:15:15.382660: This epoch took 110.044158 s

2022-05-26 15:15:15.384832: 
epoch:  37
2022-05-26 15:16:51.238853: train loss : -0.6655
2022-05-26 15:17:05.185427: validation loss: -0.7111
2022-05-26 15:17:05.189667: Average global foreground Dice: [0.7631]
2022-05-26 15:17:05.192203: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:17:05.670126: lr: 0.009313
2022-05-26 15:17:05.728579: saving checkpoint...
2022-05-26 15:17:06.673189: done, saving took 1.00 seconds
2022-05-26 15:17:06.687529: This epoch took 111.300502 s

2022-05-26 15:17:06.689814: 
epoch:  38
2022-05-26 15:18:37.864844: train loss : -0.6693
2022-05-26 15:18:51.279348: validation loss: -0.7009
2022-05-26 15:18:51.285875: Average global foreground Dice: [0.7679]
2022-05-26 15:18:51.289305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:18:51.739615: lr: 0.009295
2022-05-26 15:18:51.761770: saving checkpoint...
2022-05-26 15:18:53.360025: done, saving took 1.62 seconds
2022-05-26 15:18:53.376585: This epoch took 106.684744 s

2022-05-26 15:18:53.379706: 
epoch:  39
2022-05-26 15:20:24.661870: train loss : -0.6839
2022-05-26 15:20:35.659896: validation loss: -0.7176
2022-05-26 15:20:35.662925: Average global foreground Dice: [0.786]
2022-05-26 15:20:35.665316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:20:36.117905: lr: 0.009277
2022-05-26 15:20:36.164937: saving checkpoint...
2022-05-26 15:20:37.202291: done, saving took 1.08 seconds
2022-05-26 15:20:37.215525: This epoch took 103.832938 s

2022-05-26 15:20:37.217837: 
epoch:  40
2022-05-26 15:22:10.742032: train loss : -0.6899
2022-05-26 15:22:20.128048: validation loss: -0.7049
2022-05-26 15:22:20.131463: Average global foreground Dice: [0.7619]
2022-05-26 15:22:20.133693: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:22:20.583973: lr: 0.009259
2022-05-26 15:22:20.623656: saving checkpoint...
2022-05-26 15:22:21.744891: done, saving took 1.16 seconds
2022-05-26 15:22:21.760312: This epoch took 104.540407 s

2022-05-26 15:22:21.762645: 
epoch:  41
2022-05-26 15:23:54.874579: train loss : -0.6852
2022-05-26 15:24:02.757259: validation loss: -0.6999
2022-05-26 15:24:02.786790: Average global foreground Dice: [0.764]
2022-05-26 15:24:02.808298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:24:03.299932: lr: 0.009241
2022-05-26 15:24:03.343352: saving checkpoint...
2022-05-26 15:24:05.485343: done, saving took 2.18 seconds
2022-05-26 15:24:05.499194: This epoch took 103.734147 s

2022-05-26 15:24:05.502295: 
epoch:  42
2022-05-26 15:25:41.869725: train loss : -0.6910
2022-05-26 15:25:51.138731: validation loss: -0.7372
2022-05-26 15:25:51.165779: Average global foreground Dice: [0.7919]
2022-05-26 15:25:51.202590: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:25:52.404715: lr: 0.009223
2022-05-26 15:25:52.520954: saving checkpoint...
2022-05-26 15:25:53.728821: done, saving took 1.29 seconds
2022-05-26 15:25:53.741953: This epoch took 108.236568 s

2022-05-26 15:25:53.744214: 
epoch:  43
2022-05-26 15:27:25.643474: train loss : -0.6758
2022-05-26 15:27:35.120513: validation loss: -0.6850
2022-05-26 15:27:35.147707: Average global foreground Dice: [0.7493]
2022-05-26 15:27:35.175323: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:27:35.663888: lr: 0.009204
2022-05-26 15:27:35.666332: This epoch took 101.919912 s

2022-05-26 15:27:35.668473: 
epoch:  44
2022-05-26 15:29:08.224566: train loss : -0.6880
2022-05-26 15:29:15.325496: validation loss: -0.7132
2022-05-26 15:29:15.349831: Average global foreground Dice: [0.7835]
2022-05-26 15:29:15.370298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:29:16.013612: lr: 0.009186
2022-05-26 15:29:16.072512: saving checkpoint...
2022-05-26 15:29:17.163430: done, saving took 1.12 seconds
2022-05-26 15:29:17.229295: This epoch took 101.558421 s

2022-05-26 15:29:17.249299: 
epoch:  45
2022-05-26 15:30:55.118123: train loss : -0.6875
2022-05-26 15:31:09.667693: validation loss: -0.7442
2022-05-26 15:31:09.671258: Average global foreground Dice: [0.7933]
2022-05-26 15:31:09.673626: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:31:10.139595: lr: 0.009168
2022-05-26 15:31:10.175199: saving checkpoint...
2022-05-26 15:31:11.440431: done, saving took 1.30 seconds
2022-05-26 15:31:11.454513: This epoch took 114.187175 s

2022-05-26 15:31:11.457353: 
epoch:  46
2022-05-26 15:32:40.814858: train loss : -0.6918
2022-05-26 15:32:50.687489: validation loss: -0.7226
2022-05-26 15:32:50.691798: Average global foreground Dice: [0.7778]
2022-05-26 15:32:50.694699: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:32:51.151827: lr: 0.00915
2022-05-26 15:32:51.218060: saving checkpoint...
2022-05-26 15:32:52.304720: done, saving took 1.15 seconds
2022-05-26 15:32:52.320393: This epoch took 100.860394 s

2022-05-26 15:32:52.322805: 
epoch:  47
2022-05-26 15:34:23.017956: train loss : -0.7053
2022-05-26 15:34:33.341140: validation loss: -0.6904
2022-05-26 15:34:33.344205: Average global foreground Dice: [0.7581]
2022-05-26 15:34:33.346560: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:34:33.786368: lr: 0.009132
2022-05-26 15:34:33.789424: This epoch took 101.464469 s

2022-05-26 15:34:33.792579: 
epoch:  48
2022-05-26 15:36:12.218801: train loss : -0.6923
2022-05-26 15:36:22.185769: validation loss: -0.7134
2022-05-26 15:36:22.188833: Average global foreground Dice: [0.7615]
2022-05-26 15:36:22.191156: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:36:22.646585: lr: 0.009114
2022-05-26 15:36:22.649679: This epoch took 108.854781 s

2022-05-26 15:36:22.651959: 
epoch:  49
2022-05-26 15:37:56.593942: train loss : -0.6969
2022-05-26 15:38:06.462013: validation loss: -0.7158
2022-05-26 15:38:06.480710: Average global foreground Dice: [0.7796]
2022-05-26 15:38:06.497302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:38:07.062567: lr: 0.009095
2022-05-26 15:38:07.065384: saving scheduled checkpoint file...
2022-05-26 15:38:07.096104: saving checkpoint...
2022-05-26 15:38:08.048262: done, saving took 0.98 seconds
2022-05-26 15:38:08.064341: done
2022-05-26 15:38:08.096029: saving checkpoint...
2022-05-26 15:38:09.111148: done, saving took 1.04 seconds
2022-05-26 15:38:09.125299: This epoch took 106.471148 s

2022-05-26 15:38:09.127706: 
epoch:  50
2022-05-26 15:39:39.371444: train loss : -0.6890
2022-05-26 15:39:47.431113: validation loss: -0.7236
2022-05-26 15:39:47.435035: Average global foreground Dice: [0.7844]
2022-05-26 15:39:47.437805: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:39:47.909464: lr: 0.009077
2022-05-26 15:39:47.932343: saving checkpoint...
2022-05-26 15:39:48.900528: done, saving took 0.99 seconds
2022-05-26 15:39:48.914451: This epoch took 99.784357 s

2022-05-26 15:39:48.917418: 
epoch:  51
2022-05-26 15:41:20.716757: train loss : -0.6866
2022-05-26 15:41:30.897174: validation loss: -0.7029
2022-05-26 15:41:30.900303: Average global foreground Dice: [0.771]
2022-05-26 15:41:30.905698: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:41:31.373449: lr: 0.009059
2022-05-26 15:41:31.435573: saving checkpoint...
2022-05-26 15:41:32.527926: done, saving took 1.15 seconds
2022-05-26 15:41:32.542532: This epoch took 103.622502 s

2022-05-26 15:41:32.545162: 
epoch:  52
2022-05-26 15:43:09.760673: train loss : -0.6924
2022-05-26 15:43:19.466274: validation loss: -0.7357
2022-05-26 15:43:19.469777: Average global foreground Dice: [0.8007]
2022-05-26 15:43:19.472135: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:43:19.913961: lr: 0.009041
2022-05-26 15:43:19.949930: saving checkpoint...
2022-05-26 15:43:21.143360: done, saving took 1.23 seconds
2022-05-26 15:43:21.159507: This epoch took 108.611595 s

2022-05-26 15:43:21.162497: 
epoch:  53
2022-05-26 15:44:51.127083: train loss : -0.7160
2022-05-26 15:45:00.674536: validation loss: -0.7090
2022-05-26 15:45:00.681237: Average global foreground Dice: [0.7827]
2022-05-26 15:45:00.684995: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:45:01.135801: lr: 0.009023
2022-05-26 15:45:01.171972: saving checkpoint...
2022-05-26 15:45:02.200097: done, saving took 1.06 seconds
2022-05-26 15:45:02.213770: This epoch took 101.049084 s

2022-05-26 15:45:02.216109: 
epoch:  54
2022-05-26 15:46:35.428572: train loss : -0.7025
2022-05-26 15:46:47.023505: validation loss: -0.7167
2022-05-26 15:46:47.026393: Average global foreground Dice: [0.7912]
2022-05-26 15:46:47.029377: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:46:47.512083: lr: 0.009004
2022-05-26 15:46:47.544693: saving checkpoint...
2022-05-26 15:46:48.473914: done, saving took 0.96 seconds
2022-05-26 15:46:48.487671: This epoch took 106.269228 s

2022-05-26 15:46:48.490041: 
epoch:  55
2022-05-26 15:48:18.369427: train loss : -0.7077
2022-05-26 15:48:27.782107: validation loss: -0.7252
2022-05-26 15:48:27.785341: Average global foreground Dice: [0.7873]
2022-05-26 15:48:27.787505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:48:28.224433: lr: 0.008986
2022-05-26 15:48:28.257893: saving checkpoint...
2022-05-26 15:48:29.247342: done, saving took 1.02 seconds
2022-05-26 15:48:29.261279: This epoch took 100.769223 s

2022-05-26 15:48:29.263429: 
epoch:  56
2022-05-26 15:50:02.625356: train loss : -0.7055
2022-05-26 15:50:11.976967: validation loss: -0.7071
2022-05-26 15:50:11.980329: Average global foreground Dice: [0.7825]
2022-05-26 15:50:11.982612: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:50:12.424072: lr: 0.008968
2022-05-26 15:50:12.459063: saving checkpoint...
2022-05-26 15:50:13.621501: done, saving took 1.19 seconds
2022-05-26 15:50:13.634224: This epoch took 104.368768 s

2022-05-26 15:50:13.636806: 
epoch:  57
2022-05-26 15:51:45.492707: train loss : -0.6844
2022-05-26 15:51:54.469161: validation loss: -0.7053
2022-05-26 15:51:54.472749: Average global foreground Dice: [0.7794]
2022-05-26 15:51:54.475277: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:51:54.944690: lr: 0.00895
2022-05-26 15:51:54.997778: saving checkpoint...
2022-05-26 15:51:56.323334: done, saving took 1.36 seconds
2022-05-26 15:51:56.373295: This epoch took 102.733810 s

2022-05-26 15:51:56.393966: 
epoch:  58
2022-05-26 15:53:33.873848: train loss : -0.6921
2022-05-26 15:53:45.209175: validation loss: -0.6859
2022-05-26 15:53:45.212811: Average global foreground Dice: [0.7626]
2022-05-26 15:53:45.215010: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:53:45.664088: lr: 0.008931
2022-05-26 15:53:45.667252: This epoch took 109.253330 s

2022-05-26 15:53:45.669456: 
epoch:  59
2022-05-26 15:55:16.696087: train loss : -0.7116
2022-05-26 15:55:25.030626: validation loss: -0.7425
2022-05-26 15:55:25.044762: Average global foreground Dice: [0.8018]
2022-05-26 15:55:25.054216: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:55:25.499238: lr: 0.008913
2022-05-26 15:55:25.539155: saving checkpoint...
2022-05-26 15:55:26.649621: done, saving took 1.15 seconds
2022-05-26 15:55:26.664187: This epoch took 100.992252 s

2022-05-26 15:55:26.666612: 
epoch:  60
2022-05-26 15:56:58.983861: train loss : -0.7153
2022-05-26 15:57:07.325951: validation loss: -0.7265
2022-05-26 15:57:07.329043: Average global foreground Dice: [0.7943]
2022-05-26 15:57:07.331445: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:57:07.820323: lr: 0.008895
2022-05-26 15:57:07.852063: saving checkpoint...
2022-05-26 15:57:08.864769: done, saving took 1.04 seconds
2022-05-26 15:57:08.891269: This epoch took 102.221475 s

2022-05-26 15:57:08.909351: 
epoch:  61
2022-05-26 15:58:42.647796: train loss : -0.7174
2022-05-26 15:58:52.118631: validation loss: -0.7225
2022-05-26 15:58:52.154376: Average global foreground Dice: [0.7964]
2022-05-26 15:58:52.168311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 15:58:52.624205: lr: 0.008877
2022-05-26 15:58:52.657768: saving checkpoint...
2022-05-26 15:58:53.661608: done, saving took 1.03 seconds
2022-05-26 15:58:53.675961: This epoch took 104.759422 s

2022-05-26 15:58:53.678389: 
epoch:  62
2022-05-26 16:00:24.769249: train loss : -0.7080
2022-05-26 16:00:34.737072: validation loss: -0.7131
2022-05-26 16:00:34.740391: Average global foreground Dice: [0.7905]
2022-05-26 16:00:34.742747: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:00:35.248844: lr: 0.008859
2022-05-26 16:00:35.280212: saving checkpoint...
2022-05-26 16:00:36.470329: done, saving took 1.22 seconds
2022-05-26 16:00:36.538486: This epoch took 102.857839 s

2022-05-26 16:00:36.545011: 
epoch:  63
2022-05-26 16:02:07.079952: train loss : -0.7139
2022-05-26 16:02:16.017943: validation loss: -0.7385
2022-05-26 16:02:16.021413: Average global foreground Dice: [0.7944]
2022-05-26 16:02:16.023488: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:02:16.489685: lr: 0.00884
2022-05-26 16:02:16.525518: saving checkpoint...
2022-05-26 16:02:17.510393: done, saving took 1.02 seconds
2022-05-26 16:02:17.526350: This epoch took 100.965054 s

2022-05-26 16:02:17.529887: 
epoch:  64
2022-05-26 16:03:47.727617: train loss : -0.7305
2022-05-26 16:03:56.600248: validation loss: -0.7461
2022-05-26 16:03:56.603553: Average global foreground Dice: [0.7995]
2022-05-26 16:03:56.605848: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:03:57.037112: lr: 0.008822
2022-05-26 16:03:57.066084: saving checkpoint...
2022-05-26 16:03:58.065778: done, saving took 1.03 seconds
2022-05-26 16:03:58.080640: This epoch took 100.548606 s

2022-05-26 16:03:58.082996: 
epoch:  65
2022-05-26 16:05:28.786546: train loss : -0.7020
2022-05-26 16:05:38.673567: validation loss: -0.7102
2022-05-26 16:05:38.679107: Average global foreground Dice: [0.7777]
2022-05-26 16:05:38.682335: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:05:39.127721: lr: 0.008804
2022-05-26 16:05:39.129992: This epoch took 101.044544 s

2022-05-26 16:05:39.131919: 
epoch:  66
2022-05-26 16:07:13.768249: train loss : -0.7028
2022-05-26 16:07:23.580974: validation loss: -0.7302
2022-05-26 16:07:23.584056: Average global foreground Dice: [0.7841]
2022-05-26 16:07:23.586254: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:07:24.027368: lr: 0.008785
2022-05-26 16:07:24.031696: This epoch took 104.897803 s

2022-05-26 16:07:24.034036: 
epoch:  67
2022-05-26 16:08:54.355368: train loss : -0.7161
2022-05-26 16:09:01.267335: validation loss: -0.7380
2022-05-26 16:09:01.270180: Average global foreground Dice: [0.7868]
2022-05-26 16:09:01.272473: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:09:01.875411: lr: 0.008767
2022-05-26 16:09:01.877930: This epoch took 97.841170 s

2022-05-26 16:09:01.880159: 
epoch:  68
2022-05-26 16:10:35.430478: train loss : -0.7006
2022-05-26 16:10:45.367208: validation loss: -0.6908
2022-05-26 16:10:45.380702: Average global foreground Dice: [0.7629]
2022-05-26 16:10:45.388412: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:10:45.857859: lr: 0.008749
2022-05-26 16:10:45.863315: This epoch took 103.980384 s

2022-05-26 16:10:45.880216: 
epoch:  69
2022-05-26 16:12:20.898265: train loss : -0.6949
2022-05-26 16:12:29.801867: validation loss: -0.7076
2022-05-26 16:12:29.805121: Average global foreground Dice: [0.7758]
2022-05-26 16:12:29.807481: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:12:30.246991: lr: 0.008731
2022-05-26 16:12:30.249364: This epoch took 104.339365 s

2022-05-26 16:12:30.251636: 
epoch:  70
2022-05-26 16:14:03.589236: train loss : -0.6947
2022-05-26 16:14:10.934048: validation loss: -0.7087
2022-05-26 16:14:10.964997: Average global foreground Dice: [0.7679]
2022-05-26 16:14:10.967059: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:14:11.422236: lr: 0.008712
2022-05-26 16:14:11.424882: This epoch took 101.170893 s

2022-05-26 16:14:11.427086: 
epoch:  71
2022-05-26 16:15:41.801945: train loss : -0.6859
2022-05-26 16:15:49.253858: validation loss: -0.7117
2022-05-26 16:15:49.257588: Average global foreground Dice: [0.7831]
2022-05-26 16:15:49.260200: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:15:49.706413: lr: 0.008694
2022-05-26 16:15:49.709309: This epoch took 98.279840 s

2022-05-26 16:15:49.712135: 
epoch:  72
2022-05-26 16:17:20.230633: train loss : -0.7123
2022-05-26 16:17:30.393645: validation loss: -0.7286
2022-05-26 16:17:30.397837: Average global foreground Dice: [0.7867]
2022-05-26 16:17:30.399986: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:17:30.834740: lr: 0.008676
2022-05-26 16:17:30.837129: This epoch took 101.122315 s

2022-05-26 16:17:30.839178: 
epoch:  73
2022-05-26 16:19:05.512260: train loss : -0.7131
2022-05-26 16:19:19.932356: validation loss: -0.7265
2022-05-26 16:19:19.935735: Average global foreground Dice: [0.791]
2022-05-26 16:19:19.938166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:19:20.378846: lr: 0.008658
2022-05-26 16:19:20.382162: This epoch took 109.540734 s

2022-05-26 16:19:20.384920: 
epoch:  74
2022-05-26 16:20:58.665591: train loss : -0.7317
2022-05-26 16:21:09.870918: validation loss: -0.7677
2022-05-26 16:21:09.875011: Average global foreground Dice: [0.8031]
2022-05-26 16:21:09.877880: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:21:10.330503: lr: 0.008639
2022-05-26 16:21:10.333003: This epoch took 109.945397 s

2022-05-26 16:21:10.335228: 
epoch:  75
2022-05-26 16:22:40.365902: train loss : -0.7261
2022-05-26 16:22:48.743763: validation loss: -0.7262
2022-05-26 16:22:48.748089: Average global foreground Dice: [0.7804]
2022-05-26 16:22:48.750517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:22:49.234718: lr: 0.008621
2022-05-26 16:22:49.237717: This epoch took 98.899946 s

2022-05-26 16:22:49.239876: 
epoch:  76
2022-05-26 16:24:19.027812: train loss : -0.7347
2022-05-26 16:24:30.626016: validation loss: -0.7222
2022-05-26 16:24:30.630095: Average global foreground Dice: [0.7878]
2022-05-26 16:24:30.632743: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:24:31.082573: lr: 0.008603
2022-05-26 16:24:31.084865: This epoch took 101.842610 s

2022-05-26 16:24:31.087189: 
epoch:  77
2022-05-26 16:26:13.074823: train loss : -0.7369
2022-05-26 16:26:22.563548: validation loss: -0.7302
2022-05-26 16:26:22.567544: Average global foreground Dice: [0.7996]
2022-05-26 16:26:22.570378: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:26:23.045341: lr: 0.008584
2022-05-26 16:26:23.083433: saving checkpoint...
2022-05-26 16:26:24.711823: done, saving took 1.66 seconds
2022-05-26 16:26:24.727695: This epoch took 113.638407 s

2022-05-26 16:26:24.731094: 
epoch:  78
2022-05-26 16:27:54.833719: train loss : -0.7292
2022-05-26 16:28:06.264312: validation loss: -0.6989
2022-05-26 16:28:06.268193: Average global foreground Dice: [0.7719]
2022-05-26 16:28:06.270594: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:28:06.708701: lr: 0.008566
2022-05-26 16:28:06.711277: This epoch took 101.977699 s

2022-05-26 16:28:06.713469: 
epoch:  79
2022-05-26 16:29:39.695740: train loss : -0.7258
2022-05-26 16:29:48.607208: validation loss: -0.7195
2022-05-26 16:29:48.616949: Average global foreground Dice: [0.7732]
2022-05-26 16:29:48.620345: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:29:49.105398: lr: 0.008548
2022-05-26 16:29:49.107728: This epoch took 102.391925 s

2022-05-26 16:29:49.109923: 
epoch:  80
2022-05-26 16:31:21.488385: train loss : -0.7253
2022-05-26 16:31:34.569675: validation loss: -0.7461
2022-05-26 16:31:34.573919: Average global foreground Dice: [0.8114]
2022-05-26 16:31:34.579036: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:31:35.039977: lr: 0.008529
2022-05-26 16:31:35.070520: saving checkpoint...
2022-05-26 16:31:36.637585: done, saving took 1.59 seconds
2022-05-26 16:31:36.653357: This epoch took 107.541130 s

2022-05-26 16:31:36.656777: 
epoch:  81
2022-05-26 16:33:10.258504: train loss : -0.7287
2022-05-26 16:33:24.646038: validation loss: -0.7193
2022-05-26 16:33:24.650162: Average global foreground Dice: [0.7889]
2022-05-26 16:33:24.654007: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:33:25.101412: lr: 0.008511
2022-05-26 16:33:25.133058: saving checkpoint...
2022-05-26 16:33:26.489453: done, saving took 1.39 seconds
2022-05-26 16:33:26.507404: This epoch took 109.847102 s

2022-05-26 16:33:26.510061: 
epoch:  82
2022-05-26 16:34:58.425318: train loss : -0.7150
2022-05-26 16:35:09.861752: validation loss: -0.7290
2022-05-26 16:35:09.865544: Average global foreground Dice: [0.794]
2022-05-26 16:35:09.868167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:35:10.309277: lr: 0.008493
2022-05-26 16:35:10.343423: saving checkpoint...
2022-05-26 16:35:11.686326: done, saving took 1.37 seconds
2022-05-26 16:35:11.700466: This epoch took 105.187513 s

2022-05-26 16:35:11.702974: 
epoch:  83
2022-05-26 16:36:46.797298: train loss : -0.7288
2022-05-26 16:36:57.097076: validation loss: -0.7163
2022-05-26 16:36:57.100891: Average global foreground Dice: [0.7808]
2022-05-26 16:36:57.103324: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:36:57.574913: lr: 0.008474
2022-05-26 16:36:57.577231: This epoch took 105.871757 s

2022-05-26 16:36:57.579625: 
epoch:  84
2022-05-26 16:38:27.646645: train loss : -0.7069
2022-05-26 16:38:34.366545: validation loss: -0.7406
2022-05-26 16:38:34.370768: Average global foreground Dice: [0.8037]
2022-05-26 16:38:34.373137: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:38:34.822370: lr: 0.008456
2022-05-26 16:38:34.882032: saving checkpoint...
2022-05-26 16:38:36.409565: done, saving took 1.58 seconds
2022-05-26 16:38:36.431185: This epoch took 98.849182 s

2022-05-26 16:38:36.433589: 
epoch:  85
2022-05-26 16:40:07.448368: train loss : -0.7313
2022-05-26 16:40:18.071996: validation loss: -0.7593
2022-05-26 16:40:18.075685: Average global foreground Dice: [0.8012]
2022-05-26 16:40:18.077970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:40:18.560866: lr: 0.008438
2022-05-26 16:40:18.608209: saving checkpoint...
2022-05-26 16:40:19.573111: done, saving took 1.01 seconds
2022-05-26 16:40:19.588319: This epoch took 103.152318 s

2022-05-26 16:40:19.590587: 
epoch:  86
2022-05-26 16:41:50.029402: train loss : -0.7246
2022-05-26 16:41:58.157413: validation loss: -0.7380
2022-05-26 16:41:58.160297: Average global foreground Dice: [0.8107]
2022-05-26 16:41:58.166642: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:41:58.617812: lr: 0.008419
2022-05-26 16:41:58.667989: saving checkpoint...
2022-05-26 16:41:59.745403: done, saving took 1.13 seconds
2022-05-26 16:41:59.758922: This epoch took 100.166032 s

2022-05-26 16:41:59.761221: 
epoch:  87
2022-05-26 16:43:35.548626: train loss : -0.7271
2022-05-26 16:43:45.365533: validation loss: -0.7545
2022-05-26 16:43:45.368418: Average global foreground Dice: [0.8027]
2022-05-26 16:43:45.370709: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:43:45.807365: lr: 0.008401
2022-05-26 16:43:45.842868: saving checkpoint...
2022-05-26 16:43:46.837345: done, saving took 1.03 seconds
2022-05-26 16:43:46.851798: This epoch took 107.088490 s

2022-05-26 16:43:46.854121: 
epoch:  88
2022-05-26 16:45:24.375597: train loss : -0.7325
2022-05-26 16:45:33.215719: validation loss: -0.7596
2022-05-26 16:45:33.245606: Average global foreground Dice: [0.8042]
2022-05-26 16:45:33.262416: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:45:33.957134: lr: 0.008383
2022-05-26 16:45:34.013153: saving checkpoint...
2022-05-26 16:45:35.211348: done, saving took 1.24 seconds
2022-05-26 16:45:35.273939: This epoch took 108.417794 s

2022-05-26 16:45:35.285727: 
epoch:  89
2022-05-26 16:47:07.538431: train loss : -0.7316
2022-05-26 16:47:15.099272: validation loss: -0.7183
2022-05-26 16:47:15.105951: Average global foreground Dice: [0.7805]
2022-05-26 16:47:15.109278: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:47:15.631336: lr: 0.008364
2022-05-26 16:47:15.633902: This epoch took 100.343470 s

2022-05-26 16:47:15.653284: 
epoch:  90
2022-05-26 16:48:47.980684: train loss : -0.7289
2022-05-26 16:48:57.393797: validation loss: -0.7229
2022-05-26 16:48:57.396999: Average global foreground Dice: [0.787]
2022-05-26 16:48:57.399593: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:48:57.829931: lr: 0.008346
2022-05-26 16:48:57.832101: This epoch took 102.161544 s

2022-05-26 16:48:57.834114: 
epoch:  91
2022-05-26 16:50:29.411436: train loss : -0.7331
2022-05-26 16:50:38.517063: validation loss: -0.7427
2022-05-26 16:50:38.520413: Average global foreground Dice: [0.7902]
2022-05-26 16:50:38.522670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:50:38.976871: lr: 0.008328
2022-05-26 16:50:38.979785: This epoch took 101.143734 s

2022-05-26 16:50:38.982544: 
epoch:  92
2022-05-26 16:52:15.539048: train loss : -0.7338
2022-05-26 16:52:24.714854: validation loss: -0.7649
2022-05-26 16:52:24.737158: Average global foreground Dice: [0.8143]
2022-05-26 16:52:24.762414: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:52:25.267902: lr: 0.008309
2022-05-26 16:52:25.313074: saving checkpoint...
2022-05-26 16:52:26.242704: done, saving took 0.97 seconds
2022-05-26 16:52:26.257904: This epoch took 107.272818 s

2022-05-26 16:52:26.260022: 
epoch:  93
2022-05-26 16:54:02.339958: train loss : -0.7377
2022-05-26 16:54:11.685648: validation loss: -0.7458
2022-05-26 16:54:11.693904: Average global foreground Dice: [0.8026]
2022-05-26 16:54:11.700817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:54:12.477127: lr: 0.008291
2022-05-26 16:54:12.510053: saving checkpoint...
2022-05-26 16:54:13.522458: done, saving took 1.04 seconds
2022-05-26 16:54:13.535849: This epoch took 107.273848 s

2022-05-26 16:54:13.538038: 
epoch:  94
2022-05-26 16:55:49.248735: train loss : -0.7411
2022-05-26 16:55:58.811681: validation loss: -0.7438
2022-05-26 16:55:58.814698: Average global foreground Dice: [0.7924]
2022-05-26 16:55:58.817039: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:55:59.245698: lr: 0.008272
2022-05-26 16:55:59.248077: This epoch took 105.707898 s

2022-05-26 16:55:59.250164: 
epoch:  95
2022-05-26 16:57:35.838612: train loss : -0.7403
2022-05-26 16:57:44.912357: validation loss: -0.7388
2022-05-26 16:57:44.916631: Average global foreground Dice: [0.8012]
2022-05-26 16:57:44.918976: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:57:45.401966: lr: 0.008254
2022-05-26 16:57:45.437105: saving checkpoint...
2022-05-26 16:57:46.463772: done, saving took 1.06 seconds
2022-05-26 16:57:46.477938: This epoch took 107.225624 s

2022-05-26 16:57:46.480203: 
epoch:  96
2022-05-26 16:59:23.508158: train loss : -0.7187
2022-05-26 16:59:32.015268: validation loss: -0.7205
2022-05-26 16:59:32.041421: Average global foreground Dice: [0.7855]
2022-05-26 16:59:32.058918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 16:59:32.625324: lr: 0.008236
2022-05-26 16:59:32.628161: This epoch took 106.145942 s

2022-05-26 16:59:32.630736: 
epoch:  97
2022-05-26 17:01:04.310312: train loss : -0.7436
2022-05-26 17:01:12.327083: validation loss: -0.7389
2022-05-26 17:01:12.332108: Average global foreground Dice: [0.7968]
2022-05-26 17:01:12.334362: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:01:12.793548: lr: 0.008217
2022-05-26 17:01:12.796266: This epoch took 100.163010 s

2022-05-26 17:01:12.798707: 
epoch:  98
2022-05-26 17:02:46.258217: train loss : -0.7402
2022-05-26 17:02:56.933120: validation loss: -0.7151
2022-05-26 17:02:56.938620: Average global foreground Dice: [0.7923]
2022-05-26 17:02:56.946683: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:02:57.404913: lr: 0.008199
2022-05-26 17:02:57.407497: This epoch took 104.606483 s

2022-05-26 17:02:57.409620: 
epoch:  99
2022-05-26 17:04:32.984534: train loss : -0.7322
2022-05-26 17:04:41.376202: validation loss: -0.7692
2022-05-26 17:04:41.380360: Average global foreground Dice: [0.8144]
2022-05-26 17:04:41.382807: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:04:41.828121: lr: 0.008181
2022-05-26 17:04:41.830535: saving scheduled checkpoint file...
2022-05-26 17:04:41.874396: saving checkpoint...
2022-05-26 17:04:43.001347: done, saving took 1.17 seconds
2022-05-26 17:04:43.018965: done
2022-05-26 17:04:43.059672: saving checkpoint...
2022-05-26 17:04:44.182390: done, saving took 1.16 seconds
2022-05-26 17:04:44.196760: This epoch took 106.784925 s

2022-05-26 17:04:44.199079: 
epoch:  100
2022-05-26 17:06:16.117225: train loss : -0.7528
2022-05-26 17:06:26.323134: validation loss: -0.7412
2022-05-26 17:06:26.326207: Average global foreground Dice: [0.8051]
2022-05-26 17:06:26.328740: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:06:26.894279: lr: 0.008162
2022-05-26 17:06:26.927580: saving checkpoint...
2022-05-26 17:06:27.949091: done, saving took 1.05 seconds
2022-05-26 17:06:27.962579: This epoch took 103.761412 s

2022-05-26 17:06:27.965157: 
epoch:  101
2022-05-26 17:08:04.980211: train loss : -0.7295
2022-05-26 17:08:16.789037: validation loss: -0.7123
2022-05-26 17:08:16.793400: Average global foreground Dice: [0.7981]
2022-05-26 17:08:16.796347: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:08:17.282528: lr: 0.008144
2022-05-26 17:08:17.316257: saving checkpoint...
2022-05-26 17:08:18.565645: done, saving took 1.28 seconds
2022-05-26 17:08:18.581324: This epoch took 110.613669 s

2022-05-26 17:08:18.583653: 
epoch:  102
2022-05-26 17:09:56.555508: train loss : -0.7309
2022-05-26 17:10:04.549062: validation loss: -0.7390
2022-05-26 17:10:04.552895: Average global foreground Dice: [0.7925]
2022-05-26 17:10:04.555351: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:10:05.003809: lr: 0.008125
2022-05-26 17:10:05.006641: This epoch took 106.420690 s

2022-05-26 17:10:05.008681: 
epoch:  103
2022-05-26 17:11:35.659632: train loss : -0.7367
2022-05-26 17:11:44.061972: validation loss: -0.7281
2022-05-26 17:11:44.065993: Average global foreground Dice: [0.7974]
2022-05-26 17:11:44.068869: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:11:44.524682: lr: 0.008107
2022-05-26 17:11:44.529997: This epoch took 99.519225 s

2022-05-26 17:11:44.532261: 
epoch:  104
2022-05-26 17:13:15.172133: train loss : -0.7447
2022-05-26 17:13:24.525685: validation loss: -0.7263
2022-05-26 17:13:24.528848: Average global foreground Dice: [0.7775]
2022-05-26 17:13:24.531038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:13:25.005323: lr: 0.008088
2022-05-26 17:13:25.008431: This epoch took 100.474112 s

2022-05-26 17:13:25.011167: 
epoch:  105
2022-05-26 17:14:55.848605: train loss : -0.7321
2022-05-26 17:15:05.458232: validation loss: -0.7261
2022-05-26 17:15:05.485590: Average global foreground Dice: [0.7955]
2022-05-26 17:15:05.492660: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:15:06.168763: lr: 0.00807
2022-05-26 17:15:06.171947: This epoch took 101.158067 s

2022-05-26 17:15:06.174345: 
epoch:  106
2022-05-26 17:16:37.206144: train loss : -0.7315
2022-05-26 17:16:44.795564: validation loss: -0.7450
2022-05-26 17:16:44.800947: Average global foreground Dice: [0.8014]
2022-05-26 17:16:44.803528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:16:45.244323: lr: 0.008052
2022-05-26 17:16:45.246805: This epoch took 99.070194 s

2022-05-26 17:16:45.249066: 
epoch:  107
2022-05-26 17:18:21.615744: train loss : -0.7418
2022-05-26 17:18:29.418134: validation loss: -0.7442
2022-05-26 17:18:29.439745: Average global foreground Dice: [0.8048]
2022-05-26 17:18:29.462294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:18:29.946062: lr: 0.008033
2022-05-26 17:18:29.960051: This epoch took 104.708627 s

2022-05-26 17:18:29.983966: 
epoch:  108
2022-05-26 17:20:05.941350: train loss : -0.7404
2022-05-26 17:20:17.641805: validation loss: -0.7444
2022-05-26 17:20:17.650670: Average global foreground Dice: [0.8082]
2022-05-26 17:20:17.656288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:20:18.118743: lr: 0.008015
2022-05-26 17:20:18.165088: saving checkpoint...
2022-05-26 17:20:19.168694: done, saving took 1.05 seconds
2022-05-26 17:20:19.183390: This epoch took 109.184006 s

2022-05-26 17:20:19.185819: 
epoch:  109
2022-05-26 17:21:50.743278: train loss : -0.7354
2022-05-26 17:21:59.902369: validation loss: -0.7325
2022-05-26 17:21:59.911177: Average global foreground Dice: [0.805]
2022-05-26 17:21:59.917617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:22:00.428619: lr: 0.007996
2022-05-26 17:22:00.476957: saving checkpoint...
2022-05-26 17:22:01.556103: done, saving took 1.13 seconds
2022-05-26 17:22:01.572229: This epoch took 102.384197 s

2022-05-26 17:22:01.575139: 
epoch:  110
2022-05-26 17:23:33.849329: train loss : -0.7455
2022-05-26 17:23:43.241477: validation loss: -0.7367
2022-05-26 17:23:43.245380: Average global foreground Dice: [0.8009]
2022-05-26 17:23:43.247676: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:23:43.725155: lr: 0.007978
2022-05-26 17:23:43.750232: saving checkpoint...
2022-05-26 17:23:44.757152: done, saving took 1.03 seconds
2022-05-26 17:23:44.770783: This epoch took 103.192561 s

2022-05-26 17:23:44.772962: 
epoch:  111
2022-05-26 17:25:16.287711: train loss : -0.7283
2022-05-26 17:25:24.224676: validation loss: -0.7205
2022-05-26 17:25:24.228688: Average global foreground Dice: [0.782]
2022-05-26 17:25:24.230873: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:25:24.689031: lr: 0.007959
2022-05-26 17:25:24.691348: This epoch took 99.916278 s

2022-05-26 17:25:24.693416: 
epoch:  112
2022-05-26 17:26:58.773140: train loss : -0.7470
2022-05-26 17:27:09.361305: validation loss: -0.7634
2022-05-26 17:27:09.372859: Average global foreground Dice: [0.805]
2022-05-26 17:27:09.375191: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:27:09.821487: lr: 0.007941
2022-05-26 17:27:09.823733: This epoch took 105.128308 s

2022-05-26 17:27:09.825824: 
epoch:  113
2022-05-26 17:28:42.624928: train loss : -0.7574
2022-05-26 17:28:53.278466: validation loss: -0.7541
2022-05-26 17:28:53.281871: Average global foreground Dice: [0.7922]
2022-05-26 17:28:53.286557: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:28:53.727019: lr: 0.007922
2022-05-26 17:28:53.729667: This epoch took 103.901679 s

2022-05-26 17:28:53.732953: 
epoch:  114
2022-05-26 17:30:24.376578: train loss : -0.7574
2022-05-26 17:30:32.004562: validation loss: -0.7457
2022-05-26 17:30:32.023879: Average global foreground Dice: [0.7994]
2022-05-26 17:30:32.038503: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:30:32.487578: lr: 0.007904
2022-05-26 17:30:32.490031: This epoch took 98.754705 s

2022-05-26 17:30:32.492388: 
epoch:  115
2022-05-26 17:32:05.853077: train loss : -0.7571
2022-05-26 17:32:14.232548: validation loss: -0.7537
2022-05-26 17:32:14.268613: Average global foreground Dice: [0.8056]
2022-05-26 17:32:14.283272: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:32:14.870795: lr: 0.007885
2022-05-26 17:32:14.887322: This epoch took 102.392826 s

2022-05-26 17:32:14.902292: 
epoch:  116
2022-05-26 17:33:50.665018: train loss : -0.7550
2022-05-26 17:33:58.394427: validation loss: -0.7643
2022-05-26 17:33:58.411633: Average global foreground Dice: [0.8068]
2022-05-26 17:33:58.444304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:33:59.129472: lr: 0.007867
2022-05-26 17:33:59.172451: saving checkpoint...
2022-05-26 17:34:00.188805: done, saving took 1.06 seconds
2022-05-26 17:34:00.204400: This epoch took 105.288470 s

2022-05-26 17:34:00.206587: 
epoch:  117
2022-05-26 17:35:37.436297: train loss : -0.7446
2022-05-26 17:35:46.219236: validation loss: -0.7571
2022-05-26 17:35:46.223268: Average global foreground Dice: [0.8164]
2022-05-26 17:35:46.225539: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:35:46.717201: lr: 0.007848
2022-05-26 17:35:46.781754: saving checkpoint...
2022-05-26 17:35:47.878477: done, saving took 1.13 seconds
2022-05-26 17:35:47.910309: This epoch took 107.701514 s

2022-05-26 17:35:47.926257: 
epoch:  118
2022-05-26 17:37:18.716271: train loss : -0.7492
2022-05-26 17:37:26.661918: validation loss: -0.7270
2022-05-26 17:37:26.673621: Average global foreground Dice: [0.7902]
2022-05-26 17:37:26.680338: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:37:27.158075: lr: 0.00783
2022-05-26 17:37:27.166678: This epoch took 99.235665 s

2022-05-26 17:37:27.195547: 
epoch:  119
2022-05-26 17:39:04.047581: train loss : -0.7573
2022-05-26 17:39:13.744844: validation loss: -0.7518
2022-05-26 17:39:13.759465: Average global foreground Dice: [0.8078]
2022-05-26 17:39:13.770622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:39:14.285650: lr: 0.007811
2022-05-26 17:39:14.288279: This epoch took 107.077163 s

2022-05-26 17:39:14.290330: 
epoch:  120
2022-05-26 17:40:48.594057: train loss : -0.7425
2022-05-26 17:40:57.100088: validation loss: -0.6945
2022-05-26 17:40:57.153167: Average global foreground Dice: [0.7928]
2022-05-26 17:40:57.170304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:40:57.991956: lr: 0.007793
2022-05-26 17:40:57.998083: This epoch took 103.705473 s

2022-05-26 17:40:58.004030: 
epoch:  121
2022-05-26 17:42:29.495374: train loss : -0.7501
2022-05-26 17:42:38.051976: validation loss: -0.7485
2022-05-26 17:42:38.055158: Average global foreground Dice: [0.8103]
2022-05-26 17:42:38.057364: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:42:38.540912: lr: 0.007774
2022-05-26 17:42:38.562706: This epoch took 100.556526 s

2022-05-26 17:42:38.568398: 
epoch:  122
2022-05-26 17:44:09.558386: train loss : -0.7586
2022-05-26 17:44:18.728455: validation loss: -0.7481
2022-05-26 17:44:18.761635: Average global foreground Dice: [0.7905]
2022-05-26 17:44:18.784287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:44:19.263330: lr: 0.007756
2022-05-26 17:44:19.265624: This epoch took 100.694732 s

2022-05-26 17:44:19.267558: 
epoch:  123
2022-05-26 17:45:53.503548: train loss : -0.7379
2022-05-26 17:46:05.288186: validation loss: -0.7328
2022-05-26 17:46:05.295265: Average global foreground Dice: [0.7929]
2022-05-26 17:46:05.316307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:46:05.862614: lr: 0.007737
2022-05-26 17:46:05.865124: This epoch took 106.595488 s

2022-05-26 17:46:05.867409: 
epoch:  124
2022-05-26 17:47:38.478459: train loss : -0.7487
2022-05-26 17:47:48.323174: validation loss: -0.7286
2022-05-26 17:47:48.326428: Average global foreground Dice: [0.7934]
2022-05-26 17:47:48.328552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:47:48.802224: lr: 0.007719
2022-05-26 17:47:48.822318: This epoch took 102.952956 s

2022-05-26 17:47:48.824660: 
epoch:  125
2022-05-26 17:49:20.371730: train loss : -0.7249
2022-05-26 17:49:31.072571: validation loss: -0.7578
2022-05-26 17:49:31.076935: Average global foreground Dice: [0.8008]
2022-05-26 17:49:31.079887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:49:31.534188: lr: 0.0077
2022-05-26 17:49:31.536608: This epoch took 102.710033 s

2022-05-26 17:49:31.538832: 
epoch:  126
2022-05-26 17:51:04.859918: train loss : -0.7387
2022-05-26 17:51:12.958514: validation loss: -0.7217
2022-05-26 17:51:12.962200: Average global foreground Dice: [0.7865]
2022-05-26 17:51:12.964563: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:51:13.410975: lr: 0.007682
2022-05-26 17:51:13.413284: This epoch took 101.872006 s

2022-05-26 17:51:13.415310: 
epoch:  127
2022-05-26 17:52:47.191328: train loss : -0.7343
2022-05-26 17:52:57.467883: validation loss: -0.7618
2022-05-26 17:52:57.484805: Average global foreground Dice: [0.8029]
2022-05-26 17:52:57.498346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:52:57.980168: lr: 0.007663
2022-05-26 17:52:57.982639: This epoch took 104.565212 s

2022-05-26 17:52:57.984971: 
epoch:  128
2022-05-26 17:54:38.526368: train loss : -0.7427
2022-05-26 17:54:45.914994: validation loss: -0.7542
2022-05-26 17:54:45.945997: Average global foreground Dice: [0.8146]
2022-05-26 17:54:45.948640: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:54:46.450558: lr: 0.007645
2022-05-26 17:54:46.453989: This epoch took 108.466620 s

2022-05-26 17:54:46.456463: 
epoch:  129
2022-05-26 17:56:33.078543: train loss : -0.7454
2022-05-26 17:56:43.117274: validation loss: -0.7253
2022-05-26 17:56:43.121175: Average global foreground Dice: [0.7942]
2022-05-26 17:56:43.123436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:56:43.592133: lr: 0.007626
2022-05-26 17:56:43.594851: This epoch took 117.136032 s

2022-05-26 17:56:43.596941: 
epoch:  130
2022-05-26 17:58:15.146952: train loss : -0.7317
2022-05-26 17:58:24.608168: validation loss: -0.7601
2022-05-26 17:58:24.625116: Average global foreground Dice: [0.8072]
2022-05-26 17:58:24.649657: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 17:58:25.156271: lr: 0.007608
2022-05-26 17:58:25.158889: This epoch took 101.559774 s

2022-05-26 17:58:25.161033: 
epoch:  131
2022-05-26 17:59:59.160074: train loss : -0.7454
2022-05-26 18:00:11.104058: validation loss: -0.7399
2022-05-26 18:00:11.119022: Average global foreground Dice: [0.7957]
2022-05-26 18:00:11.128289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:00:11.753082: lr: 0.007589
2022-05-26 18:00:11.761988: This epoch took 106.598942 s

2022-05-26 18:00:11.771934: 
epoch:  132
2022-05-26 18:01:50.352849: train loss : -0.7628
2022-05-26 18:01:59.049097: validation loss: -0.7493
2022-05-26 18:01:59.053629: Average global foreground Dice: [0.8149]
2022-05-26 18:01:59.057282: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:01:59.549584: lr: 0.007571
2022-05-26 18:01:59.585374: saving checkpoint...
2022-05-26 18:02:00.575942: done, saving took 1.02 seconds
2022-05-26 18:02:00.589252: This epoch took 108.809968 s

2022-05-26 18:02:00.591517: 
epoch:  133
2022-05-26 18:03:38.883782: train loss : -0.7508
2022-05-26 18:03:47.976581: validation loss: -0.7339
2022-05-26 18:03:47.980010: Average global foreground Dice: [0.7967]
2022-05-26 18:03:47.988637: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:03:48.455494: lr: 0.007552
2022-05-26 18:03:48.474332: This epoch took 107.880810 s

2022-05-26 18:03:48.502322: 
epoch:  134
2022-05-26 18:05:27.488724: train loss : -0.7534
2022-05-26 18:05:34.931569: validation loss: -0.7724
2022-05-26 18:05:34.936535: Average global foreground Dice: [0.8151]
2022-05-26 18:05:34.939028: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:05:35.403672: lr: 0.007533
2022-05-26 18:05:35.443870: saving checkpoint...
2022-05-26 18:05:36.600178: done, saving took 1.19 seconds
2022-05-26 18:05:36.614515: This epoch took 108.101544 s

2022-05-26 18:05:36.616760: 
epoch:  135
2022-05-26 18:07:13.645180: train loss : -0.7554
2022-05-26 18:07:21.799746: validation loss: -0.7400
2022-05-26 18:07:21.802981: Average global foreground Dice: [0.7918]
2022-05-26 18:07:21.805057: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:07:22.433605: lr: 0.007515
2022-05-26 18:07:22.436117: This epoch took 105.816926 s

2022-05-26 18:07:22.438211: 
epoch:  136
2022-05-26 18:08:56.332434: train loss : -0.7508
2022-05-26 18:09:06.387692: validation loss: -0.7244
2022-05-26 18:09:06.390752: Average global foreground Dice: [0.798]
2022-05-26 18:09:06.393015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:09:06.866643: lr: 0.007496
2022-05-26 18:09:06.872453: This epoch took 104.432112 s

2022-05-26 18:09:06.875223: 
epoch:  137
2022-05-26 18:10:48.921811: train loss : -0.7586
2022-05-26 18:10:58.960903: validation loss: -0.7686
2022-05-26 18:10:58.964756: Average global foreground Dice: [0.8128]
2022-05-26 18:10:58.966904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:10:59.420945: lr: 0.007478
2022-05-26 18:10:59.423632: This epoch took 112.545727 s

2022-05-26 18:10:59.425777: 
epoch:  138
2022-05-26 18:12:32.309240: train loss : -0.7540
2022-05-26 18:12:43.119247: validation loss: -0.7730
2022-05-26 18:12:43.130089: Average global foreground Dice: [0.815]
2022-05-26 18:12:43.136415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:12:43.909009: lr: 0.007459
2022-05-26 18:12:43.951229: saving checkpoint...
2022-05-26 18:12:45.016428: done, saving took 1.10 seconds
2022-05-26 18:12:45.035672: This epoch took 105.607689 s

2022-05-26 18:12:45.038225: 
epoch:  139
2022-05-26 18:14:21.816389: train loss : -0.7518
2022-05-26 18:14:31.839909: validation loss: -0.7504
2022-05-26 18:14:31.844549: Average global foreground Dice: [0.7942]
2022-05-26 18:14:31.847015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:14:32.321449: lr: 0.00744
2022-05-26 18:14:32.324067: This epoch took 107.283303 s

2022-05-26 18:14:32.326362: 
epoch:  140
2022-05-26 18:16:04.183124: train loss : -0.7441
2022-05-26 18:16:16.196818: validation loss: -0.7289
2022-05-26 18:16:16.200532: Average global foreground Dice: [0.8035]
2022-05-26 18:16:16.203029: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:16:16.661537: lr: 0.007422
2022-05-26 18:16:16.664217: This epoch took 104.335723 s

2022-05-26 18:16:16.666635: 
epoch:  141
2022-05-26 18:17:50.613920: train loss : -0.7499
2022-05-26 18:18:00.825057: validation loss: -0.7273
2022-05-26 18:18:00.856967: Average global foreground Dice: [0.801]
2022-05-26 18:18:00.882350: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:18:01.494227: lr: 0.007403
2022-05-26 18:18:01.506443: This epoch took 104.837563 s

2022-05-26 18:18:01.529287: 
epoch:  142
2022-05-26 18:19:42.475330: train loss : -0.7391
2022-05-26 18:19:51.532660: validation loss: -0.7587
2022-05-26 18:19:51.541778: Average global foreground Dice: [0.8043]
2022-05-26 18:19:51.548630: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:19:52.016452: lr: 0.007385
2022-05-26 18:19:52.019391: This epoch took 110.480096 s

2022-05-26 18:19:52.022071: 
epoch:  143
2022-05-26 18:21:28.722631: train loss : -0.7665
2022-05-26 18:21:37.663160: validation loss: -0.7775
2022-05-26 18:21:37.668305: Average global foreground Dice: [0.82]
2022-05-26 18:21:37.674138: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:21:38.299910: lr: 0.007366
2022-05-26 18:21:38.336967: saving checkpoint...
2022-05-26 18:21:39.334195: done, saving took 1.03 seconds
2022-05-26 18:21:39.348420: This epoch took 107.323911 s

2022-05-26 18:21:39.350809: 
epoch:  144
2022-05-26 18:23:19.181687: train loss : -0.7371
2022-05-26 18:23:28.283193: validation loss: -0.7485
2022-05-26 18:23:28.289374: Average global foreground Dice: [0.802]
2022-05-26 18:23:28.291542: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:23:28.793491: lr: 0.007347
2022-05-26 18:23:28.796060: This epoch took 109.442932 s

2022-05-26 18:23:28.798178: 
epoch:  145
2022-05-26 18:25:05.488842: train loss : -0.7561
2022-05-26 18:25:14.254129: validation loss: -0.7633
2022-05-26 18:25:14.257418: Average global foreground Dice: [0.825]
2022-05-26 18:25:14.261233: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:25:14.748104: lr: 0.007329
2022-05-26 18:25:14.792467: saving checkpoint...
2022-05-26 18:25:15.846814: done, saving took 1.10 seconds
2022-05-26 18:25:15.861888: This epoch took 107.061400 s

2022-05-26 18:25:15.865275: 
epoch:  146
2022-05-26 18:26:50.212651: train loss : -0.7623
2022-05-26 18:26:58.967455: validation loss: -0.7770
2022-05-26 18:26:58.998983: Average global foreground Dice: [0.8262]
2022-05-26 18:26:59.019470: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:26:59.711198: lr: 0.00731
2022-05-26 18:26:59.825360: saving checkpoint...
2022-05-26 18:27:00.934960: done, saving took 1.21 seconds
2022-05-26 18:27:00.950073: This epoch took 105.082675 s

2022-05-26 18:27:00.952170: 
epoch:  147
2022-05-26 18:28:32.852178: train loss : -0.7571
2022-05-26 18:28:42.193994: validation loss: -0.7354
2022-05-26 18:28:42.203223: Average global foreground Dice: [0.7905]
2022-05-26 18:28:42.205834: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:28:42.689629: lr: 0.007291
2022-05-26 18:28:42.692233: This epoch took 101.737797 s

2022-05-26 18:28:42.694675: 
epoch:  148
2022-05-26 18:30:21.160606: train loss : -0.7508
2022-05-26 18:30:30.139442: validation loss: -0.7446
2022-05-26 18:30:30.142932: Average global foreground Dice: [0.8052]
2022-05-26 18:30:30.145809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:30:30.674561: lr: 0.007273
2022-05-26 18:30:30.676947: This epoch took 107.980095 s

2022-05-26 18:30:30.679359: 
epoch:  149
2022-05-26 18:32:06.845126: train loss : -0.7638
2022-05-26 18:32:15.291365: validation loss: -0.7350
2022-05-26 18:32:15.302296: Average global foreground Dice: [0.8]
2022-05-26 18:32:15.314279: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:32:15.919505: lr: 0.007254
2022-05-26 18:32:15.930329: saving scheduled checkpoint file...
2022-05-26 18:32:15.967570: saving checkpoint...
2022-05-26 18:32:17.100631: done, saving took 1.17 seconds
2022-05-26 18:32:17.114549: done
2022-05-26 18:32:17.117398: This epoch took 106.435358 s

2022-05-26 18:32:17.119375: 
epoch:  150
2022-05-26 18:33:53.527955: train loss : -0.7720
2022-05-26 18:34:01.755479: validation loss: -0.7539
2022-05-26 18:34:01.779687: Average global foreground Dice: [0.8073]
2022-05-26 18:34:01.787405: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:34:02.314159: lr: 0.007236
2022-05-26 18:34:02.340055: This epoch took 105.218700 s

2022-05-26 18:34:02.354041: 
epoch:  151
2022-05-26 18:35:40.642314: train loss : -0.7374
2022-05-26 18:35:50.111735: validation loss: -0.7140
2022-05-26 18:35:50.115001: Average global foreground Dice: [0.7812]
2022-05-26 18:35:50.117361: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:35:50.570465: lr: 0.007217
2022-05-26 18:35:50.573179: This epoch took 108.211844 s

2022-05-26 18:35:50.575469: 
epoch:  152
2022-05-26 18:37:22.204473: train loss : -0.7395
2022-05-26 18:37:31.652329: validation loss: -0.7401
2022-05-26 18:37:31.659294: Average global foreground Dice: [0.8029]
2022-05-26 18:37:31.662297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:37:32.263254: lr: 0.007198
2022-05-26 18:37:32.265858: This epoch took 101.688144 s

2022-05-26 18:37:32.268277: 
epoch:  153
2022-05-26 18:39:08.006286: train loss : -0.7467
2022-05-26 18:39:15.527253: validation loss: -0.7474
2022-05-26 18:39:15.532855: Average global foreground Dice: [0.8121]
2022-05-26 18:39:15.535945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:39:16.015200: lr: 0.00718
2022-05-26 18:39:16.017543: This epoch took 103.746989 s

2022-05-26 18:39:16.019769: 
epoch:  154
2022-05-26 18:40:46.218130: train loss : -0.7683
2022-05-26 18:40:53.384383: validation loss: -0.7514
2022-05-26 18:40:53.388713: Average global foreground Dice: [0.8114]
2022-05-26 18:40:53.390920: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:40:53.850248: lr: 0.007161
2022-05-26 18:40:53.853323: This epoch took 97.831203 s

2022-05-26 18:40:53.855642: 
epoch:  155
2022-05-26 18:42:27.667231: train loss : -0.7648
2022-05-26 18:42:37.689064: validation loss: -0.7153
2022-05-26 18:42:37.692657: Average global foreground Dice: [0.7846]
2022-05-26 18:42:37.695505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:42:38.296472: lr: 0.007142
2022-05-26 18:42:38.312392: This epoch took 104.454513 s

2022-05-26 18:42:38.331293: 
epoch:  156
2022-05-26 18:44:20.150091: train loss : -0.7621
2022-05-26 18:44:28.363080: validation loss: -0.7279
2022-05-26 18:44:28.380430: Average global foreground Dice: [0.8058]
2022-05-26 18:44:28.382906: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:44:28.859607: lr: 0.007123
2022-05-26 18:44:28.879333: This epoch took 110.529043 s

2022-05-26 18:44:28.901423: 
epoch:  157
2022-05-26 18:46:04.595240: train loss : -0.7652
2022-05-26 18:46:15.662948: validation loss: -0.7657
2022-05-26 18:46:15.665940: Average global foreground Dice: [0.8119]
2022-05-26 18:46:15.668031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:46:16.120697: lr: 0.007105
2022-05-26 18:46:16.123647: This epoch took 107.204359 s

2022-05-26 18:46:16.125790: 
epoch:  158
2022-05-26 18:47:51.473862: train loss : -0.7754
2022-05-26 18:48:01.715999: validation loss: -0.7066
2022-05-26 18:48:01.751796: Average global foreground Dice: [0.8083]
2022-05-26 18:48:01.774287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:48:02.464754: lr: 0.007086
2022-05-26 18:48:02.486475: This epoch took 106.358667 s

2022-05-26 18:48:02.505109: 
epoch:  159
2022-05-26 18:49:39.071068: train loss : -0.7603
2022-05-26 18:49:47.739138: validation loss: -0.7670
2022-05-26 18:49:47.744630: Average global foreground Dice: [0.8096]
2022-05-26 18:49:47.748579: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:49:48.293140: lr: 0.007067
2022-05-26 18:49:48.307355: This epoch took 105.799718 s

2022-05-26 18:49:48.310780: 
epoch:  160
2022-05-26 18:51:31.541284: train loss : -0.7662
2022-05-26 18:51:40.803200: validation loss: -0.7478
2022-05-26 18:51:40.810308: Average global foreground Dice: [0.8054]
2022-05-26 18:51:40.812500: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:51:41.386697: lr: 0.007049
2022-05-26 18:51:41.389350: This epoch took 113.075546 s

2022-05-26 18:51:41.391719: 
epoch:  161
2022-05-26 18:53:21.945773: train loss : -0.7670
2022-05-26 18:53:30.540927: validation loss: -0.7312
2022-05-26 18:53:30.545368: Average global foreground Dice: [0.8013]
2022-05-26 18:53:30.547922: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:53:31.009412: lr: 0.00703
2022-05-26 18:53:31.012203: This epoch took 109.618288 s

2022-05-26 18:53:31.014601: 
epoch:  162
2022-05-26 18:55:03.366612: train loss : -0.7588
2022-05-26 18:55:11.707840: validation loss: -0.7552
2022-05-26 18:55:11.711551: Average global foreground Dice: [0.8049]
2022-05-26 18:55:11.713777: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:55:12.302197: lr: 0.007011
2022-05-26 18:55:12.305543: This epoch took 101.288621 s

2022-05-26 18:55:12.309640: 
epoch:  163
2022-05-26 18:56:43.365876: train loss : -0.7611
2022-05-26 18:56:51.876100: validation loss: -0.7627
2022-05-26 18:56:51.879702: Average global foreground Dice: [0.8127]
2022-05-26 18:56:51.881789: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:56:52.326025: lr: 0.006992
2022-05-26 18:56:52.328448: This epoch took 100.013989 s

2022-05-26 18:56:52.330435: 
epoch:  164
2022-05-26 18:58:23.455498: train loss : -0.7590
2022-05-26 18:58:32.931371: validation loss: -0.7440
2022-05-26 18:58:32.935464: Average global foreground Dice: [0.7922]
2022-05-26 18:58:32.938753: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 18:58:33.428748: lr: 0.006974
2022-05-26 18:58:33.431262: This epoch took 101.098679 s

2022-05-26 18:58:33.437543: 
epoch:  165
2022-05-26 19:00:05.242355: train loss : -0.7522
2022-05-26 19:00:14.818787: validation loss: -0.7325
2022-05-26 19:00:14.821738: Average global foreground Dice: [0.7898]
2022-05-26 19:00:14.824232: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:00:15.314329: lr: 0.006955
2022-05-26 19:00:15.316880: This epoch took 101.877130 s

2022-05-26 19:00:15.319207: 
epoch:  166
2022-05-26 19:01:46.971503: train loss : -0.7748
2022-05-26 19:01:54.886554: validation loss: -0.7203
2022-05-26 19:01:54.890355: Average global foreground Dice: [0.7965]
2022-05-26 19:01:54.893035: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:01:55.338705: lr: 0.006936
2022-05-26 19:01:55.341141: This epoch took 100.019701 s

2022-05-26 19:01:55.343225: 
epoch:  167
2022-05-26 19:03:25.417059: train loss : -0.7537
2022-05-26 19:03:31.658141: validation loss: -0.6981
2022-05-26 19:03:31.661653: Average global foreground Dice: [0.7931]
2022-05-26 19:03:31.663893: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:03:32.125299: lr: 0.006918
2022-05-26 19:03:32.127762: This epoch took 96.782405 s

2022-05-26 19:03:32.129899: 
epoch:  168
2022-05-26 19:05:03.803703: train loss : -0.7685
2022-05-26 19:05:14.034153: validation loss: -0.7788
2022-05-26 19:05:14.037280: Average global foreground Dice: [0.8234]
2022-05-26 19:05:14.039522: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:05:14.487736: lr: 0.006899
2022-05-26 19:05:14.490119: This epoch took 102.357982 s

2022-05-26 19:05:14.492188: 
epoch:  169
2022-05-26 19:06:46.183337: train loss : -0.7623
2022-05-26 19:06:55.690125: validation loss: -0.7553
2022-05-26 19:06:55.695077: Average global foreground Dice: [0.8101]
2022-05-26 19:06:55.712296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:06:56.504526: lr: 0.00688
2022-05-26 19:06:56.537330: This epoch took 102.042969 s

2022-05-26 19:06:56.568316: 
epoch:  170
2022-05-26 19:08:29.751894: train loss : -0.7644
2022-05-26 19:08:40.302894: validation loss: -0.7727
2022-05-26 19:08:40.332111: Average global foreground Dice: [0.8229]
2022-05-26 19:08:40.415342: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:08:40.989514: lr: 0.006861
2022-05-26 19:08:40.992102: This epoch took 104.405813 s

2022-05-26 19:08:40.994580: 
epoch:  171
2022-05-26 19:10:13.945080: train loss : -0.7713
2022-05-26 19:10:24.445676: validation loss: -0.7377
2022-05-26 19:10:24.449102: Average global foreground Dice: [0.8013]
2022-05-26 19:10:24.451321: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:10:24.902412: lr: 0.006842
2022-05-26 19:10:24.904838: This epoch took 103.907995 s

2022-05-26 19:10:24.907068: 
epoch:  172
2022-05-26 19:11:58.667759: train loss : -0.7479
2022-05-26 19:12:08.650475: validation loss: -0.7285
2022-05-26 19:12:08.695708: Average global foreground Dice: [0.789]
2022-05-26 19:12:08.720309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:12:09.284787: lr: 0.006824
2022-05-26 19:12:09.311355: This epoch took 104.402296 s

2022-05-26 19:12:09.340744: 
epoch:  173
2022-05-26 19:13:39.911483: train loss : -0.7551
2022-05-26 19:13:48.410136: validation loss: -0.7612
2022-05-26 19:13:48.413373: Average global foreground Dice: [0.8175]
2022-05-26 19:13:48.415437: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:13:48.871300: lr: 0.006805
2022-05-26 19:13:48.877166: This epoch took 99.524798 s

2022-05-26 19:13:48.880122: 
epoch:  174
2022-05-26 19:15:20.049664: train loss : -0.7647
2022-05-26 19:15:26.863737: validation loss: -0.7332
2022-05-26 19:15:26.867007: Average global foreground Dice: [0.7896]
2022-05-26 19:15:26.869230: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:15:27.309439: lr: 0.006786
2022-05-26 19:15:27.312153: This epoch took 98.429838 s

2022-05-26 19:15:27.314110: 
epoch:  175
2022-05-26 19:16:58.170058: train loss : -0.7660
2022-05-26 19:17:07.900189: validation loss: -0.7756
2022-05-26 19:17:07.903541: Average global foreground Dice: [0.8189]
2022-05-26 19:17:07.906673: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:17:08.348215: lr: 0.006767
2022-05-26 19:17:08.350597: This epoch took 101.034335 s

2022-05-26 19:17:08.352825: 
epoch:  176
2022-05-26 19:18:39.319498: train loss : -0.7800
2022-05-26 19:18:50.035234: validation loss: -0.7827
2022-05-26 19:18:50.038270: Average global foreground Dice: [0.8192]
2022-05-26 19:18:50.044737: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:18:50.515334: lr: 0.006749
2022-05-26 19:18:50.517629: This epoch took 102.162795 s

2022-05-26 19:18:50.520265: 
epoch:  177
2022-05-26 19:20:20.598890: train loss : -0.7754
2022-05-26 19:20:29.343867: validation loss: -0.7520
2022-05-26 19:20:29.347767: Average global foreground Dice: [0.81]
2022-05-26 19:20:29.350015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:20:29.800184: lr: 0.00673
2022-05-26 19:20:29.802826: This epoch took 99.280379 s

2022-05-26 19:20:29.804941: 
epoch:  178
2022-05-26 19:22:03.644310: train loss : -0.7763
2022-05-26 19:22:12.947492: validation loss: -0.7592
2022-05-26 19:22:12.972784: Average global foreground Dice: [0.81]
2022-05-26 19:22:13.000314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:22:13.752047: lr: 0.006711
2022-05-26 19:22:13.754416: This epoch took 103.947382 s

2022-05-26 19:22:13.761962: 
epoch:  179
2022-05-26 19:23:46.695020: train loss : -0.7702
2022-05-26 19:23:55.057466: validation loss: -0.7173
2022-05-26 19:23:55.085688: Average global foreground Dice: [0.8128]
2022-05-26 19:23:55.114339: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:23:55.735216: lr: 0.006692
2022-05-26 19:23:55.738223: This epoch took 101.973645 s

2022-05-26 19:23:55.742527: 
epoch:  180
2022-05-26 19:25:27.501788: train loss : -0.7762
2022-05-26 19:25:35.655834: validation loss: -0.7708
2022-05-26 19:25:35.658962: Average global foreground Dice: [0.8124]
2022-05-26 19:25:35.675279: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:25:36.156476: lr: 0.006673
2022-05-26 19:25:36.185763: saving checkpoint...
2022-05-26 19:25:37.111465: done, saving took 0.95 seconds
2022-05-26 19:25:37.125683: This epoch took 101.380107 s

2022-05-26 19:25:37.127896: 
epoch:  181
2022-05-26 19:27:09.546993: train loss : -0.7749
2022-05-26 19:27:18.350505: validation loss: -0.7603
2022-05-26 19:27:18.353568: Average global foreground Dice: [0.8082]
2022-05-26 19:27:18.355891: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:27:18.807058: lr: 0.006654
2022-05-26 19:27:18.809290: This epoch took 101.679524 s

2022-05-26 19:27:18.811222: 
epoch:  182
2022-05-26 19:28:53.946589: train loss : -0.7710
2022-05-26 19:29:02.838378: validation loss: -0.7577
2022-05-26 19:29:02.850839: Average global foreground Dice: [0.8009]
2022-05-26 19:29:02.871848: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:29:03.338318: lr: 0.006636
2022-05-26 19:29:03.340802: This epoch took 104.527755 s

2022-05-26 19:29:03.343172: 
epoch:  183
2022-05-26 19:30:37.379577: train loss : -0.7582
2022-05-26 19:30:46.227656: validation loss: -0.7465
2022-05-26 19:30:46.230735: Average global foreground Dice: [0.8088]
2022-05-26 19:30:46.232712: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:30:46.700346: lr: 0.006617
2022-05-26 19:30:46.703389: This epoch took 103.357993 s

2022-05-26 19:30:46.705579: 
epoch:  184
2022-05-26 19:32:17.932381: train loss : -0.7776
2022-05-26 19:32:23.769975: validation loss: -0.7668
2022-05-26 19:32:23.774350: Average global foreground Dice: [0.8045]
2022-05-26 19:32:23.776379: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:32:24.321267: lr: 0.006598
2022-05-26 19:32:24.326363: This epoch took 97.618412 s

2022-05-26 19:32:24.328544: 
epoch:  185
2022-05-26 19:33:55.636994: train loss : -0.7879
2022-05-26 19:34:02.923049: validation loss: -0.7746
2022-05-26 19:34:02.926193: Average global foreground Dice: [0.8254]
2022-05-26 19:34:02.928257: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:34:03.386633: lr: 0.006579
2022-05-26 19:34:03.416169: saving checkpoint...
2022-05-26 19:34:04.297264: done, saving took 0.91 seconds
2022-05-26 19:34:04.311555: This epoch took 99.981045 s

2022-05-26 19:34:04.314608: 
epoch:  186
2022-05-26 19:35:35.089580: train loss : -0.7705
2022-05-26 19:35:45.657733: validation loss: -0.7676
2022-05-26 19:35:45.661360: Average global foreground Dice: [0.8022]
2022-05-26 19:35:45.663494: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:35:46.145165: lr: 0.00656
2022-05-26 19:35:46.148621: This epoch took 101.831827 s

2022-05-26 19:35:46.150552: 
epoch:  187
2022-05-26 19:37:25.148681: train loss : -0.7849
2022-05-26 19:37:35.223801: validation loss: -0.7712
2022-05-26 19:37:35.254739: Average global foreground Dice: [0.8258]
2022-05-26 19:37:35.279836: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:37:36.009012: lr: 0.006541
2022-05-26 19:37:36.065568: saving checkpoint...
2022-05-26 19:37:37.212616: done, saving took 1.20 seconds
2022-05-26 19:37:37.227073: This epoch took 111.074589 s

2022-05-26 19:37:37.229368: 
epoch:  188
2022-05-26 19:39:08.402222: train loss : -0.7708
2022-05-26 19:39:17.225927: validation loss: -0.7542
2022-05-26 19:39:17.229453: Average global foreground Dice: [0.8068]
2022-05-26 19:39:17.231711: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:39:17.704354: lr: 0.006522
2022-05-26 19:39:17.709748: This epoch took 100.477660 s

2022-05-26 19:39:17.711879: 
epoch:  189
2022-05-26 19:40:51.615579: train loss : -0.7617
2022-05-26 19:41:01.735883: validation loss: -0.7347
2022-05-26 19:41:01.765915: Average global foreground Dice: [0.8022]
2022-05-26 19:41:01.775471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:41:02.328114: lr: 0.006504
2022-05-26 19:41:02.330549: This epoch took 104.616432 s

2022-05-26 19:41:02.332756: 
epoch:  190
2022-05-26 19:42:40.080281: train loss : -0.7545
2022-05-26 19:42:49.050211: validation loss: -0.7690
2022-05-26 19:42:49.053694: Average global foreground Dice: [0.8319]
2022-05-26 19:42:49.056124: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:42:49.526627: lr: 0.006485
2022-05-26 19:42:49.568044: saving checkpoint...
2022-05-26 19:42:50.890670: done, saving took 1.36 seconds
2022-05-26 19:42:50.921339: This epoch took 108.586287 s

2022-05-26 19:42:50.941916: 
epoch:  191
2022-05-26 19:44:21.297195: train loss : -0.7767
2022-05-26 19:44:27.073234: validation loss: -0.7635
2022-05-26 19:44:27.076506: Average global foreground Dice: [0.8195]
2022-05-26 19:44:27.078624: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:44:27.522547: lr: 0.006466
2022-05-26 19:44:27.552485: saving checkpoint...
2022-05-26 19:44:28.634134: done, saving took 1.11 seconds
2022-05-26 19:44:28.647241: This epoch took 97.682912 s

2022-05-26 19:44:28.649379: 
epoch:  192
2022-05-26 19:46:00.315749: train loss : -0.7680
2022-05-26 19:46:10.390569: validation loss: -0.7642
2022-05-26 19:46:10.393966: Average global foreground Dice: [0.8127]
2022-05-26 19:46:10.396554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:46:10.844043: lr: 0.006447
2022-05-26 19:46:10.875020: saving checkpoint...
2022-05-26 19:46:11.895905: done, saving took 1.05 seconds
2022-05-26 19:46:11.909017: This epoch took 103.257272 s

2022-05-26 19:46:11.911380: 
epoch:  193
2022-05-26 19:47:47.713769: train loss : -0.7786
2022-05-26 19:47:56.224976: validation loss: -0.7558
2022-05-26 19:47:56.229739: Average global foreground Dice: [0.8144]
2022-05-26 19:47:56.232383: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:47:56.674723: lr: 0.006428
2022-05-26 19:47:56.705436: saving checkpoint...
2022-05-26 19:47:57.734139: done, saving took 1.06 seconds
2022-05-26 19:47:57.747133: This epoch took 105.832722 s

2022-05-26 19:47:57.749571: 
epoch:  194
2022-05-26 19:49:29.534517: train loss : -0.7686
2022-05-26 19:49:37.841119: validation loss: -0.7612
2022-05-26 19:49:37.865707: Average global foreground Dice: [0.8049]
2022-05-26 19:49:37.884190: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:49:38.361976: lr: 0.006409
2022-05-26 19:49:38.364644: This epoch took 100.611564 s

2022-05-26 19:49:38.367959: 
epoch:  195
2022-05-26 19:51:09.955341: train loss : -0.7699
2022-05-26 19:51:17.655392: validation loss: -0.7636
2022-05-26 19:51:17.683789: Average global foreground Dice: [0.7975]
2022-05-26 19:51:17.706291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:51:18.213652: lr: 0.00639
2022-05-26 19:51:18.216313: This epoch took 99.845814 s

2022-05-26 19:51:18.218543: 
epoch:  196
2022-05-26 19:52:50.708221: train loss : -0.7448
2022-05-26 19:52:59.219571: validation loss: -0.7256
2022-05-26 19:52:59.222800: Average global foreground Dice: [0.7907]
2022-05-26 19:52:59.224996: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:52:59.743186: lr: 0.006371
2022-05-26 19:52:59.750869: This epoch took 101.530354 s

2022-05-26 19:52:59.756050: 
epoch:  197
2022-05-26 19:54:31.075333: train loss : -0.7536
2022-05-26 19:54:38.902118: validation loss: -0.7596
2022-05-26 19:54:38.906452: Average global foreground Dice: [0.8058]
2022-05-26 19:54:38.908675: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:54:39.398232: lr: 0.006352
2022-05-26 19:54:39.414326: This epoch took 99.656092 s

2022-05-26 19:54:39.429279: 
epoch:  198
2022-05-26 19:56:11.011292: train loss : -0.7685
2022-05-26 19:56:19.833489: validation loss: -0.7471
2022-05-26 19:56:19.837520: Average global foreground Dice: [0.7889]
2022-05-26 19:56:19.839760: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:56:20.447265: lr: 0.006333
2022-05-26 19:56:20.449538: This epoch took 101.015922 s

2022-05-26 19:56:20.451593: 
epoch:  199
2022-05-26 19:57:59.494028: train loss : -0.7582
2022-05-26 19:58:07.090597: validation loss: -0.7627
2022-05-26 19:58:07.093954: Average global foreground Dice: [0.821]
2022-05-26 19:58:07.096359: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:58:07.538755: lr: 0.006314
2022-05-26 19:58:07.541281: saving scheduled checkpoint file...
2022-05-26 19:58:07.573943: saving checkpoint...
2022-05-26 19:58:08.636669: done, saving took 1.09 seconds
2022-05-26 19:58:08.651927: done
2022-05-26 19:58:08.654281: This epoch took 108.200668 s

2022-05-26 19:58:08.656496: 
epoch:  200
2022-05-26 19:59:39.408463: train loss : -0.7690
2022-05-26 19:59:45.671347: validation loss: -0.7124
2022-05-26 19:59:45.674529: Average global foreground Dice: [0.7951]
2022-05-26 19:59:45.676625: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 19:59:46.127670: lr: 0.006296
2022-05-26 19:59:46.130125: This epoch took 97.471295 s

2022-05-26 19:59:46.132277: 
epoch:  201
2022-05-26 20:01:17.424787: train loss : -0.7816
2022-05-26 20:01:24.254035: validation loss: -0.7679
2022-05-26 20:01:24.260671: Average global foreground Dice: [0.8249]
2022-05-26 20:01:24.263278: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:01:24.840158: lr: 0.006277
2022-05-26 20:01:24.858476: This epoch took 98.724075 s

2022-05-26 20:01:24.861123: 
epoch:  202
2022-05-26 20:02:57.550274: train loss : -0.7752
2022-05-26 20:03:06.392568: validation loss: -0.7809
2022-05-26 20:03:06.396296: Average global foreground Dice: [0.82]
2022-05-26 20:03:06.398611: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:03:06.849157: lr: 0.006258
2022-05-26 20:03:06.851596: This epoch took 101.988339 s

2022-05-26 20:03:06.853730: 
epoch:  203
2022-05-26 20:04:45.021489: train loss : -0.7749
2022-05-26 20:04:53.302156: validation loss: -0.7559
2022-05-26 20:04:53.306315: Average global foreground Dice: [0.8205]
2022-05-26 20:04:53.308483: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:04:53.753932: lr: 0.006239
2022-05-26 20:04:53.756298: This epoch took 106.900516 s

2022-05-26 20:04:53.758340: 
epoch:  204
2022-05-26 20:06:26.106516: train loss : -0.7787
2022-05-26 20:06:35.271312: validation loss: -0.7556
2022-05-26 20:06:35.274415: Average global foreground Dice: [0.819]
2022-05-26 20:06:35.276680: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:06:35.823073: lr: 0.00622
2022-05-26 20:06:35.834286: This epoch took 102.073959 s

2022-05-26 20:06:35.836225: 
epoch:  205
2022-05-26 20:08:15.834805: train loss : -0.7856
2022-05-26 20:08:24.820462: validation loss: -0.7455
2022-05-26 20:08:24.826101: Average global foreground Dice: [0.8023]
2022-05-26 20:08:24.828845: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:08:25.322113: lr: 0.006201
2022-05-26 20:08:25.324444: This epoch took 109.486168 s

2022-05-26 20:08:25.326483: 
epoch:  206
2022-05-26 20:10:02.396708: train loss : -0.7595
2022-05-26 20:10:10.362597: validation loss: -0.7402
2022-05-26 20:10:10.366111: Average global foreground Dice: [0.8006]
2022-05-26 20:10:10.385296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:10:10.908801: lr: 0.006182
2022-05-26 20:10:10.913396: This epoch took 105.584928 s

2022-05-26 20:10:10.915560: 
epoch:  207
2022-05-26 20:11:42.878840: train loss : -0.7740
2022-05-26 20:11:49.727031: validation loss: -0.7390
2022-05-26 20:11:49.732168: Average global foreground Dice: [0.8085]
2022-05-26 20:11:49.735072: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:11:50.219913: lr: 0.006163
2022-05-26 20:11:50.222238: This epoch took 99.304425 s

2022-05-26 20:11:50.224265: 
epoch:  208
2022-05-26 20:13:22.443791: train loss : -0.7838
2022-05-26 20:13:31.880247: validation loss: -0.7715
2022-05-26 20:13:31.926798: Average global foreground Dice: [0.8268]
2022-05-26 20:13:31.947139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:13:32.650974: lr: 0.006144
2022-05-26 20:13:32.669500: This epoch took 102.443224 s

2022-05-26 20:13:32.689481: 
epoch:  209
2022-05-26 20:15:20.921315: train loss : -0.7784
2022-05-26 20:15:29.420060: validation loss: -0.7767
2022-05-26 20:15:29.451491: Average global foreground Dice: [0.8343]
2022-05-26 20:15:29.471039: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:15:30.169416: lr: 0.006125
2022-05-26 20:15:30.244333: saving checkpoint...
2022-05-26 20:15:31.299441: done, saving took 1.09 seconds
2022-05-26 20:15:31.313446: This epoch took 118.603766 s

2022-05-26 20:15:31.315757: 
epoch:  210
2022-05-26 20:17:04.990634: train loss : -0.7773
2022-05-26 20:17:13.878382: validation loss: -0.7703
2022-05-26 20:17:13.882578: Average global foreground Dice: [0.8145]
2022-05-26 20:17:13.885442: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:17:14.406108: lr: 0.006106
2022-05-26 20:17:14.440454: saving checkpoint...
2022-05-26 20:17:15.620085: done, saving took 1.21 seconds
2022-05-26 20:17:15.635066: This epoch took 104.317374 s

2022-05-26 20:17:15.637491: 
epoch:  211
2022-05-26 20:18:52.770614: train loss : -0.7707
2022-05-26 20:19:04.002442: validation loss: -0.7565
2022-05-26 20:19:04.006598: Average global foreground Dice: [0.8174]
2022-05-26 20:19:04.009328: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:19:04.555218: lr: 0.006087
2022-05-26 20:19:04.599075: saving checkpoint...
2022-05-26 20:19:05.684952: done, saving took 1.13 seconds
2022-05-26 20:19:05.699312: This epoch took 110.058148 s

2022-05-26 20:19:05.701458: 
epoch:  212
2022-05-26 20:20:44.509204: train loss : -0.7477
2022-05-26 20:20:52.376197: validation loss: -0.7713
2022-05-26 20:20:52.383593: Average global foreground Dice: [0.8174]
2022-05-26 20:20:52.385992: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:20:52.981777: lr: 0.006068
2022-05-26 20:20:53.011550: saving checkpoint...
2022-05-26 20:20:54.084648: done, saving took 1.10 seconds
2022-05-26 20:20:54.098241: This epoch took 108.394606 s

2022-05-26 20:20:54.101024: 
epoch:  213
2022-05-26 20:22:24.145544: train loss : -0.7770
2022-05-26 20:22:30.745179: validation loss: -0.7342
2022-05-26 20:22:30.748742: Average global foreground Dice: [0.8034]
2022-05-26 20:22:30.751067: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:22:31.202723: lr: 0.006049
2022-05-26 20:22:31.204991: This epoch took 97.101812 s

2022-05-26 20:22:31.207113: 
epoch:  214
2022-05-26 20:24:10.266623: train loss : -0.7740
2022-05-26 20:24:19.788662: validation loss: -0.7372
2022-05-26 20:24:19.792100: Average global foreground Dice: [0.7939]
2022-05-26 20:24:19.794202: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:24:20.229640: lr: 0.00603
2022-05-26 20:24:20.232092: This epoch took 109.022958 s

2022-05-26 20:24:20.234204: 
epoch:  215
2022-05-26 20:25:50.806553: train loss : -0.7516
2022-05-26 20:25:59.865255: validation loss: -0.7474
2022-05-26 20:25:59.896681: Average global foreground Dice: [0.8187]
2022-05-26 20:25:59.912059: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:26:00.653901: lr: 0.006011
2022-05-26 20:26:00.661653: This epoch took 100.425395 s

2022-05-26 20:26:00.664469: 
epoch:  216
2022-05-26 20:27:31.442388: train loss : -0.7536
2022-05-26 20:27:38.147310: validation loss: -0.7544
2022-05-26 20:27:38.151049: Average global foreground Dice: [0.8059]
2022-05-26 20:27:38.153291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:27:38.595580: lr: 0.005991
2022-05-26 20:27:38.597917: This epoch took 97.928408 s

2022-05-26 20:27:38.599810: 
epoch:  217
2022-05-26 20:29:09.586310: train loss : -0.7637
2022-05-26 20:29:19.677597: validation loss: -0.7588
2022-05-26 20:29:19.680957: Average global foreground Dice: [0.8079]
2022-05-26 20:29:19.683106: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:29:20.188683: lr: 0.005972
2022-05-26 20:29:20.191155: This epoch took 101.589473 s

2022-05-26 20:29:20.193335: 
epoch:  218
2022-05-26 20:30:50.943837: train loss : -0.7707
2022-05-26 20:30:59.838396: validation loss: -0.7519
2022-05-26 20:30:59.841737: Average global foreground Dice: [0.8098]
2022-05-26 20:30:59.844092: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:31:00.307510: lr: 0.005953
2022-05-26 20:31:00.309901: This epoch took 100.114581 s

2022-05-26 20:31:00.312284: 
epoch:  219
2022-05-26 20:32:31.383719: train loss : -0.7657
2022-05-26 20:32:41.980765: validation loss: -0.7609
2022-05-26 20:32:41.983825: Average global foreground Dice: [0.8315]
2022-05-26 20:32:41.985690: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:32:42.459210: lr: 0.005934
2022-05-26 20:32:42.461284: This epoch took 102.146960 s

2022-05-26 20:32:42.463537: 
epoch:  220
2022-05-26 20:34:12.850872: train loss : -0.7816
2022-05-26 20:34:20.669584: validation loss: -0.7815
2022-05-26 20:34:20.672984: Average global foreground Dice: [0.8359]
2022-05-26 20:34:20.675455: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:34:21.124884: lr: 0.005915
2022-05-26 20:34:21.167200: saving checkpoint...
2022-05-26 20:34:22.235576: done, saving took 1.11 seconds
2022-05-26 20:34:22.250880: This epoch took 99.785060 s

2022-05-26 20:34:22.253249: 
epoch:  221
2022-05-26 20:35:55.922953: train loss : -0.7889
2022-05-26 20:36:05.632615: validation loss: -0.7320
2022-05-26 20:36:05.644690: Average global foreground Dice: [0.7943]
2022-05-26 20:36:05.689311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:36:06.766341: lr: 0.005896
2022-05-26 20:36:06.822756: This epoch took 104.567404 s

2022-05-26 20:36:06.838978: 
epoch:  222
2022-05-26 20:37:38.389589: train loss : -0.7729
2022-05-26 20:37:47.035364: validation loss: -0.7439
2022-05-26 20:37:47.038727: Average global foreground Dice: [0.8092]
2022-05-26 20:37:47.041277: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:37:47.515224: lr: 0.005877
2022-05-26 20:37:47.524334: This epoch took 100.680919 s

2022-05-26 20:37:47.539106: 
epoch:  223
2022-05-26 20:39:18.677952: train loss : -0.7843
2022-05-26 20:39:27.868796: validation loss: -0.7702
2022-05-26 20:39:27.872084: Average global foreground Dice: [0.819]
2022-05-26 20:39:27.874429: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:39:28.401731: lr: 0.005858
2022-05-26 20:39:28.404227: This epoch took 100.842697 s

2022-05-26 20:39:28.406548: 
epoch:  224
2022-05-26 20:40:59.526127: train loss : -0.7820
2022-05-26 20:41:07.921768: validation loss: -0.7518
2022-05-26 20:41:07.925269: Average global foreground Dice: [0.8084]
2022-05-26 20:41:07.927667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:41:08.442297: lr: 0.005839
2022-05-26 20:41:08.445107: This epoch took 100.036321 s

2022-05-26 20:41:08.447961: 
epoch:  225
2022-05-26 20:42:40.149667: train loss : -0.7719
2022-05-26 20:42:49.171718: validation loss: -0.7431
2022-05-26 20:42:49.190232: Average global foreground Dice: [0.8093]
2022-05-26 20:42:49.197156: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:42:49.680706: lr: 0.00582
2022-05-26 20:42:49.701315: This epoch took 101.251014 s

2022-05-26 20:42:49.710040: 
epoch:  226
2022-05-26 20:44:22.910276: train loss : -0.7691
2022-05-26 20:44:31.763141: validation loss: -0.7496
2022-05-26 20:44:31.767174: Average global foreground Dice: [0.812]
2022-05-26 20:44:31.769247: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:44:32.244962: lr: 0.005801
2022-05-26 20:44:32.247136: This epoch took 102.534698 s

2022-05-26 20:44:32.248937: 
epoch:  227
2022-05-26 20:46:03.756039: train loss : -0.7891
2022-05-26 20:46:10.865316: validation loss: -0.7779
2022-05-26 20:46:10.869496: Average global foreground Dice: [0.8234]
2022-05-26 20:46:10.877193: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:46:11.381822: lr: 0.005781
2022-05-26 20:46:11.384478: This epoch took 99.133540 s

2022-05-26 20:46:11.386666: 
epoch:  228
2022-05-26 20:47:42.414400: train loss : -0.7881
2022-05-26 20:47:50.589095: validation loss: -0.7470
2022-05-26 20:47:50.593288: Average global foreground Dice: [0.821]
2022-05-26 20:47:50.595563: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:47:51.071257: lr: 0.005762
2022-05-26 20:47:51.073593: This epoch took 99.684593 s

2022-05-26 20:47:51.075888: 
epoch:  229
2022-05-26 20:49:21.846206: train loss : -0.7806
2022-05-26 20:49:31.477116: validation loss: -0.7470
2022-05-26 20:49:31.480724: Average global foreground Dice: [0.8182]
2022-05-26 20:49:31.483750: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:49:31.924324: lr: 0.005743
2022-05-26 20:49:31.926450: This epoch took 100.848126 s

2022-05-26 20:49:31.928551: 
epoch:  230
2022-05-26 20:51:02.960904: train loss : -0.7969
2022-05-26 20:51:13.814422: validation loss: -0.7555
2022-05-26 20:51:13.817742: Average global foreground Dice: [0.8248]
2022-05-26 20:51:13.822172: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:51:14.333034: lr: 0.005724
2022-05-26 20:51:14.365453: saving checkpoint...
2022-05-26 20:51:15.366189: done, saving took 1.03 seconds
2022-05-26 20:51:15.380053: This epoch took 103.449651 s

2022-05-26 20:51:15.382332: 
epoch:  231
2022-05-26 20:52:48.064921: train loss : -0.7952
2022-05-26 20:52:58.320968: validation loss: -0.7701
2022-05-26 20:52:58.336992: Average global foreground Dice: [0.8186]
2022-05-26 20:52:58.342925: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:52:58.896407: lr: 0.005705
2022-05-26 20:52:58.963520: saving checkpoint...
2022-05-26 20:53:00.180436: done, saving took 1.26 seconds
2022-05-26 20:53:00.194490: This epoch took 104.810093 s

2022-05-26 20:53:00.196617: 
epoch:  232
2022-05-26 20:54:31.096405: train loss : -0.7962
2022-05-26 20:54:40.981186: validation loss: -0.7645
2022-05-26 20:54:40.984343: Average global foreground Dice: [0.8159]
2022-05-26 20:54:40.986399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:54:41.437360: lr: 0.005686
2022-05-26 20:54:41.441337: This epoch took 101.242570 s

2022-05-26 20:54:41.443719: 
epoch:  233
2022-05-26 20:56:20.524276: train loss : -0.7939
2022-05-26 20:56:29.135476: validation loss: -0.7624
2022-05-26 20:56:29.138581: Average global foreground Dice: [0.8011]
2022-05-26 20:56:29.140919: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:56:29.581773: lr: 0.005667
2022-05-26 20:56:29.584311: This epoch took 108.135376 s

2022-05-26 20:56:29.586429: 
epoch:  234
2022-05-26 20:58:00.826099: train loss : -0.7937
2022-05-26 20:58:10.012227: validation loss: -0.7280
2022-05-26 20:58:10.015218: Average global foreground Dice: [0.8131]
2022-05-26 20:58:10.017305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:58:10.464296: lr: 0.005647
2022-05-26 20:58:10.466601: This epoch took 100.877640 s

2022-05-26 20:58:10.468727: 
epoch:  235
2022-05-26 20:59:42.561377: train loss : -0.7821
2022-05-26 20:59:49.627289: validation loss: -0.7565
2022-05-26 20:59:49.661728: Average global foreground Dice: [0.8119]
2022-05-26 20:59:49.680403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 20:59:50.465891: lr: 0.005628
2022-05-26 20:59:50.497454: This epoch took 100.026704 s

2022-05-26 20:59:50.503417: 
epoch:  236
2022-05-26 21:01:25.331307: train loss : -0.7884
2022-05-26 21:01:33.243016: validation loss: -0.7510
2022-05-26 21:01:33.249881: Average global foreground Dice: [0.8032]
2022-05-26 21:01:33.258534: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:01:33.723497: lr: 0.005609
2022-05-26 21:01:33.725976: This epoch took 103.195673 s

2022-05-26 21:01:33.728251: 
epoch:  237
2022-05-26 21:03:04.954745: train loss : -0.7967
2022-05-26 21:03:14.421759: validation loss: -0.7524
2022-05-26 21:03:14.424981: Average global foreground Dice: [0.7955]
2022-05-26 21:03:14.427231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:03:14.914362: lr: 0.00559
2022-05-26 21:03:14.916907: This epoch took 101.185301 s

2022-05-26 21:03:14.919174: 
epoch:  238
2022-05-26 21:04:49.652298: train loss : -0.7807
2022-05-26 21:04:56.953456: validation loss: -0.7569
2022-05-26 21:04:56.957310: Average global foreground Dice: [0.8168]
2022-05-26 21:04:56.959489: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:04:57.407377: lr: 0.005571
2022-05-26 21:04:57.416915: This epoch took 102.495569 s

2022-05-26 21:04:57.419307: 
epoch:  239
2022-05-26 21:06:28.714006: train loss : -0.7954
2022-05-26 21:06:38.995953: validation loss: -0.7513
2022-05-26 21:06:38.999259: Average global foreground Dice: [0.8068]
2022-05-26 21:06:39.001757: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:06:39.435402: lr: 0.005551
2022-05-26 21:06:39.438308: This epoch took 102.012317 s

2022-05-26 21:06:39.441375: 
epoch:  240
2022-05-26 21:08:09.721647: train loss : -0.7871
2022-05-26 21:08:17.968250: validation loss: -0.7763
2022-05-26 21:08:17.971825: Average global foreground Dice: [0.8171]
2022-05-26 21:08:17.973839: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:08:18.462668: lr: 0.005532
2022-05-26 21:08:18.465424: This epoch took 99.021890 s

2022-05-26 21:08:18.467974: 
epoch:  241
2022-05-26 21:09:48.371158: train loss : -0.7795
2022-05-26 21:09:55.120602: validation loss: -0.7376
2022-05-26 21:09:55.125681: Average global foreground Dice: [0.8057]
2022-05-26 21:09:55.128126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:09:55.572802: lr: 0.005513
2022-05-26 21:09:55.574962: This epoch took 97.104566 s

2022-05-26 21:09:55.577080: 
epoch:  242
2022-05-26 21:11:26.263351: train loss : -0.7802
2022-05-26 21:11:34.493751: validation loss: -0.7379
2022-05-26 21:11:34.497171: Average global foreground Dice: [0.795]
2022-05-26 21:11:34.499359: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:11:34.957999: lr: 0.005494
2022-05-26 21:11:34.960454: This epoch took 99.381340 s

2022-05-26 21:11:34.962575: 
epoch:  243
2022-05-26 21:13:10.622869: train loss : -0.7766
2022-05-26 21:13:19.151955: validation loss: -0.7405
2022-05-26 21:13:19.181923: Average global foreground Dice: [0.8012]
2022-05-26 21:13:19.193331: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:13:19.682074: lr: 0.005474
2022-05-26 21:13:19.684802: This epoch took 104.720052 s

2022-05-26 21:13:19.686906: 
epoch:  244
2022-05-26 21:14:55.567167: train loss : -0.7645
2022-05-26 21:15:05.333869: validation loss: -0.7686
2022-05-26 21:15:05.337551: Average global foreground Dice: [0.8057]
2022-05-26 21:15:05.339706: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:15:05.906737: lr: 0.005455
2022-05-26 21:15:05.909195: This epoch took 106.220189 s

2022-05-26 21:15:05.911556: 
epoch:  245
2022-05-26 21:16:36.369348: train loss : -0.7869
2022-05-26 21:16:44.099259: validation loss: -0.7500
2022-05-26 21:16:44.102883: Average global foreground Dice: [0.8085]
2022-05-26 21:16:44.104990: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:16:44.712588: lr: 0.005436
2022-05-26 21:16:44.731612: This epoch took 98.817849 s

2022-05-26 21:16:44.745970: 
epoch:  246
2022-05-26 21:18:18.861782: train loss : -0.7925
2022-05-26 21:18:26.265252: validation loss: -0.7821
2022-05-26 21:18:26.268553: Average global foreground Dice: [0.8303]
2022-05-26 21:18:26.271201: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:18:26.730728: lr: 0.005417
2022-05-26 21:18:26.733418: This epoch took 101.982619 s

2022-05-26 21:18:26.735773: 
epoch:  247
2022-05-26 21:19:59.838683: train loss : -0.7911
2022-05-26 21:20:07.775168: validation loss: -0.7570
2022-05-26 21:20:07.802729: Average global foreground Dice: [0.8133]
2022-05-26 21:20:07.826260: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:20:08.310385: lr: 0.005397
2022-05-26 21:20:08.313166: This epoch took 101.575253 s

2022-05-26 21:20:08.315725: 
epoch:  248
2022-05-26 21:21:44.215308: train loss : -0.7887
2022-05-26 21:21:52.909366: validation loss: -0.7507
2022-05-26 21:21:52.912851: Average global foreground Dice: [0.8062]
2022-05-26 21:21:52.915383: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:21:53.418267: lr: 0.005378
2022-05-26 21:21:53.430361: This epoch took 105.112273 s

2022-05-26 21:21:53.432936: 
epoch:  249
2022-05-26 21:23:27.952588: train loss : -0.7873
2022-05-26 21:23:37.018980: validation loss: -0.7758
2022-05-26 21:23:37.024016: Average global foreground Dice: [0.8338]
2022-05-26 21:23:37.028309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:23:37.484118: lr: 0.005359
2022-05-26 21:23:37.486310: saving scheduled checkpoint file...
2022-05-26 21:23:37.521966: saving checkpoint...
2022-05-26 21:23:38.576691: done, saving took 1.09 seconds
2022-05-26 21:23:38.593734: done
2022-05-26 21:23:38.596009: This epoch took 105.160472 s

2022-05-26 21:23:38.598106: 
epoch:  250
2022-05-26 21:25:11.198903: train loss : -0.7892
2022-05-26 21:25:20.926936: validation loss: -0.7380
2022-05-26 21:25:20.946653: Average global foreground Dice: [0.7956]
2022-05-26 21:25:20.956513: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:25:21.440048: lr: 0.00534
2022-05-26 21:25:21.442527: This epoch took 102.842281 s

2022-05-26 21:25:21.444499: 
epoch:  251
2022-05-26 21:26:52.354017: train loss : -0.8020
2022-05-26 21:26:59.684417: validation loss: -0.7337
2022-05-26 21:26:59.714902: Average global foreground Dice: [0.8094]
2022-05-26 21:26:59.726353: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:27:00.254650: lr: 0.00532
2022-05-26 21:27:00.257430: This epoch took 98.810975 s

2022-05-26 21:27:00.260168: 
epoch:  252
2022-05-26 21:28:44.592818: train loss : -0.7782
2022-05-26 21:28:51.414908: validation loss: -0.7634
2022-05-26 21:28:51.421254: Average global foreground Dice: [0.8101]
2022-05-26 21:28:51.427562: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:28:51.919052: lr: 0.005301
2022-05-26 21:28:51.921515: This epoch took 111.658795 s

2022-05-26 21:28:51.924010: 
epoch:  253
2022-05-26 21:30:23.118892: train loss : -0.7858
2022-05-26 21:30:33.118029: validation loss: -0.7639
2022-05-26 21:30:33.121699: Average global foreground Dice: [0.822]
2022-05-26 21:30:33.124284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:30:33.601077: lr: 0.005282
2022-05-26 21:30:33.613046: This epoch took 101.686747 s

2022-05-26 21:30:33.627034: 
epoch:  254
2022-05-26 21:32:05.040836: train loss : -0.7876
2022-05-26 21:32:15.353129: validation loss: -0.7509
2022-05-26 21:32:15.381968: Average global foreground Dice: [0.82]
2022-05-26 21:32:15.392910: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:32:15.984814: lr: 0.005262
2022-05-26 21:32:15.987201: This epoch took 102.357500 s

2022-05-26 21:32:15.989057: 
epoch:  255
2022-05-26 21:33:52.001158: train loss : -0.7754
2022-05-26 21:34:01.168211: validation loss: -0.7664
2022-05-26 21:34:01.171517: Average global foreground Dice: [0.8289]
2022-05-26 21:34:01.173847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:34:01.651556: lr: 0.005243
2022-05-26 21:34:01.664538: This epoch took 105.673486 s

2022-05-26 21:34:01.695850: 
epoch:  256
2022-05-26 21:35:32.413533: train loss : -0.7787
2022-05-26 21:35:39.648136: validation loss: -0.7758
2022-05-26 21:35:39.661988: Average global foreground Dice: [0.8176]
2022-05-26 21:35:39.672377: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:35:40.365653: lr: 0.005224
2022-05-26 21:35:40.397325: This epoch took 98.685485 s

2022-05-26 21:35:40.411140: 
epoch:  257
2022-05-26 21:37:12.411448: train loss : -0.7977
2022-05-26 21:37:23.917595: validation loss: -0.7713
2022-05-26 21:37:23.952710: Average global foreground Dice: [0.8261]
2022-05-26 21:37:23.973196: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:37:24.604669: lr: 0.005204
2022-05-26 21:37:24.606984: This epoch took 104.181751 s

2022-05-26 21:37:24.608958: 
epoch:  258
2022-05-26 21:38:55.814811: train loss : -0.7952
2022-05-26 21:39:03.777194: validation loss: -0.7695
2022-05-26 21:39:03.786086: Average global foreground Dice: [0.8238]
2022-05-26 21:39:03.788331: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:39:04.249606: lr: 0.005185
2022-05-26 21:39:04.326465: saving checkpoint...
2022-05-26 21:39:05.474302: done, saving took 1.20 seconds
2022-05-26 21:39:05.487387: This epoch took 100.876331 s

2022-05-26 21:39:05.490973: 
epoch:  259
2022-05-26 21:40:37.200772: train loss : -0.7908
2022-05-26 21:40:44.901586: validation loss: -0.7577
2022-05-26 21:40:44.904755: Average global foreground Dice: [0.7999]
2022-05-26 21:40:44.918946: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:40:45.667959: lr: 0.005166
2022-05-26 21:40:45.688966: This epoch took 100.195915 s

2022-05-26 21:40:45.724289: 
epoch:  260
2022-05-26 21:42:17.126424: train loss : -0.7903
2022-05-26 21:42:24.501622: validation loss: -0.7729
2022-05-26 21:42:24.505821: Average global foreground Dice: [0.8166]
2022-05-26 21:42:24.508448: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:42:24.958412: lr: 0.005146
2022-05-26 21:42:24.961050: This epoch took 99.203764 s

2022-05-26 21:42:24.963286: 
epoch:  261
2022-05-26 21:43:55.967347: train loss : -0.7852
2022-05-26 21:44:06.269378: validation loss: -0.7757
2022-05-26 21:44:06.276095: Average global foreground Dice: [0.8199]
2022-05-26 21:44:06.296390: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:44:07.011710: lr: 0.005127
2022-05-26 21:44:07.038383: This epoch took 102.073059 s

2022-05-26 21:44:07.058982: 
epoch:  262
2022-05-26 21:45:42.342853: train loss : -0.7936
2022-05-26 21:45:51.292029: validation loss: -0.7716
2022-05-26 21:45:51.295401: Average global foreground Dice: [0.819]
2022-05-26 21:45:51.297818: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:45:51.761986: lr: 0.005107
2022-05-26 21:45:51.764415: This epoch took 104.693835 s

2022-05-26 21:45:51.766496: 
epoch:  263
2022-05-26 21:47:22.888492: train loss : -0.7982
2022-05-26 21:47:31.681543: validation loss: -0.7665
2022-05-26 21:47:31.684687: Average global foreground Dice: [0.8237]
2022-05-26 21:47:31.687075: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:47:32.136075: lr: 0.005088
2022-05-26 21:47:32.178145: saving checkpoint...
2022-05-26 21:47:33.183178: done, saving took 1.04 seconds
2022-05-26 21:47:33.197677: This epoch took 101.429017 s

2022-05-26 21:47:33.199817: 
epoch:  264
2022-05-26 21:49:14.355645: train loss : -0.8013
2022-05-26 21:49:23.461535: validation loss: -0.7868
2022-05-26 21:49:23.465472: Average global foreground Dice: [0.816]
2022-05-26 21:49:23.494571: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:49:24.045289: lr: 0.005069
2022-05-26 21:49:24.047444: This epoch took 110.845466 s

2022-05-26 21:49:24.049483: 
epoch:  265
2022-05-26 21:50:56.405329: train loss : -0.7869
2022-05-26 21:51:06.042540: validation loss: -0.7640
2022-05-26 21:51:06.070114: Average global foreground Dice: [0.8201]
2022-05-26 21:51:06.103311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:51:06.834308: lr: 0.005049
2022-05-26 21:51:06.910623: saving checkpoint...
2022-05-26 21:51:08.040946: done, saving took 1.19 seconds
2022-05-26 21:51:08.056523: This epoch took 104.004933 s

2022-05-26 21:51:08.059160: 
epoch:  266
2022-05-26 21:52:40.633384: train loss : -0.7922
2022-05-26 21:52:48.608445: validation loss: -0.7604
2022-05-26 21:52:48.613314: Average global foreground Dice: [0.8116]
2022-05-26 21:52:48.616642: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:52:49.182036: lr: 0.00503
2022-05-26 21:52:49.185211: This epoch took 101.123666 s

2022-05-26 21:52:49.187825: 
epoch:  267
2022-05-26 21:54:22.288408: train loss : -0.7791
2022-05-26 21:54:33.247095: validation loss: -0.7532
2022-05-26 21:54:33.279937: Average global foreground Dice: [0.8004]
2022-05-26 21:54:33.289619: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:54:33.801258: lr: 0.00501
2022-05-26 21:54:33.823333: This epoch took 104.632953 s

2022-05-26 21:54:33.859308: 
epoch:  268
2022-05-26 21:56:07.976500: train loss : -0.7898
2022-05-26 21:56:18.758230: validation loss: -0.7642
2022-05-26 21:56:18.761926: Average global foreground Dice: [0.8213]
2022-05-26 21:56:18.764232: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:56:19.231002: lr: 0.004991
2022-05-26 21:56:19.233163: This epoch took 105.361228 s

2022-05-26 21:56:19.235344: 
epoch:  269
2022-05-26 21:57:50.160301: train loss : -0.7863
2022-05-26 21:57:59.578694: validation loss: -0.7416
2022-05-26 21:57:59.609964: Average global foreground Dice: [0.8163]
2022-05-26 21:57:59.629718: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:58:00.186270: lr: 0.004971
2022-05-26 21:58:00.232309: This epoch took 100.994976 s

2022-05-26 21:58:00.234941: 
epoch:  270
2022-05-26 21:59:31.882339: train loss : -0.7907
2022-05-26 21:59:38.352308: validation loss: -0.7957
2022-05-26 21:59:38.355553: Average global foreground Dice: [0.8363]
2022-05-26 21:59:38.357905: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 21:59:38.840806: lr: 0.004952
2022-05-26 21:59:38.875220: saving checkpoint...
2022-05-26 21:59:39.892087: done, saving took 1.05 seconds
2022-05-26 21:59:39.905048: This epoch took 99.667630 s

2022-05-26 21:59:39.907104: 
epoch:  271
2022-05-26 22:01:11.223631: train loss : -0.8004
2022-05-26 22:01:19.308115: validation loss: -0.7816
2022-05-26 22:01:19.342006: Average global foreground Dice: [0.8325]
2022-05-26 22:01:19.366265: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:01:20.025918: lr: 0.004933
2022-05-26 22:01:20.076761: saving checkpoint...
2022-05-26 22:01:21.584400: done, saving took 1.54 seconds
2022-05-26 22:01:21.657368: This epoch took 101.748272 s

2022-05-26 22:01:21.678745: 
epoch:  272
2022-05-26 22:02:53.440854: train loss : -0.7828
2022-05-26 22:03:03.185479: validation loss: -0.7401
2022-05-26 22:03:03.188938: Average global foreground Dice: [0.8095]
2022-05-26 22:03:03.191548: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:03:03.685473: lr: 0.004913
2022-05-26 22:03:03.688101: This epoch took 101.979710 s

2022-05-26 22:03:03.690282: 
epoch:  273
2022-05-26 22:04:35.893946: train loss : -0.7826
2022-05-26 22:04:43.971238: validation loss: -0.7646
2022-05-26 22:04:43.974499: Average global foreground Dice: [0.8065]
2022-05-26 22:04:43.979079: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:04:44.422418: lr: 0.004894
2022-05-26 22:04:44.425008: This epoch took 100.732319 s

2022-05-26 22:04:44.427090: 
epoch:  274
2022-05-26 22:06:15.759730: train loss : -0.7940
2022-05-26 22:06:25.284347: validation loss: -0.7567
2022-05-26 22:06:25.287908: Average global foreground Dice: [0.8152]
2022-05-26 22:06:25.292422: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:06:25.751585: lr: 0.004874
2022-05-26 22:06:25.753786: This epoch took 101.324421 s

2022-05-26 22:06:25.755738: 
epoch:  275
2022-05-26 22:07:56.047689: train loss : -0.8005
2022-05-26 22:08:05.874899: validation loss: -0.7636
2022-05-26 22:08:05.878582: Average global foreground Dice: [0.8112]
2022-05-26 22:08:05.881545: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:08:06.354677: lr: 0.004855
2022-05-26 22:08:06.357533: This epoch took 100.599899 s

2022-05-26 22:08:06.361494: 
epoch:  276
2022-05-26 22:09:37.665774: train loss : -0.7887
2022-05-26 22:09:48.588566: validation loss: -0.7368
2022-05-26 22:09:48.591838: Average global foreground Dice: [0.8182]
2022-05-26 22:09:48.594275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:09:49.046068: lr: 0.004835
2022-05-26 22:09:49.053921: This epoch took 102.689820 s

2022-05-26 22:09:49.059057: 
epoch:  277
2022-05-26 22:11:22.344536: train loss : -0.8023
2022-05-26 22:11:31.925393: validation loss: -0.7829
2022-05-26 22:11:31.945844: Average global foreground Dice: [0.824]
2022-05-26 22:11:31.948414: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:11:32.442602: lr: 0.004816
2022-05-26 22:11:32.445086: This epoch took 103.381545 s

2022-05-26 22:11:32.447435: 
epoch:  278
2022-05-26 22:13:05.542229: train loss : -0.7890
2022-05-26 22:13:14.070380: validation loss: -0.7572
2022-05-26 22:13:14.073725: Average global foreground Dice: [0.8195]
2022-05-26 22:13:14.076108: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:13:14.609407: lr: 0.004796
2022-05-26 22:13:14.612291: This epoch took 102.162479 s

2022-05-26 22:13:14.614698: 
epoch:  279
2022-05-26 22:14:44.827170: train loss : -0.7904
2022-05-26 22:14:51.915195: validation loss: -0.7392
2022-05-26 22:14:51.918675: Average global foreground Dice: [0.7961]
2022-05-26 22:14:51.921100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:14:52.363086: lr: 0.004776
2022-05-26 22:14:52.365482: This epoch took 97.748439 s

2022-05-26 22:14:52.367704: 
epoch:  280
2022-05-26 22:16:23.661659: train loss : -0.7925
2022-05-26 22:16:32.443886: validation loss: -0.7433
2022-05-26 22:16:32.447431: Average global foreground Dice: [0.8223]
2022-05-26 22:16:32.450368: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:16:33.065379: lr: 0.004757
2022-05-26 22:16:33.078099: This epoch took 100.708100 s

2022-05-26 22:16:33.087502: 
epoch:  281
2022-05-26 22:18:08.358237: train loss : -0.7906
2022-05-26 22:18:15.901227: validation loss: -0.7484
2022-05-26 22:18:15.904466: Average global foreground Dice: [0.7938]
2022-05-26 22:18:15.906970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:18:16.360269: lr: 0.004737
2022-05-26 22:18:16.363073: This epoch took 103.271480 s

2022-05-26 22:18:16.365202: 
epoch:  282
2022-05-26 22:19:52.687877: train loss : -0.7953
2022-05-26 22:20:02.561814: validation loss: -0.7301
2022-05-26 22:20:02.565544: Average global foreground Dice: [0.783]
2022-05-26 22:20:02.568188: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:20:03.029891: lr: 0.004718
2022-05-26 22:20:03.033029: This epoch took 106.665654 s

2022-05-26 22:20:03.036008: 
epoch:  283
2022-05-26 22:21:34.442428: train loss : -0.7780
2022-05-26 22:21:42.275517: validation loss: -0.7336
2022-05-26 22:21:42.279647: Average global foreground Dice: [0.8179]
2022-05-26 22:21:42.281819: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:21:42.728185: lr: 0.004698
2022-05-26 22:21:42.731144: This epoch took 99.692349 s

2022-05-26 22:21:42.733729: 
epoch:  284
2022-05-26 22:23:15.331578: train loss : -0.8002
2022-05-26 22:23:25.275103: validation loss: -0.7356
2022-05-26 22:23:25.278469: Average global foreground Dice: [0.8139]
2022-05-26 22:23:25.280833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:23:25.766021: lr: 0.004679
2022-05-26 22:23:25.769226: This epoch took 103.033063 s

2022-05-26 22:23:25.771557: 
epoch:  285
2022-05-26 22:24:56.489276: train loss : -0.7887
2022-05-26 22:25:03.294954: validation loss: -0.7455
2022-05-26 22:25:03.298590: Average global foreground Dice: [0.8201]
2022-05-26 22:25:03.301309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:25:03.795592: lr: 0.004659
2022-05-26 22:25:03.798192: This epoch took 98.024226 s

2022-05-26 22:25:03.801435: 
epoch:  286
2022-05-26 22:26:35.329822: train loss : -0.7992
2022-05-26 22:26:43.803257: validation loss: -0.7421
2022-05-26 22:26:43.806626: Average global foreground Dice: [0.8036]
2022-05-26 22:26:43.808719: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:26:44.254795: lr: 0.004639
2022-05-26 22:26:44.257211: This epoch took 100.452091 s

2022-05-26 22:26:44.259319: 
epoch:  287
2022-05-26 22:28:17.181447: train loss : -0.7941
2022-05-26 22:28:26.166482: validation loss: -0.7586
2022-05-26 22:28:26.169774: Average global foreground Dice: [0.8106]
2022-05-26 22:28:26.171962: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:28:26.642372: lr: 0.00462
2022-05-26 22:28:26.645363: This epoch took 102.383882 s

2022-05-26 22:28:26.647880: 
epoch:  288
2022-05-26 22:29:59.235927: train loss : -0.8129
2022-05-26 22:30:09.370212: validation loss: -0.7792
2022-05-26 22:30:09.374528: Average global foreground Dice: [0.8205]
2022-05-26 22:30:09.377997: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:30:09.955879: lr: 0.0046
2022-05-26 22:30:09.958130: This epoch took 103.307920 s

2022-05-26 22:30:09.960212: 
epoch:  289
2022-05-26 22:31:44.370321: train loss : -0.8176
2022-05-26 22:31:52.916741: validation loss: -0.7493
2022-05-26 22:31:52.920818: Average global foreground Dice: [0.8204]
2022-05-26 22:31:52.923469: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:31:53.393281: lr: 0.004581
2022-05-26 22:31:53.395849: This epoch took 103.433132 s

2022-05-26 22:31:53.408516: 
epoch:  290
2022-05-26 22:33:25.415900: train loss : -0.8157
2022-05-26 22:33:33.316431: validation loss: -0.7561
2022-05-26 22:33:33.324157: Average global foreground Dice: [0.8184]
2022-05-26 22:33:33.327017: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:33:33.920759: lr: 0.004561
2022-05-26 22:33:33.941237: This epoch took 100.530371 s

2022-05-26 22:33:33.957447: 
epoch:  291
2022-05-26 22:35:04.606864: train loss : -0.8138
2022-05-26 22:35:11.946100: validation loss: -0.7592
2022-05-26 22:35:11.949393: Average global foreground Dice: [0.816]
2022-05-26 22:35:11.951499: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:35:12.410648: lr: 0.004541
2022-05-26 22:35:12.413338: This epoch took 98.437031 s

2022-05-26 22:35:12.415797: 
epoch:  292
2022-05-26 22:36:43.871884: train loss : -0.8096
2022-05-26 22:36:53.781846: validation loss: -0.7529
2022-05-26 22:36:53.786028: Average global foreground Dice: [0.8184]
2022-05-26 22:36:53.788334: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:36:54.282206: lr: 0.004522
2022-05-26 22:36:54.285249: This epoch took 101.867172 s

2022-05-26 22:36:54.288106: 
epoch:  293
2022-05-26 22:38:24.663794: train loss : -0.8025
2022-05-26 22:38:30.484038: validation loss: -0.7711
2022-05-26 22:38:30.487622: Average global foreground Dice: [0.8205]
2022-05-26 22:38:30.489879: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:38:30.940654: lr: 0.004502
2022-05-26 22:38:30.942990: This epoch took 96.652194 s

2022-05-26 22:38:30.945261: 
epoch:  294
2022-05-26 22:40:02.352960: train loss : -0.8005
2022-05-26 22:40:11.847573: validation loss: -0.7787
2022-05-26 22:40:11.851422: Average global foreground Dice: [0.8292]
2022-05-26 22:40:11.853840: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:40:12.313373: lr: 0.004482
2022-05-26 22:40:12.315868: This epoch took 101.368655 s

2022-05-26 22:40:12.323944: 
epoch:  295
2022-05-26 22:41:43.316003: train loss : -0.8175
2022-05-26 22:41:52.380363: validation loss: -0.7970
2022-05-26 22:41:52.390982: Average global foreground Dice: [0.8399]
2022-05-26 22:41:52.394042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:41:52.960333: lr: 0.004463
2022-05-26 22:41:52.962743: This epoch took 100.635927 s

2022-05-26 22:41:52.965183: 
epoch:  296
2022-05-26 22:43:23.560437: train loss : -0.8043
2022-05-26 22:43:30.523935: validation loss: -0.7503
2022-05-26 22:43:30.527204: Average global foreground Dice: [0.8184]
2022-05-26 22:43:30.529388: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:43:30.975466: lr: 0.004443
2022-05-26 22:43:30.978371: This epoch took 98.010613 s

2022-05-26 22:43:30.981045: 
epoch:  297
2022-05-26 22:45:01.756556: train loss : -0.8003
2022-05-26 22:45:08.798068: validation loss: -0.7598
2022-05-26 22:45:08.801217: Average global foreground Dice: [0.8148]
2022-05-26 22:45:08.803432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:45:09.290904: lr: 0.004423
2022-05-26 22:45:09.293558: This epoch took 98.309915 s

2022-05-26 22:45:09.296101: 
epoch:  298
2022-05-26 22:46:40.761857: train loss : -0.8040
2022-05-26 22:46:49.945781: validation loss: -0.7534
2022-05-26 22:46:49.974831: Average global foreground Dice: [0.8137]
2022-05-26 22:46:50.002315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:46:50.481071: lr: 0.004404
2022-05-26 22:46:50.483871: This epoch took 101.185151 s

2022-05-26 22:46:50.486727: 
epoch:  299
2022-05-26 22:48:23.392232: train loss : -0.8046
2022-05-26 22:48:32.561800: validation loss: -0.7871
2022-05-26 22:48:32.582493: Average global foreground Dice: [0.8298]
2022-05-26 22:48:32.602327: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:48:33.394763: lr: 0.004384
2022-05-26 22:48:33.417292: saving scheduled checkpoint file...
2022-05-26 22:48:33.481716: saving checkpoint...
2022-05-26 22:48:34.668421: done, saving took 1.23 seconds
2022-05-26 22:48:34.731308: done
2022-05-26 22:48:34.754316: This epoch took 104.264919 s

2022-05-26 22:48:34.776290: 
epoch:  300
2022-05-26 22:50:06.114391: train loss : -0.8104
2022-05-26 22:50:15.724882: validation loss: -0.7423
2022-05-26 22:50:15.758656: Average global foreground Dice: [0.8034]
2022-05-26 22:50:15.804309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:50:16.490034: lr: 0.004364
2022-05-26 22:50:16.510453: This epoch took 101.696158 s

2022-05-26 22:50:16.532374: 
epoch:  301
2022-05-26 22:51:47.421302: train loss : -0.8052
2022-05-26 22:51:55.347061: validation loss: -0.7679
2022-05-26 22:51:55.350726: Average global foreground Dice: [0.8166]
2022-05-26 22:51:55.353717: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:51:55.797518: lr: 0.004344
2022-05-26 22:51:55.800107: This epoch took 99.237828 s

2022-05-26 22:51:55.802387: 
epoch:  302
2022-05-26 22:53:27.595059: train loss : -0.7932
2022-05-26 22:53:35.559557: validation loss: -0.7374
2022-05-26 22:53:35.563284: Average global foreground Dice: [0.8139]
2022-05-26 22:53:35.565754: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:53:36.046596: lr: 0.004325
2022-05-26 22:53:36.049001: This epoch took 100.244470 s

2022-05-26 22:53:36.051889: 
epoch:  303
2022-05-26 22:55:07.298679: train loss : -0.8021
2022-05-26 22:55:15.320547: validation loss: -0.7628
2022-05-26 22:55:15.324002: Average global foreground Dice: [0.8248]
2022-05-26 22:55:15.326605: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:55:15.899425: lr: 0.004305
2022-05-26 22:55:15.901897: This epoch took 99.847589 s

2022-05-26 22:55:15.903925: 
epoch:  304
2022-05-26 22:56:47.542225: train loss : -0.8008
2022-05-26 22:56:55.533215: validation loss: -0.7751
2022-05-26 22:56:55.536487: Average global foreground Dice: [0.8223]
2022-05-26 22:56:55.538874: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:56:55.980891: lr: 0.004285
2022-05-26 22:56:55.983386: This epoch took 100.077467 s

2022-05-26 22:56:55.988280: 
epoch:  305
2022-05-26 22:58:28.889369: train loss : -0.8060
2022-05-26 22:58:37.154175: validation loss: -0.7741
2022-05-26 22:58:37.157742: Average global foreground Dice: [0.8228]
2022-05-26 22:58:37.160237: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 22:58:37.629527: lr: 0.004265
2022-05-26 22:58:37.632153: This epoch took 101.641500 s

2022-05-26 22:58:37.634935: 
epoch:  306
2022-05-26 23:00:11.107962: train loss : -0.8147
2022-05-26 23:00:19.419965: validation loss: -0.7510
2022-05-26 23:00:19.423187: Average global foreground Dice: [0.8229]
2022-05-26 23:00:19.425451: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:00:19.879470: lr: 0.004245
2022-05-26 23:00:19.912629: saving checkpoint...
2022-05-26 23:00:20.953691: done, saving took 1.07 seconds
2022-05-26 23:00:20.967764: This epoch took 103.330621 s

2022-05-26 23:00:20.970021: 
epoch:  307
2022-05-26 23:01:54.103452: train loss : -0.8127
2022-05-26 23:02:05.470258: validation loss: -0.7539
2022-05-26 23:02:05.498919: Average global foreground Dice: [0.8114]
2022-05-26 23:02:05.519311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:02:06.111277: lr: 0.004226
2022-05-26 23:02:06.114316: This epoch took 105.142153 s

2022-05-26 23:02:06.120878: 
epoch:  308
2022-05-26 23:03:38.303832: train loss : -0.7939
2022-05-26 23:03:47.666071: validation loss: -0.7420
2022-05-26 23:03:47.686448: Average global foreground Dice: [0.8052]
2022-05-26 23:03:47.700485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:03:48.220706: lr: 0.004206
2022-05-26 23:03:48.241018: This epoch took 102.117664 s

2022-05-26 23:03:48.257688: 
epoch:  309
2022-05-26 23:05:19.164995: train loss : -0.8073
2022-05-26 23:05:28.561069: validation loss: -0.7472
2022-05-26 23:05:28.564820: Average global foreground Dice: [0.787]
2022-05-26 23:05:28.567336: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:05:29.024713: lr: 0.004186
2022-05-26 23:05:29.027183: This epoch took 100.766601 s

2022-05-26 23:05:29.029260: 
epoch:  310
2022-05-26 23:07:01.750691: train loss : -0.8018
2022-05-26 23:07:09.656703: validation loss: -0.7475
2022-05-26 23:07:09.659844: Average global foreground Dice: [0.8095]
2022-05-26 23:07:09.662653: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:07:10.120676: lr: 0.004166
2022-05-26 23:07:10.124879: This epoch took 101.093424 s

2022-05-26 23:07:10.127535: 
epoch:  311
2022-05-26 23:08:41.544327: train loss : -0.7837
2022-05-26 23:08:52.134407: validation loss: -0.7728
2022-05-26 23:08:52.137596: Average global foreground Dice: [0.8196]
2022-05-26 23:08:52.139763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:08:52.613809: lr: 0.004146
2022-05-26 23:08:52.616865: This epoch took 102.486225 s

2022-05-26 23:08:52.619130: 
epoch:  312
2022-05-26 23:10:24.732568: train loss : -0.7996
2022-05-26 23:10:33.347726: validation loss: -0.7538
2022-05-26 23:10:33.352293: Average global foreground Dice: [0.8203]
2022-05-26 23:10:33.355591: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:10:33.835129: lr: 0.004127
2022-05-26 23:10:33.846525: This epoch took 101.224918 s

2022-05-26 23:10:33.855561: 
epoch:  313
2022-05-26 23:12:04.348269: train loss : -0.8142
2022-05-26 23:12:10.919633: validation loss: -0.7640
2022-05-26 23:12:10.923157: Average global foreground Dice: [0.8304]
2022-05-26 23:12:10.925322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:12:11.371887: lr: 0.004107
2022-05-26 23:12:11.374427: This epoch took 97.501174 s

2022-05-26 23:12:11.376982: 
epoch:  314
2022-05-26 23:13:42.464674: train loss : -0.8182
2022-05-26 23:13:50.386720: validation loss: -0.7649
2022-05-26 23:13:50.395298: Average global foreground Dice: [0.8295]
2022-05-26 23:13:50.400012: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:13:51.101611: lr: 0.004087
2022-05-26 23:13:51.103936: This epoch took 99.724435 s

2022-05-26 23:13:51.106099: 
epoch:  315
2022-05-26 23:15:23.131108: train loss : -0.8048
2022-05-26 23:15:33.956475: validation loss: -0.7327
2022-05-26 23:15:33.959793: Average global foreground Dice: [0.8208]
2022-05-26 23:15:33.962826: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:15:34.437868: lr: 0.004067
2022-05-26 23:15:34.440685: This epoch took 103.332285 s

2022-05-26 23:15:34.443205: 
epoch:  316
2022-05-26 23:17:08.912019: train loss : -0.8131
2022-05-26 23:17:18.922392: validation loss: -0.7239
2022-05-26 23:17:18.928478: Average global foreground Dice: [0.8049]
2022-05-26 23:17:18.938870: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:17:19.448711: lr: 0.004047
2022-05-26 23:17:19.455548: This epoch took 105.010063 s

2022-05-26 23:17:19.459095: 
epoch:  317
2022-05-26 23:18:52.495888: train loss : -0.7930
2022-05-26 23:19:00.520611: validation loss: -0.7706
2022-05-26 23:19:00.540153: Average global foreground Dice: [0.8128]
2022-05-26 23:19:00.557519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:19:01.151300: lr: 0.004027
2022-05-26 23:19:01.154306: This epoch took 101.692139 s

2022-05-26 23:19:01.157111: 
epoch:  318
2022-05-26 23:20:32.031045: train loss : -0.8147
2022-05-26 23:20:40.602170: validation loss: -0.7692
2022-05-26 23:20:40.650240: Average global foreground Dice: [0.821]
2022-05-26 23:20:40.652439: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:20:41.111140: lr: 0.004007
2022-05-26 23:20:41.113338: This epoch took 99.953785 s

2022-05-26 23:20:41.115422: 
epoch:  319
2022-05-26 23:22:12.127206: train loss : -0.8070
2022-05-26 23:22:20.127460: validation loss: -0.7672
2022-05-26 23:22:20.130717: Average global foreground Dice: [0.8231]
2022-05-26 23:22:20.133639: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:22:20.600459: lr: 0.003987
2022-05-26 23:22:20.603004: This epoch took 99.485454 s

2022-05-26 23:22:20.605187: 
epoch:  320
2022-05-26 23:23:52.606694: train loss : -0.8041
2022-05-26 23:24:01.844503: validation loss: -0.7646
2022-05-26 23:24:01.847879: Average global foreground Dice: [0.817]
2022-05-26 23:24:01.850224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:24:02.341274: lr: 0.003967
2022-05-26 23:24:02.343782: This epoch took 101.736465 s

2022-05-26 23:24:02.345923: 
epoch:  321
2022-05-26 23:25:33.476505: train loss : -0.7970
2022-05-26 23:25:40.006229: validation loss: -0.7685
2022-05-26 23:25:40.009352: Average global foreground Dice: [0.8149]
2022-05-26 23:25:40.011683: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:25:40.483156: lr: 0.003947
2022-05-26 23:25:40.485526: This epoch took 98.137378 s

2022-05-26 23:25:40.487644: 
epoch:  322
2022-05-26 23:27:10.873553: train loss : -0.8124
2022-05-26 23:27:16.995720: validation loss: -0.7826
2022-05-26 23:27:16.998848: Average global foreground Dice: [0.8257]
2022-05-26 23:27:17.001609: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:27:17.446491: lr: 0.003927
2022-05-26 23:27:17.448854: This epoch took 96.958979 s

2022-05-26 23:27:17.450936: 
epoch:  323
2022-05-26 23:28:49.045247: train loss : -0.8145
2022-05-26 23:28:57.208980: validation loss: -0.7496
2022-05-26 23:28:57.212092: Average global foreground Dice: [0.8126]
2022-05-26 23:28:57.214276: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:28:57.707168: lr: 0.003907
2022-05-26 23:28:57.709428: This epoch took 100.256418 s

2022-05-26 23:28:57.711766: 
epoch:  324
2022-05-26 23:30:29.485641: train loss : -0.7960
2022-05-26 23:30:39.830108: validation loss: -0.7565
2022-05-26 23:30:39.833390: Average global foreground Dice: [0.8192]
2022-05-26 23:30:39.835784: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:30:40.385064: lr: 0.003887
2022-05-26 23:30:40.387505: This epoch took 102.673585 s

2022-05-26 23:30:40.390305: 
epoch:  325
2022-05-26 23:32:10.825768: train loss : -0.7924
2022-05-26 23:32:19.096507: validation loss: -0.7643
2022-05-26 23:32:19.116614: Average global foreground Dice: [0.8119]
2022-05-26 23:32:19.136411: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:32:19.728601: lr: 0.003867
2022-05-26 23:32:19.741396: This epoch took 99.346399 s

2022-05-26 23:32:19.755345: 
epoch:  326
2022-05-26 23:33:51.331074: train loss : -0.8107
2022-05-26 23:34:00.060436: validation loss: -0.7814
2022-05-26 23:34:00.064260: Average global foreground Dice: [0.8331]
2022-05-26 23:34:00.066700: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:34:00.538229: lr: 0.003847
2022-05-26 23:34:00.540686: This epoch took 100.770841 s

2022-05-26 23:34:00.542839: 
epoch:  327
2022-05-26 23:35:31.831237: train loss : -0.8170
2022-05-26 23:35:39.877024: validation loss: -0.7696
2022-05-26 23:35:39.880524: Average global foreground Dice: [0.8335]
2022-05-26 23:35:39.882952: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:35:40.355968: lr: 0.003827
2022-05-26 23:35:40.388369: saving checkpoint...
2022-05-26 23:35:41.538355: done, saving took 1.18 seconds
2022-05-26 23:35:41.553531: This epoch took 101.008629 s

2022-05-26 23:35:41.556457: 
epoch:  328
2022-05-26 23:37:12.448267: train loss : -0.8209
2022-05-26 23:37:23.050384: validation loss: -0.7326
2022-05-26 23:37:23.054072: Average global foreground Dice: [0.802]
2022-05-26 23:37:23.056577: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:37:23.591276: lr: 0.003807
2022-05-26 23:37:23.593922: This epoch took 102.035065 s

2022-05-26 23:37:23.596214: 
epoch:  329
2022-05-26 23:38:56.842316: train loss : -0.8113
2022-05-26 23:39:06.139794: validation loss: -0.7559
2022-05-26 23:39:06.142690: Average global foreground Dice: [0.824]
2022-05-26 23:39:06.144899: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:39:06.669387: lr: 0.003787
2022-05-26 23:39:06.674179: This epoch took 103.075102 s

2022-05-26 23:39:06.676606: 
epoch:  330
2022-05-26 23:40:37.513263: train loss : -0.8239
2022-05-26 23:40:46.516951: validation loss: -0.7542
2022-05-26 23:40:46.520635: Average global foreground Dice: [0.8108]
2022-05-26 23:40:46.523022: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:40:46.988360: lr: 0.003767
2022-05-26 23:40:46.991323: This epoch took 100.311394 s

2022-05-26 23:40:46.993801: 
epoch:  331
2022-05-26 23:42:18.502218: train loss : -0.8107
2022-05-26 23:42:24.943296: validation loss: -0.7629
2022-05-26 23:42:24.946423: Average global foreground Dice: [0.8226]
2022-05-26 23:42:24.948840: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:42:25.453254: lr: 0.003747
2022-05-26 23:42:25.455846: This epoch took 98.459993 s

2022-05-26 23:42:25.458144: 
epoch:  332
2022-05-26 23:43:57.930308: train loss : -0.8218
2022-05-26 23:44:07.086849: validation loss: -0.7719
2022-05-26 23:44:07.090303: Average global foreground Dice: [0.8316]
2022-05-26 23:44:07.093523: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:44:07.574105: lr: 0.003727
2022-05-26 23:44:07.577396: This epoch took 102.117071 s

2022-05-26 23:44:07.579510: 
epoch:  333
2022-05-26 23:45:44.290661: train loss : -0.8197
2022-05-26 23:45:52.773706: validation loss: -0.7754
2022-05-26 23:45:52.776970: Average global foreground Dice: [0.8139]
2022-05-26 23:45:52.780432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:45:53.310561: lr: 0.003707
2022-05-26 23:45:53.313090: This epoch took 105.731445 s

2022-05-26 23:45:53.345654: 
epoch:  334
2022-05-26 23:47:24.576458: train loss : -0.8067
2022-05-26 23:47:34.459411: validation loss: -0.7457
2022-05-26 23:47:34.470071: Average global foreground Dice: [0.8195]
2022-05-26 23:47:34.479308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:47:35.002147: lr: 0.003687
2022-05-26 23:47:35.004622: This epoch took 101.643231 s

2022-05-26 23:47:35.006661: 
epoch:  335
2022-05-26 23:49:05.607588: train loss : -0.8091
2022-05-26 23:49:15.391866: validation loss: -0.7527
2022-05-26 23:49:15.396510: Average global foreground Dice: [0.8128]
2022-05-26 23:49:15.399073: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:49:15.879063: lr: 0.003667
2022-05-26 23:49:15.881562: This epoch took 100.872822 s

2022-05-26 23:49:15.883704: 
epoch:  336
2022-05-26 23:50:47.768706: train loss : -0.7957
2022-05-26 23:50:56.512690: validation loss: -0.7692
2022-05-26 23:50:56.516077: Average global foreground Dice: [0.8137]
2022-05-26 23:50:56.518349: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:50:57.075364: lr: 0.003647
2022-05-26 23:50:57.084422: This epoch took 101.198428 s

2022-05-26 23:50:57.116290: 
epoch:  337
2022-05-26 23:52:28.460931: train loss : -0.8122
2022-05-26 23:52:37.832190: validation loss: -0.7642
2022-05-26 23:52:37.835739: Average global foreground Dice: [0.8064]
2022-05-26 23:52:37.838276: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:52:38.282686: lr: 0.003627
2022-05-26 23:52:38.285083: This epoch took 101.140781 s

2022-05-26 23:52:38.287388: 
epoch:  338
2022-05-26 23:54:09.187545: train loss : -0.8103
2022-05-26 23:54:19.541746: validation loss: -0.7392
2022-05-26 23:54:19.545451: Average global foreground Dice: [0.8125]
2022-05-26 23:54:19.548627: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:54:20.140824: lr: 0.003606
2022-05-26 23:54:20.143397: This epoch took 101.853715 s

2022-05-26 23:54:20.180405: 
epoch:  339
2022-05-26 23:55:53.071232: train loss : -0.8121
2022-05-26 23:56:03.392875: validation loss: -0.7841
2022-05-26 23:56:03.396844: Average global foreground Dice: [0.83]
2022-05-26 23:56:03.399328: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:56:03.885512: lr: 0.003586
2022-05-26 23:56:03.888539: This epoch took 103.694604 s

2022-05-26 23:56:03.891288: 
epoch:  340
2022-05-26 23:57:36.083519: train loss : -0.8186
2022-05-26 23:57:46.105833: validation loss: -0.7332
2022-05-26 23:57:46.109346: Average global foreground Dice: [0.8068]
2022-05-26 23:57:46.112094: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:57:46.583661: lr: 0.003566
2022-05-26 23:57:46.586545: This epoch took 102.692796 s

2022-05-26 23:57:46.589119: 
epoch:  341
2022-05-26 23:59:17.952847: train loss : -0.8215
2022-05-26 23:59:26.337548: validation loss: -0.7810
2022-05-26 23:59:26.362773: Average global foreground Dice: [0.8253]
2022-05-26 23:59:26.380320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-26 23:59:26.912759: lr: 0.003546
2022-05-26 23:59:26.915326: This epoch took 100.323571 s

2022-05-26 23:59:26.917539: 
epoch:  342
2022-05-27 00:01:00.996352: train loss : -0.8083
2022-05-27 00:01:09.502331: validation loss: -0.7646
2022-05-27 00:01:09.529555: Average global foreground Dice: [0.8282]
2022-05-27 00:01:09.542989: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:01:10.067920: lr: 0.003526
2022-05-27 00:01:10.071619: This epoch took 103.151785 s

2022-05-27 00:01:10.079377: 
epoch:  343
2022-05-27 00:02:41.469606: train loss : -0.8231
2022-05-27 00:02:50.737241: validation loss: -0.7461
2022-05-27 00:02:50.747522: Average global foreground Dice: [0.8259]
2022-05-27 00:02:50.785311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:02:51.451792: lr: 0.003505
2022-05-27 00:02:51.480416: This epoch took 101.389550 s

2022-05-27 00:02:51.499525: 
epoch:  344
2022-05-27 00:04:22.770637: train loss : -0.8091
2022-05-27 00:04:29.327774: validation loss: -0.7457
2022-05-27 00:04:29.333632: Average global foreground Dice: [0.7952]
2022-05-27 00:04:29.336111: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:04:29.817353: lr: 0.003485
2022-05-27 00:04:29.819829: This epoch took 98.315557 s

2022-05-27 00:04:29.822012: 
epoch:  345
2022-05-27 00:06:01.295169: train loss : -0.8033
2022-05-27 00:06:09.816684: validation loss: -0.7655
2022-05-27 00:06:09.820480: Average global foreground Dice: [0.8178]
2022-05-27 00:06:09.829276: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:06:10.366709: lr: 0.003465
2022-05-27 00:06:10.370451: This epoch took 100.546473 s

2022-05-27 00:06:10.372653: 
epoch:  346
2022-05-27 00:07:41.621369: train loss : -0.8136
2022-05-27 00:07:48.187064: validation loss: -0.7543
2022-05-27 00:07:48.190832: Average global foreground Dice: [0.8046]
2022-05-27 00:07:48.193058: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:07:48.669820: lr: 0.003445
2022-05-27 00:07:48.672118: This epoch took 98.297235 s

2022-05-27 00:07:48.674128: 
epoch:  347
2022-05-27 00:09:19.942545: train loss : -0.8203
2022-05-27 00:09:26.825634: validation loss: -0.7190
2022-05-27 00:09:26.829769: Average global foreground Dice: [0.7756]
2022-05-27 00:09:26.832140: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:09:27.317247: lr: 0.003424
2022-05-27 00:09:27.319663: This epoch took 98.643508 s

2022-05-27 00:09:27.321713: 
epoch:  348
2022-05-27 00:11:01.081386: train loss : -0.8042
2022-05-27 00:11:10.005937: validation loss: -0.7618
2022-05-27 00:11:10.019558: Average global foreground Dice: [0.8203]
2022-05-27 00:11:10.022444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:11:10.522396: lr: 0.003404
2022-05-27 00:11:10.525019: This epoch took 103.201291 s

2022-05-27 00:11:10.527390: 
epoch:  349
2022-05-27 00:12:41.676022: train loss : -0.8061
2022-05-27 00:12:50.223025: validation loss: -0.7497
2022-05-27 00:12:50.226273: Average global foreground Dice: [0.806]
2022-05-27 00:12:50.228640: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:12:50.927057: lr: 0.003384
2022-05-27 00:12:50.947951: saving scheduled checkpoint file...
2022-05-27 00:12:51.019185: saving checkpoint...
2022-05-27 00:12:52.168023: done, saving took 1.20 seconds
2022-05-27 00:12:52.184441: done
2022-05-27 00:12:52.186947: This epoch took 101.657311 s

2022-05-27 00:12:52.189305: 
epoch:  350
2022-05-27 00:14:25.452300: train loss : -0.8183
2022-05-27 00:14:34.964020: validation loss: -0.7749
2022-05-27 00:14:34.967575: Average global foreground Dice: [0.8233]
2022-05-27 00:14:34.969986: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:14:35.466141: lr: 0.003364
2022-05-27 00:14:35.488158: This epoch took 103.296225 s

2022-05-27 00:14:35.494062: 
epoch:  351
2022-05-27 00:16:07.193941: train loss : -0.8173
2022-05-27 00:16:15.502764: validation loss: -0.7217
2022-05-27 00:16:15.512585: Average global foreground Dice: [0.8149]
2022-05-27 00:16:15.515054: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:16:16.164286: lr: 0.003343
2022-05-27 00:16:16.167241: This epoch took 100.669144 s

2022-05-27 00:16:16.169932: 
epoch:  352
2022-05-27 00:17:47.643404: train loss : -0.8101
2022-05-27 00:17:56.807742: validation loss: -0.7517
2022-05-27 00:17:56.843725: Average global foreground Dice: [0.8188]
2022-05-27 00:17:56.869713: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:17:57.602744: lr: 0.003323
2022-05-27 00:17:57.605313: This epoch took 101.432921 s

2022-05-27 00:17:57.608538: 
epoch:  353
2022-05-27 00:19:30.252147: train loss : -0.8132
2022-05-27 00:19:40.260797: validation loss: -0.7859
2022-05-27 00:19:40.264310: Average global foreground Dice: [0.8288]
2022-05-27 00:19:40.267070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:19:40.728137: lr: 0.003303
2022-05-27 00:19:40.733410: This epoch took 103.122340 s

2022-05-27 00:19:40.736030: 
epoch:  354
2022-05-27 00:21:17.351135: train loss : -0.8150
2022-05-27 00:21:26.794783: validation loss: -0.7620
2022-05-27 00:21:26.797871: Average global foreground Dice: [0.8113]
2022-05-27 00:21:26.801079: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:21:27.338995: lr: 0.003282
2022-05-27 00:21:27.341755: This epoch took 106.603316 s

2022-05-27 00:21:27.344105: 
epoch:  355
2022-05-27 00:22:58.426735: train loss : -0.8234
2022-05-27 00:23:06.174610: validation loss: -0.7551
2022-05-27 00:23:06.178165: Average global foreground Dice: [0.8209]
2022-05-27 00:23:06.182718: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:23:06.658425: lr: 0.003262
2022-05-27 00:23:06.661104: This epoch took 99.314765 s

2022-05-27 00:23:06.663281: 
epoch:  356
2022-05-27 00:24:41.043921: train loss : -0.8164
2022-05-27 00:24:50.192163: validation loss: -0.7550
2022-05-27 00:24:50.213119: Average global foreground Dice: [0.8129]
2022-05-27 00:24:50.229360: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:24:50.709306: lr: 0.003241
2022-05-27 00:24:50.721335: This epoch took 104.055743 s

2022-05-27 00:24:50.741296: 
epoch:  357
2022-05-27 00:26:24.200989: train loss : -0.8158
2022-05-27 00:26:33.505497: validation loss: -0.7604
2022-05-27 00:26:33.509658: Average global foreground Dice: [0.8299]
2022-05-27 00:26:33.511943: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:26:33.973989: lr: 0.003221
2022-05-27 00:26:33.977167: This epoch took 103.217580 s

2022-05-27 00:26:33.979609: 
epoch:  358
2022-05-27 00:28:13.081659: train loss : -0.8226
2022-05-27 00:28:21.813370: validation loss: -0.7895
2022-05-27 00:28:21.826015: Average global foreground Dice: [0.8263]
2022-05-27 00:28:21.845407: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:28:22.464817: lr: 0.003201
2022-05-27 00:28:22.486341: This epoch took 108.504017 s

2022-05-27 00:28:22.504382: 
epoch:  359
2022-05-27 00:29:59.221439: train loss : -0.8189
2022-05-27 00:30:07.393862: validation loss: -0.7245
2022-05-27 00:30:07.404384: Average global foreground Dice: [0.8197]
2022-05-27 00:30:07.410141: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:30:08.072064: lr: 0.00318
2022-05-27 00:30:08.074471: This epoch took 105.549664 s

2022-05-27 00:30:08.076491: 
epoch:  360
2022-05-27 00:31:44.811029: train loss : -0.8208
2022-05-27 00:31:53.551862: validation loss: -0.7701
2022-05-27 00:31:53.573692: Average global foreground Dice: [0.8145]
2022-05-27 00:31:53.587297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:31:54.227877: lr: 0.00316
2022-05-27 00:31:54.232302: This epoch took 106.153837 s

2022-05-27 00:31:54.235278: 
epoch:  361
2022-05-27 00:33:27.387844: train loss : -0.8170
2022-05-27 00:33:34.995113: validation loss: -0.7824
2022-05-27 00:33:35.008930: Average global foreground Dice: [0.836]
2022-05-27 00:33:35.024387: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:33:35.564112: lr: 0.003139
2022-05-27 00:33:35.570351: This epoch took 101.332930 s

2022-05-27 00:33:35.599393: 
epoch:  362
2022-05-27 00:35:10.988338: train loss : -0.8271
2022-05-27 00:35:18.885800: validation loss: -0.7721
2022-05-27 00:35:18.891645: Average global foreground Dice: [0.8222]
2022-05-27 00:35:18.893785: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:35:19.441468: lr: 0.003119
2022-05-27 00:35:19.443967: This epoch took 103.828668 s

2022-05-27 00:35:19.447346: 
epoch:  363
2022-05-27 00:36:52.599597: train loss : -0.8112
2022-05-27 00:37:01.392304: validation loss: -0.7704
2022-05-27 00:37:01.415740: Average global foreground Dice: [0.8352]
2022-05-27 00:37:01.430329: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:37:01.960222: lr: 0.003098
2022-05-27 00:37:02.004987: saving checkpoint...
2022-05-27 00:37:03.087943: done, saving took 1.12 seconds
2022-05-27 00:37:03.111561: This epoch took 103.654256 s

2022-05-27 00:37:03.114289: 
epoch:  364
2022-05-27 00:38:42.237638: train loss : -0.8147
2022-05-27 00:38:49.365283: validation loss: -0.7468
2022-05-27 00:38:49.368677: Average global foreground Dice: [0.8159]
2022-05-27 00:38:49.371145: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:38:49.855796: lr: 0.003078
2022-05-27 00:38:49.858533: This epoch took 106.741975 s

2022-05-27 00:38:49.860983: 
epoch:  365
2022-05-27 00:40:25.262575: train loss : -0.8124
2022-05-27 00:40:33.600100: validation loss: -0.7453
2022-05-27 00:40:33.606629: Average global foreground Dice: [0.8251]
2022-05-27 00:40:33.611340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:40:34.310484: lr: 0.003057
2022-05-27 00:40:34.312854: This epoch took 104.449530 s

2022-05-27 00:40:34.318823: 
epoch:  366
2022-05-27 00:42:12.955627: train loss : -0.8171
2022-05-27 00:42:23.233554: validation loss: -0.7314
2022-05-27 00:42:23.240601: Average global foreground Dice: [0.8236]
2022-05-27 00:42:23.244185: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:42:23.855980: lr: 0.003037
2022-05-27 00:42:23.913407: saving checkpoint...
2022-05-27 00:42:25.260556: done, saving took 1.40 seconds
2022-05-27 00:42:25.276961: This epoch took 110.952677 s

2022-05-27 00:42:25.280258: 
epoch:  367
2022-05-27 00:44:00.043185: train loss : -0.8132
2022-05-27 00:44:11.969768: validation loss: -0.7339
2022-05-27 00:44:11.973411: Average global foreground Dice: [0.8207]
2022-05-27 00:44:11.976078: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:44:12.462609: lr: 0.003016
2022-05-27 00:44:12.464983: This epoch took 107.182256 s

2022-05-27 00:44:12.467189: 
epoch:  368
2022-05-27 00:45:44.439306: train loss : -0.8122
2022-05-27 00:45:54.208599: validation loss: -0.7830
2022-05-27 00:45:54.218835: Average global foreground Dice: [0.8243]
2022-05-27 00:45:54.221893: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:45:54.691347: lr: 0.002996
2022-05-27 00:45:54.733550: saving checkpoint...
2022-05-27 00:45:55.822252: done, saving took 1.13 seconds
2022-05-27 00:45:55.837575: This epoch took 103.367944 s

2022-05-27 00:45:55.844400: 
epoch:  369
2022-05-27 00:47:35.472289: train loss : -0.8252
2022-05-27 00:47:43.825265: validation loss: -0.7952
2022-05-27 00:47:43.829550: Average global foreground Dice: [0.8347]
2022-05-27 00:47:43.834333: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:47:44.309063: lr: 0.002975
2022-05-27 00:47:44.361178: saving checkpoint...
2022-05-27 00:47:45.465701: done, saving took 1.14 seconds
2022-05-27 00:47:45.487827: This epoch took 109.640830 s

2022-05-27 00:47:45.510432: 
epoch:  370
2022-05-27 00:49:24.743184: train loss : -0.8328
2022-05-27 00:49:35.680433: validation loss: -0.7719
2022-05-27 00:49:35.688745: Average global foreground Dice: [0.8154]
2022-05-27 00:49:35.691885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:49:36.204122: lr: 0.002954
2022-05-27 00:49:36.207201: This epoch took 110.685366 s

2022-05-27 00:49:36.209673: 
epoch:  371
2022-05-27 00:51:08.801282: train loss : -0.8212
2022-05-27 00:51:18.190466: validation loss: -0.7253
2022-05-27 00:51:18.222410: Average global foreground Dice: [0.8042]
2022-05-27 00:51:18.238306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:51:18.779603: lr: 0.002934
2022-05-27 00:51:18.782797: This epoch took 102.570092 s

2022-05-27 00:51:18.785425: 
epoch:  372
2022-05-27 00:53:00.992378: train loss : -0.8055
2022-05-27 00:53:09.182179: validation loss: -0.7617
2022-05-27 00:53:09.219790: Average global foreground Dice: [0.8213]
2022-05-27 00:53:09.248316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:53:09.978832: lr: 0.002913
2022-05-27 00:53:09.988432: This epoch took 111.181124 s

2022-05-27 00:53:09.992477: 
epoch:  373
2022-05-27 00:54:39.968014: train loss : -0.8283
2022-05-27 00:54:48.503016: validation loss: -0.7789
2022-05-27 00:54:48.525645: Average global foreground Dice: [0.8162]
2022-05-27 00:54:48.556329: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:54:49.089483: lr: 0.002892
2022-05-27 00:54:49.095329: This epoch took 99.100440 s

2022-05-27 00:54:49.111878: 
epoch:  374
2022-05-27 00:56:25.556756: train loss : -0.8233
2022-05-27 00:56:36.596981: validation loss: -0.7795
2022-05-27 00:56:36.600535: Average global foreground Dice: [0.8157]
2022-05-27 00:56:36.606269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:56:37.205412: lr: 0.002872
2022-05-27 00:56:37.229995: This epoch took 108.103765 s

2022-05-27 00:56:37.242989: 
epoch:  375
2022-05-27 00:58:13.343975: train loss : -0.8390
2022-05-27 00:58:23.158660: validation loss: -0.7592
2022-05-27 00:58:23.164627: Average global foreground Dice: [0.8143]
2022-05-27 00:58:23.169773: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 00:58:23.705149: lr: 0.002851
2022-05-27 00:58:23.707708: This epoch took 106.452699 s

2022-05-27 00:58:23.711695: 
epoch:  376
2022-05-27 00:59:58.622653: train loss : -0.8419
2022-05-27 01:00:08.609014: validation loss: -0.7998
2022-05-27 01:00:08.638298: Average global foreground Dice: [0.8403]
2022-05-27 01:00:08.704407: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:00:09.413192: lr: 0.00283
2022-05-27 01:00:09.431641: This epoch took 105.716466 s

2022-05-27 01:00:09.445495: 
epoch:  377
2022-05-27 01:01:44.695856: train loss : -0.8337
2022-05-27 01:01:53.512884: validation loss: -0.7863
2022-05-27 01:01:53.524708: Average global foreground Dice: [0.8226]
2022-05-27 01:01:53.544457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:01:54.418131: lr: 0.00281
2022-05-27 01:01:54.444358: This epoch took 104.986061 s

2022-05-27 01:01:54.466300: 
epoch:  378
2022-05-27 01:03:30.331236: train loss : -0.8399
2022-05-27 01:03:39.474365: validation loss: -0.7775
2022-05-27 01:03:39.477952: Average global foreground Dice: [0.8206]
2022-05-27 01:03:39.480399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:03:40.459659: lr: 0.002789
2022-05-27 01:03:40.486520: This epoch took 105.997225 s

2022-05-27 01:03:40.504318: 
epoch:  379
2022-05-27 01:05:15.238099: train loss : -0.8297
2022-05-27 01:05:24.705562: validation loss: -0.7337
2022-05-27 01:05:24.708880: Average global foreground Dice: [0.8127]
2022-05-27 01:05:24.711434: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:05:25.259024: lr: 0.002768
2022-05-27 01:05:25.261846: This epoch took 104.733376 s

2022-05-27 01:05:25.264058: 
epoch:  380
2022-05-27 01:07:00.720064: train loss : -0.8274
2022-05-27 01:07:08.054465: validation loss: -0.7448
2022-05-27 01:07:08.078166: Average global foreground Dice: [0.8007]
2022-05-27 01:07:08.097617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:07:08.748626: lr: 0.002747
2022-05-27 01:07:08.759265: This epoch took 103.492730 s

2022-05-27 01:07:08.780290: 
epoch:  381
2022-05-27 01:08:51.384025: train loss : -0.8145
2022-05-27 01:08:59.404458: validation loss: -0.7995
2022-05-27 01:08:59.425015: Average global foreground Dice: [0.8414]
2022-05-27 01:08:59.457331: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:09:00.067707: lr: 0.002727
2022-05-27 01:09:00.086552: This epoch took 111.298348 s

2022-05-27 01:09:00.092294: 
epoch:  382
2022-05-27 01:10:35.313813: train loss : -0.8303
2022-05-27 01:10:43.870468: validation loss: -0.7812
2022-05-27 01:10:43.873769: Average global foreground Dice: [0.8237]
2022-05-27 01:10:43.876104: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:10:44.572828: lr: 0.002706
2022-05-27 01:10:44.605365: This epoch took 104.502066 s

2022-05-27 01:10:44.627302: 
epoch:  383
2022-05-27 01:12:22.925288: train loss : -0.8242
2022-05-27 01:12:32.971040: validation loss: -0.7562
2022-05-27 01:12:32.985716: Average global foreground Dice: [0.8136]
2022-05-27 01:12:32.989933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:12:33.850812: lr: 0.002685
2022-05-27 01:12:33.853500: This epoch took 109.203064 s

2022-05-27 01:12:33.856087: 
epoch:  384
2022-05-27 01:14:07.748449: train loss : -0.8176
2022-05-27 01:14:18.424814: validation loss: -0.7661
2022-05-27 01:14:18.428323: Average global foreground Dice: [0.8237]
2022-05-27 01:14:18.432606: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:14:19.128839: lr: 0.002664
2022-05-27 01:14:19.150004: This epoch took 105.292284 s

2022-05-27 01:14:19.154099: 
epoch:  385
2022-05-27 01:15:51.138741: train loss : -0.8277
2022-05-27 01:16:00.133445: validation loss: -0.7605
2022-05-27 01:16:00.151756: Average global foreground Dice: [0.8344]
2022-05-27 01:16:00.173500: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:16:00.715747: lr: 0.002643
2022-05-27 01:16:00.738346: This epoch took 101.578592 s

2022-05-27 01:16:00.768449: 
epoch:  386
2022-05-27 01:17:37.788575: train loss : -0.8289
2022-05-27 01:17:46.367343: validation loss: -0.7821
2022-05-27 01:17:46.391778: Average global foreground Dice: [0.8265]
2022-05-27 01:17:46.404947: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:17:47.735826: lr: 0.002622
2022-05-27 01:17:47.738388: This epoch took 106.946880 s

2022-05-27 01:17:47.750877: 
epoch:  387
2022-05-27 01:19:29.033382: train loss : -0.8328
2022-05-27 01:19:38.679098: validation loss: -0.7400
2022-05-27 01:19:38.684913: Average global foreground Dice: [0.8135]
2022-05-27 01:19:38.689082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:19:39.344825: lr: 0.002601
2022-05-27 01:19:39.349185: This epoch took 111.564900 s

2022-05-27 01:19:39.352978: 
epoch:  388
2022-05-27 01:21:24.593519: train loss : -0.8333
2022-05-27 01:21:33.373500: validation loss: -0.7904
2022-05-27 01:21:33.383235: Average global foreground Dice: [0.8231]
2022-05-27 01:21:33.386437: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:21:34.268120: lr: 0.002581
2022-05-27 01:21:34.279737: This epoch took 114.924415 s

2022-05-27 01:21:34.299555: 
epoch:  389
2022-05-27 01:23:07.502817: train loss : -0.8290
2022-05-27 01:23:16.145930: validation loss: -0.7839
2022-05-27 01:23:16.168692: Average global foreground Dice: [0.8326]
2022-05-27 01:23:16.176291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:23:16.838084: lr: 0.00256
2022-05-27 01:23:16.876395: This epoch took 102.555050 s

2022-05-27 01:23:16.888436: 
epoch:  390
2022-05-27 01:24:55.688423: train loss : -0.8320
2022-05-27 01:25:04.038417: validation loss: -0.7977
2022-05-27 01:25:04.043200: Average global foreground Dice: [0.8341]
2022-05-27 01:25:04.046640: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:25:04.535053: lr: 0.002539
2022-05-27 01:25:04.569500: saving checkpoint...
2022-05-27 01:25:05.825983: done, saving took 1.29 seconds
2022-05-27 01:25:05.842843: This epoch took 108.951939 s

2022-05-27 01:25:05.846173: 
epoch:  391
2022-05-27 01:26:39.290652: train loss : -0.8379
2022-05-27 01:26:48.856121: validation loss: -0.7816
2022-05-27 01:26:48.867443: Average global foreground Dice: [0.8245]
2022-05-27 01:26:48.887048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:26:49.370907: lr: 0.002518
2022-05-27 01:26:49.521386: saving checkpoint...
2022-05-27 01:26:50.818940: done, saving took 1.43 seconds
2022-05-27 01:26:50.834002: This epoch took 104.985624 s

2022-05-27 01:26:50.836468: 
epoch:  392
2022-05-27 01:28:25.396148: train loss : -0.8229
2022-05-27 01:28:34.214661: validation loss: -0.7815
2022-05-27 01:28:34.226993: Average global foreground Dice: [0.8332]
2022-05-27 01:28:34.230790: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:28:34.857757: lr: 0.002497
2022-05-27 01:28:34.943189: saving checkpoint...
2022-05-27 01:28:36.352386: done, saving took 1.48 seconds
2022-05-27 01:28:36.386509: This epoch took 105.547951 s

2022-05-27 01:28:36.402693: 
epoch:  393
2022-05-27 01:30:07.305053: train loss : -0.8385
2022-05-27 01:30:15.008095: validation loss: -0.7770
2022-05-27 01:30:15.011546: Average global foreground Dice: [0.8275]
2022-05-27 01:30:15.014148: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:30:15.500815: lr: 0.002476
2022-05-27 01:30:15.531908: saving checkpoint...
2022-05-27 01:30:16.605471: done, saving took 1.10 seconds
2022-05-27 01:30:16.619843: This epoch took 100.210626 s

2022-05-27 01:30:16.622044: 
epoch:  394
2022-05-27 01:31:46.986079: train loss : -0.8238
2022-05-27 01:31:52.939293: validation loss: -0.7488
2022-05-27 01:31:52.942677: Average global foreground Dice: [0.8179]
2022-05-27 01:31:52.945053: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:31:53.395044: lr: 0.002455
2022-05-27 01:31:53.397340: This epoch took 96.773276 s

2022-05-27 01:31:53.399417: 
epoch:  395
2022-05-27 01:33:25.580861: train loss : -0.8326
2022-05-27 01:33:33.810934: validation loss: -0.7816
2022-05-27 01:33:33.814893: Average global foreground Dice: [0.8306]
2022-05-27 01:33:33.817042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:33:34.375416: lr: 0.002434
2022-05-27 01:33:34.397503: This epoch took 100.995456 s

2022-05-27 01:33:34.400002: 
epoch:  396
2022-05-27 01:35:04.864231: train loss : -0.8307
2022-05-27 01:35:11.593706: validation loss: -0.7841
2022-05-27 01:35:11.596839: Average global foreground Dice: [0.8313]
2022-05-27 01:35:11.599147: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:35:12.063761: lr: 0.002413
2022-05-27 01:35:12.101886: saving checkpoint...
2022-05-27 01:35:13.185882: done, saving took 1.12 seconds
2022-05-27 01:35:13.203747: This epoch took 98.787269 s

2022-05-27 01:35:13.206167: 
epoch:  397
2022-05-27 01:36:44.077526: train loss : -0.8261
2022-05-27 01:36:54.754003: validation loss: -0.7684
2022-05-27 01:36:54.756632: Average global foreground Dice: [0.816]
2022-05-27 01:36:54.759281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:36:55.222561: lr: 0.002391
2022-05-27 01:36:55.225197: This epoch took 102.014521 s

2022-05-27 01:36:55.227326: 
epoch:  398
2022-05-27 01:38:26.748365: train loss : -0.8269
2022-05-27 01:38:36.507023: validation loss: -0.7875
2022-05-27 01:38:36.510370: Average global foreground Dice: [0.8163]
2022-05-27 01:38:36.513183: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:38:36.957309: lr: 0.00237
2022-05-27 01:38:36.959903: This epoch took 101.730345 s

2022-05-27 01:38:36.962454: 
epoch:  399
2022-05-27 01:40:12.531029: train loss : -0.8198
2022-05-27 01:40:21.927129: validation loss: -0.7470
2022-05-27 01:40:21.931410: Average global foreground Dice: [0.8141]
2022-05-27 01:40:21.933807: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:40:22.484832: lr: 0.002349
2022-05-27 01:40:22.487715: saving scheduled checkpoint file...
2022-05-27 01:40:22.543686: saving checkpoint...
2022-05-27 01:40:23.795868: done, saving took 1.31 seconds
2022-05-27 01:40:23.818409: done
2022-05-27 01:40:23.823068: This epoch took 106.858247 s

2022-05-27 01:40:23.832155: 
epoch:  400
2022-05-27 01:41:54.708225: train loss : -0.8310
2022-05-27 01:42:02.544144: validation loss: -0.7564
2022-05-27 01:42:02.547612: Average global foreground Dice: [0.8104]
2022-05-27 01:42:02.550094: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:42:03.004127: lr: 0.002328
2022-05-27 01:42:03.006585: This epoch took 99.157924 s

2022-05-27 01:42:03.008987: 
epoch:  401
2022-05-27 01:43:41.641806: train loss : -0.8215
2022-05-27 01:43:51.215013: validation loss: -0.7521
2022-05-27 01:43:51.218421: Average global foreground Dice: [0.8181]
2022-05-27 01:43:51.221736: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:43:51.692883: lr: 0.002307
2022-05-27 01:43:51.696084: This epoch took 108.684557 s

2022-05-27 01:43:51.698304: 
epoch:  402
2022-05-27 01:45:22.317495: train loss : -0.8197
2022-05-27 01:45:30.853666: validation loss: -0.7342
2022-05-27 01:45:30.857394: Average global foreground Dice: [0.7956]
2022-05-27 01:45:30.859945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:45:31.331026: lr: 0.002286
2022-05-27 01:45:31.334067: This epoch took 99.633561 s

2022-05-27 01:45:31.338965: 
epoch:  403
2022-05-27 01:47:02.192991: train loss : -0.8265
2022-05-27 01:47:09.237570: validation loss: -0.7521
2022-05-27 01:47:09.241533: Average global foreground Dice: [0.8069]
2022-05-27 01:47:09.244440: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:47:09.783439: lr: 0.002264
2022-05-27 01:47:09.785860: This epoch took 98.444279 s

2022-05-27 01:47:09.803290: 
epoch:  404
2022-05-27 01:48:42.819657: train loss : -0.8359
2022-05-27 01:48:50.788221: validation loss: -0.7518
2022-05-27 01:48:50.792450: Average global foreground Dice: [0.8138]
2022-05-27 01:48:50.795261: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:48:51.294567: lr: 0.002243
2022-05-27 01:48:51.297179: This epoch took 101.461863 s

2022-05-27 01:48:51.300090: 
epoch:  405
2022-05-27 01:50:25.940506: train loss : -0.8364
2022-05-27 01:50:33.962669: validation loss: -0.7443
2022-05-27 01:50:33.971134: Average global foreground Dice: [0.8078]
2022-05-27 01:50:33.989359: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:50:34.570411: lr: 0.002222
2022-05-27 01:50:34.593318: This epoch took 103.290844 s

2022-05-27 01:50:34.623395: 
epoch:  406
2022-05-27 01:52:06.141544: train loss : -0.8431
2022-05-27 01:52:14.834242: validation loss: -0.8043
2022-05-27 01:52:14.847195: Average global foreground Dice: [0.834]
2022-05-27 01:52:14.849405: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:52:15.312682: lr: 0.002201
2022-05-27 01:52:15.315496: This epoch took 100.680011 s

2022-05-27 01:52:15.318075: 
epoch:  407
2022-05-27 01:53:46.331817: train loss : -0.8328
2022-05-27 01:53:54.915617: validation loss: -0.7524
2022-05-27 01:53:54.919073: Average global foreground Dice: [0.8143]
2022-05-27 01:53:54.921941: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:53:55.373683: lr: 0.002179
2022-05-27 01:53:55.375887: This epoch took 100.055358 s

2022-05-27 01:53:55.380397: 
epoch:  408
2022-05-27 01:55:25.301523: train loss : -0.8341
2022-05-27 01:55:32.674091: validation loss: -0.7600
2022-05-27 01:55:32.677683: Average global foreground Dice: [0.8184]
2022-05-27 01:55:32.680160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:55:33.138299: lr: 0.002158
2022-05-27 01:55:33.140707: This epoch took 97.754140 s

2022-05-27 01:55:33.142876: 
epoch:  409
2022-05-27 01:57:04.844539: train loss : -0.8360
2022-05-27 01:57:15.335430: validation loss: -0.7825
2022-05-27 01:57:15.338880: Average global foreground Dice: [0.8293]
2022-05-27 01:57:15.341210: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:57:15.847483: lr: 0.002137
2022-05-27 01:57:15.850090: This epoch took 102.705191 s

2022-05-27 01:57:15.852619: 
epoch:  410
2022-05-27 01:58:47.670099: train loss : -0.8270
2022-05-27 01:58:57.466127: validation loss: -0.7542
2022-05-27 01:58:57.469634: Average global foreground Dice: [0.816]
2022-05-27 01:58:57.471959: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 01:58:57.920075: lr: 0.002115
2022-05-27 01:58:57.922616: This epoch took 102.067425 s

2022-05-27 01:58:57.924838: 
epoch:  411
2022-05-27 02:00:28.823324: train loss : -0.8286
2022-05-27 02:00:37.288216: validation loss: -0.7556
2022-05-27 02:00:37.291791: Average global foreground Dice: [0.8309]
2022-05-27 02:00:37.293952: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:00:37.803231: lr: 0.002094
2022-05-27 02:00:37.805578: This epoch took 99.878425 s

2022-05-27 02:00:37.807572: 
epoch:  412
2022-05-27 02:02:08.058914: train loss : -0.8243
2022-05-27 02:02:15.847250: validation loss: -0.7648
2022-05-27 02:02:15.850972: Average global foreground Dice: [0.816]
2022-05-27 02:02:15.853323: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:02:16.311007: lr: 0.002072
2022-05-27 02:02:16.313356: This epoch took 98.501353 s

2022-05-27 02:02:16.315510: 
epoch:  413
2022-05-27 02:03:47.615263: train loss : -0.8416
2022-05-27 02:03:56.170004: validation loss: -0.7800
2022-05-27 02:03:56.173580: Average global foreground Dice: [0.8344]
2022-05-27 02:03:56.183028: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:03:56.658615: lr: 0.002051
2022-05-27 02:03:56.661393: This epoch took 100.343886 s

2022-05-27 02:03:56.663450: 
epoch:  414
2022-05-27 02:05:27.003344: train loss : -0.8416
2022-05-27 02:05:36.197461: validation loss: -0.7645
2022-05-27 02:05:36.201558: Average global foreground Dice: [0.811]
2022-05-27 02:05:36.204010: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:05:36.686379: lr: 0.00203
2022-05-27 02:05:36.689133: This epoch took 100.023593 s

2022-05-27 02:05:36.691375: 
epoch:  415
2022-05-27 02:07:10.576108: train loss : -0.8446
2022-05-27 02:07:18.631547: validation loss: -0.7907
2022-05-27 02:07:18.634936: Average global foreground Dice: [0.8267]
2022-05-27 02:07:18.640052: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:07:19.096759: lr: 0.002008
2022-05-27 02:07:19.099674: This epoch took 102.405962 s

2022-05-27 02:07:19.102210: 
epoch:  416
2022-05-27 02:08:50.299844: train loss : -0.8390
2022-05-27 02:08:57.975105: validation loss: -0.7842
2022-05-27 02:08:58.005510: Average global foreground Dice: [0.8348]
2022-05-27 02:08:58.019302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:08:58.615851: lr: 0.001987
2022-05-27 02:08:58.632553: This epoch took 99.527768 s

2022-05-27 02:08:58.650281: 
epoch:  417
2022-05-27 02:10:29.431578: train loss : -0.8426
2022-05-27 02:10:35.889433: validation loss: -0.7817
2022-05-27 02:10:35.893501: Average global foreground Dice: [0.8306]
2022-05-27 02:10:35.896191: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:10:36.361277: lr: 0.001965
2022-05-27 02:10:36.363935: This epoch took 97.698648 s

2022-05-27 02:10:36.366655: 
epoch:  418
2022-05-27 02:12:07.431464: train loss : -0.8401
2022-05-27 02:12:14.538681: validation loss: -0.7496
2022-05-27 02:12:14.542042: Average global foreground Dice: [0.811]
2022-05-27 02:12:14.546712: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:12:15.042570: lr: 0.001943
2022-05-27 02:12:15.045176: This epoch took 98.676296 s

2022-05-27 02:12:15.047906: 
epoch:  419
2022-05-27 02:13:46.579182: train loss : -0.8349
2022-05-27 02:13:59.164907: validation loss: -0.7490
2022-05-27 02:13:59.190955: Average global foreground Dice: [0.8064]
2022-05-27 02:13:59.206399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:13:59.733971: lr: 0.001922
2022-05-27 02:13:59.736476: This epoch took 104.686242 s

2022-05-27 02:13:59.739078: 
epoch:  420
2022-05-27 02:15:31.589921: train loss : -0.8392
2022-05-27 02:15:40.538058: validation loss: -0.7770
2022-05-27 02:15:40.541271: Average global foreground Dice: [0.8174]
2022-05-27 02:15:40.543541: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:15:41.072432: lr: 0.0019
2022-05-27 02:15:41.075143: This epoch took 101.333808 s

2022-05-27 02:15:41.077335: 
epoch:  421
2022-05-27 02:17:15.120330: train loss : -0.8261
2022-05-27 02:17:24.614624: validation loss: -0.7696
2022-05-27 02:17:24.618476: Average global foreground Dice: [0.8228]
2022-05-27 02:17:24.620971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:17:25.156732: lr: 0.001879
2022-05-27 02:17:25.160068: This epoch took 104.080575 s

2022-05-27 02:17:25.162360: 
epoch:  422
2022-05-27 02:18:56.936031: train loss : -0.8318
2022-05-27 02:19:06.039528: validation loss: -0.7388
2022-05-27 02:19:06.064173: Average global foreground Dice: [0.8043]
2022-05-27 02:19:06.066802: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:19:06.542209: lr: 0.001857
2022-05-27 02:19:06.545336: This epoch took 101.380427 s

2022-05-27 02:19:06.547735: 
epoch:  423
2022-05-27 02:20:37.511951: train loss : -0.8408
2022-05-27 02:20:47.037184: validation loss: -0.7368
2022-05-27 02:20:47.041126: Average global foreground Dice: [0.815]
2022-05-27 02:20:47.043993: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:20:47.682413: lr: 0.001835
2022-05-27 02:20:47.717342: This epoch took 101.166768 s

2022-05-27 02:20:47.741300: 
epoch:  424
2022-05-27 02:22:20.317878: train loss : -0.8370
2022-05-27 02:22:27.052633: validation loss: -0.7424
2022-05-27 02:22:27.057069: Average global foreground Dice: [0.8127]
2022-05-27 02:22:27.060863: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:22:27.548432: lr: 0.001813
2022-05-27 02:22:27.550734: This epoch took 99.792361 s

2022-05-27 02:22:27.552972: 
epoch:  425
2022-05-27 02:24:00.187286: train loss : -0.8267
2022-05-27 02:24:11.377872: validation loss: -0.7562
2022-05-27 02:24:11.408761: Average global foreground Dice: [0.8247]
2022-05-27 02:24:11.442613: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:24:12.038642: lr: 0.001792
2022-05-27 02:24:12.056188: This epoch took 104.501018 s

2022-05-27 02:24:12.058671: 
epoch:  426
2022-05-27 02:25:43.341312: train loss : -0.8419
2022-05-27 02:25:50.816153: validation loss: -0.7863
2022-05-27 02:25:50.819114: Average global foreground Dice: [0.8243]
2022-05-27 02:25:50.821610: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:25:51.283078: lr: 0.00177
2022-05-27 02:25:51.285873: This epoch took 99.224412 s

2022-05-27 02:25:51.288286: 
epoch:  427
2022-05-27 02:27:23.837019: train loss : -0.8253
2022-05-27 02:27:36.211522: validation loss: -0.7326
2022-05-27 02:27:36.238863: Average global foreground Dice: [0.8171]
2022-05-27 02:27:36.253943: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:27:36.801320: lr: 0.001748
2022-05-27 02:27:36.804129: This epoch took 105.513132 s

2022-05-27 02:27:36.821014: 
epoch:  428
2022-05-27 02:29:14.523374: train loss : -0.8302
2022-05-27 02:29:23.178978: validation loss: -0.7782
2022-05-27 02:29:23.182875: Average global foreground Dice: [0.8323]
2022-05-27 02:29:23.185879: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:29:23.686044: lr: 0.001726
2022-05-27 02:29:23.688356: This epoch took 106.864203 s

2022-05-27 02:29:23.690455: 
epoch:  429
2022-05-27 02:30:55.181039: train loss : -0.8308
2022-05-27 02:31:04.220872: validation loss: -0.7508
2022-05-27 02:31:04.223916: Average global foreground Dice: [0.807]
2022-05-27 02:31:04.226189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:31:04.703823: lr: 0.001704
2022-05-27 02:31:04.725332: This epoch took 101.032725 s

2022-05-27 02:31:04.736540: 
epoch:  430
2022-05-27 02:32:42.703509: train loss : -0.8335
2022-05-27 02:32:52.981361: validation loss: -0.7561
2022-05-27 02:32:52.984989: Average global foreground Dice: [0.8185]
2022-05-27 02:32:52.987582: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:32:53.484624: lr: 0.001682
2022-05-27 02:32:53.487936: This epoch took 108.747061 s

2022-05-27 02:32:53.490701: 
epoch:  431
2022-05-27 02:34:25.054801: train loss : -0.8222
2022-05-27 02:34:33.564195: validation loss: -0.7801
2022-05-27 02:34:33.569828: Average global foreground Dice: [0.8207]
2022-05-27 02:34:33.580447: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:34:34.119459: lr: 0.00166
2022-05-27 02:34:34.142354: This epoch took 100.648829 s

2022-05-27 02:34:34.147360: 
epoch:  432
2022-05-27 02:36:05.272384: train loss : -0.8378
2022-05-27 02:36:12.854591: validation loss: -0.7611
2022-05-27 02:36:12.857839: Average global foreground Dice: [0.8115]
2022-05-27 02:36:12.861324: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:36:13.390584: lr: 0.001638
2022-05-27 02:36:13.394000: This epoch took 99.242038 s

2022-05-27 02:36:13.402928: 
epoch:  433
2022-05-27 02:37:45.004177: train loss : -0.8351
2022-05-27 02:37:51.325452: validation loss: -0.7849
2022-05-27 02:37:51.329175: Average global foreground Dice: [0.8328]
2022-05-27 02:37:51.331569: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:37:51.799572: lr: 0.001616
2022-05-27 02:37:51.802106: This epoch took 98.396596 s

2022-05-27 02:37:51.804533: 
epoch:  434
2022-05-27 02:39:25.612150: train loss : -0.8432
2022-05-27 02:39:34.709668: validation loss: -0.7537
2022-05-27 02:39:34.713445: Average global foreground Dice: [0.8062]
2022-05-27 02:39:34.716156: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:39:35.171689: lr: 0.001594
2022-05-27 02:39:35.174174: This epoch took 103.367483 s

2022-05-27 02:39:35.176504: 
epoch:  435
2022-05-27 02:41:06.419395: train loss : -0.8439
2022-05-27 02:41:15.929649: validation loss: -0.7693
2022-05-27 02:41:15.933665: Average global foreground Dice: [0.8322]
2022-05-27 02:41:15.936346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:41:16.487077: lr: 0.001572
2022-05-27 02:41:16.490159: This epoch took 101.311308 s

2022-05-27 02:41:16.492726: 
epoch:  436
2022-05-27 02:42:46.921436: train loss : -0.8396
2022-05-27 02:42:55.028627: validation loss: -0.7551
2022-05-27 02:42:55.032091: Average global foreground Dice: [0.8065]
2022-05-27 02:42:55.034346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:42:55.503798: lr: 0.00155
2022-05-27 02:42:55.506557: This epoch took 99.011062 s

2022-05-27 02:42:55.508788: 
epoch:  437
2022-05-27 02:44:27.315747: train loss : -0.8405
2022-05-27 02:44:35.845949: validation loss: -0.7836
2022-05-27 02:44:35.849861: Average global foreground Dice: [0.8327]
2022-05-27 02:44:35.852207: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:44:36.385161: lr: 0.001528
2022-05-27 02:44:36.389376: This epoch took 100.878267 s

2022-05-27 02:44:36.415565: 
epoch:  438
2022-05-27 02:46:07.240495: train loss : -0.8411
2022-05-27 02:46:13.855047: validation loss: -0.7741
2022-05-27 02:46:13.858529: Average global foreground Dice: [0.8296]
2022-05-27 02:46:13.863088: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:46:14.378052: lr: 0.001506
2022-05-27 02:46:14.380699: This epoch took 97.961423 s

2022-05-27 02:46:14.382740: 
epoch:  439
2022-05-27 02:47:45.731705: train loss : -0.8396
2022-05-27 02:47:55.563916: validation loss: -0.7641
2022-05-27 02:47:55.567710: Average global foreground Dice: [0.821]
2022-05-27 02:47:55.570014: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:47:56.052537: lr: 0.001483
2022-05-27 02:47:56.055604: This epoch took 101.665216 s

2022-05-27 02:47:56.058316: 
epoch:  440
2022-05-27 02:49:29.100926: train loss : -0.8374
2022-05-27 02:49:38.134412: validation loss: -0.7822
2022-05-27 02:49:38.138293: Average global foreground Dice: [0.8241]
2022-05-27 02:49:38.140727: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:49:38.602343: lr: 0.001461
2022-05-27 02:49:38.604976: This epoch took 102.544110 s

2022-05-27 02:49:38.607143: 
epoch:  441
2022-05-27 02:51:09.765499: train loss : -0.8332
2022-05-27 02:51:19.349699: validation loss: -0.7817
2022-05-27 02:51:19.354281: Average global foreground Dice: [0.839]
2022-05-27 02:51:19.357497: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:51:19.857593: lr: 0.001439
2022-05-27 02:51:19.865864: This epoch took 101.256566 s

2022-05-27 02:51:19.898372: 
epoch:  442
2022-05-27 02:52:51.054459: train loss : -0.8400
2022-05-27 02:52:58.914390: validation loss: -0.7697
2022-05-27 02:52:58.918184: Average global foreground Dice: [0.815]
2022-05-27 02:52:58.920970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:52:59.423422: lr: 0.001416
2022-05-27 02:52:59.426232: This epoch took 99.522871 s

2022-05-27 02:52:59.428612: 
epoch:  443
2022-05-27 02:54:32.243752: train loss : -0.8489
2022-05-27 02:54:41.848742: validation loss: -0.7739
2022-05-27 02:54:41.855784: Average global foreground Dice: [0.8323]
2022-05-27 02:54:41.858389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:54:42.375617: lr: 0.001394
2022-05-27 02:54:42.397331: This epoch took 102.966058 s

2022-05-27 02:54:42.440622: 
epoch:  444
2022-05-27 02:56:14.255013: train loss : -0.8416
2022-05-27 02:56:24.710099: validation loss: -0.7756
2022-05-27 02:56:24.729225: Average global foreground Dice: [0.8199]
2022-05-27 02:56:24.731953: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:56:25.237514: lr: 0.001372
2022-05-27 02:56:25.240412: This epoch took 102.780071 s

2022-05-27 02:56:25.243007: 
epoch:  445
2022-05-27 02:57:58.184473: train loss : -0.8380
2022-05-27 02:58:09.267676: validation loss: -0.7764
2022-05-27 02:58:09.271238: Average global foreground Dice: [0.8082]
2022-05-27 02:58:09.273463: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:58:09.739836: lr: 0.001349
2022-05-27 02:58:09.742379: This epoch took 104.496809 s

2022-05-27 02:58:09.744912: 
epoch:  446
2022-05-27 02:59:43.624755: train loss : -0.8451
2022-05-27 02:59:53.199757: validation loss: -0.7805
2022-05-27 02:59:53.205596: Average global foreground Dice: [0.8227]
2022-05-27 02:59:53.208468: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 02:59:53.697102: lr: 0.001327
2022-05-27 02:59:53.700740: This epoch took 103.953374 s

2022-05-27 02:59:53.710943: 
epoch:  447
2022-05-27 03:01:24.519823: train loss : -0.8407
2022-05-27 03:01:33.547528: validation loss: -0.7786
2022-05-27 03:01:33.578652: Average global foreground Dice: [0.8199]
2022-05-27 03:01:33.594303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:01:34.301122: lr: 0.001304
2022-05-27 03:01:34.304707: This epoch took 100.591401 s

2022-05-27 03:01:34.307494: 
epoch:  448
2022-05-27 03:03:07.613746: train loss : -0.8478
2022-05-27 03:03:16.866465: validation loss: -0.7797
2022-05-27 03:03:16.889223: Average global foreground Dice: [0.8248]
2022-05-27 03:03:16.908876: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:03:17.503304: lr: 0.001282
2022-05-27 03:03:17.514376: This epoch took 103.204306 s

2022-05-27 03:03:17.525394: 
epoch:  449
2022-05-27 03:04:49.133755: train loss : -0.8511
2022-05-27 03:04:57.697444: validation loss: -0.7564
2022-05-27 03:04:57.722870: Average global foreground Dice: [0.8228]
2022-05-27 03:04:57.747671: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:04:58.252002: lr: 0.001259
2022-05-27 03:04:58.267303: saving scheduled checkpoint file...
2022-05-27 03:04:58.342266: saving checkpoint...
2022-05-27 03:04:59.464513: done, saving took 1.18 seconds
2022-05-27 03:04:59.480847: done
2022-05-27 03:04:59.483262: This epoch took 101.953987 s

2022-05-27 03:04:59.485629: 
epoch:  450
2022-05-27 03:06:30.007995: train loss : -0.8304
2022-05-27 03:06:39.676121: validation loss: -0.7781
2022-05-27 03:06:39.679395: Average global foreground Dice: [0.8389]
2022-05-27 03:06:39.683372: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:06:40.184726: lr: 0.001236
2022-05-27 03:06:40.187171: This epoch took 100.698036 s

2022-05-27 03:06:40.189856: 
epoch:  451
2022-05-27 03:08:10.823113: train loss : -0.8456
2022-05-27 03:08:18.200824: validation loss: -0.8049
2022-05-27 03:08:18.204967: Average global foreground Dice: [0.839]
2022-05-27 03:08:18.207745: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:08:18.671963: lr: 0.001214
2022-05-27 03:08:18.674348: This epoch took 98.482482 s

2022-05-27 03:08:18.676865: 
epoch:  452
2022-05-27 03:09:50.899563: train loss : -0.8496
2022-05-27 03:10:00.731894: validation loss: -0.7640
2022-05-27 03:10:00.735324: Average global foreground Dice: [0.8215]
2022-05-27 03:10:00.737357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:10:01.204009: lr: 0.001191
2022-05-27 03:10:01.215252: This epoch took 102.536328 s

2022-05-27 03:10:01.218690: 
epoch:  453
2022-05-27 03:11:32.232047: train loss : -0.8535
2022-05-27 03:11:40.939231: validation loss: -0.7674
2022-05-27 03:11:40.943406: Average global foreground Dice: [0.8313]
2022-05-27 03:11:40.945926: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:11:41.420390: lr: 0.001168
2022-05-27 03:11:41.422902: This epoch took 100.200846 s

2022-05-27 03:11:41.424991: 
epoch:  454
2022-05-27 03:13:15.618581: train loss : -0.8442
2022-05-27 03:13:24.729140: validation loss: -0.7529
2022-05-27 03:13:24.732705: Average global foreground Dice: [0.8283]
2022-05-27 03:13:24.735805: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:13:25.202541: lr: 0.001145
2022-05-27 03:13:25.205258: This epoch took 103.777920 s

2022-05-27 03:13:25.207624: 
epoch:  455
2022-05-27 03:15:01.496924: train loss : -0.8567
2022-05-27 03:15:12.042984: validation loss: -0.7859
2022-05-27 03:15:12.046345: Average global foreground Dice: [0.8399]
2022-05-27 03:15:12.048655: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:15:12.578391: lr: 0.001122
2022-05-27 03:15:12.640392: saving checkpoint...
2022-05-27 03:15:14.094146: done, saving took 1.51 seconds
2022-05-27 03:15:14.111433: This epoch took 108.901084 s

2022-05-27 03:15:14.114618: 
epoch:  456
2022-05-27 03:16:45.056348: train loss : -0.8449
2022-05-27 03:16:53.649211: validation loss: -0.7521
2022-05-27 03:16:53.663645: Average global foreground Dice: [0.8168]
2022-05-27 03:16:53.680297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:16:54.161923: lr: 0.001099
2022-05-27 03:16:54.183411: This epoch took 100.066411 s

2022-05-27 03:16:54.205278: 
epoch:  457
2022-05-27 03:18:29.471613: train loss : -0.8434
2022-05-27 03:18:37.647262: validation loss: -0.7484
2022-05-27 03:18:37.650410: Average global foreground Dice: [0.8255]
2022-05-27 03:18:37.652858: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:18:38.107131: lr: 0.001076
2022-05-27 03:18:38.109548: This epoch took 103.881492 s

2022-05-27 03:18:38.111780: 
epoch:  458
2022-05-27 03:20:09.162608: train loss : -0.8537
2022-05-27 03:20:17.666645: validation loss: -0.7869
2022-05-27 03:20:17.672353: Average global foreground Dice: [0.8416]
2022-05-27 03:20:17.678021: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:20:18.255129: lr: 0.001053
2022-05-27 03:20:18.285488: saving checkpoint...
2022-05-27 03:20:19.404070: done, saving took 1.15 seconds
2022-05-27 03:20:19.418860: This epoch took 101.304782 s

2022-05-27 03:20:19.420973: 
epoch:  459
2022-05-27 03:21:54.115906: train loss : -0.8440
2022-05-27 03:22:02.699392: validation loss: -0.7685
2022-05-27 03:22:02.704070: Average global foreground Dice: [0.8298]
2022-05-27 03:22:02.711419: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:22:03.195261: lr: 0.00103
2022-05-27 03:22:03.234126: saving checkpoint...
2022-05-27 03:22:04.313001: done, saving took 1.12 seconds
2022-05-27 03:22:04.328563: This epoch took 104.905391 s

2022-05-27 03:22:04.330833: 
epoch:  460
2022-05-27 03:23:38.518096: train loss : -0.8528
2022-05-27 03:23:46.606601: validation loss: -0.7618
2022-05-27 03:23:46.612502: Average global foreground Dice: [0.8238]
2022-05-27 03:23:46.615084: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:23:47.082814: lr: 0.001007
2022-05-27 03:23:47.086354: This epoch took 102.753147 s

2022-05-27 03:23:47.089931: 
epoch:  461
2022-05-27 03:25:19.293781: train loss : -0.8431
2022-05-27 03:25:28.511585: validation loss: -0.7737
2022-05-27 03:25:28.515024: Average global foreground Dice: [0.8206]
2022-05-27 03:25:28.518409: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:25:28.999050: lr: 0.000983
2022-05-27 03:25:29.001425: This epoch took 101.909112 s

2022-05-27 03:25:29.003534: 
epoch:  462
2022-05-27 03:27:00.211379: train loss : -0.8459
2022-05-27 03:27:08.878343: validation loss: -0.7611
2022-05-27 03:27:08.882020: Average global foreground Dice: [0.8135]
2022-05-27 03:27:08.884561: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:27:09.347705: lr: 0.00096
2022-05-27 03:27:09.351882: This epoch took 100.346262 s

2022-05-27 03:27:09.354138: 
epoch:  463
2022-05-27 03:28:44.585538: train loss : -0.8480
2022-05-27 03:28:52.958766: validation loss: -0.7711
2022-05-27 03:28:52.962264: Average global foreground Dice: [0.8172]
2022-05-27 03:28:52.964709: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:28:53.411616: lr: 0.000937
2022-05-27 03:28:53.414416: This epoch took 104.058017 s

2022-05-27 03:28:53.416651: 
epoch:  464
2022-05-27 03:30:23.491309: train loss : -0.8536
2022-05-27 03:30:32.604051: validation loss: -0.7667
2022-05-27 03:30:32.617068: Average global foreground Dice: [0.8212]
2022-05-27 03:30:32.619206: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:30:33.186121: lr: 0.000913
2022-05-27 03:30:33.191047: This epoch took 99.772304 s

2022-05-27 03:30:33.193457: 
epoch:  465
2022-05-27 03:32:04.495934: train loss : -0.8425
2022-05-27 03:32:10.931123: validation loss: -0.7904
2022-05-27 03:32:10.934682: Average global foreground Dice: [0.8265]
2022-05-27 03:32:10.937150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:32:11.397080: lr: 0.00089
2022-05-27 03:32:11.399802: This epoch took 98.204162 s

2022-05-27 03:32:11.402272: 
epoch:  466
2022-05-27 03:33:42.614499: train loss : -0.8489
2022-05-27 03:33:51.111627: validation loss: -0.7788
2022-05-27 03:33:51.132527: Average global foreground Dice: [0.8228]
2022-05-27 03:33:51.135041: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:33:51.607548: lr: 0.000866
2022-05-27 03:33:51.609938: This epoch took 100.205066 s

2022-05-27 03:33:51.612152: 
epoch:  467
2022-05-27 03:35:22.366626: train loss : -0.8464
2022-05-27 03:35:30.507033: validation loss: -0.7963
2022-05-27 03:35:30.510704: Average global foreground Dice: [0.8399]
2022-05-27 03:35:30.513024: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:35:30.969387: lr: 0.000842
2022-05-27 03:35:30.972273: This epoch took 99.358032 s

2022-05-27 03:35:30.974634: 
epoch:  468
2022-05-27 03:37:04.275941: train loss : -0.8521
2022-05-27 03:37:13.029164: validation loss: -0.7495
2022-05-27 03:37:13.032372: Average global foreground Dice: [0.8224]
2022-05-27 03:37:13.034682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:37:13.517840: lr: 0.000819
2022-05-27 03:37:13.520480: This epoch took 102.543016 s

2022-05-27 03:37:13.523093: 
epoch:  469
2022-05-27 03:38:48.577836: train loss : -0.8549
2022-05-27 03:38:58.284274: validation loss: -0.7676
2022-05-27 03:38:58.288251: Average global foreground Dice: [0.8207]
2022-05-27 03:38:58.290822: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:38:58.755774: lr: 0.000795
2022-05-27 03:38:58.758514: This epoch took 105.233145 s

2022-05-27 03:38:58.760881: 
epoch:  470
2022-05-27 03:40:29.327881: train loss : -0.8520
2022-05-27 03:40:37.621471: validation loss: -0.7729
2022-05-27 03:40:37.624797: Average global foreground Dice: [0.831]
2022-05-27 03:40:37.627081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:40:38.089179: lr: 0.000771
2022-05-27 03:40:38.091554: This epoch took 99.327999 s

2022-05-27 03:40:38.095095: 
epoch:  471
2022-05-27 03:42:09.268355: train loss : -0.8557
2022-05-27 03:42:16.260520: validation loss: -0.7895
2022-05-27 03:42:16.287806: Average global foreground Dice: [0.8336]
2022-05-27 03:42:16.303299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:42:16.807981: lr: 0.000747
2022-05-27 03:42:16.810309: This epoch took 98.711720 s

2022-05-27 03:42:16.812436: 
epoch:  472
2022-05-27 03:43:47.895034: train loss : -0.8477
2022-05-27 03:43:55.444452: validation loss: -0.7623
2022-05-27 03:43:55.448078: Average global foreground Dice: [0.8181]
2022-05-27 03:43:55.450381: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:43:55.894392: lr: 0.000723
2022-05-27 03:43:55.896709: This epoch took 99.082271 s

2022-05-27 03:43:55.898873: 
epoch:  473
2022-05-27 03:45:27.558658: train loss : -0.8492
2022-05-27 03:45:38.552566: validation loss: -0.7882
2022-05-27 03:45:38.555781: Average global foreground Dice: [0.8434]
2022-05-27 03:45:38.558043: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:45:39.029862: lr: 0.000699
2022-05-27 03:45:39.032732: This epoch took 103.131832 s

2022-05-27 03:45:39.034901: 
epoch:  474
2022-05-27 03:47:09.478607: train loss : -0.8501
2022-05-27 03:47:16.666720: validation loss: -0.7632
2022-05-27 03:47:16.670105: Average global foreground Dice: [0.8308]
2022-05-27 03:47:16.672516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:47:17.120103: lr: 0.000675
2022-05-27 03:47:17.122466: This epoch took 98.085636 s

2022-05-27 03:47:17.124671: 
epoch:  475
2022-05-27 03:48:47.868911: train loss : -0.8551
2022-05-27 03:48:54.895191: validation loss: -0.7672
2022-05-27 03:48:54.898578: Average global foreground Dice: [0.8142]
2022-05-27 03:48:54.900925: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:48:55.361751: lr: 0.00065
2022-05-27 03:48:55.365134: This epoch took 98.238367 s

2022-05-27 03:48:55.367491: 
epoch:  476
2022-05-27 03:50:26.849997: train loss : -0.8551
2022-05-27 03:50:36.442369: validation loss: -0.7842
2022-05-27 03:50:36.465735: Average global foreground Dice: [0.8405]
2022-05-27 03:50:36.495262: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:50:37.064190: lr: 0.000626
2022-05-27 03:50:37.084559: This epoch took 101.714682 s

2022-05-27 03:50:37.104349: 
epoch:  477
2022-05-27 03:52:10.502483: train loss : -0.8417
2022-05-27 03:52:19.905434: validation loss: -0.8001
2022-05-27 03:52:19.935681: Average global foreground Dice: [0.8337]
2022-05-27 03:52:19.950313: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:52:20.561086: lr: 0.000601
2022-05-27 03:52:20.605104: saving checkpoint...
2022-05-27 03:52:21.710338: done, saving took 1.15 seconds
2022-05-27 03:52:21.726400: This epoch took 104.611374 s

2022-05-27 03:52:21.728865: 
epoch:  478
2022-05-27 03:53:58.161332: train loss : -0.8385
2022-05-27 03:54:06.633261: validation loss: -0.7896
2022-05-27 03:54:06.636557: Average global foreground Dice: [0.8378]
2022-05-27 03:54:06.638812: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:54:07.110503: lr: 0.000577
2022-05-27 03:54:07.162763: saving checkpoint...
2022-05-27 03:54:08.262729: done, saving took 1.15 seconds
2022-05-27 03:54:08.277190: This epoch took 106.545907 s

2022-05-27 03:54:08.279523: 
epoch:  479
2022-05-27 03:55:39.084773: train loss : -0.8547
2022-05-27 03:55:46.678259: validation loss: -0.7705
2022-05-27 03:55:46.683565: Average global foreground Dice: [0.8281]
2022-05-27 03:55:46.686503: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:55:47.145455: lr: 0.000552
2022-05-27 03:55:47.147883: This epoch took 98.866286 s

2022-05-27 03:55:47.153416: 
epoch:  480
2022-05-27 03:57:19.196152: train loss : -0.8440
2022-05-27 03:57:28.402934: validation loss: -0.7807
2022-05-27 03:57:28.406300: Average global foreground Dice: [0.824]
2022-05-27 03:57:28.421303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:57:29.051709: lr: 0.000527
2022-05-27 03:57:29.062371: This epoch took 101.906789 s

2022-05-27 03:57:29.098446: 
epoch:  481
2022-05-27 03:59:07.060951: train loss : -0.8424
2022-05-27 03:59:17.257271: validation loss: -0.7929
2022-05-27 03:59:17.260503: Average global foreground Dice: [0.8356]
2022-05-27 03:59:17.266312: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 03:59:17.808148: lr: 0.000502
2022-05-27 03:59:17.857962: saving checkpoint...
2022-05-27 03:59:19.008401: done, saving took 1.20 seconds
2022-05-27 03:59:19.024804: This epoch took 109.912985 s

2022-05-27 03:59:19.027035: 
epoch:  482
2022-05-27 04:00:50.409232: train loss : -0.8515
2022-05-27 04:00:58.897790: validation loss: -0.7701
2022-05-27 04:00:58.903928: Average global foreground Dice: [0.8239]
2022-05-27 04:00:58.906444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:00:59.392000: lr: 0.000477
2022-05-27 04:00:59.395121: This epoch took 100.365534 s

2022-05-27 04:00:59.397666: 
epoch:  483
2022-05-27 04:02:30.182354: train loss : -0.8580
2022-05-27 04:02:36.033101: validation loss: -0.7762
2022-05-27 04:02:36.036997: Average global foreground Dice: [0.8277]
2022-05-27 04:02:36.039435: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:02:36.520180: lr: 0.000451
2022-05-27 04:02:36.523065: This epoch took 97.118315 s

2022-05-27 04:02:36.525302: 
epoch:  484
2022-05-27 04:04:07.485277: train loss : -0.8454
2022-05-27 04:04:13.596469: validation loss: -0.7798
2022-05-27 04:04:13.599770: Average global foreground Dice: [0.8259]
2022-05-27 04:04:13.602058: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:04:14.058120: lr: 0.000426
2022-05-27 04:04:14.060346: This epoch took 97.532915 s

2022-05-27 04:04:14.062335: 
epoch:  485
2022-05-27 04:05:44.768530: train loss : -0.8487
2022-05-27 04:05:54.523769: validation loss: -0.7623
2022-05-27 04:05:54.527543: Average global foreground Dice: [0.8411]
2022-05-27 04:05:54.530054: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:05:55.029003: lr: 0.0004
2022-05-27 04:05:55.100969: saving checkpoint...
2022-05-27 04:05:56.179190: done, saving took 1.12 seconds
2022-05-27 04:05:56.193238: This epoch took 102.128972 s

2022-05-27 04:05:56.196004: 
epoch:  486
2022-05-27 04:07:27.059127: train loss : -0.8465
2022-05-27 04:07:35.792501: validation loss: -0.7608
2022-05-27 04:07:35.795878: Average global foreground Dice: [0.8238]
2022-05-27 04:07:35.798738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:07:36.246569: lr: 0.000375
2022-05-27 04:07:36.248927: This epoch took 100.050707 s

2022-05-27 04:07:36.250574: 
epoch:  487
2022-05-27 04:09:07.083556: train loss : -0.8475
2022-05-27 04:09:14.551795: validation loss: -0.7772
2022-05-27 04:09:14.555216: Average global foreground Dice: [0.824]
2022-05-27 04:09:14.557659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:09:15.024154: lr: 0.000348
2022-05-27 04:09:15.026574: This epoch took 98.773342 s

2022-05-27 04:09:15.028661: 
epoch:  488
2022-05-27 04:10:46.990705: train loss : -0.8490
2022-05-27 04:10:55.118921: validation loss: -0.7542
2022-05-27 04:10:55.122368: Average global foreground Dice: [0.8328]
2022-05-27 04:10:55.124709: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:10:55.605146: lr: 0.000322
2022-05-27 04:10:55.608035: This epoch took 100.577346 s

2022-05-27 04:10:55.610366: 
epoch:  489
2022-05-27 04:12:26.810525: train loss : -0.8584
2022-05-27 04:12:36.689251: validation loss: -0.7854
2022-05-27 04:12:36.692652: Average global foreground Dice: [0.8283]
2022-05-27 04:12:36.695637: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:12:37.238017: lr: 0.000296
2022-05-27 04:12:37.247089: This epoch took 101.634372 s

2022-05-27 04:12:37.261986: 
epoch:  490
2022-05-27 04:14:08.419979: train loss : -0.8581
2022-05-27 04:14:17.230187: validation loss: -0.7831
2022-05-27 04:14:17.233758: Average global foreground Dice: [0.85]
2022-05-27 04:14:17.236191: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:14:17.693720: lr: 0.000269
2022-05-27 04:14:17.751715: saving checkpoint...
2022-05-27 04:14:19.052203: done, saving took 1.36 seconds
2022-05-27 04:14:19.068731: This epoch took 101.786391 s

2022-05-27 04:14:19.071651: 
epoch:  491
2022-05-27 04:15:55.054292: train loss : -0.8614
2022-05-27 04:16:04.530619: validation loss: -0.7471
2022-05-27 04:16:04.533865: Average global foreground Dice: [0.8267]
2022-05-27 04:16:04.536572: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:16:04.993834: lr: 0.000242
2022-05-27 04:16:04.996569: This epoch took 105.922252 s

2022-05-27 04:16:04.998678: 
epoch:  492
2022-05-27 04:17:41.541172: train loss : -0.8536
2022-05-27 04:17:51.671545: validation loss: -0.7816
2022-05-27 04:17:51.694691: Average global foreground Dice: [0.8235]
2022-05-27 04:17:51.716348: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:17:52.205883: lr: 0.000215
2022-05-27 04:17:52.213295: This epoch took 107.212192 s

2022-05-27 04:17:52.236275: 
epoch:  493
2022-05-27 04:19:23.152714: train loss : -0.8493
2022-05-27 04:19:32.327004: validation loss: -0.7818
2022-05-27 04:19:32.330615: Average global foreground Dice: [0.8306]
2022-05-27 04:19:32.332943: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:19:32.806038: lr: 0.000187
2022-05-27 04:19:32.808349: This epoch took 100.556074 s

2022-05-27 04:19:32.810450: 
epoch:  494
2022-05-27 04:21:05.905140: train loss : -0.8638
2022-05-27 04:21:15.755210: validation loss: -0.7801
2022-05-27 04:21:15.758952: Average global foreground Dice: [0.8234]
2022-05-27 04:21:15.762729: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:21:16.231037: lr: 0.000158
2022-05-27 04:21:16.233463: This epoch took 103.420954 s

2022-05-27 04:21:16.235506: 
epoch:  495
2022-05-27 04:22:47.326545: train loss : -0.8564
2022-05-27 04:22:54.172961: validation loss: -0.7586
2022-05-27 04:22:54.176131: Average global foreground Dice: [0.8133]
2022-05-27 04:22:54.178398: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:22:54.671118: lr: 0.00013
2022-05-27 04:22:54.674538: This epoch took 98.437064 s

2022-05-27 04:22:54.677970: 
epoch:  496
2022-05-27 04:24:25.719581: train loss : -0.8624
2022-05-27 04:24:33.552766: validation loss: -0.7935
2022-05-27 04:24:33.569429: Average global foreground Dice: [0.8344]
2022-05-27 04:24:33.571995: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:24:34.028563: lr: 0.0001
2022-05-27 04:24:34.030905: This epoch took 99.350406 s

2022-05-27 04:24:34.033188: 
epoch:  497
2022-05-27 04:26:05.742729: train loss : -0.8496
2022-05-27 04:26:14.911780: validation loss: -0.7633
2022-05-27 04:26:14.915471: Average global foreground Dice: [0.8218]
2022-05-27 04:26:14.917541: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:26:15.380654: lr: 6.9e-05
2022-05-27 04:26:15.386156: This epoch took 101.350879 s

2022-05-27 04:26:15.388179: 
epoch:  498
2022-05-27 04:27:49.129272: train loss : -0.8551
2022-05-27 04:27:56.876642: validation loss: -0.7834
2022-05-27 04:27:56.879983: Average global foreground Dice: [0.8241]
2022-05-27 04:27:56.882059: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:27:57.348477: lr: 3.7e-05
2022-05-27 04:27:57.353669: This epoch took 101.963450 s

2022-05-27 04:27:57.374485: 
epoch:  499
2022-05-27 04:29:28.282022: train loss : -0.8522
2022-05-27 04:29:36.557713: validation loss: -0.7831
2022-05-27 04:29:36.562819: Average global foreground Dice: [0.8404]
2022-05-27 04:29:36.565205: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:29:37.040060: lr: 0.0
2022-05-27 04:29:37.042221: saving scheduled checkpoint file...
2022-05-27 04:29:37.092816: saving checkpoint...
2022-05-27 04:29:38.154378: done, saving took 1.11 seconds
2022-05-27 04:29:38.172133: done
2022-05-27 04:29:38.175292: This epoch took 100.796148 s

2022-05-27 04:29:38.224395: saving checkpoint...
2022-05-27 04:29:39.168031: done, saving took 0.99 seconds
panc_024 (2, 102, 314, 314)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 314, 314)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 61, 122], [0, 61, 122]]
number of tiles: 27
computing Gaussian
done
prediction done
panc_040 (2, 87, 326, 326)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 326, 326)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 67, 134], [0, 67, 134]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_048 (2, 117, 384, 384)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 384, 384)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 96, 192], [0, 96, 192]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_058 (2, 177, 376, 376)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 177, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 85, 113], [0, 92, 184], [0, 92, 184]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_067 (2, 100, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 66, 133], [0, 66, 133]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_075 (2, 59, 323, 323)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 66, 131], [0, 66, 131]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_086 (2, 50, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 82, 163], [0, 82, 163]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_101 (2, 190, 298, 298)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 190, 298, 298)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 63, 94, 126], [0, 53, 106], [0, 53, 106]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_105 (2, 190, 304, 304)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 190, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 63, 94, 126], [0, 56, 112], [0, 56, 112]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_107 (2, 99, 309, 309)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 58, 117], [0, 58, 117]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_113 (2, 97, 273, 273)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 273, 273)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 81], [0, 81]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_119 (2, 83, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_131 (2, 57, 318, 318)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 63, 126], [0, 63, 126]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_137 (2, 83, 332, 332)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_148 (2, 82, 301, 301)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 54, 109], [0, 54, 109]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_157 (2, 75, 309, 309)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_182 (2, 77, 267, 267)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 77, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 13], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_191 (2, 55, 292, 292)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 292, 292)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 50, 100], [0, 50, 100]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_193 (2, 110, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 58, 116], [0, 58, 116]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_194 (2, 95, 289, 289)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 289, 289)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 48, 97], [0, 48, 97]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_204 (2, 71, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_207 (2, 79, 291, 291)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_211 (2, 117, 362, 362)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 85, 170], [0, 85, 170]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_215 (2, 96, 300, 300)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 300, 300)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 54, 108], [0, 54, 108]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_219 (2, 186, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 80
using precomputed Gaussian
prediction done
panc_224 (2, 90, 342, 342)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 75, 150], [0, 75, 150]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_236 (2, 79, 340, 340)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 74, 148], [0, 74, 148]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_241 (2, 96, 316, 316)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 62, 124], [0, 62, 124]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_256 (2, 86, 306, 306)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 306, 306)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 57, 114], [0, 57, 114]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_285 (2, 110, 329, 329)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 329, 329)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 68, 137], [0, 68, 137]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_286 (2, 90, 304, 304)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_294 (2, 94, 321, 321)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_296 (2, 83, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_302 (2, 81, 375, 375)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 375, 375)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 92, 183], [0, 92, 183]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_305 (2, 71, 293, 293)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 293, 293)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 50, 101], [0, 50, 101]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_321 (2, 114, 354, 354)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 354, 354)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 81, 162], [0, 81, 162]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_325 (2, 90, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_364 (2, 86, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_367 (2, 101, 342, 342)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 75, 150], [0, 75, 150]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_369 (2, 94, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_374 (2, 133, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 133, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46, 69], [0, 51, 102], [0, 51, 102]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_386 (2, 79, 301, 301)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 54, 109], [0, 54, 109]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_393 (2, 116, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 116, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_399 (2, 113, 371, 371)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 113, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49], [0, 90, 179], [0, 90, 179]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_410 (2, 98, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_412 (2, 191, 362, 362)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 191, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 64, 95, 127], [0, 85, 170], [0, 85, 170]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_413 (2, 83, 309, 309)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_415 (2, 118, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 118, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27, 54], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done
2022-05-27 04:38:51.066997: finished prediction
2022-05-27 04:38:51.071092: evaluation of raw predictions
2022-05-27 04:39:16.279815: determining postprocessing
Foreground vs background
before: 0.8236074998683384
after:  0.8240219645589907
Removing all but the largest foreground region improved results!
for_which_classes [1]
min_valid_object_sizes None
Only one class present, no need to do each class separately as this is covered in fg vs bg
done
for which classes:
[[1]]
min_object_sizes
None
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
done
predicting segmentations for the next stage of the cascade
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
panc_024
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 314, 314)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 61, 122], [0, 61, 122]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_040
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 326, 326)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 67, 134], [0, 67, 134]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_048
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 384, 384)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 96, 192], [0, 96, 192]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_058
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 177, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 85, 113], [0, 92, 184], [0, 92, 184]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_067
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 66, 133], [0, 66, 133]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_075
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 66, 131], [0, 66, 131]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_086
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 82, 163], [0, 82, 163]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_101
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 190, 298, 298)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 63, 94, 126], [0, 53, 106], [0, 53, 106]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_105
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 190, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 63, 94, 126], [0, 56, 112], [0, 56, 112]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_107
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 58, 117], [0, 58, 117]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_113
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 273, 273)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 81], [0, 81]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_119
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_131
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 63, 126], [0, 63, 126]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_137
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_148
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 54, 109], [0, 54, 109]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_157
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_182
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 77, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 13], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_191
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 292, 292)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 50, 100], [0, 50, 100]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_193
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 58, 116], [0, 58, 116]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_194
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 289, 289)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 48, 97], [0, 48, 97]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_204
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_207
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_211
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 85, 170], [0, 85, 170]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_215
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 300, 300)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 54, 108], [0, 54, 108]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_219
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 80
using precomputed Gaussian
prediction done
panc_224
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 75, 150], [0, 75, 150]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_236
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 74, 148], [0, 74, 148]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_241
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 62, 124], [0, 62, 124]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_256
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 306, 306)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 57, 114], [0, 57, 114]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_285
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 329, 329)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 68, 137], [0, 68, 137]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_286
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_294
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_296
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_302
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 375, 375)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 92, 183], [0, 92, 183]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_305
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 293, 293)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 50, 101], [0, 50, 101]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_321
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 354, 354)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 81, 162], [0, 81, 162]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_325
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_364
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_367
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 75, 150], [0, 75, 150]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_369
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_374
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 133, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46, 69], [0, 51, 102], [0, 51, 102]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_386
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 54, 109], [0, 54, 109]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_393
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 116, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_399
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 113, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49], [0, 90, 179], [0, 90, 179]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_410
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_412
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 191, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 64, 95, 127], [0, 85, 170], [0, 85, 170]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_413
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_415
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 118, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27, 54], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_lowres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 93, 318, 318]), 'current_spacing': array([2.5757525 , 1.29418872, 1.29418872]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 40, 224, 224]), 'median_patient_size_in_voxels': array([ 96, 512, 512]), 'current_spacing': array([2.5       , 0.80273402, 0.80273402]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-05-27 04:50:53.573079: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/splits_final.pkl
2022-05-27 04:50:53.600069: The split file contains 5 splits.
2022-05-27 04:50:53.602416: Desired fold for training: 1
2022-05-27 04:50:53.604468: This split has 191 training and 48 validation cases.
unpacking dataset
done
Susy hier
Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-27 04:50:57.239554: lr: 0.01
using pin_memory on device 0
using pin_memory on device 0
2022-05-27 04:51:04.166890: Unable to plot network architecture:
2022-05-27 04:51:04.190279: No module named 'hiddenlayer'
2022-05-27 04:51:04.212332: 
printing the network instead:

2022-05-27 04:51:04.235054: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-27 04:51:04.249277: 

2022-05-27 04:51:04.257883: 
epoch:  0
2022-05-27 04:52:49.272729: train loss : -0.0606
2022-05-27 04:52:56.782040: validation loss: -0.1794
2022-05-27 04:52:56.822759: Average global foreground Dice: [0.2823]
2022-05-27 04:52:56.835718: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:52:57.877995: lr: 0.009982
2022-05-27 04:52:57.911353: This epoch took 113.650911 s

2022-05-27 04:52:57.936215: 
epoch:  1
2022-05-27 04:54:31.138668: train loss : -0.2718
2022-05-27 04:54:40.435578: validation loss: -0.3458
2022-05-27 04:54:40.438633: Average global foreground Dice: [0.4433]
2022-05-27 04:54:40.441173: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:54:40.886869: lr: 0.009964
2022-05-27 04:54:40.938956: saving checkpoint...
2022-05-27 04:54:41.993592: done, saving took 1.10 seconds
2022-05-27 04:54:42.015811: This epoch took 104.059484 s

2022-05-27 04:54:42.026616: 
epoch:  2
2022-05-27 04:56:15.220897: train loss : -0.3525
2022-05-27 04:56:24.282011: validation loss: -0.3313
2022-05-27 04:56:24.298425: Average global foreground Dice: [0.4127]
2022-05-27 04:56:24.308012: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:56:24.792907: lr: 0.009946
2022-05-27 04:56:24.843436: saving checkpoint...
2022-05-27 04:56:25.842788: done, saving took 1.05 seconds
2022-05-27 04:56:25.860418: This epoch took 103.822136 s

2022-05-27 04:56:25.862695: 
epoch:  3
2022-05-27 04:57:57.988952: train loss : -0.4062
2022-05-27 04:58:06.943557: validation loss: -0.4073
2022-05-27 04:58:06.972065: Average global foreground Dice: [0.4941]
2022-05-27 04:58:07.002303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:58:07.929887: lr: 0.009928
2022-05-27 04:58:08.015197: saving checkpoint...
2022-05-27 04:58:09.113563: done, saving took 1.16 seconds
2022-05-27 04:58:09.174302: This epoch took 103.309434 s

2022-05-27 04:58:09.205590: 
epoch:  4
2022-05-27 04:59:43.617701: train loss : -0.4602
2022-05-27 04:59:52.414805: validation loss: -0.4919
2022-05-27 04:59:52.418547: Average global foreground Dice: [0.5811]
2022-05-27 04:59:52.420807: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 04:59:52.853565: lr: 0.00991
2022-05-27 04:59:52.916164: saving checkpoint...
2022-05-27 04:59:53.937261: done, saving took 1.08 seconds
2022-05-27 04:59:53.954148: This epoch took 104.725745 s

2022-05-27 04:59:53.956259: 
epoch:  5
2022-05-27 05:01:27.870072: train loss : -0.4812
2022-05-27 05:01:35.059701: validation loss: -0.5026
2022-05-27 05:01:35.079172: Average global foreground Dice: [0.5943]
2022-05-27 05:01:35.116950: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:01:35.918975: lr: 0.009892
2022-05-27 05:01:35.982338: saving checkpoint...
2022-05-27 05:01:37.268692: done, saving took 1.34 seconds
2022-05-27 05:01:37.321392: This epoch took 103.363033 s

2022-05-27 05:01:37.330331: 
epoch:  6
2022-05-27 05:03:09.601322: train loss : -0.5058
2022-05-27 05:03:17.542507: validation loss: -0.4754
2022-05-27 05:03:17.563973: Average global foreground Dice: [0.569]
2022-05-27 05:03:17.566683: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:03:18.457966: lr: 0.009874
2022-05-27 05:03:18.551213: saving checkpoint...
2022-05-27 05:03:19.966019: done, saving took 1.49 seconds
2022-05-27 05:03:20.004046: This epoch took 102.671377 s

2022-05-27 05:03:20.024287: 
epoch:  7
2022-05-27 05:04:55.535362: train loss : -0.5302
2022-05-27 05:05:02.555464: validation loss: -0.5128
2022-05-27 05:05:02.559871: Average global foreground Dice: [0.6016]
2022-05-27 05:05:02.563032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:05:03.002485: lr: 0.009856
2022-05-27 05:05:03.050641: saving checkpoint...
2022-05-27 05:05:04.109762: done, saving took 1.10 seconds
2022-05-27 05:05:04.127625: This epoch took 104.091280 s

2022-05-27 05:05:04.130041: 
epoch:  8
2022-05-27 05:06:38.071731: train loss : -0.5358
2022-05-27 05:06:44.602323: validation loss: -0.5691
2022-05-27 05:06:44.623200: Average global foreground Dice: [0.648]
2022-05-27 05:06:44.647302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:06:45.287986: lr: 0.009838
2022-05-27 05:06:45.324690: saving checkpoint...
2022-05-27 05:06:46.357788: done, saving took 1.07 seconds
2022-05-27 05:06:46.370940: This epoch took 102.238755 s

2022-05-27 05:06:46.373276: 
epoch:  9
2022-05-27 05:08:17.311687: train loss : -0.5347
2022-05-27 05:08:23.446377: validation loss: -0.5380
2022-05-27 05:08:23.449610: Average global foreground Dice: [0.6142]
2022-05-27 05:08:23.451781: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:08:23.878633: lr: 0.00982
2022-05-27 05:08:23.910226: saving checkpoint...
2022-05-27 05:08:24.994112: done, saving took 1.11 seconds
2022-05-27 05:08:25.007845: This epoch took 98.632330 s

2022-05-27 05:08:25.010121: 
epoch:  10
2022-05-27 05:09:58.699240: train loss : -0.5610
2022-05-27 05:10:06.776775: validation loss: -0.6048
2022-05-27 05:10:06.793644: Average global foreground Dice: [0.6665]
2022-05-27 05:10:06.811726: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:10:07.265686: lr: 0.009802
2022-05-27 05:10:07.305395: saving checkpoint...
2022-05-27 05:10:08.349948: done, saving took 1.08 seconds
2022-05-27 05:10:08.363796: This epoch took 103.351581 s

2022-05-27 05:10:08.366126: 
epoch:  11
2022-05-27 05:11:39.842259: train loss : -0.5868
2022-05-27 05:11:46.630502: validation loss: -0.6180
2022-05-27 05:11:46.634330: Average global foreground Dice: [0.6746]
2022-05-27 05:11:46.636562: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:11:47.072031: lr: 0.009784
2022-05-27 05:11:47.107736: saving checkpoint...
2022-05-27 05:11:48.159960: done, saving took 1.09 seconds
2022-05-27 05:11:48.174369: This epoch took 99.806089 s

2022-05-27 05:11:48.176494: 
epoch:  12
2022-05-27 05:13:19.036595: train loss : -0.5918
2022-05-27 05:13:29.257833: validation loss: -0.6231
2022-05-27 05:13:29.264272: Average global foreground Dice: [0.6892]
2022-05-27 05:13:29.269275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:13:29.721721: lr: 0.009766
2022-05-27 05:13:29.754548: saving checkpoint...
2022-05-27 05:13:30.791459: done, saving took 1.07 seconds
2022-05-27 05:13:30.805454: This epoch took 102.626878 s

2022-05-27 05:13:30.807909: 
epoch:  13
2022-05-27 05:15:01.339510: train loss : -0.5786
2022-05-27 05:15:08.556951: validation loss: -0.5646
2022-05-27 05:15:08.560039: Average global foreground Dice: [0.6451]
2022-05-27 05:15:08.562293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:15:08.999993: lr: 0.009748
2022-05-27 05:15:09.032838: saving checkpoint...
2022-05-27 05:15:10.018239: done, saving took 1.02 seconds
2022-05-27 05:15:10.033812: This epoch took 99.223954 s

2022-05-27 05:15:10.036508: 
epoch:  14
2022-05-27 05:16:40.932342: train loss : -0.5853
2022-05-27 05:16:46.901468: validation loss: -0.6127
2022-05-27 05:16:46.904915: Average global foreground Dice: [0.6786]
2022-05-27 05:16:46.906931: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:16:47.360085: lr: 0.00973
2022-05-27 05:16:47.400765: saving checkpoint...
2022-05-27 05:16:48.471541: done, saving took 1.11 seconds
2022-05-27 05:16:48.485812: This epoch took 98.447052 s

2022-05-27 05:16:48.488027: 
epoch:  15
2022-05-27 05:18:19.327152: train loss : -0.6214
2022-05-27 05:18:27.550945: validation loss: -0.6147
2022-05-27 05:18:27.573156: Average global foreground Dice: [0.6813]
2022-05-27 05:18:27.587279: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:18:28.254778: lr: 0.009712
2022-05-27 05:18:28.294761: saving checkpoint...
2022-05-27 05:18:29.473606: done, saving took 1.21 seconds
2022-05-27 05:18:29.492158: This epoch took 101.002153 s

2022-05-27 05:18:29.504174: 
epoch:  16
2022-05-27 05:19:59.588795: train loss : -0.6136
2022-05-27 05:20:05.530545: validation loss: -0.6017
2022-05-27 05:20:05.541519: Average global foreground Dice: [0.6694]
2022-05-27 05:20:05.545814: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:20:05.997693: lr: 0.009693
2022-05-27 05:20:06.029775: saving checkpoint...
2022-05-27 05:20:07.057250: done, saving took 1.06 seconds
2022-05-27 05:20:07.071132: This epoch took 97.544839 s

2022-05-27 05:20:07.073368: 
epoch:  17
2022-05-27 05:21:39.943105: train loss : -0.6196
2022-05-27 05:21:48.895531: validation loss: -0.6365
2022-05-27 05:21:48.899255: Average global foreground Dice: [0.6857]
2022-05-27 05:21:48.901622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:21:49.344881: lr: 0.009675
2022-05-27 05:21:49.379030: saving checkpoint...
2022-05-27 05:21:50.465407: done, saving took 1.12 seconds
2022-05-27 05:21:50.480036: This epoch took 103.404444 s

2022-05-27 05:21:50.482335: 
epoch:  18
2022-05-27 05:23:21.999694: train loss : -0.6338
2022-05-27 05:23:28.537176: validation loss: -0.6152
2022-05-27 05:23:28.540067: Average global foreground Dice: [0.6916]
2022-05-27 05:23:28.542371: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:23:29.003789: lr: 0.009657
2022-05-27 05:23:29.042696: saving checkpoint...
2022-05-27 05:23:30.195876: done, saving took 1.19 seconds
2022-05-27 05:23:30.210580: This epoch took 99.725918 s

2022-05-27 05:23:30.212737: 
epoch:  19
2022-05-27 05:25:01.977058: train loss : -0.6216
2022-05-27 05:25:07.859367: validation loss: -0.6300
2022-05-27 05:25:07.862464: Average global foreground Dice: [0.7155]
2022-05-27 05:25:07.864681: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:25:08.293239: lr: 0.009639
2022-05-27 05:25:08.330898: saving checkpoint...
2022-05-27 05:25:09.382645: done, saving took 1.09 seconds
2022-05-27 05:25:09.396713: This epoch took 99.181877 s

2022-05-27 05:25:09.398868: 
epoch:  20
2022-05-27 05:26:39.996861: train loss : -0.6283
2022-05-27 05:26:46.272997: validation loss: -0.6423
2022-05-27 05:26:46.276401: Average global foreground Dice: [0.691]
2022-05-27 05:26:46.279149: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:26:46.708360: lr: 0.009621
2022-05-27 05:26:46.743287: saving checkpoint...
2022-05-27 05:26:47.824161: done, saving took 1.11 seconds
2022-05-27 05:26:47.838653: This epoch took 98.437726 s

2022-05-27 05:26:47.840726: 
epoch:  21
2022-05-27 05:28:18.801347: train loss : -0.6491
2022-05-27 05:28:26.230670: validation loss: -0.6218
2022-05-27 05:28:26.234146: Average global foreground Dice: [0.7037]
2022-05-27 05:28:26.236419: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:28:26.692603: lr: 0.009603
2022-05-27 05:28:26.734263: saving checkpoint...
2022-05-27 05:28:27.777957: done, saving took 1.08 seconds
2022-05-27 05:28:27.793088: This epoch took 99.950142 s

2022-05-27 05:28:27.795424: 
epoch:  22
2022-05-27 05:29:59.376448: train loss : -0.6516
2022-05-27 05:30:08.081428: validation loss: -0.6448
2022-05-27 05:30:08.130183: Average global foreground Dice: [0.7035]
2022-05-27 05:30:08.151304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:30:08.757499: lr: 0.009585
2022-05-27 05:30:08.834329: saving checkpoint...
2022-05-27 05:30:10.027952: done, saving took 1.23 seconds
2022-05-27 05:30:10.044366: This epoch took 102.246837 s

2022-05-27 05:30:10.046755: 
epoch:  23
2022-05-27 05:31:40.978420: train loss : -0.6345
2022-05-27 05:31:48.990412: validation loss: -0.6540
2022-05-27 05:31:49.021789: Average global foreground Dice: [0.717]
2022-05-27 05:31:49.031608: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:31:49.541911: lr: 0.009567
2022-05-27 05:31:49.608120: saving checkpoint...
2022-05-27 05:31:50.742281: done, saving took 1.16 seconds
2022-05-27 05:31:50.757109: This epoch took 100.708187 s

2022-05-27 05:31:50.759254: 
epoch:  24
2022-05-27 05:33:25.548866: train loss : -0.6577
2022-05-27 05:33:32.784804: validation loss: -0.6626
2022-05-27 05:33:32.788299: Average global foreground Dice: [0.7361]
2022-05-27 05:33:32.791313: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:33:33.319054: lr: 0.009549
2022-05-27 05:33:33.397388: saving checkpoint...
2022-05-27 05:33:34.587271: done, saving took 1.25 seconds
2022-05-27 05:33:34.602697: This epoch took 103.840579 s

2022-05-27 05:33:34.605060: 
epoch:  25
2022-05-27 05:35:06.718647: train loss : -0.6558
2022-05-27 05:35:15.127399: validation loss: -0.6303
2022-05-27 05:35:15.156861: Average global foreground Dice: [0.703]
2022-05-27 05:35:15.159336: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:35:15.684650: lr: 0.009531
2022-05-27 05:35:15.808969: saving checkpoint...
2022-05-27 05:35:16.940398: done, saving took 1.22 seconds
2022-05-27 05:35:16.989332: This epoch took 102.382064 s

2022-05-27 05:35:17.010526: 
epoch:  26
2022-05-27 05:36:49.078965: train loss : -0.6584
2022-05-27 05:36:57.316975: validation loss: -0.6307
2022-05-27 05:36:57.328478: Average global foreground Dice: [0.7032]
2022-05-27 05:36:57.347082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:36:57.904893: lr: 0.009513
2022-05-27 05:36:57.967698: saving checkpoint...
2022-05-27 05:36:59.048786: done, saving took 1.14 seconds
2022-05-27 05:36:59.065014: This epoch took 102.034556 s

2022-05-27 05:36:59.067248: 
epoch:  27
2022-05-27 05:38:30.647464: train loss : -0.6630
2022-05-27 05:38:38.012622: validation loss: -0.6891
2022-05-27 05:38:38.016691: Average global foreground Dice: [0.7445]
2022-05-27 05:38:38.019593: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:38:38.460084: lr: 0.009495
2022-05-27 05:38:38.509629: saving checkpoint...
2022-05-27 05:38:39.529553: done, saving took 1.07 seconds
2022-05-27 05:38:39.544146: This epoch took 100.474709 s

2022-05-27 05:38:39.546542: 
epoch:  28
2022-05-27 05:40:10.171623: train loss : -0.6677
2022-05-27 05:40:18.315802: validation loss: -0.6671
2022-05-27 05:40:18.356828: Average global foreground Dice: [0.7338]
2022-05-27 05:40:18.383302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:40:18.999595: lr: 0.009476
2022-05-27 05:40:19.102748: saving checkpoint...
2022-05-27 05:40:20.291974: done, saving took 1.26 seconds
2022-05-27 05:40:20.311185: This epoch took 100.762493 s

2022-05-27 05:40:20.313791: 
epoch:  29
2022-05-27 05:41:51.072770: train loss : -0.6769
2022-05-27 05:41:58.646401: validation loss: -0.6631
2022-05-27 05:41:58.677740: Average global foreground Dice: [0.7312]
2022-05-27 05:41:58.700361: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:41:59.638946: lr: 0.009458
2022-05-27 05:41:59.775705: saving checkpoint...
2022-05-27 05:42:01.154581: done, saving took 1.49 seconds
2022-05-27 05:42:01.169461: This epoch took 100.853310 s

2022-05-27 05:42:01.172130: 
epoch:  30
2022-05-27 05:43:32.654386: train loss : -0.6566
2022-05-27 05:43:40.445922: validation loss: -0.6748
2022-05-27 05:43:40.495691: Average global foreground Dice: [0.7464]
2022-05-27 05:43:40.529290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:43:41.431781: lr: 0.00944
2022-05-27 05:43:41.488129: saving checkpoint...
2022-05-27 05:43:42.566415: done, saving took 1.11 seconds
2022-05-27 05:43:42.580520: This epoch took 101.406078 s

2022-05-27 05:43:42.582619: 
epoch:  31
2022-05-27 05:45:13.944362: train loss : -0.6724
2022-05-27 05:45:22.207058: validation loss: -0.6246
2022-05-27 05:45:22.235801: Average global foreground Dice: [0.714]
2022-05-27 05:45:22.253286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:45:22.807774: lr: 0.009422
2022-05-27 05:45:22.881924: saving checkpoint...
2022-05-27 05:45:24.088219: done, saving took 1.26 seconds
2022-05-27 05:45:24.104361: This epoch took 101.519723 s

2022-05-27 05:45:24.110349: 
epoch:  32
2022-05-27 05:46:57.187040: train loss : -0.6634
2022-05-27 05:47:05.714480: validation loss: -0.6627
2022-05-27 05:47:05.748134: Average global foreground Dice: [0.7245]
2022-05-27 05:47:05.797258: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:47:06.573613: lr: 0.009404
2022-05-27 05:47:06.607873: saving checkpoint...
2022-05-27 05:47:08.127331: done, saving took 1.55 seconds
2022-05-27 05:47:08.173456: This epoch took 104.060599 s

2022-05-27 05:47:08.184875: 
epoch:  33
2022-05-27 05:48:40.043539: train loss : -0.6709
2022-05-27 05:48:48.738675: validation loss: -0.6410
2022-05-27 05:48:48.753384: Average global foreground Dice: [0.7102]
2022-05-27 05:48:48.755880: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:48:49.250891: lr: 0.009386
2022-05-27 05:48:49.286949: saving checkpoint...
2022-05-27 05:48:50.483688: done, saving took 1.23 seconds
2022-05-27 05:48:50.532863: This epoch took 102.325588 s

2022-05-27 05:48:50.535124: 
epoch:  34
2022-05-27 05:50:26.637863: train loss : -0.6787
2022-05-27 05:50:34.332642: validation loss: -0.6688
2022-05-27 05:50:34.354728: Average global foreground Dice: [0.7284]
2022-05-27 05:50:34.381287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:50:35.063504: lr: 0.009368
2022-05-27 05:50:35.157978: saving checkpoint...
2022-05-27 05:50:36.386642: done, saving took 1.30 seconds
2022-05-27 05:50:36.401454: This epoch took 105.864094 s

2022-05-27 05:50:36.403748: 
epoch:  35
2022-05-27 05:52:07.577013: train loss : -0.6984
2022-05-27 05:52:15.195869: validation loss: -0.6981
2022-05-27 05:52:15.198936: Average global foreground Dice: [0.7465]
2022-05-27 05:52:15.201492: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:52:15.740792: lr: 0.00935
2022-05-27 05:52:15.822945: saving checkpoint...
2022-05-27 05:52:16.971942: done, saving took 1.20 seconds
2022-05-27 05:52:16.988602: This epoch took 100.582605 s

2022-05-27 05:52:16.990724: 
epoch:  36
2022-05-27 05:53:48.821345: train loss : -0.6896
2022-05-27 05:53:55.605485: validation loss: -0.6940
2022-05-27 05:53:55.608916: Average global foreground Dice: [0.7542]
2022-05-27 05:53:55.611485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:53:56.066060: lr: 0.009331
2022-05-27 05:53:56.103547: saving checkpoint...
2022-05-27 05:53:57.242436: done, saving took 1.17 seconds
2022-05-27 05:53:57.311339: This epoch took 100.318063 s

2022-05-27 05:53:57.332331: 
epoch:  37
2022-05-27 05:55:31.060874: train loss : -0.6870
2022-05-27 05:55:39.347159: validation loss: -0.6826
2022-05-27 05:55:39.369744: Average global foreground Dice: [0.747]
2022-05-27 05:55:39.389298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:55:40.061947: lr: 0.009313
2022-05-27 05:55:40.147542: saving checkpoint...
2022-05-27 05:55:41.358446: done, saving took 1.26 seconds
2022-05-27 05:55:41.425833: This epoch took 104.089868 s

2022-05-27 05:55:41.453279: 
epoch:  38
2022-05-27 05:57:17.557971: train loss : -0.6854
2022-05-27 05:57:25.298146: validation loss: -0.6927
2022-05-27 05:57:25.329265: Average global foreground Dice: [0.7502]
2022-05-27 05:57:25.347323: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:57:25.915819: lr: 0.009295
2022-05-27 05:57:25.964287: saving checkpoint...
2022-05-27 05:57:27.002884: done, saving took 1.07 seconds
2022-05-27 05:57:27.017024: This epoch took 105.539984 s

2022-05-27 05:57:27.019159: 
epoch:  39
2022-05-27 05:59:01.308508: train loss : -0.6800
2022-05-27 05:59:09.204162: validation loss: -0.6792
2022-05-27 05:59:09.207623: Average global foreground Dice: [0.7526]
2022-05-27 05:59:09.210129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 05:59:09.688735: lr: 0.009277
2022-05-27 05:59:09.744031: saving checkpoint...
2022-05-27 05:59:10.778309: done, saving took 1.07 seconds
2022-05-27 05:59:10.792403: This epoch took 103.771108 s

2022-05-27 05:59:10.794590: 
epoch:  40
2022-05-27 06:00:40.828533: train loss : -0.6923
2022-05-27 06:00:46.857382: validation loss: -0.6578
2022-05-27 06:00:46.860616: Average global foreground Dice: [0.7237]
2022-05-27 06:00:46.862867: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:00:47.373305: lr: 0.009259
2022-05-27 06:00:47.427119: saving checkpoint...
2022-05-27 06:00:48.530578: done, saving took 1.15 seconds
2022-05-27 06:00:48.544966: This epoch took 97.748134 s

2022-05-27 06:00:48.547042: 
epoch:  41
2022-05-27 06:02:20.614630: train loss : -0.6799
2022-05-27 06:02:27.588544: validation loss: -0.6882
2022-05-27 06:02:27.616917: Average global foreground Dice: [0.7463]
2022-05-27 06:02:27.639133: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:02:28.356897: lr: 0.009241
2022-05-27 06:02:28.460546: saving checkpoint...
2022-05-27 06:02:29.514588: done, saving took 1.13 seconds
2022-05-27 06:02:29.529475: This epoch took 100.980360 s

2022-05-27 06:02:29.531708: 
epoch:  42
2022-05-27 06:04:01.379695: train loss : -0.6855
2022-05-27 06:04:10.280596: validation loss: -0.6891
2022-05-27 06:04:10.284405: Average global foreground Dice: [0.7466]
2022-05-27 06:04:10.287086: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:04:10.922381: lr: 0.009223
2022-05-27 06:04:10.959717: saving checkpoint...
2022-05-27 06:04:12.053771: done, saving took 1.13 seconds
2022-05-27 06:04:12.067694: This epoch took 102.533925 s

2022-05-27 06:04:12.069764: 
epoch:  43
2022-05-27 06:05:48.589190: train loss : -0.6877
2022-05-27 06:05:56.866361: validation loss: -0.7116
2022-05-27 06:05:56.885934: Average global foreground Dice: [0.7623]
2022-05-27 06:05:56.915297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:05:57.506800: lr: 0.009204
2022-05-27 06:05:57.549965: saving checkpoint...
2022-05-27 06:05:58.696087: done, saving took 1.18 seconds
2022-05-27 06:05:58.709004: This epoch took 106.637246 s

2022-05-27 06:05:58.725496: 
epoch:  44
2022-05-27 06:07:29.929655: train loss : -0.6962
2022-05-27 06:07:36.925828: validation loss: -0.6771
2022-05-27 06:07:36.929119: Average global foreground Dice: [0.7571]
2022-05-27 06:07:36.931818: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:07:37.435867: lr: 0.009186
2022-05-27 06:07:37.468225: saving checkpoint...
2022-05-27 06:07:38.503089: done, saving took 1.06 seconds
2022-05-27 06:07:38.517578: This epoch took 99.789751 s

2022-05-27 06:07:38.520011: 
epoch:  45
2022-05-27 06:09:10.410738: train loss : -0.6969
2022-05-27 06:09:19.663808: validation loss: -0.6911
2022-05-27 06:09:19.674639: Average global foreground Dice: [0.7631]
2022-05-27 06:09:19.677669: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:09:20.116428: lr: 0.009168
2022-05-27 06:09:20.168365: saving checkpoint...
2022-05-27 06:09:21.232457: done, saving took 1.10 seconds
2022-05-27 06:09:21.246412: This epoch took 102.724212 s

2022-05-27 06:09:21.248590: 
epoch:  46
2022-05-27 06:10:51.828768: train loss : -0.6977
2022-05-27 06:10:57.822126: validation loss: -0.7062
2022-05-27 06:10:57.827623: Average global foreground Dice: [0.7785]
2022-05-27 06:10:57.830130: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:10:58.266647: lr: 0.00915
2022-05-27 06:10:58.299705: saving checkpoint...
2022-05-27 06:10:59.443297: done, saving took 1.17 seconds
2022-05-27 06:10:59.457950: This epoch took 98.206273 s

2022-05-27 06:10:59.460155: 
epoch:  47
2022-05-27 06:12:31.289235: train loss : -0.7123
2022-05-27 06:12:39.083877: validation loss: -0.6855
2022-05-27 06:12:39.120810: Average global foreground Dice: [0.7526]
2022-05-27 06:12:39.141317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:12:39.890470: lr: 0.009132
2022-05-27 06:12:39.969864: saving checkpoint...
2022-05-27 06:12:41.244745: done, saving took 1.33 seconds
2022-05-27 06:12:41.259083: This epoch took 101.796579 s

2022-05-27 06:12:41.261557: 
epoch:  48
2022-05-27 06:14:12.603587: train loss : -0.7024
2022-05-27 06:14:20.548467: validation loss: -0.6707
2022-05-27 06:14:20.552775: Average global foreground Dice: [0.7613]
2022-05-27 06:14:20.555175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:14:20.988727: lr: 0.009114
2022-05-27 06:14:21.019184: saving checkpoint...
2022-05-27 06:14:22.063278: done, saving took 1.07 seconds
2022-05-27 06:14:22.077052: This epoch took 100.813025 s

2022-05-27 06:14:22.079579: 
epoch:  49
2022-05-27 06:15:54.579195: train loss : -0.7135
2022-05-27 06:16:03.345688: validation loss: -0.6715
2022-05-27 06:16:03.353837: Average global foreground Dice: [0.7396]
2022-05-27 06:16:03.378679: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:16:03.970493: lr: 0.009095
2022-05-27 06:16:03.972914: saving scheduled checkpoint file...
2022-05-27 06:16:04.019303: saving checkpoint...
2022-05-27 06:16:05.048439: done, saving took 1.07 seconds
2022-05-27 06:16:05.063602: done
2022-05-27 06:16:05.066304: This epoch took 102.984472 s

2022-05-27 06:16:05.068751: 
epoch:  50
2022-05-27 06:17:35.950240: train loss : -0.7086
2022-05-27 06:17:43.235417: validation loss: -0.6845
2022-05-27 06:17:43.261901: Average global foreground Dice: [0.7389]
2022-05-27 06:17:43.276449: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:17:43.770226: lr: 0.009077
2022-05-27 06:17:43.772979: This epoch took 98.701958 s

2022-05-27 06:17:43.775218: 
epoch:  51
2022-05-27 06:19:15.881415: train loss : -0.6984
2022-05-27 06:19:24.042296: validation loss: -0.6659
2022-05-27 06:19:24.045555: Average global foreground Dice: [0.7531]
2022-05-27 06:19:24.058321: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:19:24.755209: lr: 0.009059
2022-05-27 06:19:24.787675: saving checkpoint...
2022-05-27 06:19:25.858540: done, saving took 1.10 seconds
2022-05-27 06:19:25.872956: This epoch took 102.095675 s

2022-05-27 06:19:25.875067: 
epoch:  52
2022-05-27 06:20:57.490726: train loss : -0.7080
2022-05-27 06:21:05.410879: validation loss: -0.6651
2022-05-27 06:21:05.418261: Average global foreground Dice: [0.7442]
2022-05-27 06:21:05.420447: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:21:05.861071: lr: 0.009041
2022-05-27 06:21:05.893811: saving checkpoint...
2022-05-27 06:21:06.971288: done, saving took 1.11 seconds
2022-05-27 06:21:06.986048: This epoch took 101.108811 s

2022-05-27 06:21:06.988363: 
epoch:  53
2022-05-27 06:22:38.371381: train loss : -0.7068
2022-05-27 06:22:45.962124: validation loss: -0.6948
2022-05-27 06:22:45.996973: Average global foreground Dice: [0.7582]
2022-05-27 06:22:46.015305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:22:46.500982: lr: 0.009023
2022-05-27 06:22:46.547910: saving checkpoint...
2022-05-27 06:22:47.748654: done, saving took 1.25 seconds
2022-05-27 06:22:47.764055: This epoch took 100.773452 s

2022-05-27 06:22:47.766290: 
epoch:  54
2022-05-27 06:24:21.517469: train loss : -0.6933
2022-05-27 06:24:30.164260: validation loss: -0.6776
2022-05-27 06:24:30.184979: Average global foreground Dice: [0.7343]
2022-05-27 06:24:30.219339: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:24:30.895397: lr: 0.009004
2022-05-27 06:24:30.900343: This epoch took 103.131835 s

2022-05-27 06:24:30.902671: 
epoch:  55
2022-05-27 06:26:02.565210: train loss : -0.6916
2022-05-27 06:26:10.898710: validation loss: -0.6842
2022-05-27 06:26:10.950495: Average global foreground Dice: [0.7451]
2022-05-27 06:26:10.965922: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:26:11.880942: lr: 0.008986
2022-05-27 06:26:11.902304: This epoch took 100.997093 s

2022-05-27 06:26:11.925291: 
epoch:  56
2022-05-27 06:27:46.745953: train loss : -0.7069
2022-05-27 06:27:55.014840: validation loss: -0.7071
2022-05-27 06:27:55.023755: Average global foreground Dice: [0.7799]
2022-05-27 06:27:55.026694: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:27:55.496089: lr: 0.008968
2022-05-27 06:27:55.539524: saving checkpoint...
2022-05-27 06:27:56.663150: done, saving took 1.16 seconds
2022-05-27 06:27:56.680446: This epoch took 104.741151 s

2022-05-27 06:27:56.682989: 
epoch:  57
2022-05-27 06:29:27.958404: train loss : -0.7230
2022-05-27 06:29:35.971117: validation loss: -0.7210
2022-05-27 06:29:35.996425: Average global foreground Dice: [0.7778]
2022-05-27 06:29:36.023239: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:29:36.567885: lr: 0.00895
2022-05-27 06:29:36.681363: saving checkpoint...
2022-05-27 06:29:37.971426: done, saving took 1.38 seconds
2022-05-27 06:29:38.015288: This epoch took 101.329563 s

2022-05-27 06:29:38.017824: 
epoch:  58
2022-05-27 06:31:13.877732: train loss : -0.7043
2022-05-27 06:31:20.611592: validation loss: -0.7029
2022-05-27 06:31:20.617704: Average global foreground Dice: [0.7604]
2022-05-27 06:31:20.622128: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:31:21.272173: lr: 0.008931
2022-05-27 06:31:21.334839: saving checkpoint...
2022-05-27 06:31:22.491222: done, saving took 1.20 seconds
2022-05-27 06:31:22.504899: This epoch took 104.484532 s

2022-05-27 06:31:22.507048: 
epoch:  59
2022-05-27 06:32:58.591491: train loss : -0.6985
2022-05-27 06:33:07.467733: validation loss: -0.6794
2022-05-27 06:33:07.470928: Average global foreground Dice: [0.7579]
2022-05-27 06:33:07.473059: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:33:07.910723: lr: 0.008913
2022-05-27 06:33:07.951120: saving checkpoint...
2022-05-27 06:33:09.037908: done, saving took 1.12 seconds
2022-05-27 06:33:09.054220: This epoch took 106.545063 s

2022-05-27 06:33:09.056520: 
epoch:  60
2022-05-27 06:34:42.772737: train loss : -0.7018
2022-05-27 06:34:51.444057: validation loss: -0.7058
2022-05-27 06:34:51.477759: Average global foreground Dice: [0.7589]
2022-05-27 06:34:51.501462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:34:51.971196: lr: 0.008895
2022-05-27 06:34:52.026125: saving checkpoint...
2022-05-27 06:34:53.345476: done, saving took 1.37 seconds
2022-05-27 06:34:53.397521: This epoch took 104.338603 s

2022-05-27 06:34:53.419494: 
epoch:  61
2022-05-27 06:36:24.354013: train loss : -0.7149
2022-05-27 06:36:31.935187: validation loss: -0.7171
2022-05-27 06:36:31.952670: Average global foreground Dice: [0.7634]
2022-05-27 06:36:31.976318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:36:32.929054: lr: 0.008877
2022-05-27 06:36:33.075206: saving checkpoint...
2022-05-27 06:36:34.295788: done, saving took 1.36 seconds
2022-05-27 06:36:34.314393: This epoch took 100.855901 s

2022-05-27 06:36:34.316724: 
epoch:  62
2022-05-27 06:38:05.196237: train loss : -0.6923
2022-05-27 06:38:14.855958: validation loss: -0.7252
2022-05-27 06:38:14.859495: Average global foreground Dice: [0.7823]
2022-05-27 06:38:14.862379: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:38:15.340450: lr: 0.008859
2022-05-27 06:38:15.440704: saving checkpoint...
2022-05-27 06:38:16.562557: done, saving took 1.19 seconds
2022-05-27 06:38:16.579153: This epoch took 102.259687 s

2022-05-27 06:38:16.581735: 
epoch:  63
2022-05-27 06:39:49.891942: train loss : -0.7005
2022-05-27 06:39:57.994696: validation loss: -0.6457
2022-05-27 06:39:58.004085: Average global foreground Dice: [0.7332]
2022-05-27 06:39:58.022797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:39:58.556746: lr: 0.00884
2022-05-27 06:39:58.587336: This epoch took 102.002965 s

2022-05-27 06:39:58.604281: 
epoch:  64
2022-05-27 06:41:29.830012: train loss : -0.7063
2022-05-27 06:41:38.544454: validation loss: -0.7088
2022-05-27 06:41:38.565456: Average global foreground Dice: [0.7598]
2022-05-27 06:41:38.584938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:41:39.542100: lr: 0.008822
2022-05-27 06:41:39.563399: This epoch took 100.939111 s

2022-05-27 06:41:39.568506: 
epoch:  65
2022-05-27 06:43:11.209459: train loss : -0.7003
2022-05-27 06:43:19.513939: validation loss: -0.7039
2022-05-27 06:43:19.539127: Average global foreground Dice: [0.7481]
2022-05-27 06:43:19.558297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:43:20.648447: lr: 0.008804
2022-05-27 06:43:20.679721: This epoch took 101.098797 s

2022-05-27 06:43:20.700297: 
epoch:  66
2022-05-27 06:44:58.559458: train loss : -0.7031
2022-05-27 06:45:05.496560: validation loss: -0.6821
2022-05-27 06:45:05.506606: Average global foreground Dice: [0.7413]
2022-05-27 06:45:05.520371: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:45:06.209958: lr: 0.008785
2022-05-27 06:45:06.269326: This epoch took 105.546021 s

2022-05-27 06:45:06.294362: 
epoch:  67
2022-05-27 06:46:39.034738: train loss : -0.7129
2022-05-27 06:46:46.493804: validation loss: -0.7179
2022-05-27 06:46:46.502672: Average global foreground Dice: [0.7639]
2022-05-27 06:46:46.514648: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:46:47.063926: lr: 0.008767
2022-05-27 06:46:47.066861: This epoch took 100.750494 s

2022-05-27 06:46:47.069660: 
epoch:  68
2022-05-27 06:48:19.167952: train loss : -0.7190
2022-05-27 06:48:28.373346: validation loss: -0.7186
2022-05-27 06:48:28.376839: Average global foreground Dice: [0.7757]
2022-05-27 06:48:28.379093: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:48:28.836675: lr: 0.008749
2022-05-27 06:48:28.839790: This epoch took 101.767495 s

2022-05-27 06:48:28.842275: 
epoch:  69
2022-05-27 06:50:05.236188: train loss : -0.7246
2022-05-27 06:50:12.728512: validation loss: -0.7369
2022-05-27 06:50:12.763005: Average global foreground Dice: [0.7896]
2022-05-27 06:50:12.782565: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:50:13.281608: lr: 0.008731
2022-05-27 06:50:13.340961: saving checkpoint...
2022-05-27 06:50:14.478983: done, saving took 1.19 seconds
2022-05-27 06:50:14.495644: This epoch took 105.651586 s

2022-05-27 06:50:14.497931: 
epoch:  70
2022-05-27 06:51:48.243973: train loss : -0.7170
2022-05-27 06:51:55.235604: validation loss: -0.7284
2022-05-27 06:51:55.239158: Average global foreground Dice: [0.7745]
2022-05-27 06:51:55.241517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:51:55.721911: lr: 0.008712
2022-05-27 06:51:55.770776: saving checkpoint...
2022-05-27 06:51:56.926586: done, saving took 1.20 seconds
2022-05-27 06:51:56.940430: This epoch took 102.440184 s

2022-05-27 06:51:56.942583: 
epoch:  71
2022-05-27 06:53:28.226591: train loss : -0.7285
2022-05-27 06:53:36.855642: validation loss: -0.6903
2022-05-27 06:53:36.873736: Average global foreground Dice: [0.7552]
2022-05-27 06:53:36.894362: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:53:37.440197: lr: 0.008694
2022-05-27 06:53:37.443073: This epoch took 100.498344 s

2022-05-27 06:53:37.446823: 
epoch:  72
2022-05-27 06:55:09.385098: train loss : -0.7302
2022-05-27 06:55:18.241390: validation loss: -0.6857
2022-05-27 06:55:18.261218: Average global foreground Dice: [0.7469]
2022-05-27 06:55:18.287606: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:55:18.979508: lr: 0.008676
2022-05-27 06:55:18.985990: This epoch took 101.536620 s

2022-05-27 06:55:18.988299: 
epoch:  73
2022-05-27 06:56:50.748411: train loss : -0.7026
2022-05-27 06:56:59.609373: validation loss: -0.6817
2022-05-27 06:56:59.641263: Average global foreground Dice: [0.7455]
2022-05-27 06:56:59.686307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:57:00.381499: lr: 0.008658
2022-05-27 06:57:00.422447: This epoch took 101.431830 s

2022-05-27 06:57:00.441169: 
epoch:  74
2022-05-27 06:58:32.039826: train loss : -0.7204
2022-05-27 06:58:40.709453: validation loss: -0.7105
2022-05-27 06:58:40.712758: Average global foreground Dice: [0.7606]
2022-05-27 06:58:40.715138: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 06:58:41.169595: lr: 0.008639
2022-05-27 06:58:41.172275: This epoch took 100.728859 s

2022-05-27 06:58:41.174765: 
epoch:  75
2022-05-27 07:00:21.762823: train loss : -0.7156
2022-05-27 07:00:30.613936: validation loss: -0.7021
2022-05-27 07:00:30.618250: Average global foreground Dice: [0.7767]
2022-05-27 07:00:30.620788: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:00:31.060271: lr: 0.008621
2022-05-27 07:00:31.062855: This epoch took 109.885275 s

2022-05-27 07:00:31.065228: 
epoch:  76
2022-05-27 07:02:02.853306: train loss : -0.7346
2022-05-27 07:02:10.066774: validation loss: -0.7454
2022-05-27 07:02:10.070461: Average global foreground Dice: [0.7906]
2022-05-27 07:02:10.073614: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:02:10.514768: lr: 0.008603
2022-05-27 07:02:10.569869: saving checkpoint...
2022-05-27 07:02:11.786919: done, saving took 1.27 seconds
2022-05-27 07:02:11.819439: This epoch took 100.751778 s

2022-05-27 07:02:11.834101: 
epoch:  77
2022-05-27 07:03:45.310493: train loss : -0.7334
2022-05-27 07:03:53.123391: validation loss: -0.7244
2022-05-27 07:03:53.144476: Average global foreground Dice: [0.7855]
2022-05-27 07:03:53.152374: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:03:53.868112: lr: 0.008584
2022-05-27 07:03:53.985755: saving checkpoint...
2022-05-27 07:03:55.401129: done, saving took 1.50 seconds
2022-05-27 07:03:55.418035: This epoch took 103.579604 s

2022-05-27 07:03:55.429262: 
epoch:  78
2022-05-27 07:05:26.153655: train loss : -0.7206
2022-05-27 07:05:33.752131: validation loss: -0.7266
2022-05-27 07:05:33.778989: Average global foreground Dice: [0.7787]
2022-05-27 07:05:33.781686: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:05:34.416973: lr: 0.008566
2022-05-27 07:05:34.490050: saving checkpoint...
2022-05-27 07:05:35.531743: done, saving took 1.11 seconds
2022-05-27 07:05:35.545220: This epoch took 100.102939 s

2022-05-27 07:05:35.547441: 
epoch:  79
2022-05-27 07:07:08.890058: train loss : -0.7332
2022-05-27 07:07:20.001444: validation loss: -0.7061
2022-05-27 07:07:20.050949: Average global foreground Dice: [0.781]
2022-05-27 07:07:20.073282: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:07:20.984006: lr: 0.008548
2022-05-27 07:07:21.033308: saving checkpoint...
2022-05-27 07:07:22.524767: done, saving took 1.52 seconds
2022-05-27 07:07:22.537971: This epoch took 106.988364 s

2022-05-27 07:07:22.540044: 
epoch:  80
2022-05-27 07:08:52.496876: train loss : -0.7355
2022-05-27 07:09:00.581529: validation loss: -0.6991
2022-05-27 07:09:00.586171: Average global foreground Dice: [0.7789]
2022-05-27 07:09:00.591459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:09:01.044742: lr: 0.008529
2022-05-27 07:09:01.082456: saving checkpoint...
2022-05-27 07:09:02.142509: done, saving took 1.10 seconds
2022-05-27 07:09:02.156539: This epoch took 99.614373 s

2022-05-27 07:09:02.158710: 
epoch:  81
2022-05-27 07:10:34.487117: train loss : -0.7316
2022-05-27 07:10:44.093480: validation loss: -0.7248
2022-05-27 07:10:44.115442: Average global foreground Dice: [0.7779]
2022-05-27 07:10:44.152267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:10:44.733635: lr: 0.008511
2022-05-27 07:10:44.783994: saving checkpoint...
2022-05-27 07:10:45.935297: done, saving took 1.20 seconds
2022-05-27 07:10:45.950184: This epoch took 103.789093 s

2022-05-27 07:10:45.952565: 
epoch:  82
2022-05-27 07:12:16.786850: train loss : -0.7295
2022-05-27 07:12:24.945171: validation loss: -0.7086
2022-05-27 07:12:24.948723: Average global foreground Dice: [0.7743]
2022-05-27 07:12:24.951269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:12:25.384945: lr: 0.008493
2022-05-27 07:12:25.416572: saving checkpoint...
2022-05-27 07:12:26.529295: done, saving took 1.14 seconds
2022-05-27 07:12:26.542765: This epoch took 100.587794 s

2022-05-27 07:12:26.544912: 
epoch:  83
2022-05-27 07:14:01.055135: train loss : -0.7441
2022-05-27 07:14:09.297879: validation loss: -0.7156
2022-05-27 07:14:09.301392: Average global foreground Dice: [0.7897]
2022-05-27 07:14:09.303807: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:14:09.745832: lr: 0.008474
2022-05-27 07:14:09.783927: saving checkpoint...
2022-05-27 07:14:10.856446: done, saving took 1.11 seconds
2022-05-27 07:14:10.872981: This epoch took 104.325740 s

2022-05-27 07:14:10.875341: 
epoch:  84
2022-05-27 07:15:41.972617: train loss : -0.7456
2022-05-27 07:15:48.392585: validation loss: -0.7079
2022-05-27 07:15:48.396349: Average global foreground Dice: [0.7759]
2022-05-27 07:15:48.398690: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:15:48.904837: lr: 0.008456
2022-05-27 07:15:48.954457: saving checkpoint...
2022-05-27 07:15:49.984544: done, saving took 1.08 seconds
2022-05-27 07:15:50.010167: This epoch took 99.132713 s

2022-05-27 07:15:50.013274: 
epoch:  85
2022-05-27 07:17:21.308208: train loss : -0.7384
2022-05-27 07:17:29.757895: validation loss: -0.7165
2022-05-27 07:17:29.761188: Average global foreground Dice: [0.7737]
2022-05-27 07:17:29.763457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:17:30.198972: lr: 0.008438
2022-05-27 07:17:30.243349: saving checkpoint...
2022-05-27 07:17:31.401647: done, saving took 1.20 seconds
2022-05-27 07:17:31.416513: This epoch took 101.401175 s

2022-05-27 07:17:31.418761: 
epoch:  86
2022-05-27 07:19:07.965355: train loss : -0.7319
2022-05-27 07:19:15.309697: validation loss: -0.6971
2022-05-27 07:19:15.336666: Average global foreground Dice: [0.7627]
2022-05-27 07:19:15.359289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:19:16.114901: lr: 0.008419
2022-05-27 07:19:16.117296: This epoch took 104.696380 s

2022-05-27 07:19:16.119359: 
epoch:  87
2022-05-27 07:20:51.970234: train loss : -0.7330
2022-05-27 07:21:00.689522: validation loss: -0.7346
2022-05-27 07:21:00.693455: Average global foreground Dice: [0.7827]
2022-05-27 07:21:00.695938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:21:01.145318: lr: 0.008401
2022-05-27 07:21:01.184416: saving checkpoint...
2022-05-27 07:21:02.399085: done, saving took 1.25 seconds
2022-05-27 07:21:02.417478: This epoch took 106.295915 s

2022-05-27 07:21:02.419866: 
epoch:  88
2022-05-27 07:22:33.536690: train loss : -0.7451
2022-05-27 07:22:41.225314: validation loss: -0.7359
2022-05-27 07:22:41.230255: Average global foreground Dice: [0.7855]
2022-05-27 07:22:41.233376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:22:41.675555: lr: 0.008383
2022-05-27 07:22:41.734609: saving checkpoint...
2022-05-27 07:22:42.790595: done, saving took 1.08 seconds
2022-05-27 07:22:42.805782: This epoch took 100.383765 s

2022-05-27 07:22:42.808351: 
epoch:  89
2022-05-27 07:24:19.517627: train loss : -0.7425
2022-05-27 07:24:28.995199: validation loss: -0.6660
2022-05-27 07:24:28.998928: Average global foreground Dice: [0.716]
2022-05-27 07:24:29.001234: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:24:29.440450: lr: 0.008364
2022-05-27 07:24:29.442971: This epoch took 106.632570 s

2022-05-27 07:24:29.445467: 
epoch:  90
2022-05-27 07:26:08.213838: train loss : -0.7264
2022-05-27 07:26:19.119645: validation loss: -0.7467
2022-05-27 07:26:19.143690: Average global foreground Dice: [0.7919]
2022-05-27 07:26:19.162282: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:26:19.804548: lr: 0.008346
2022-05-27 07:26:19.807236: This epoch took 110.359442 s

2022-05-27 07:26:19.809404: 
epoch:  91
2022-05-27 07:27:53.393435: train loss : -0.7370
2022-05-27 07:28:02.712446: validation loss: -0.7040
2022-05-27 07:28:02.733863: Average global foreground Dice: [0.7679]
2022-05-27 07:28:02.756285: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:28:03.524064: lr: 0.008328
2022-05-27 07:28:03.537333: This epoch took 103.725839 s

2022-05-27 07:28:03.570689: 
epoch:  92
2022-05-27 07:29:35.725616: train loss : -0.7388
2022-05-27 07:29:44.469573: validation loss: -0.6960
2022-05-27 07:29:44.473453: Average global foreground Dice: [0.7673]
2022-05-27 07:29:44.475914: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:29:44.918962: lr: 0.008309
2022-05-27 07:29:44.921445: This epoch took 101.322662 s

2022-05-27 07:29:44.923816: 
epoch:  93
2022-05-27 07:31:20.570187: train loss : -0.7269
2022-05-27 07:31:28.044381: validation loss: -0.7128
2022-05-27 07:31:28.047922: Average global foreground Dice: [0.7702]
2022-05-27 07:31:28.051190: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:31:28.545435: lr: 0.008291
2022-05-27 07:31:28.547988: This epoch took 103.619593 s

2022-05-27 07:31:28.550076: 
epoch:  94
2022-05-27 07:33:02.085512: train loss : -0.7293
2022-05-27 07:33:08.038931: validation loss: -0.7276
2022-05-27 07:33:08.042177: Average global foreground Dice: [0.7757]
2022-05-27 07:33:08.044333: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:33:08.491693: lr: 0.008272
2022-05-27 07:33:08.494311: This epoch took 99.942060 s

2022-05-27 07:33:08.496975: 
epoch:  95
2022-05-27 07:34:39.916547: train loss : -0.7312
2022-05-27 07:34:48.028173: validation loss: -0.7154
2022-05-27 07:34:48.045722: Average global foreground Dice: [0.7759]
2022-05-27 07:34:48.062589: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:34:48.656894: lr: 0.008254
2022-05-27 07:34:48.678332: This epoch took 100.179011 s

2022-05-27 07:34:48.687824: 
epoch:  96
2022-05-27 07:36:21.922253: train loss : -0.7421
2022-05-27 07:36:30.676041: validation loss: -0.7174
2022-05-27 07:36:30.679891: Average global foreground Dice: [0.7835]
2022-05-27 07:36:30.682778: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:36:31.136824: lr: 0.008236
2022-05-27 07:36:31.152393: This epoch took 102.457891 s

2022-05-27 07:36:31.154910: 
epoch:  97
2022-05-27 07:38:01.417399: train loss : -0.7435
2022-05-27 07:38:08.493321: validation loss: -0.7185
2022-05-27 07:38:08.518688: Average global foreground Dice: [0.7764]
2022-05-27 07:38:08.532094: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:38:09.177276: lr: 0.008217
2022-05-27 07:38:09.205340: This epoch took 98.017721 s

2022-05-27 07:38:09.226450: 
epoch:  98
2022-05-27 07:39:42.244278: train loss : -0.7386
2022-05-27 07:39:50.988217: validation loss: -0.7089
2022-05-27 07:39:50.991571: Average global foreground Dice: [0.7906]
2022-05-27 07:39:50.993943: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:39:51.431115: lr: 0.008199
2022-05-27 07:39:51.484810: saving checkpoint...
2022-05-27 07:39:52.540796: done, saving took 1.11 seconds
2022-05-27 07:39:52.556431: This epoch took 103.326459 s

2022-05-27 07:39:52.558796: 
epoch:  99
2022-05-27 07:41:30.852628: train loss : -0.7375
2022-05-27 07:41:37.901397: validation loss: -0.7101
2022-05-27 07:41:37.904903: Average global foreground Dice: [0.7773]
2022-05-27 07:41:37.907532: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:41:38.416372: lr: 0.008181
2022-05-27 07:41:38.418887: saving scheduled checkpoint file...
2022-05-27 07:41:38.468056: saving checkpoint...
2022-05-27 07:41:39.664144: done, saving took 1.24 seconds
2022-05-27 07:41:39.697415: done
2022-05-27 07:41:39.732741: saving checkpoint...
2022-05-27 07:41:40.724641: done, saving took 1.02 seconds
2022-05-27 07:41:40.739047: This epoch took 108.177961 s

2022-05-27 07:41:40.741253: 
epoch:  100
2022-05-27 07:43:16.936623: train loss : -0.7356
2022-05-27 07:43:26.084313: validation loss: -0.7310
2022-05-27 07:43:26.115801: Average global foreground Dice: [0.7902]
2022-05-27 07:43:26.158309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:43:26.713325: lr: 0.008162
2022-05-27 07:43:26.806136: saving checkpoint...
2022-05-27 07:43:27.860337: done, saving took 1.12 seconds
2022-05-27 07:43:27.907710: This epoch took 107.164327 s

2022-05-27 07:43:27.927473: 
epoch:  101
2022-05-27 07:45:02.707738: train loss : -0.7450
2022-05-27 07:45:11.628699: validation loss: -0.7314
2022-05-27 07:45:11.632346: Average global foreground Dice: [0.7954]
2022-05-27 07:45:11.634582: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:45:12.111491: lr: 0.008144
2022-05-27 07:45:12.142513: saving checkpoint...
2022-05-27 07:45:13.220294: done, saving took 1.11 seconds
2022-05-27 07:45:13.235527: This epoch took 105.294242 s

2022-05-27 07:45:13.237573: 
epoch:  102
2022-05-27 07:46:43.483285: train loss : -0.7534
2022-05-27 07:46:50.990107: validation loss: -0.7369
2022-05-27 07:46:50.993559: Average global foreground Dice: [0.7948]
2022-05-27 07:46:50.996300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:46:51.429191: lr: 0.008125
2022-05-27 07:46:51.472001: saving checkpoint...
2022-05-27 07:46:52.618109: done, saving took 1.19 seconds
2022-05-27 07:46:52.641145: This epoch took 99.401517 s

2022-05-27 07:46:52.656378: 
epoch:  103
2022-05-27 07:48:29.972218: train loss : -0.7472
2022-05-27 07:48:39.484923: validation loss: -0.7000
2022-05-27 07:48:39.515732: Average global foreground Dice: [0.7792]
2022-05-27 07:48:39.526398: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:48:40.175033: lr: 0.008107
2022-05-27 07:48:40.193317: This epoch took 107.523531 s

2022-05-27 07:48:40.215290: 
epoch:  104
2022-05-27 07:50:11.719609: train loss : -0.7519
2022-05-27 07:50:19.941082: validation loss: -0.7183
2022-05-27 07:50:19.955697: Average global foreground Dice: [0.8031]
2022-05-27 07:50:19.978475: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:50:20.743819: lr: 0.008088
2022-05-27 07:50:20.812692: saving checkpoint...
2022-05-27 07:50:21.913267: done, saving took 1.15 seconds
2022-05-27 07:50:21.929368: This epoch took 101.692077 s

2022-05-27 07:50:21.932377: 
epoch:  105
2022-05-27 07:51:52.683697: train loss : -0.7617
2022-05-27 07:52:00.091856: validation loss: -0.7243
2022-05-27 07:52:00.113077: Average global foreground Dice: [0.781]
2022-05-27 07:52:00.120417: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:52:00.761321: lr: 0.00807
2022-05-27 07:52:00.775198: This epoch took 98.840444 s

2022-05-27 07:52:00.778480: 
epoch:  106
2022-05-27 07:53:35.436747: train loss : -0.7535
2022-05-27 07:53:42.203918: validation loss: -0.7099
2022-05-27 07:53:42.207924: Average global foreground Dice: [0.7652]
2022-05-27 07:53:42.211368: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:53:42.667898: lr: 0.008052
2022-05-27 07:53:42.691325: This epoch took 101.906961 s

2022-05-27 07:53:42.694512: 
epoch:  107
2022-05-27 07:55:13.736692: train loss : -0.7507
2022-05-27 07:55:20.311522: validation loss: -0.7138
2022-05-27 07:55:20.315150: Average global foreground Dice: [0.7981]
2022-05-27 07:55:20.317528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:55:20.937110: lr: 0.008033
2022-05-27 07:55:20.939686: This epoch took 98.241784 s

2022-05-27 07:55:20.941889: 
epoch:  108
2022-05-27 07:56:51.375855: train loss : -0.7458
2022-05-27 07:56:57.669377: validation loss: -0.7456
2022-05-27 07:56:57.674336: Average global foreground Dice: [0.8014]
2022-05-27 07:56:57.678002: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:56:58.199224: lr: 0.008015
2022-05-27 07:56:58.314462: saving checkpoint...
2022-05-27 07:56:59.589699: done, saving took 1.37 seconds
2022-05-27 07:56:59.606074: This epoch took 98.662076 s

2022-05-27 07:56:59.608785: 
epoch:  109
2022-05-27 07:58:30.336500: train loss : -0.7495
2022-05-27 07:58:37.916511: validation loss: -0.7289
2022-05-27 07:58:37.928408: Average global foreground Dice: [0.7857]
2022-05-27 07:58:37.940800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 07:58:38.437100: lr: 0.007996
2022-05-27 07:58:38.490029: saving checkpoint...
2022-05-27 07:58:39.553878: done, saving took 1.11 seconds
2022-05-27 07:58:39.569695: This epoch took 99.958689 s

2022-05-27 07:58:39.572178: 
epoch:  110
2022-05-27 08:00:10.752865: train loss : -0.7589
2022-05-27 08:00:18.428891: validation loss: -0.7580
2022-05-27 08:00:18.432666: Average global foreground Dice: [0.797]
2022-05-27 08:00:18.435719: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:00:18.888289: lr: 0.007978
2022-05-27 08:00:18.942834: saving checkpoint...
2022-05-27 08:00:20.000589: done, saving took 1.11 seconds
2022-05-27 08:00:20.016747: This epoch took 100.442510 s

2022-05-27 08:00:20.019042: 
epoch:  111
2022-05-27 08:01:54.753521: train loss : -0.7508
2022-05-27 08:02:02.515633: validation loss: -0.7377
2022-05-27 08:02:02.519819: Average global foreground Dice: [0.783]
2022-05-27 08:02:02.522208: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:02:03.058905: lr: 0.007959
2022-05-27 08:02:03.061464: This epoch took 103.040092 s

2022-05-27 08:02:03.063572: 
epoch:  112
2022-05-27 08:03:34.709674: train loss : -0.7529
2022-05-27 08:03:42.509474: validation loss: -0.7302
2022-05-27 08:03:42.520757: Average global foreground Dice: [0.788]
2022-05-27 08:03:42.549344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:03:43.414331: lr: 0.007941
2022-05-27 08:03:43.477964: saving checkpoint...
2022-05-27 08:03:44.792028: done, saving took 1.38 seconds
2022-05-27 08:03:44.805869: This epoch took 101.740051 s

2022-05-27 08:03:44.808383: 
epoch:  113
2022-05-27 08:05:19.275817: train loss : -0.7475
2022-05-27 08:05:28.355576: validation loss: -0.7371
2022-05-27 08:05:28.384800: Average global foreground Dice: [0.7965]
2022-05-27 08:05:28.404683: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:05:29.032300: lr: 0.007922
2022-05-27 08:05:29.116611: saving checkpoint...
2022-05-27 08:05:30.414065: done, saving took 1.36 seconds
2022-05-27 08:05:30.431125: This epoch took 105.620106 s

2022-05-27 08:05:30.433520: 
epoch:  114
2022-05-27 08:07:03.315198: train loss : -0.7654
2022-05-27 08:07:13.023314: validation loss: -0.7277
2022-05-27 08:07:13.027712: Average global foreground Dice: [0.7779]
2022-05-27 08:07:13.030627: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:07:13.514664: lr: 0.007904
2022-05-27 08:07:13.517339: This epoch took 103.081242 s

2022-05-27 08:07:13.526382: 
epoch:  115
2022-05-27 08:08:46.667658: train loss : -0.7497
2022-05-27 08:08:55.133471: validation loss: -0.7473
2022-05-27 08:08:55.162727: Average global foreground Dice: [0.7842]
2022-05-27 08:08:55.182297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:08:55.789357: lr: 0.007885
2022-05-27 08:08:55.792566: This epoch took 102.218473 s

2022-05-27 08:08:55.808588: 
epoch:  116
2022-05-27 08:10:27.486628: train loss : -0.7564
2022-05-27 08:10:35.523611: validation loss: -0.7504
2022-05-27 08:10:35.527409: Average global foreground Dice: [0.7905]
2022-05-27 08:10:35.530161: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:10:35.988675: lr: 0.007867
2022-05-27 08:10:35.991738: This epoch took 100.167368 s

2022-05-27 08:10:35.994061: 
epoch:  117
2022-05-27 08:12:07.470273: train loss : -0.7434
2022-05-27 08:12:14.569205: validation loss: -0.7186
2022-05-27 08:12:14.572585: Average global foreground Dice: [0.7826]
2022-05-27 08:12:14.574881: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:12:15.016150: lr: 0.007848
2022-05-27 08:12:15.018456: This epoch took 99.022162 s

2022-05-27 08:12:15.020784: 
epoch:  118
2022-05-27 08:13:46.192280: train loss : -0.7462
2022-05-27 08:13:55.089505: validation loss: -0.6878
2022-05-27 08:13:55.093388: Average global foreground Dice: [0.7735]
2022-05-27 08:13:55.098450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:13:55.551474: lr: 0.00783
2022-05-27 08:13:55.553764: This epoch took 100.530545 s

2022-05-27 08:13:55.556098: 
epoch:  119
2022-05-27 08:15:26.185205: train loss : -0.7377
2022-05-27 08:15:33.779929: validation loss: -0.7252
2022-05-27 08:15:33.783435: Average global foreground Dice: [0.7847]
2022-05-27 08:15:33.785716: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:15:34.254751: lr: 0.007811
2022-05-27 08:15:34.279738: This epoch took 98.721420 s

2022-05-27 08:15:34.301325: 
epoch:  120
2022-05-27 08:17:05.640615: train loss : -0.7487
2022-05-27 08:17:14.265845: validation loss: -0.7209
2022-05-27 08:17:14.271759: Average global foreground Dice: [0.7962]
2022-05-27 08:17:14.274849: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:17:14.948447: lr: 0.007793
2022-05-27 08:17:14.955025: This epoch took 100.631719 s

2022-05-27 08:17:14.961688: 
epoch:  121
2022-05-27 08:18:47.530033: train loss : -0.7618
2022-05-27 08:18:57.610540: validation loss: -0.7506
2022-05-27 08:18:57.614161: Average global foreground Dice: [0.7993]
2022-05-27 08:18:57.628302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:18:58.146137: lr: 0.007774
2022-05-27 08:18:58.197874: saving checkpoint...
2022-05-27 08:18:59.315180: done, saving took 1.17 seconds
2022-05-27 08:18:59.331531: This epoch took 104.354248 s

2022-05-27 08:18:59.333952: 
epoch:  122
2022-05-27 08:20:31.913420: train loss : -0.7308
2022-05-27 08:20:42.034446: validation loss: -0.7320
2022-05-27 08:20:42.066770: Average global foreground Dice: [0.7952]
2022-05-27 08:20:42.069438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:20:42.621913: lr: 0.007756
2022-05-27 08:20:42.696843: saving checkpoint...
2022-05-27 08:20:43.912106: done, saving took 1.26 seconds
2022-05-27 08:20:43.925854: This epoch took 104.589693 s

2022-05-27 08:20:43.927876: 
epoch:  123
2022-05-27 08:22:14.896524: train loss : -0.7540
2022-05-27 08:22:22.197147: validation loss: -0.7214
2022-05-27 08:22:22.200617: Average global foreground Dice: [0.787]
2022-05-27 08:22:22.202968: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:22:22.650998: lr: 0.007737
2022-05-27 08:22:22.653731: This epoch took 98.723828 s

2022-05-27 08:22:22.655996: 
epoch:  124
2022-05-27 08:23:54.611740: train loss : -0.7632
2022-05-27 08:24:01.763084: validation loss: -0.7451
2022-05-27 08:24:01.783022: Average global foreground Dice: [0.7965]
2022-05-27 08:24:01.805538: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:24:02.607078: lr: 0.007719
2022-05-27 08:24:02.676364: saving checkpoint...
2022-05-27 08:24:03.889874: done, saving took 1.25 seconds
2022-05-27 08:24:03.907222: This epoch took 101.248813 s

2022-05-27 08:24:03.910315: 
epoch:  125
2022-05-27 08:25:35.463064: train loss : -0.7542
2022-05-27 08:25:45.847510: validation loss: -0.6971
2022-05-27 08:25:45.882916: Average global foreground Dice: [0.7761]
2022-05-27 08:25:45.905380: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:25:46.509787: lr: 0.0077
2022-05-27 08:25:46.529526: This epoch took 102.616208 s

2022-05-27 08:25:46.542896: 
epoch:  126
2022-05-27 08:27:22.435442: train loss : -0.7524
2022-05-27 08:27:29.731120: validation loss: -0.7407
2022-05-27 08:27:29.752296: Average global foreground Dice: [0.7941]
2022-05-27 08:27:29.754839: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:27:30.311547: lr: 0.007682
2022-05-27 08:27:30.314098: This epoch took 103.751044 s

2022-05-27 08:27:30.316362: 
epoch:  127
2022-05-27 08:29:01.745831: train loss : -0.7546
2022-05-27 08:29:09.917549: validation loss: -0.7116
2022-05-27 08:29:09.935971: Average global foreground Dice: [0.7675]
2022-05-27 08:29:09.951283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:29:10.508730: lr: 0.007663
2022-05-27 08:29:10.535097: This epoch took 100.216619 s

2022-05-27 08:29:10.544390: 
epoch:  128
2022-05-27 08:30:45.138331: train loss : -0.7674
2022-05-27 08:30:54.439946: validation loss: -0.7288
2022-05-27 08:30:54.475740: Average global foreground Dice: [0.7848]
2022-05-27 08:30:54.513074: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:30:55.197654: lr: 0.007645
2022-05-27 08:30:55.228392: This epoch took 104.679581 s

2022-05-27 08:30:55.251435: 
epoch:  129
2022-05-27 08:32:29.908874: train loss : -0.7514
2022-05-27 08:32:40.860551: validation loss: -0.6973
2022-05-27 08:32:40.880856: Average global foreground Dice: [0.7816]
2022-05-27 08:32:40.900312: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:32:41.479704: lr: 0.007626
2022-05-27 08:32:41.502557: This epoch took 106.224257 s

2022-05-27 08:32:41.522298: 
epoch:  130
2022-05-27 08:34:15.539338: train loss : -0.7549
2022-05-27 08:34:24.411033: validation loss: -0.7324
2022-05-27 08:34:24.414556: Average global foreground Dice: [0.8046]
2022-05-27 08:34:24.417144: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:34:24.892081: lr: 0.007608
2022-05-27 08:34:24.894675: This epoch took 103.350165 s

2022-05-27 08:34:24.897004: 
epoch:  131
2022-05-27 08:35:55.753939: train loss : -0.7646
2022-05-27 08:36:04.417095: validation loss: -0.7389
2022-05-27 08:36:04.432864: Average global foreground Dice: [0.7964]
2022-05-27 08:36:04.437564: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:36:04.926076: lr: 0.007589
2022-05-27 08:36:04.928733: This epoch took 100.029071 s

2022-05-27 08:36:04.931912: 
epoch:  132
2022-05-27 08:37:36.119941: train loss : -0.7842
2022-05-27 08:37:44.306906: validation loss: -0.7487
2022-05-27 08:37:44.310424: Average global foreground Dice: [0.8016]
2022-05-27 08:37:44.312869: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:37:44.939035: lr: 0.007571
2022-05-27 08:37:44.999976: saving checkpoint...
2022-05-27 08:37:46.119127: done, saving took 1.17 seconds
2022-05-27 08:37:46.166592: This epoch took 101.229835 s

2022-05-27 08:37:46.169261: 
epoch:  133
2022-05-27 08:39:16.731378: train loss : -0.7583
2022-05-27 08:39:25.909456: validation loss: -0.7230
2022-05-27 08:39:25.912862: Average global foreground Dice: [0.774]
2022-05-27 08:39:25.915381: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:39:26.370407: lr: 0.007552
2022-05-27 08:39:26.372941: This epoch took 100.201561 s

2022-05-27 08:39:26.375412: 
epoch:  134
2022-05-27 08:40:57.849176: train loss : -0.7443
2022-05-27 08:41:06.519497: validation loss: -0.7691
2022-05-27 08:41:06.549762: Average global foreground Dice: [0.81]
2022-05-27 08:41:06.572321: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:41:07.064689: lr: 0.007533
2022-05-27 08:41:07.114962: saving checkpoint...
2022-05-27 08:41:08.202588: done, saving took 1.14 seconds
2022-05-27 08:41:08.219511: This epoch took 101.841629 s

2022-05-27 08:41:08.221902: 
epoch:  135
2022-05-27 08:42:38.932461: train loss : -0.7659
2022-05-27 08:42:47.188457: validation loss: -0.6865
2022-05-27 08:42:47.191955: Average global foreground Dice: [0.7802]
2022-05-27 08:42:47.194850: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:42:47.815088: lr: 0.007515
2022-05-27 08:42:47.817271: This epoch took 99.592428 s

2022-05-27 08:42:47.819532: 
epoch:  136
2022-05-27 08:44:24.366435: train loss : -0.7467
2022-05-27 08:44:31.687309: validation loss: -0.7149
2022-05-27 08:44:31.697733: Average global foreground Dice: [0.7859]
2022-05-27 08:44:31.712533: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:44:32.232696: lr: 0.007496
2022-05-27 08:44:32.242512: This epoch took 104.420781 s

2022-05-27 08:44:32.245636: 
epoch:  137
2022-05-27 08:46:02.798510: train loss : -0.7502
2022-05-27 08:46:10.153495: validation loss: -0.7599
2022-05-27 08:46:10.157613: Average global foreground Dice: [0.8038]
2022-05-27 08:46:10.160091: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:46:10.718386: lr: 0.007478
2022-05-27 08:46:10.754211: saving checkpoint...
2022-05-27 08:46:11.874657: done, saving took 1.15 seconds
2022-05-27 08:46:11.889920: This epoch took 99.641129 s

2022-05-27 08:46:11.892849: 
epoch:  138
2022-05-27 08:47:41.671276: train loss : -0.7514
2022-05-27 08:47:49.870316: validation loss: -0.7463
2022-05-27 08:47:49.874679: Average global foreground Dice: [0.7929]
2022-05-27 08:47:49.877857: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:47:50.320029: lr: 0.007459
2022-05-27 08:47:50.357496: saving checkpoint...
2022-05-27 08:47:51.575884: done, saving took 1.25 seconds
2022-05-27 08:47:51.591786: This epoch took 99.696372 s

2022-05-27 08:47:51.594650: 
epoch:  139
2022-05-27 08:49:21.622747: train loss : -0.7503
2022-05-27 08:49:28.062856: validation loss: -0.7433
2022-05-27 08:49:28.076707: Average global foreground Dice: [0.7921]
2022-05-27 08:49:28.084528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:49:28.704934: lr: 0.00744
2022-05-27 08:49:28.754495: saving checkpoint...
2022-05-27 08:49:29.898347: done, saving took 1.19 seconds
2022-05-27 08:49:29.915194: This epoch took 98.317976 s

2022-05-27 08:49:29.917698: 
epoch:  140
2022-05-27 08:51:03.756549: train loss : -0.7448
2022-05-27 08:51:11.709612: validation loss: -0.7197
2022-05-27 08:51:11.713401: Average global foreground Dice: [0.7735]
2022-05-27 08:51:11.716078: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:51:12.176825: lr: 0.007422
2022-05-27 08:51:12.184014: This epoch took 102.263785 s

2022-05-27 08:51:12.186753: 
epoch:  141
2022-05-27 08:52:42.898130: train loss : -0.7540
2022-05-27 08:52:49.832819: validation loss: -0.7000
2022-05-27 08:52:49.836161: Average global foreground Dice: [0.7704]
2022-05-27 08:52:49.838354: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:52:50.283285: lr: 0.007403
2022-05-27 08:52:50.285978: This epoch took 98.093936 s

2022-05-27 08:52:50.289432: 
epoch:  142
2022-05-27 08:54:20.995822: train loss : -0.7492
2022-05-27 08:54:30.465694: validation loss: -0.7383
2022-05-27 08:54:30.469349: Average global foreground Dice: [0.7908]
2022-05-27 08:54:30.489420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:54:30.976362: lr: 0.007385
2022-05-27 08:54:30.996303: This epoch took 100.702479 s

2022-05-27 08:54:30.999138: 
epoch:  143
2022-05-27 08:56:02.465710: train loss : -0.7582
2022-05-27 08:56:12.066955: validation loss: -0.7078
2022-05-27 08:56:12.077705: Average global foreground Dice: [0.7821]
2022-05-27 08:56:12.087834: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:56:12.827350: lr: 0.007366
2022-05-27 08:56:12.830306: This epoch took 101.828767 s

2022-05-27 08:56:12.832811: 
epoch:  144
2022-05-27 08:57:44.799573: train loss : -0.7541
2022-05-27 08:57:54.022078: validation loss: -0.7314
2022-05-27 08:57:54.025394: Average global foreground Dice: [0.8033]
2022-05-27 08:57:54.027885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:57:54.522041: lr: 0.007347
2022-05-27 08:57:54.524694: This epoch took 101.686227 s

2022-05-27 08:57:54.526966: 
epoch:  145
2022-05-27 08:59:25.953165: train loss : -0.7588
2022-05-27 08:59:35.045193: validation loss: -0.7381
2022-05-27 08:59:35.048959: Average global foreground Dice: [0.7904]
2022-05-27 08:59:35.051960: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 08:59:35.501632: lr: 0.007329
2022-05-27 08:59:35.526357: This epoch took 100.997077 s

2022-05-27 08:59:35.543297: 
epoch:  146
2022-05-27 09:01:06.871802: train loss : -0.7618
2022-05-27 09:01:14.748361: validation loss: -0.7501
2022-05-27 09:01:14.752587: Average global foreground Dice: [0.8004]
2022-05-27 09:01:14.757530: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:01:15.210959: lr: 0.00731
2022-05-27 09:01:15.214984: This epoch took 99.661768 s

2022-05-27 09:01:15.217234: 
epoch:  147
2022-05-27 09:02:45.999764: train loss : -0.7652
2022-05-27 09:02:53.734384: validation loss: -0.7380
2022-05-27 09:02:53.738752: Average global foreground Dice: [0.7897]
2022-05-27 09:02:53.745315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:02:54.210130: lr: 0.007291
2022-05-27 09:02:54.221211: This epoch took 98.992022 s

2022-05-27 09:02:54.223624: 
epoch:  148
2022-05-27 09:04:25.349345: train loss : -0.7821
2022-05-27 09:04:33.209547: validation loss: -0.7543
2022-05-27 09:04:33.213606: Average global foreground Dice: [0.809]
2022-05-27 09:04:33.216259: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:04:33.677047: lr: 0.007273
2022-05-27 09:04:33.726619: saving checkpoint...
2022-05-27 09:04:34.819762: done, saving took 1.14 seconds
2022-05-27 09:04:34.836364: This epoch took 100.605608 s

2022-05-27 09:04:34.838968: 
epoch:  149
2022-05-27 09:06:09.540615: train loss : -0.7620
2022-05-27 09:06:19.002485: validation loss: -0.7398
2022-05-27 09:06:19.006323: Average global foreground Dice: [0.7908]
2022-05-27 09:06:19.008518: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:06:19.577291: lr: 0.007254
2022-05-27 09:06:19.580315: saving scheduled checkpoint file...
2022-05-27 09:06:19.620049: saving checkpoint...
2022-05-27 09:06:20.698274: done, saving took 1.11 seconds
2022-05-27 09:06:20.714890: done
2022-05-27 09:06:20.717082: This epoch took 105.875697 s

2022-05-27 09:06:20.719161: 
epoch:  150
2022-05-27 09:07:51.688960: train loss : -0.7622
2022-05-27 09:08:00.794083: validation loss: -0.7230
2022-05-27 09:08:00.797833: Average global foreground Dice: [0.7837]
2022-05-27 09:08:00.800357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:08:01.270068: lr: 0.007236
2022-05-27 09:08:01.303308: This epoch took 100.581821 s

2022-05-27 09:08:01.336284: 
epoch:  151
2022-05-27 09:09:35.079474: train loss : -0.7677
2022-05-27 09:09:43.886418: validation loss: -0.7574
2022-05-27 09:09:43.922204: Average global foreground Dice: [0.8002]
2022-05-27 09:09:43.943361: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:09:44.517806: lr: 0.007217
2022-05-27 09:09:44.552755: saving checkpoint...
2022-05-27 09:09:45.695256: done, saving took 1.17 seconds
2022-05-27 09:09:45.712105: This epoch took 104.355339 s

2022-05-27 09:09:45.714799: 
epoch:  152
2022-05-27 09:11:16.708039: train loss : -0.7683
2022-05-27 09:11:25.828604: validation loss: -0.7264
2022-05-27 09:11:25.861812: Average global foreground Dice: [0.7728]
2022-05-27 09:11:25.891305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:11:26.445620: lr: 0.007198
2022-05-27 09:11:26.448137: This epoch took 100.730293 s

2022-05-27 09:11:26.450696: 
epoch:  153
2022-05-27 09:12:58.198468: train loss : -0.7793
2022-05-27 09:13:07.483534: validation loss: -0.7361
2022-05-27 09:13:07.527932: Average global foreground Dice: [0.7966]
2022-05-27 09:13:07.549337: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:13:08.453054: lr: 0.00718
2022-05-27 09:13:08.482353: This epoch took 102.029043 s

2022-05-27 09:13:08.504292: 
epoch:  154
2022-05-27 09:14:42.978367: train loss : -0.7450
2022-05-27 09:14:51.469679: validation loss: -0.7177
2022-05-27 09:14:51.473117: Average global foreground Dice: [0.7628]
2022-05-27 09:14:51.476102: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:14:51.925363: lr: 0.007161
2022-05-27 09:14:51.927634: This epoch took 103.390334 s

2022-05-27 09:14:51.929840: 
epoch:  155
2022-05-27 09:16:21.513793: train loss : -0.7576
2022-05-27 09:16:28.191597: validation loss: -0.6971
2022-05-27 09:16:28.196038: Average global foreground Dice: [0.7589]
2022-05-27 09:16:28.198803: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:16:28.666309: lr: 0.007142
2022-05-27 09:16:28.668804: This epoch took 96.736951 s

2022-05-27 09:16:28.671165: 
epoch:  156
2022-05-27 09:17:59.395395: train loss : -0.7548
2022-05-27 09:18:05.981287: validation loss: -0.7375
2022-05-27 09:18:05.985076: Average global foreground Dice: [0.7836]
2022-05-27 09:18:05.987846: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:18:06.556689: lr: 0.007123
2022-05-27 09:18:06.559092: This epoch took 97.885923 s

2022-05-27 09:18:06.561205: 
epoch:  157
2022-05-27 09:19:37.843430: train loss : -0.7567
2022-05-27 09:19:47.418511: validation loss: -0.6975
2022-05-27 09:19:47.421954: Average global foreground Dice: [0.7421]
2022-05-27 09:19:47.424440: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:19:47.901703: lr: 0.007105
2022-05-27 09:19:47.904357: This epoch took 101.341138 s

2022-05-27 09:19:47.906587: 
epoch:  158
2022-05-27 09:21:21.624207: train loss : -0.7248
2022-05-27 09:21:31.758502: validation loss: -0.7194
2022-05-27 09:21:31.764393: Average global foreground Dice: [0.7846]
2022-05-27 09:21:31.766714: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:21:32.328514: lr: 0.007086
2022-05-27 09:21:32.333963: This epoch took 104.425071 s

2022-05-27 09:21:32.337821: 
epoch:  159
2022-05-27 09:23:05.239928: train loss : -0.7435
2022-05-27 09:23:15.411861: validation loss: -0.7054
2022-05-27 09:23:15.453711: Average global foreground Dice: [0.764]
2022-05-27 09:23:15.474487: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:23:16.126502: lr: 0.007067
2022-05-27 09:23:16.129521: This epoch took 103.789123 s

2022-05-27 09:23:16.131720: 
epoch:  160
2022-05-27 09:24:51.580285: train loss : -0.7409
2022-05-27 09:24:58.656126: validation loss: -0.7384
2022-05-27 09:24:58.663379: Average global foreground Dice: [0.7944]
2022-05-27 09:24:58.668826: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:24:59.166657: lr: 0.007049
2022-05-27 09:24:59.169294: This epoch took 103.035170 s

2022-05-27 09:24:59.171569: 
epoch:  161
2022-05-27 09:26:36.012601: train loss : -0.7447
2022-05-27 09:26:44.588136: validation loss: -0.7096
2022-05-27 09:26:44.592997: Average global foreground Dice: [0.7855]
2022-05-27 09:26:44.595752: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:26:45.074570: lr: 0.00703
2022-05-27 09:26:45.076818: This epoch took 105.903097 s

2022-05-27 09:26:45.087485: 
epoch:  162
2022-05-27 09:28:16.461684: train loss : -0.7575
2022-05-27 09:28:24.030192: validation loss: -0.7287
2022-05-27 09:28:24.033664: Average global foreground Dice: [0.7805]
2022-05-27 09:28:24.035836: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:28:24.494820: lr: 0.007011
2022-05-27 09:28:24.497282: This epoch took 99.402028 s

2022-05-27 09:28:24.499330: 
epoch:  163
2022-05-27 09:29:55.799716: train loss : -0.7512
2022-05-27 09:30:03.590020: validation loss: -0.7693
2022-05-27 09:30:03.593148: Average global foreground Dice: [0.8127]
2022-05-27 09:30:03.595212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:30:04.054534: lr: 0.006992
2022-05-27 09:30:04.057027: This epoch took 99.555551 s

2022-05-27 09:30:04.059040: 
epoch:  164
2022-05-27 09:31:35.406090: train loss : -0.7650
2022-05-27 09:31:44.818370: validation loss: -0.7415
2022-05-27 09:31:44.827137: Average global foreground Dice: [0.798]
2022-05-27 09:31:44.829655: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:31:45.435695: lr: 0.006974
2022-05-27 09:31:45.438273: This epoch took 101.377088 s

2022-05-27 09:31:45.440822: 
epoch:  165
2022-05-27 09:33:17.421684: train loss : -0.7770
2022-05-27 09:33:25.343406: validation loss: -0.7404
2022-05-27 09:33:25.375697: Average global foreground Dice: [0.7925]
2022-05-27 09:33:25.392357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:33:25.974755: lr: 0.006955
2022-05-27 09:33:25.977613: This epoch took 100.534725 s

2022-05-27 09:33:25.979732: 
epoch:  166
2022-05-27 09:34:57.446359: train loss : -0.7686
2022-05-27 09:35:06.345611: validation loss: -0.7320
2022-05-27 09:35:06.368061: Average global foreground Dice: [0.79]
2022-05-27 09:35:06.389416: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:35:06.942285: lr: 0.006936
2022-05-27 09:35:06.945341: This epoch took 100.963592 s

2022-05-27 09:35:06.947922: 
epoch:  167
2022-05-27 09:36:38.797277: train loss : -0.7720
2022-05-27 09:36:46.159083: validation loss: -0.7398
2022-05-27 09:36:46.162347: Average global foreground Dice: [0.7735]
2022-05-27 09:36:46.164690: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:36:46.633340: lr: 0.006918
2022-05-27 09:36:46.635590: This epoch took 99.684994 s

2022-05-27 09:36:46.637570: 
epoch:  168
2022-05-27 09:38:17.790272: train loss : -0.7548
2022-05-27 09:38:24.983694: validation loss: -0.7249
2022-05-27 09:38:24.987385: Average global foreground Dice: [0.7907]
2022-05-27 09:38:24.989442: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:38:25.474923: lr: 0.006899
2022-05-27 09:38:25.478992: This epoch took 98.835508 s

2022-05-27 09:38:25.481351: 
epoch:  169
2022-05-27 09:39:56.545134: train loss : -0.7462
2022-05-27 09:40:05.268027: validation loss: -0.7304
2022-05-27 09:40:05.274354: Average global foreground Dice: [0.7948]
2022-05-27 09:40:05.280126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:40:05.779468: lr: 0.00688
2022-05-27 09:40:05.782124: This epoch took 100.298578 s

2022-05-27 09:40:05.784333: 
epoch:  170
2022-05-27 09:41:39.039299: train loss : -0.7548
2022-05-27 09:41:46.104654: validation loss: -0.7151
2022-05-27 09:41:46.108480: Average global foreground Dice: [0.7666]
2022-05-27 09:41:46.112612: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:41:46.595541: lr: 0.006861
2022-05-27 09:41:46.598385: This epoch took 100.811894 s

2022-05-27 09:41:46.600848: 
epoch:  171
2022-05-27 09:43:18.179151: train loss : -0.7634
2022-05-27 09:43:26.131306: validation loss: -0.7243
2022-05-27 09:43:26.152030: Average global foreground Dice: [0.7926]
2022-05-27 09:43:26.171798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:43:26.782888: lr: 0.006842
2022-05-27 09:43:26.815365: This epoch took 100.212275 s

2022-05-27 09:43:26.838288: 
epoch:  172
2022-05-27 09:44:59.221970: train loss : -0.7651
2022-05-27 09:45:08.226003: validation loss: -0.7432
2022-05-27 09:45:08.232715: Average global foreground Dice: [0.7922]
2022-05-27 09:45:08.235125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:45:08.684933: lr: 0.006824
2022-05-27 09:45:08.687467: This epoch took 101.826174 s

2022-05-27 09:45:08.689519: 
epoch:  173
2022-05-27 09:46:39.422041: train loss : -0.7720
2022-05-27 09:46:47.930746: validation loss: -0.7488
2022-05-27 09:46:47.953385: Average global foreground Dice: [0.8004]
2022-05-27 09:46:47.986311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:46:48.643742: lr: 0.006805
2022-05-27 09:46:48.666755: This epoch took 99.974635 s

2022-05-27 09:46:48.685791: 
epoch:  174
2022-05-27 09:48:22.945149: train loss : -0.7634
2022-05-27 09:48:30.886410: validation loss: -0.7046
2022-05-27 09:48:30.890238: Average global foreground Dice: [0.7716]
2022-05-27 09:48:30.892323: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:48:31.371828: lr: 0.006786
2022-05-27 09:48:31.374326: This epoch took 102.675038 s

2022-05-27 09:48:31.376755: 
epoch:  175
2022-05-27 09:50:02.469174: train loss : -0.7898
2022-05-27 09:50:09.109640: validation loss: -0.7229
2022-05-27 09:50:09.113093: Average global foreground Dice: [0.788]
2022-05-27 09:50:09.115692: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:50:09.611451: lr: 0.006767
2022-05-27 09:50:09.614124: This epoch took 98.235116 s

2022-05-27 09:50:09.616084: 
epoch:  176
2022-05-27 09:51:45.538847: train loss : -0.7612
2022-05-27 09:51:53.777785: validation loss: -0.7561
2022-05-27 09:51:53.781139: Average global foreground Dice: [0.793]
2022-05-27 09:51:53.783190: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:51:54.242664: lr: 0.006749
2022-05-27 09:51:54.246913: This epoch took 104.628592 s

2022-05-27 09:51:54.251287: 
epoch:  177
2022-05-27 09:53:28.498607: train loss : -0.7763
2022-05-27 09:53:37.810052: validation loss: -0.7388
2022-05-27 09:53:37.813475: Average global foreground Dice: [0.7993]
2022-05-27 09:53:37.826393: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:53:38.421335: lr: 0.00673
2022-05-27 09:53:38.424295: This epoch took 104.170567 s

2022-05-27 09:53:38.426749: 
epoch:  178
2022-05-27 09:55:10.109122: train loss : -0.7705
2022-05-27 09:55:20.125108: validation loss: -0.7579
2022-05-27 09:55:20.131200: Average global foreground Dice: [0.8136]
2022-05-27 09:55:20.133301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:55:20.627581: lr: 0.006711
2022-05-27 09:55:20.650408: This epoch took 102.218797 s

2022-05-27 09:55:20.662986: 
epoch:  179
2022-05-27 09:56:51.926630: train loss : -0.7662
2022-05-27 09:57:01.871701: validation loss: -0.7318
2022-05-27 09:57:01.905020: Average global foreground Dice: [0.7865]
2022-05-27 09:57:01.932623: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:57:02.783232: lr: 0.006692
2022-05-27 09:57:02.786241: This epoch took 102.121034 s

2022-05-27 09:57:02.788847: 
epoch:  180
2022-05-27 09:58:38.715492: train loss : -0.7636
2022-05-27 09:58:47.586603: validation loss: -0.7684
2022-05-27 09:58:47.592679: Average global foreground Dice: [0.8161]
2022-05-27 09:58:47.595706: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 09:58:48.066221: lr: 0.006673
2022-05-27 09:58:48.118175: saving checkpoint...
2022-05-27 09:58:49.153932: done, saving took 1.09 seconds
2022-05-27 09:58:49.168468: This epoch took 106.377213 s

2022-05-27 09:58:49.170832: 
epoch:  181
2022-05-27 10:00:21.827435: train loss : -0.7741
2022-05-27 10:00:31.146517: validation loss: -0.7368
2022-05-27 10:00:31.150023: Average global foreground Dice: [0.809]
2022-05-27 10:00:31.152292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:00:31.747469: lr: 0.006654
2022-05-27 10:00:31.783469: saving checkpoint...
2022-05-27 10:00:32.782035: done, saving took 1.03 seconds
2022-05-27 10:00:32.795057: This epoch took 103.622145 s

2022-05-27 10:00:32.797692: 
epoch:  182
2022-05-27 10:02:08.135698: train loss : -0.7872
2022-05-27 10:02:16.293934: validation loss: -0.7415
2022-05-27 10:02:16.298294: Average global foreground Dice: [0.7885]
2022-05-27 10:02:16.300521: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:02:16.751149: lr: 0.006636
2022-05-27 10:02:16.753455: This epoch took 103.953702 s

2022-05-27 10:02:16.755407: 
epoch:  183
2022-05-27 10:03:47.847872: train loss : -0.7783
2022-05-27 10:03:56.025614: validation loss: -0.7365
2022-05-27 10:03:56.038658: Average global foreground Dice: [0.8103]
2022-05-27 10:03:56.040900: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:03:56.499291: lr: 0.006617
2022-05-27 10:03:56.531857: saving checkpoint...
2022-05-27 10:03:57.638108: done, saving took 1.14 seconds
2022-05-27 10:03:57.651937: This epoch took 100.894457 s

2022-05-27 10:03:57.654068: 
epoch:  184
2022-05-27 10:05:30.367922: train loss : -0.7708
2022-05-27 10:05:37.649199: validation loss: -0.7322
2022-05-27 10:05:37.653481: Average global foreground Dice: [0.7884]
2022-05-27 10:05:37.655785: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:05:38.220314: lr: 0.006598
2022-05-27 10:05:38.222798: This epoch took 100.566654 s

2022-05-27 10:05:38.225170: 
epoch:  185
2022-05-27 10:07:09.389122: train loss : -0.7811
2022-05-27 10:07:17.142677: validation loss: -0.7556
2022-05-27 10:07:17.173098: Average global foreground Dice: [0.7876]
2022-05-27 10:07:17.201395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:07:17.801046: lr: 0.006579
2022-05-27 10:07:17.820539: This epoch took 99.588135 s

2022-05-27 10:07:17.846504: 
epoch:  186
2022-05-27 10:08:51.012597: train loss : -0.7743
2022-05-27 10:08:59.750796: validation loss: -0.7361
2022-05-27 10:08:59.755564: Average global foreground Dice: [0.782]
2022-05-27 10:08:59.758230: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:09:00.232832: lr: 0.00656
2022-05-27 10:09:00.235441: This epoch took 102.365458 s

2022-05-27 10:09:00.237844: 
epoch:  187
2022-05-27 10:10:31.633096: train loss : -0.7852
2022-05-27 10:10:39.453004: validation loss: -0.7409
2022-05-27 10:10:39.486823: Average global foreground Dice: [0.7996]
2022-05-27 10:10:39.495417: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:10:39.981337: lr: 0.006541
2022-05-27 10:10:39.983986: This epoch took 99.743996 s

2022-05-27 10:10:39.986260: 
epoch:  188
2022-05-27 10:12:11.436919: train loss : -0.7705
2022-05-27 10:12:19.388501: validation loss: -0.7493
2022-05-27 10:12:19.391799: Average global foreground Dice: [0.7973]
2022-05-27 10:12:19.393933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:12:19.842552: lr: 0.006522
2022-05-27 10:12:19.845514: This epoch took 99.856839 s

2022-05-27 10:12:19.849053: 
epoch:  189
2022-05-27 10:13:50.643630: train loss : -0.7821
2022-05-27 10:13:59.421029: validation loss: -0.7388
2022-05-27 10:13:59.426329: Average global foreground Dice: [0.801]
2022-05-27 10:13:59.429672: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:13:59.905874: lr: 0.006504
2022-05-27 10:13:59.933465: This epoch took 100.082390 s

2022-05-27 10:13:59.947815: 
epoch:  190
2022-05-27 10:15:31.597259: train loss : -0.7816
2022-05-27 10:15:41.826802: validation loss: -0.7154
2022-05-27 10:15:41.830795: Average global foreground Dice: [0.7758]
2022-05-27 10:15:41.833201: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:15:42.320813: lr: 0.006485
2022-05-27 10:15:42.323101: This epoch took 102.359127 s

2022-05-27 10:15:42.325359: 
epoch:  191
2022-05-27 10:17:15.445574: train loss : -0.7769
2022-05-27 10:17:27.183844: validation loss: -0.7415
2022-05-27 10:17:27.205873: Average global foreground Dice: [0.8018]
2022-05-27 10:17:27.227337: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:17:27.897696: lr: 0.006466
2022-05-27 10:17:27.907988: This epoch took 105.580442 s

2022-05-27 10:17:27.932270: 
epoch:  192
2022-05-27 10:19:02.083863: train loss : -0.7740
2022-05-27 10:19:11.233965: validation loss: -0.7314
2022-05-27 10:19:11.238748: Average global foreground Dice: [0.7873]
2022-05-27 10:19:11.240673: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:19:11.735039: lr: 0.006447
2022-05-27 10:19:11.740800: This epoch took 103.780503 s

2022-05-27 10:19:11.757288: 
epoch:  193
2022-05-27 10:20:43.713549: train loss : -0.7804
2022-05-27 10:20:52.791543: validation loss: -0.7601
2022-05-27 10:20:52.824143: Average global foreground Dice: [0.8071]
2022-05-27 10:20:52.838467: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:20:53.491649: lr: 0.006428
2022-05-27 10:20:53.524332: This epoch took 101.747036 s

2022-05-27 10:20:53.547292: 
epoch:  194
2022-05-27 10:22:25.015268: train loss : -0.7841
2022-05-27 10:22:32.834619: validation loss: -0.7206
2022-05-27 10:22:32.837967: Average global foreground Dice: [0.818]
2022-05-27 10:22:32.842825: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:22:33.328701: lr: 0.006409
2022-05-27 10:22:33.388352: saving checkpoint...
2022-05-27 10:22:34.423575: done, saving took 1.09 seconds
2022-05-27 10:22:34.438135: This epoch took 100.867834 s

2022-05-27 10:22:34.440767: 
epoch:  195
2022-05-27 10:24:06.303794: train loss : -0.7869
2022-05-27 10:24:13.408377: validation loss: -0.7631
2022-05-27 10:24:13.411595: Average global foreground Dice: [0.8134]
2022-05-27 10:24:13.414378: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:24:13.902064: lr: 0.00639
2022-05-27 10:24:13.948640: saving checkpoint...
2022-05-27 10:24:15.050993: done, saving took 1.15 seconds
2022-05-27 10:24:15.064530: This epoch took 100.621634 s

2022-05-27 10:24:15.066496: 
epoch:  196
2022-05-27 10:25:46.262973: train loss : -0.7818
2022-05-27 10:25:55.824865: validation loss: -0.7715
2022-05-27 10:25:55.853848: Average global foreground Dice: [0.8156]
2022-05-27 10:25:55.883311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:25:56.869220: lr: 0.006371
2022-05-27 10:25:56.949494: saving checkpoint...
2022-05-27 10:25:58.090820: done, saving took 1.21 seconds
2022-05-27 10:25:58.104863: This epoch took 103.036337 s

2022-05-27 10:25:58.107209: 
epoch:  197
2022-05-27 10:27:29.943536: train loss : -0.7954
2022-05-27 10:27:40.172711: validation loss: -0.7600
2022-05-27 10:27:40.175969: Average global foreground Dice: [0.8052]
2022-05-27 10:27:40.179027: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:27:40.674930: lr: 0.006352
2022-05-27 10:27:40.728941: saving checkpoint...
2022-05-27 10:27:41.815018: done, saving took 1.12 seconds
2022-05-27 10:27:41.828761: This epoch took 103.719257 s

2022-05-27 10:27:41.830867: 
epoch:  198
2022-05-27 10:29:13.695160: train loss : -0.8001
2022-05-27 10:29:24.245609: validation loss: -0.7499
2022-05-27 10:29:24.249402: Average global foreground Dice: [0.802]
2022-05-27 10:29:24.251654: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:29:24.745656: lr: 0.006333
2022-05-27 10:29:24.781960: saving checkpoint...
2022-05-27 10:29:25.816912: done, saving took 1.07 seconds
2022-05-27 10:29:25.830657: This epoch took 103.997670 s

2022-05-27 10:29:25.832825: 
epoch:  199
2022-05-27 10:30:58.883758: train loss : -0.7898
2022-05-27 10:31:08.927732: validation loss: -0.7358
2022-05-27 10:31:08.958679: Average global foreground Dice: [0.7797]
2022-05-27 10:31:08.974296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:31:09.836823: lr: 0.006314
2022-05-27 10:31:09.849226: saving scheduled checkpoint file...
2022-05-27 10:31:09.970427: saving checkpoint...
2022-05-27 10:31:11.223638: done, saving took 1.33 seconds
2022-05-27 10:31:11.239189: done
2022-05-27 10:31:11.241423: This epoch took 105.406562 s

2022-05-27 10:31:11.243484: 
epoch:  200
2022-05-27 10:32:47.636321: train loss : -0.7801
2022-05-27 10:32:54.463952: validation loss: -0.7510
2022-05-27 10:32:54.467314: Average global foreground Dice: [0.804]
2022-05-27 10:32:54.469390: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:32:54.926494: lr: 0.006296
2022-05-27 10:32:54.931566: This epoch took 103.686029 s

2022-05-27 10:32:54.933833: 
epoch:  201
2022-05-27 10:34:26.350689: train loss : -0.7838
2022-05-27 10:34:34.994033: validation loss: -0.7240
2022-05-27 10:34:34.997805: Average global foreground Dice: [0.7921]
2022-05-27 10:34:35.000402: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:34:35.539215: lr: 0.006277
2022-05-27 10:34:35.568596: This epoch took 100.632372 s

2022-05-27 10:34:35.588769: 
epoch:  202
2022-05-27 10:36:06.729342: train loss : -0.7882
2022-05-27 10:36:13.379750: validation loss: -0.7183
2022-05-27 10:36:13.383185: Average global foreground Dice: [0.7869]
2022-05-27 10:36:13.386103: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:36:13.829597: lr: 0.006258
2022-05-27 10:36:13.831889: This epoch took 98.223149 s

2022-05-27 10:36:13.834100: 
epoch:  203
2022-05-27 10:37:44.191733: train loss : -0.7812
2022-05-27 10:37:50.443776: validation loss: -0.7348
2022-05-27 10:37:50.447331: Average global foreground Dice: [0.7889]
2022-05-27 10:37:50.449666: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:37:50.894317: lr: 0.006239
2022-05-27 10:37:50.896642: This epoch took 97.060549 s

2022-05-27 10:37:50.898658: 
epoch:  204
2022-05-27 10:39:21.994154: train loss : -0.7862
2022-05-27 10:39:28.977280: validation loss: -0.7053
2022-05-27 10:39:28.981225: Average global foreground Dice: [0.7951]
2022-05-27 10:39:28.983270: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:39:29.444558: lr: 0.00622
2022-05-27 10:39:29.446731: This epoch took 98.545624 s

2022-05-27 10:39:29.448608: 
epoch:  205
2022-05-27 10:41:02.158918: train loss : -0.7825
2022-05-27 10:41:10.683498: validation loss: -0.7355
2022-05-27 10:41:10.686696: Average global foreground Dice: [0.7867]
2022-05-27 10:41:10.688667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:41:11.132510: lr: 0.006201
2022-05-27 10:41:11.134805: This epoch took 101.684230 s

2022-05-27 10:41:11.137464: 
epoch:  206
2022-05-27 10:42:45.617564: train loss : -0.7827
2022-05-27 10:42:52.747627: validation loss: -0.7247
2022-05-27 10:42:52.750836: Average global foreground Dice: [0.7992]
2022-05-27 10:42:52.753031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:42:53.188887: lr: 0.006182
2022-05-27 10:42:53.211296: This epoch took 102.071597 s

2022-05-27 10:42:53.217214: 
epoch:  207
2022-05-27 10:44:23.859030: train loss : -0.7903
2022-05-27 10:44:33.772901: validation loss: -0.7539
2022-05-27 10:44:33.781709: Average global foreground Dice: [0.7985]
2022-05-27 10:44:33.783993: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:44:34.536556: lr: 0.006163
2022-05-27 10:44:34.539025: This epoch took 101.319295 s

2022-05-27 10:44:34.540983: 
epoch:  208
2022-05-27 10:46:11.571297: train loss : -0.7781
2022-05-27 10:46:24.045135: validation loss: -0.7356
2022-05-27 10:46:24.048814: Average global foreground Dice: [0.7935]
2022-05-27 10:46:24.051140: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:46:24.496631: lr: 0.006144
2022-05-27 10:46:24.499089: This epoch took 109.942618 s

2022-05-27 10:46:24.501320: 
epoch:  209
2022-05-27 10:47:56.750423: train loss : -0.7946
2022-05-27 10:48:05.706303: validation loss: -0.7313
2022-05-27 10:48:05.711150: Average global foreground Dice: [0.8051]
2022-05-27 10:48:05.714173: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:48:06.162704: lr: 0.006125
2022-05-27 10:48:06.165215: This epoch took 101.661644 s

2022-05-27 10:48:06.167303: 
epoch:  210
2022-05-27 10:49:37.572559: train loss : -0.7957
2022-05-27 10:49:44.848807: validation loss: -0.7722
2022-05-27 10:49:44.851983: Average global foreground Dice: [0.8184]
2022-05-27 10:49:44.860195: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:49:45.319476: lr: 0.006106
2022-05-27 10:49:45.321815: This epoch took 99.152449 s

2022-05-27 10:49:45.323842: 
epoch:  211
2022-05-27 10:51:16.893920: train loss : -0.7969
2022-05-27 10:51:24.868034: validation loss: -0.7267
2022-05-27 10:51:24.871583: Average global foreground Dice: [0.8047]
2022-05-27 10:51:24.873674: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:51:25.334567: lr: 0.006087
2022-05-27 10:51:25.337067: This epoch took 100.011079 s

2022-05-27 10:51:25.339302: 
epoch:  212
2022-05-27 10:52:58.664622: train loss : -0.7926
2022-05-27 10:53:07.319041: validation loss: -0.7495
2022-05-27 10:53:07.349130: Average global foreground Dice: [0.7897]
2022-05-27 10:53:07.361531: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:53:07.837070: lr: 0.006068
2022-05-27 10:53:07.839256: This epoch took 102.497732 s

2022-05-27 10:53:07.841169: 
epoch:  213
2022-05-27 10:54:41.684516: train loss : -0.7564
2022-05-27 10:54:51.153795: validation loss: -0.7421
2022-05-27 10:54:51.157083: Average global foreground Dice: [0.7866]
2022-05-27 10:54:51.159448: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:54:51.639350: lr: 0.006049
2022-05-27 10:54:51.642047: This epoch took 103.798994 s

2022-05-27 10:54:51.644496: 
epoch:  214
2022-05-27 10:56:22.655078: train loss : -0.7784
2022-05-27 10:56:31.458457: validation loss: -0.7319
2022-05-27 10:56:31.461907: Average global foreground Dice: [0.7781]
2022-05-27 10:56:31.464088: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:56:31.940717: lr: 0.00603
2022-05-27 10:56:31.943168: This epoch took 100.295680 s

2022-05-27 10:56:31.945310: 
epoch:  215
2022-05-27 10:58:08.285210: train loss : -0.7798
2022-05-27 10:58:17.003380: validation loss: -0.7508
2022-05-27 10:58:17.006549: Average global foreground Dice: [0.8123]
2022-05-27 10:58:17.008857: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:58:17.455379: lr: 0.006011
2022-05-27 10:58:17.457596: This epoch took 105.510117 s

2022-05-27 10:58:17.459538: 
epoch:  216
2022-05-27 10:59:49.042529: train loss : -0.7747
2022-05-27 10:59:57.826036: validation loss: -0.7358
2022-05-27 10:59:57.829239: Average global foreground Dice: [0.7926]
2022-05-27 10:59:57.831498: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 10:59:58.301860: lr: 0.005991
2022-05-27 10:59:58.304300: This epoch took 100.840966 s

2022-05-27 10:59:58.306609: 
epoch:  217
2022-05-27 11:01:29.948024: train loss : -0.7767
2022-05-27 11:01:37.333735: validation loss: -0.7638
2022-05-27 11:01:37.336852: Average global foreground Dice: [0.8099]
2022-05-27 11:01:37.338932: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:01:37.801797: lr: 0.005972
2022-05-27 11:01:37.804594: This epoch took 99.495892 s

2022-05-27 11:01:37.806937: 
epoch:  218
2022-05-27 11:03:12.157321: train loss : -0.7729
2022-05-27 11:03:22.166434: validation loss: -0.7441
2022-05-27 11:03:22.170496: Average global foreground Dice: [0.7878]
2022-05-27 11:03:22.173248: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:03:22.702443: lr: 0.005953
2022-05-27 11:03:22.709869: This epoch took 104.900722 s

2022-05-27 11:03:22.722318: 
epoch:  219
2022-05-27 11:04:54.330610: train loss : -0.7700
2022-05-27 11:05:03.196561: validation loss: -0.7258
2022-05-27 11:05:03.212647: Average global foreground Dice: [0.7899]
2022-05-27 11:05:03.215657: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:05:03.734419: lr: 0.005934
2022-05-27 11:05:03.737157: This epoch took 100.988863 s

2022-05-27 11:05:03.739451: 
epoch:  220
2022-05-27 11:06:35.318506: train loss : -0.7781
2022-05-27 11:06:43.381544: validation loss: -0.7162
2022-05-27 11:06:43.385809: Average global foreground Dice: [0.8]
2022-05-27 11:06:43.388365: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:06:43.881084: lr: 0.005915
2022-05-27 11:06:43.883626: This epoch took 100.141940 s

2022-05-27 11:06:43.886020: 
epoch:  221
2022-05-27 11:08:17.740548: train loss : -0.7869
2022-05-27 11:08:27.157006: validation loss: -0.7284
2022-05-27 11:08:27.160364: Average global foreground Dice: [0.798]
2022-05-27 11:08:27.162796: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:08:27.614451: lr: 0.005896
2022-05-27 11:08:27.616916: This epoch took 103.728606 s

2022-05-27 11:08:27.619745: 
epoch:  222
2022-05-27 11:09:59.314226: train loss : -0.7777
2022-05-27 11:10:08.785062: validation loss: -0.7682
2022-05-27 11:10:08.803363: Average global foreground Dice: [0.821]
2022-05-27 11:10:08.805805: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:10:09.306657: lr: 0.005877
2022-05-27 11:10:09.309065: This epoch took 101.683790 s

2022-05-27 11:10:09.313804: 
epoch:  223
2022-05-27 11:11:41.619300: train loss : -0.7921
2022-05-27 11:11:50.155607: validation loss: -0.7643
2022-05-27 11:11:50.159626: Average global foreground Dice: [0.8165]
2022-05-27 11:11:50.165330: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:11:50.694051: lr: 0.005858
2022-05-27 11:11:50.754884: saving checkpoint...
2022-05-27 11:11:51.884425: done, saving took 1.19 seconds
2022-05-27 11:11:51.900333: This epoch took 102.583911 s

2022-05-27 11:11:51.902706: 
epoch:  224
2022-05-27 11:13:21.909910: train loss : -0.7806
2022-05-27 11:13:29.490450: validation loss: -0.7346
2022-05-27 11:13:29.495746: Average global foreground Dice: [0.807]
2022-05-27 11:13:29.498112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:13:30.100143: lr: 0.005839
2022-05-27 11:13:30.133752: saving checkpoint...
2022-05-27 11:13:31.187582: done, saving took 1.08 seconds
2022-05-27 11:13:31.202341: This epoch took 99.297492 s

2022-05-27 11:13:31.204427: 
epoch:  225
2022-05-27 11:15:01.872299: train loss : -0.7981
2022-05-27 11:15:08.442942: validation loss: -0.7087
2022-05-27 11:15:08.452050: Average global foreground Dice: [0.7883]
2022-05-27 11:15:08.454490: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:15:08.926567: lr: 0.00582
2022-05-27 11:15:08.930362: This epoch took 97.723964 s

2022-05-27 11:15:08.932448: 
epoch:  226
2022-05-27 11:16:39.389360: train loss : -0.7776
2022-05-27 11:16:47.238925: validation loss: -0.7434
2022-05-27 11:16:47.247608: Average global foreground Dice: [0.7868]
2022-05-27 11:16:47.251209: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:16:47.811107: lr: 0.005801
2022-05-27 11:16:47.854320: This epoch took 98.919781 s

2022-05-27 11:16:47.889288: 
epoch:  227
2022-05-27 11:18:18.788273: train loss : -0.7840
2022-05-27 11:18:28.765015: validation loss: -0.7386
2022-05-27 11:18:28.769844: Average global foreground Dice: [0.8058]
2022-05-27 11:18:28.771945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:18:29.248201: lr: 0.005781
2022-05-27 11:18:29.250662: This epoch took 101.343370 s

2022-05-27 11:18:29.252779: 
epoch:  228
2022-05-27 11:20:04.284544: train loss : -0.7905
2022-05-27 11:20:15.512493: validation loss: -0.7626
2022-05-27 11:20:15.515606: Average global foreground Dice: [0.804]
2022-05-27 11:20:15.517820: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:20:15.959326: lr: 0.005762
2022-05-27 11:20:15.961870: This epoch took 106.707007 s

2022-05-27 11:20:15.964028: 
epoch:  229
2022-05-27 11:21:51.935164: train loss : -0.7807
2022-05-27 11:22:00.615860: validation loss: -0.7581
2022-05-27 11:22:00.633316: Average global foreground Dice: [0.8106]
2022-05-27 11:22:00.636530: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:22:01.215630: lr: 0.005743
2022-05-27 11:22:01.226362: This epoch took 105.260287 s

2022-05-27 11:22:01.245501: 
epoch:  230
2022-05-27 11:23:33.725006: train loss : -0.7814
2022-05-27 11:23:43.833514: validation loss: -0.7502
2022-05-27 11:23:43.837604: Average global foreground Dice: [0.7985]
2022-05-27 11:23:43.839737: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:23:44.338925: lr: 0.005724
2022-05-27 11:23:44.341217: This epoch took 103.084479 s

2022-05-27 11:23:44.343452: 
epoch:  231
2022-05-27 11:25:15.114495: train loss : -0.7939
2022-05-27 11:25:24.738274: validation loss: -0.7543
2022-05-27 11:25:24.741998: Average global foreground Dice: [0.8091]
2022-05-27 11:25:24.744445: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:25:25.247219: lr: 0.005705
2022-05-27 11:25:25.299782: saving checkpoint...
2022-05-27 11:25:26.419518: done, saving took 1.17 seconds
2022-05-27 11:25:26.437534: This epoch took 102.091886 s

2022-05-27 11:25:26.440499: 
epoch:  232
2022-05-27 11:27:03.195202: train loss : -0.8014
2022-05-27 11:27:12.786248: validation loss: -0.7576
2022-05-27 11:27:12.791462: Average global foreground Dice: [0.8018]
2022-05-27 11:27:12.794083: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:27:13.263517: lr: 0.005686
2022-05-27 11:27:13.302196: saving checkpoint...
2022-05-27 11:27:14.358580: done, saving took 1.09 seconds
2022-05-27 11:27:14.371920: This epoch took 107.928510 s

2022-05-27 11:27:14.374196: 
epoch:  233
2022-05-27 11:28:44.729370: train loss : -0.7985
2022-05-27 11:28:52.563249: validation loss: -0.7536
2022-05-27 11:28:52.575727: Average global foreground Dice: [0.8062]
2022-05-27 11:28:52.578026: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:28:53.061688: lr: 0.005667
2022-05-27 11:28:53.094563: saving checkpoint...
2022-05-27 11:28:54.152529: done, saving took 1.09 seconds
2022-05-27 11:28:54.166281: This epoch took 99.789808 s

2022-05-27 11:28:54.168442: 
epoch:  234
2022-05-27 11:30:25.247676: train loss : -0.8018
2022-05-27 11:30:33.498419: validation loss: -0.7230
2022-05-27 11:30:33.501739: Average global foreground Dice: [0.7962]
2022-05-27 11:30:33.503994: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:30:33.960113: lr: 0.005647
2022-05-27 11:30:33.962826: This epoch took 99.792287 s

2022-05-27 11:30:33.965079: 
epoch:  235
2022-05-27 11:32:04.998027: train loss : -0.7856
2022-05-27 11:32:13.449167: validation loss: -0.7509
2022-05-27 11:32:13.452412: Average global foreground Dice: [0.7941]
2022-05-27 11:32:13.454548: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:32:13.926468: lr: 0.005628
2022-05-27 11:32:13.929080: This epoch took 99.961643 s

2022-05-27 11:32:13.933207: 
epoch:  236
2022-05-27 11:33:44.881272: train loss : -0.7950
2022-05-27 11:33:56.153514: validation loss: -0.7321
2022-05-27 11:33:56.177940: Average global foreground Dice: [0.7931]
2022-05-27 11:33:56.189459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:33:56.764573: lr: 0.005609
2022-05-27 11:33:56.784545: This epoch took 102.847898 s

2022-05-27 11:33:56.807408: 
epoch:  237
2022-05-27 11:35:28.879601: train loss : -0.7918
2022-05-27 11:35:38.713317: validation loss: -0.7775
2022-05-27 11:35:38.722756: Average global foreground Dice: [0.8155]
2022-05-27 11:35:38.725151: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:35:39.244902: lr: 0.00559
2022-05-27 11:35:39.247105: This epoch took 102.417704 s

2022-05-27 11:35:39.249115: 
epoch:  238
2022-05-27 11:37:09.273949: train loss : -0.8073
2022-05-27 11:37:17.748168: validation loss: -0.7679
2022-05-27 11:37:17.752417: Average global foreground Dice: [0.8073]
2022-05-27 11:37:17.754841: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:37:18.248098: lr: 0.005571
2022-05-27 11:37:18.301882: saving checkpoint...
2022-05-27 11:37:19.357777: done, saving took 1.11 seconds
2022-05-27 11:37:19.371040: This epoch took 100.119886 s

2022-05-27 11:37:19.373193: 
epoch:  239
2022-05-27 11:38:53.267781: train loss : -0.8033
2022-05-27 11:39:02.195810: validation loss: -0.7648
2022-05-27 11:39:02.198695: Average global foreground Dice: [0.8064]
2022-05-27 11:39:02.200846: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:39:02.804977: lr: 0.005551
2022-05-27 11:39:02.842225: saving checkpoint...
2022-05-27 11:39:03.902848: done, saving took 1.10 seconds
2022-05-27 11:39:03.916586: This epoch took 104.541245 s

2022-05-27 11:39:03.918809: 
epoch:  240
2022-05-27 11:40:43.800310: train loss : -0.7933
2022-05-27 11:40:53.368116: validation loss: -0.7229
2022-05-27 11:40:53.386938: Average global foreground Dice: [0.7749]
2022-05-27 11:40:53.404357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:40:54.242572: lr: 0.005532
2022-05-27 11:40:54.254027: This epoch took 110.332773 s

2022-05-27 11:40:54.255841: 
epoch:  241
2022-05-27 11:42:26.321852: train loss : -0.7927
2022-05-27 11:42:35.343678: validation loss: -0.7542
2022-05-27 11:42:35.347743: Average global foreground Dice: [0.8008]
2022-05-27 11:42:35.351129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:42:35.817097: lr: 0.005513
2022-05-27 11:42:35.819288: This epoch took 101.560551 s

2022-05-27 11:42:35.821378: 
epoch:  242
2022-05-27 11:44:06.082605: train loss : -0.7839
2022-05-27 11:44:15.031812: validation loss: -0.7842
2022-05-27 11:44:15.038910: Average global foreground Dice: [0.8159]
2022-05-27 11:44:15.041211: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:44:15.513489: lr: 0.005494
2022-05-27 11:44:15.534338: This epoch took 99.711011 s

2022-05-27 11:44:15.565689: 
epoch:  243
2022-05-27 11:45:46.604130: train loss : -0.8013
2022-05-27 11:45:54.587901: validation loss: -0.7592
2022-05-27 11:45:54.591027: Average global foreground Dice: [0.8053]
2022-05-27 11:45:54.593381: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:45:55.095534: lr: 0.005474
2022-05-27 11:45:55.098146: This epoch took 99.506846 s

2022-05-27 11:45:55.100281: 
epoch:  244
2022-05-27 11:47:26.408006: train loss : -0.7975
2022-05-27 11:47:35.474627: validation loss: -0.7139
2022-05-27 11:47:35.479270: Average global foreground Dice: [0.7769]
2022-05-27 11:47:35.482302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:47:35.935423: lr: 0.005455
2022-05-27 11:47:35.938286: This epoch took 100.835791 s

2022-05-27 11:47:35.940665: 
epoch:  245
2022-05-27 11:49:08.114016: train loss : -0.7975
2022-05-27 11:49:17.202900: validation loss: -0.7327
2022-05-27 11:49:17.214677: Average global foreground Dice: [0.7769]
2022-05-27 11:49:17.228295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:49:17.721006: lr: 0.005436
2022-05-27 11:49:17.723652: This epoch took 101.780822 s

2022-05-27 11:49:17.725953: 
epoch:  246
2022-05-27 11:50:49.360846: train loss : -0.7986
2022-05-27 11:50:58.208652: validation loss: -0.7457
2022-05-27 11:50:58.234206: Average global foreground Dice: [0.7825]
2022-05-27 11:50:58.250484: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:50:58.756063: lr: 0.005417
2022-05-27 11:50:58.758675: This epoch took 101.030722 s

2022-05-27 11:50:58.761058: 
epoch:  247
2022-05-27 11:52:30.223071: train loss : -0.8136
2022-05-27 11:52:40.462152: validation loss: -0.7716
2022-05-27 11:52:40.482840: Average global foreground Dice: [0.8129]
2022-05-27 11:52:40.486436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:52:40.998330: lr: 0.005397
2022-05-27 11:52:41.019652: This epoch took 102.255235 s

2022-05-27 11:52:41.047419: 
epoch:  248
2022-05-27 11:54:13.861587: train loss : -0.8086
2022-05-27 11:54:23.577826: validation loss: -0.7363
2022-05-27 11:54:23.581636: Average global foreground Dice: [0.7913]
2022-05-27 11:54:23.587306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:54:24.178880: lr: 0.005378
2022-05-27 11:54:24.187644: This epoch took 103.118349 s

2022-05-27 11:54:24.191324: 
epoch:  249
2022-05-27 11:55:57.175529: train loss : -0.7931
2022-05-27 11:56:06.468290: validation loss: -0.7560
2022-05-27 11:56:06.471455: Average global foreground Dice: [0.8133]
2022-05-27 11:56:06.473697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:56:06.928581: lr: 0.005359
2022-05-27 11:56:06.931235: saving scheduled checkpoint file...
2022-05-27 11:56:06.969020: saving checkpoint...
2022-05-27 11:56:08.036036: done, saving took 1.10 seconds
2022-05-27 11:56:08.059757: done
2022-05-27 11:56:08.062554: This epoch took 103.869169 s

2022-05-27 11:56:08.066214: 
epoch:  250
2022-05-27 11:57:43.021878: train loss : -0.8113
2022-05-27 11:57:52.513593: validation loss: -0.7660
2022-05-27 11:57:52.517490: Average global foreground Dice: [0.8057]
2022-05-27 11:57:52.519783: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:57:52.969739: lr: 0.00534
2022-05-27 11:57:52.972096: This epoch took 104.902201 s

2022-05-27 11:57:52.974307: 
epoch:  251
2022-05-27 11:59:26.137780: train loss : -0.8039
2022-05-27 11:59:35.573308: validation loss: -0.7499
2022-05-27 11:59:35.620938: Average global foreground Dice: [0.7937]
2022-05-27 11:59:35.640630: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 11:59:36.089918: lr: 0.00532
2022-05-27 11:59:36.092556: This epoch took 103.115984 s

2022-05-27 11:59:36.094674: 
epoch:  252
2022-05-27 12:01:06.872510: train loss : -0.8017
2022-05-27 12:01:14.948699: validation loss: -0.7523
2022-05-27 12:01:14.952408: Average global foreground Dice: [0.7934]
2022-05-27 12:01:14.954597: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:01:15.483993: lr: 0.005301
2022-05-27 12:01:15.486365: This epoch took 99.389618 s

2022-05-27 12:01:15.488421: 
epoch:  253
2022-05-27 12:02:45.654158: train loss : -0.8103
2022-05-27 12:02:51.644638: validation loss: -0.7683
2022-05-27 12:02:51.648813: Average global foreground Dice: [0.8167]
2022-05-27 12:02:51.654843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:02:52.118351: lr: 0.005282
2022-05-27 12:02:52.120549: This epoch took 96.630135 s

2022-05-27 12:02:52.122480: 
epoch:  254
2022-05-27 12:04:23.248598: train loss : -0.8041
2022-05-27 12:04:32.117521: validation loss: -0.7758
2022-05-27 12:04:32.121477: Average global foreground Dice: [0.8161]
2022-05-27 12:04:32.124267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:04:32.585488: lr: 0.005262
2022-05-27 12:04:32.588319: This epoch took 100.463931 s

2022-05-27 12:04:32.601589: 
epoch:  255
2022-05-27 12:06:03.964741: train loss : -0.7960
2022-05-27 12:06:13.458887: validation loss: -0.7533
2022-05-27 12:06:13.463079: Average global foreground Dice: [0.8027]
2022-05-27 12:06:13.465579: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:06:13.959864: lr: 0.005243
2022-05-27 12:06:13.962230: This epoch took 101.358109 s

2022-05-27 12:06:13.964332: 
epoch:  256
2022-05-27 12:07:48.178688: train loss : -0.7890
2022-05-27 12:07:57.257628: validation loss: -0.7364
2022-05-27 12:07:57.261233: Average global foreground Dice: [0.8067]
2022-05-27 12:07:57.263498: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:07:57.717073: lr: 0.005224
2022-05-27 12:07:57.719318: This epoch took 103.752353 s

2022-05-27 12:07:57.723556: 
epoch:  257
2022-05-27 12:09:30.579185: train loss : -0.7836
2022-05-27 12:09:40.665493: validation loss: -0.7299
2022-05-27 12:09:40.675459: Average global foreground Dice: [0.7954]
2022-05-27 12:09:40.692462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:09:41.312271: lr: 0.005204
2022-05-27 12:09:41.314682: This epoch took 103.588782 s

2022-05-27 12:09:41.317022: 
epoch:  258
2022-05-27 12:11:17.882207: train loss : -0.8079
2022-05-27 12:11:26.589900: validation loss: -0.7509
2022-05-27 12:11:26.593091: Average global foreground Dice: [0.8077]
2022-05-27 12:11:26.595365: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:11:27.042074: lr: 0.005185
2022-05-27 12:11:27.044874: This epoch took 105.725682 s

2022-05-27 12:11:27.046914: 
epoch:  259
2022-05-27 12:12:57.808885: train loss : -0.8069
2022-05-27 12:13:04.029072: validation loss: -0.7626
2022-05-27 12:13:04.034017: Average global foreground Dice: [0.8079]
2022-05-27 12:13:04.036638: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:13:04.514113: lr: 0.005166
2022-05-27 12:13:04.569353: saving checkpoint...
2022-05-27 12:13:05.619287: done, saving took 1.10 seconds
2022-05-27 12:13:05.634875: This epoch took 98.585996 s

2022-05-27 12:13:05.637357: 
epoch:  260
2022-05-27 12:14:36.352024: train loss : -0.8227
2022-05-27 12:14:45.140357: validation loss: -0.7614
2022-05-27 12:14:45.156112: Average global foreground Dice: [0.8126]
2022-05-27 12:14:45.158358: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:14:45.624637: lr: 0.005146
2022-05-27 12:14:45.673311: saving checkpoint...
2022-05-27 12:14:46.722632: done, saving took 1.09 seconds
2022-05-27 12:14:46.737970: This epoch took 101.098096 s

2022-05-27 12:14:46.740195: 
epoch:  261
2022-05-27 12:16:18.142564: train loss : -0.7977
2022-05-27 12:16:26.748586: validation loss: -0.7480
2022-05-27 12:16:26.752093: Average global foreground Dice: [0.8023]
2022-05-27 12:16:26.753681: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:16:27.260739: lr: 0.005127
2022-05-27 12:16:27.263266: This epoch took 100.520911 s

2022-05-27 12:16:27.265808: 
epoch:  262
2022-05-27 12:17:57.388030: train loss : -0.7986
2022-05-27 12:18:05.513070: validation loss: -0.7670
2022-05-27 12:18:05.517079: Average global foreground Dice: [0.8148]
2022-05-27 12:18:05.519504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:18:05.986847: lr: 0.005107
2022-05-27 12:18:06.038235: saving checkpoint...
2022-05-27 12:18:07.007240: done, saving took 1.02 seconds
2022-05-27 12:18:07.022115: This epoch took 99.754018 s

2022-05-27 12:18:07.024332: 
epoch:  263
2022-05-27 12:19:40.036647: train loss : -0.7930
2022-05-27 12:19:49.643641: validation loss: -0.7306
2022-05-27 12:19:49.647435: Average global foreground Dice: [0.7954]
2022-05-27 12:19:49.649799: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:19:50.261485: lr: 0.005088
2022-05-27 12:19:50.264818: This epoch took 103.238381 s

2022-05-27 12:19:50.267232: 
epoch:  264
2022-05-27 12:21:22.876113: train loss : -0.8117
2022-05-27 12:21:34.474901: validation loss: -0.7185
2022-05-27 12:21:34.482560: Average global foreground Dice: [0.8005]
2022-05-27 12:21:34.484947: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:21:34.951026: lr: 0.005069
2022-05-27 12:21:34.953567: This epoch took 104.683927 s

2022-05-27 12:21:34.955803: 
epoch:  265
2022-05-27 12:23:05.908187: train loss : -0.8071
2022-05-27 12:23:15.454672: validation loss: -0.7624
2022-05-27 12:23:15.458273: Average global foreground Dice: [0.8103]
2022-05-27 12:23:15.460850: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:23:15.964732: lr: 0.005049
2022-05-27 12:23:15.967411: This epoch took 101.004390 s

2022-05-27 12:23:15.970093: 
epoch:  266
2022-05-27 12:24:46.606488: train loss : -0.8131
2022-05-27 12:24:55.630521: validation loss: -0.7397
2022-05-27 12:24:55.633769: Average global foreground Dice: [0.7977]
2022-05-27 12:24:55.636165: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:24:56.200708: lr: 0.00503
2022-05-27 12:24:56.223304: This epoch took 100.250879 s

2022-05-27 12:24:56.241280: 
epoch:  267
2022-05-27 12:26:27.864372: train loss : -0.8046
2022-05-27 12:26:36.886194: validation loss: -0.7266
2022-05-27 12:26:36.891178: Average global foreground Dice: [0.7818]
2022-05-27 12:26:36.904512: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:26:37.383949: lr: 0.00501
2022-05-27 12:26:37.386392: This epoch took 101.121103 s

2022-05-27 12:26:37.388555: 
epoch:  268
2022-05-27 12:28:08.345821: train loss : -0.7957
2022-05-27 12:28:14.808990: validation loss: -0.7254
2022-05-27 12:28:14.812814: Average global foreground Dice: [0.7815]
2022-05-27 12:28:14.814830: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:28:15.279263: lr: 0.004991
2022-05-27 12:28:15.282209: This epoch took 97.891538 s

2022-05-27 12:28:15.284058: 
epoch:  269
2022-05-27 12:29:47.104974: train loss : -0.8024
2022-05-27 12:29:56.438752: validation loss: -0.7494
2022-05-27 12:29:56.443005: Average global foreground Dice: [0.8077]
2022-05-27 12:29:56.445688: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:29:56.921403: lr: 0.004971
2022-05-27 12:29:56.923793: This epoch took 101.637905 s

2022-05-27 12:29:56.926007: 
epoch:  270
2022-05-27 12:31:26.643511: train loss : -0.8013
2022-05-27 12:31:34.428378: validation loss: -0.7616
2022-05-27 12:31:34.431253: Average global foreground Dice: [0.7982]
2022-05-27 12:31:34.433448: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:31:34.907151: lr: 0.004952
2022-05-27 12:31:34.910120: This epoch took 97.981962 s

2022-05-27 12:31:34.912874: 
epoch:  271
2022-05-27 12:33:06.694659: train loss : -0.8136
2022-05-27 12:33:14.518211: validation loss: -0.7466
2022-05-27 12:33:14.542716: Average global foreground Dice: [0.8041]
2022-05-27 12:33:14.570215: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:33:15.220524: lr: 0.004933
2022-05-27 12:33:15.222951: This epoch took 100.307583 s

2022-05-27 12:33:15.225160: 
epoch:  272
2022-05-27 12:34:49.792024: train loss : -0.8096
2022-05-27 12:34:57.599894: validation loss: -0.7624
2022-05-27 12:34:57.603763: Average global foreground Dice: [0.8131]
2022-05-27 12:34:57.605666: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:34:58.116772: lr: 0.004913
2022-05-27 12:34:58.119148: This epoch took 102.891366 s

2022-05-27 12:34:58.121176: 
epoch:  273
2022-05-27 12:36:31.815148: train loss : -0.8039
2022-05-27 12:36:42.384838: validation loss: -0.7603
2022-05-27 12:36:42.388066: Average global foreground Dice: [0.7988]
2022-05-27 12:36:42.390090: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:36:42.843993: lr: 0.004894
2022-05-27 12:36:42.847379: This epoch took 104.723825 s

2022-05-27 12:36:42.851265: 
epoch:  274
2022-05-27 12:38:16.529284: train loss : -0.8072
2022-05-27 12:38:25.567863: validation loss: -0.7346
2022-05-27 12:38:25.571086: Average global foreground Dice: [0.7942]
2022-05-27 12:38:25.573283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:38:26.024343: lr: 0.004874
2022-05-27 12:38:26.026887: This epoch took 103.173444 s

2022-05-27 12:38:26.029687: 
epoch:  275
2022-05-27 12:39:56.534305: train loss : -0.7977
2022-05-27 12:40:04.326275: validation loss: -0.7683
2022-05-27 12:40:04.330517: Average global foreground Dice: [0.8136]
2022-05-27 12:40:04.334826: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:40:04.785221: lr: 0.004855
2022-05-27 12:40:04.787814: This epoch took 98.755867 s

2022-05-27 12:40:04.790047: 
epoch:  276
2022-05-27 12:41:36.510226: train loss : -0.7964
2022-05-27 12:41:47.067479: validation loss: -0.7707
2022-05-27 12:41:47.071186: Average global foreground Dice: [0.8162]
2022-05-27 12:41:47.073445: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:41:47.576525: lr: 0.004835
2022-05-27 12:41:47.585687: This epoch took 102.793393 s

2022-05-27 12:41:47.603307: 
epoch:  277
2022-05-27 12:43:19.708860: train loss : -0.8251
2022-05-27 12:43:28.968221: validation loss: -0.7572
2022-05-27 12:43:28.973374: Average global foreground Dice: [0.8114]
2022-05-27 12:43:28.976084: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:43:29.483723: lr: 0.004816
2022-05-27 12:43:29.499328: This epoch took 101.891091 s

2022-05-27 12:43:29.505002: 
epoch:  278
2022-05-27 12:45:01.373261: train loss : -0.8012
2022-05-27 12:45:11.211069: validation loss: -0.7594
2022-05-27 12:45:11.242036: Average global foreground Dice: [0.8034]
2022-05-27 12:45:11.244661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:45:11.850761: lr: 0.004796
2022-05-27 12:45:11.872315: This epoch took 102.339044 s

2022-05-27 12:45:11.904288: 
epoch:  279
2022-05-27 12:46:49.388878: train loss : -0.8119
2022-05-27 12:46:57.998190: validation loss: -0.7560
2022-05-27 12:46:58.015935: Average global foreground Dice: [0.8181]
2022-05-27 12:46:58.022521: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:46:58.545619: lr: 0.004776
2022-05-27 12:46:58.636961: saving checkpoint...
2022-05-27 12:46:59.718551: done, saving took 1.15 seconds
2022-05-27 12:46:59.733380: This epoch took 107.797971 s

2022-05-27 12:46:59.735835: 
epoch:  280
2022-05-27 12:48:32.556494: train loss : -0.8002
2022-05-27 12:48:41.036730: validation loss: -0.7720
2022-05-27 12:48:41.052569: Average global foreground Dice: [0.8132]
2022-05-27 12:48:41.085306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:48:41.921263: lr: 0.004757
2022-05-27 12:48:41.971044: saving checkpoint...
2022-05-27 12:48:43.389075: done, saving took 1.46 seconds
2022-05-27 12:48:43.404055: This epoch took 103.665767 s

2022-05-27 12:48:43.406298: 
epoch:  281
2022-05-27 12:50:13.839888: train loss : -0.8042
2022-05-27 12:50:22.722225: validation loss: -0.7468
2022-05-27 12:50:22.726192: Average global foreground Dice: [0.7968]
2022-05-27 12:50:22.728692: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:50:23.172667: lr: 0.004737
2022-05-27 12:50:23.175342: This epoch took 99.767026 s

2022-05-27 12:50:23.177536: 
epoch:  282
2022-05-27 12:51:54.594903: train loss : -0.8058
2022-05-27 12:52:04.298867: validation loss: -0.7791
2022-05-27 12:52:04.331768: Average global foreground Dice: [0.8116]
2022-05-27 12:52:04.360308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:52:04.876074: lr: 0.004718
2022-05-27 12:52:04.879196: This epoch took 101.699069 s

2022-05-27 12:52:04.881710: 
epoch:  283
2022-05-27 12:53:35.847969: train loss : -0.8087
2022-05-27 12:53:43.321743: validation loss: -0.7696
2022-05-27 12:53:43.325093: Average global foreground Dice: [0.813]
2022-05-27 12:53:43.327176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:53:43.800423: lr: 0.004698
2022-05-27 12:53:43.850909: saving checkpoint...
2022-05-27 12:53:44.833888: done, saving took 1.03 seconds
2022-05-27 12:53:44.846839: This epoch took 99.939559 s

2022-05-27 12:53:44.848753: 
epoch:  284
2022-05-27 12:55:14.942600: train loss : -0.8133
2022-05-27 12:55:20.694146: validation loss: -0.7735
2022-05-27 12:55:20.697275: Average global foreground Dice: [0.8145]
2022-05-27 12:55:20.699956: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:55:21.143600: lr: 0.004679
2022-05-27 12:55:21.192408: saving checkpoint...
2022-05-27 12:55:22.211556: done, saving took 1.06 seconds
2022-05-27 12:55:22.226754: This epoch took 97.376112 s

2022-05-27 12:55:22.229158: 
epoch:  285
2022-05-27 12:56:56.731537: train loss : -0.7967
2022-05-27 12:57:03.947761: validation loss: -0.7361
2022-05-27 12:57:03.950816: Average global foreground Dice: [0.8079]
2022-05-27 12:57:03.952836: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:57:04.444943: lr: 0.004659
2022-05-27 12:57:04.495717: saving checkpoint...
2022-05-27 12:57:05.622388: done, saving took 1.17 seconds
2022-05-27 12:57:05.636075: This epoch took 103.404284 s

2022-05-27 12:57:05.638539: 
epoch:  286
2022-05-27 12:58:36.754701: train loss : -0.8060
2022-05-27 12:58:44.134793: validation loss: -0.7446
2022-05-27 12:58:44.137906: Average global foreground Dice: [0.7972]
2022-05-27 12:58:44.140390: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 12:58:44.606799: lr: 0.004639
2022-05-27 12:58:44.609149: This epoch took 98.968500 s

2022-05-27 12:58:44.619366: 
epoch:  287
2022-05-27 13:00:20.703825: train loss : -0.8069
2022-05-27 13:00:29.964270: validation loss: -0.7563
2022-05-27 13:00:29.967920: Average global foreground Dice: [0.8072]
2022-05-27 13:00:29.969905: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:00:30.418286: lr: 0.00462
2022-05-27 13:00:30.428174: This epoch took 105.786882 s

2022-05-27 13:00:30.430250: 
epoch:  288
2022-05-27 13:02:00.520534: train loss : -0.8220
2022-05-27 13:02:08.045845: validation loss: -0.7480
2022-05-27 13:02:08.049577: Average global foreground Dice: [0.7994]
2022-05-27 13:02:08.051759: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:02:08.549825: lr: 0.0046
2022-05-27 13:02:08.552250: This epoch took 98.120007 s

2022-05-27 13:02:08.554399: 
epoch:  289
2022-05-27 13:03:40.562262: train loss : -0.8069
2022-05-27 13:03:49.747528: validation loss: -0.7397
2022-05-27 13:03:49.751386: Average global foreground Dice: [0.8003]
2022-05-27 13:03:49.754077: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:03:50.283887: lr: 0.004581
2022-05-27 13:03:50.305443: This epoch took 101.748883 s

2022-05-27 13:03:50.326298: 
epoch:  290
2022-05-27 13:05:21.393879: train loss : -0.7933
2022-05-27 13:05:28.297995: validation loss: -0.7170
2022-05-27 13:05:28.301441: Average global foreground Dice: [0.782]
2022-05-27 13:05:28.303803: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:05:28.751997: lr: 0.004561
2022-05-27 13:05:28.754535: This epoch took 98.406240 s

2022-05-27 13:05:28.756515: 
epoch:  291
2022-05-27 13:06:59.313696: train loss : -0.8121
2022-05-27 13:07:07.734267: validation loss: -0.7708
2022-05-27 13:07:07.737543: Average global foreground Dice: [0.8252]
2022-05-27 13:07:07.739732: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:07:08.221252: lr: 0.004541
2022-05-27 13:07:08.223646: This epoch took 99.465020 s

2022-05-27 13:07:08.226094: 
epoch:  292
2022-05-27 13:08:41.595237: train loss : -0.8161
2022-05-27 13:08:51.231073: validation loss: -0.7400
2022-05-27 13:08:51.256041: Average global foreground Dice: [0.813]
2022-05-27 13:08:51.288351: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:08:51.820974: lr: 0.004522
2022-05-27 13:08:51.832050: This epoch took 103.602236 s

2022-05-27 13:08:51.836850: 
epoch:  293
2022-05-27 13:10:23.663602: train loss : -0.8137
2022-05-27 13:10:33.293461: validation loss: -0.7468
2022-05-27 13:10:33.326310: Average global foreground Dice: [0.8058]
2022-05-27 13:10:33.328964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:10:33.859440: lr: 0.004502
2022-05-27 13:10:33.862154: This epoch took 102.020032 s

2022-05-27 13:10:33.864457: 
epoch:  294
2022-05-27 13:12:05.690991: train loss : -0.8126
2022-05-27 13:12:13.142941: validation loss: -0.7067
2022-05-27 13:12:13.146134: Average global foreground Dice: [0.7667]
2022-05-27 13:12:13.148226: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:12:13.594551: lr: 0.004482
2022-05-27 13:12:13.596837: This epoch took 99.722650 s

2022-05-27 13:12:13.598871: 
epoch:  295
2022-05-27 13:13:44.799697: train loss : -0.8034
2022-05-27 13:13:53.035260: validation loss: -0.7295
2022-05-27 13:13:53.045062: Average global foreground Dice: [0.8043]
2022-05-27 13:13:53.070291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:13:53.578846: lr: 0.004463
2022-05-27 13:13:53.581527: This epoch took 99.980272 s

2022-05-27 13:13:53.583932: 
epoch:  296
2022-05-27 13:15:24.917656: train loss : -0.7991
2022-05-27 13:15:33.981751: validation loss: -0.7579
2022-05-27 13:15:33.985163: Average global foreground Dice: [0.8142]
2022-05-27 13:15:33.987113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:15:34.445915: lr: 0.004443
2022-05-27 13:15:34.448957: This epoch took 100.861542 s

2022-05-27 13:15:34.452438: 
epoch:  297
2022-05-27 13:17:09.490964: train loss : -0.7925
2022-05-27 13:17:19.520281: validation loss: -0.7500
2022-05-27 13:17:19.551749: Average global foreground Dice: [0.7955]
2022-05-27 13:17:19.571321: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:17:20.316664: lr: 0.004423
2022-05-27 13:17:20.339320: This epoch took 105.884736 s

2022-05-27 13:17:20.362432: 
epoch:  298
2022-05-27 13:18:52.230944: train loss : -0.7905
2022-05-27 13:19:02.223703: validation loss: -0.7736
2022-05-27 13:19:02.228907: Average global foreground Dice: [0.8134]
2022-05-27 13:19:02.232127: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:19:02.680688: lr: 0.004404
2022-05-27 13:19:02.683087: This epoch took 102.300464 s

2022-05-27 13:19:02.685174: 
epoch:  299
2022-05-27 13:20:33.777863: train loss : -0.7972
2022-05-27 13:20:41.368931: validation loss: -0.7541
2022-05-27 13:20:41.373437: Average global foreground Dice: [0.7991]
2022-05-27 13:20:41.375708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:20:41.859385: lr: 0.004384
2022-05-27 13:20:41.861582: saving scheduled checkpoint file...
2022-05-27 13:20:41.911169: saving checkpoint...
2022-05-27 13:20:43.015457: done, saving took 1.15 seconds
2022-05-27 13:20:43.034449: done
2022-05-27 13:20:43.036593: This epoch took 100.349184 s

2022-05-27 13:20:43.038792: 
epoch:  300
2022-05-27 13:22:15.727177: train loss : -0.8046
2022-05-27 13:22:26.119404: validation loss: -0.7336
2022-05-27 13:22:26.133894: Average global foreground Dice: [0.809]
2022-05-27 13:22:26.136562: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:22:26.674120: lr: 0.004364
2022-05-27 13:22:26.680184: This epoch took 103.638911 s

2022-05-27 13:22:26.685694: 
epoch:  301
2022-05-27 13:24:03.194021: train loss : -0.7891
2022-05-27 13:24:10.946746: validation loss: -0.7270
2022-05-27 13:24:10.950665: Average global foreground Dice: [0.7613]
2022-05-27 13:24:10.956388: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:24:11.464614: lr: 0.004344
2022-05-27 13:24:11.467642: This epoch took 104.777097 s

2022-05-27 13:24:11.474544: 
epoch:  302
2022-05-27 13:25:42.953363: train loss : -0.7918
2022-05-27 13:25:53.770077: validation loss: -0.7424
2022-05-27 13:25:53.802374: Average global foreground Dice: [0.8061]
2022-05-27 13:25:53.830342: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:25:54.470301: lr: 0.004325
2022-05-27 13:25:54.472648: This epoch took 102.994831 s

2022-05-27 13:25:54.503844: 
epoch:  303
2022-05-27 13:27:26.546336: train loss : -0.8006
2022-05-27 13:27:37.004732: validation loss: -0.7447
2022-05-27 13:27:37.012981: Average global foreground Dice: [0.8004]
2022-05-27 13:27:37.017928: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:27:37.484833: lr: 0.004305
2022-05-27 13:27:37.496702: This epoch took 102.981411 s

2022-05-27 13:27:37.517312: 
epoch:  304
2022-05-27 13:29:07.809797: train loss : -0.8050
2022-05-27 13:29:14.847591: validation loss: -0.7518
2022-05-27 13:29:14.851710: Average global foreground Dice: [0.8018]
2022-05-27 13:29:14.854813: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:29:15.336138: lr: 0.004285
2022-05-27 13:29:15.341344: This epoch took 97.805036 s

2022-05-27 13:29:15.343465: 
epoch:  305
2022-05-27 13:30:46.602703: train loss : -0.7982
2022-05-27 13:30:55.656563: validation loss: -0.7124
2022-05-27 13:30:55.659776: Average global foreground Dice: [0.8015]
2022-05-27 13:30:55.661901: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:30:56.128058: lr: 0.004265
2022-05-27 13:30:56.130368: This epoch took 100.785016 s

2022-05-27 13:30:56.132641: 
epoch:  306
2022-05-27 13:32:26.198492: train loss : -0.8087
2022-05-27 13:32:32.702502: validation loss: -0.7338
2022-05-27 13:32:32.707480: Average global foreground Dice: [0.7903]
2022-05-27 13:32:32.711220: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:32:33.205835: lr: 0.004245
2022-05-27 13:32:33.208163: This epoch took 97.073432 s

2022-05-27 13:32:33.210277: 
epoch:  307
2022-05-27 13:34:04.318785: train loss : -0.8162
2022-05-27 13:34:13.477702: validation loss: -0.7153
2022-05-27 13:34:13.481070: Average global foreground Dice: [0.7819]
2022-05-27 13:34:13.483147: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:34:13.936859: lr: 0.004226
2022-05-27 13:34:13.939107: This epoch took 100.725513 s

2022-05-27 13:34:13.940984: 
epoch:  308
2022-05-27 13:35:45.112072: train loss : -0.8033
2022-05-27 13:35:52.228017: validation loss: -0.7557
2022-05-27 13:35:52.232286: Average global foreground Dice: [0.7956]
2022-05-27 13:35:52.234586: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:35:52.709706: lr: 0.004206
2022-05-27 13:35:52.712028: This epoch took 98.769135 s

2022-05-27 13:35:52.714281: 
epoch:  309
2022-05-27 13:37:23.652711: train loss : -0.8081
2022-05-27 13:37:29.770359: validation loss: -0.7595
2022-05-27 13:37:29.774136: Average global foreground Dice: [0.7999]
2022-05-27 13:37:29.776702: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:37:30.270254: lr: 0.004186
2022-05-27 13:37:30.272936: This epoch took 97.556750 s

2022-05-27 13:37:30.283000: 
epoch:  310
2022-05-27 13:39:05.038376: train loss : -0.8020
2022-05-27 13:39:13.023901: validation loss: -0.7485
2022-05-27 13:39:13.028179: Average global foreground Dice: [0.8044]
2022-05-27 13:39:13.030238: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:39:13.481956: lr: 0.004166
2022-05-27 13:39:13.484103: This epoch took 103.198810 s

2022-05-27 13:39:13.485961: 
epoch:  311
2022-05-27 13:40:50.444692: train loss : -0.7992
2022-05-27 13:40:59.070698: validation loss: -0.7454
2022-05-27 13:40:59.074163: Average global foreground Dice: [0.7961]
2022-05-27 13:40:59.076313: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:40:59.556585: lr: 0.004146
2022-05-27 13:40:59.559453: This epoch took 106.071320 s

2022-05-27 13:40:59.561493: 
epoch:  312
2022-05-27 13:42:30.012545: train loss : -0.8053
2022-05-27 13:42:39.520374: validation loss: -0.7451
2022-05-27 13:42:39.524629: Average global foreground Dice: [0.8063]
2022-05-27 13:42:39.526728: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:42:39.975495: lr: 0.004127
2022-05-27 13:42:39.978044: This epoch took 100.413500 s

2022-05-27 13:42:39.980596: 
epoch:  313
2022-05-27 13:44:11.855053: train loss : -0.7992
2022-05-27 13:44:21.645071: validation loss: -0.7623
2022-05-27 13:44:21.648557: Average global foreground Dice: [0.818]
2022-05-27 13:44:21.650653: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:44:22.126552: lr: 0.004107
2022-05-27 13:44:22.129663: This epoch took 102.146095 s

2022-05-27 13:44:22.131785: 
epoch:  314
2022-05-27 13:45:52.637812: train loss : -0.8194
2022-05-27 13:46:01.755882: validation loss: -0.7268
2022-05-27 13:46:01.759504: Average global foreground Dice: [0.7886]
2022-05-27 13:46:01.761808: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:46:02.235516: lr: 0.004087
2022-05-27 13:46:02.237793: This epoch took 100.103403 s

2022-05-27 13:46:02.239993: 
epoch:  315
2022-05-27 13:47:35.405827: train loss : -0.7991
2022-05-27 13:47:43.853559: validation loss: -0.7688
2022-05-27 13:47:43.893670: Average global foreground Dice: [0.8105]
2022-05-27 13:47:43.917301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:47:44.794075: lr: 0.004067
2022-05-27 13:47:44.797241: This epoch took 102.555218 s

2022-05-27 13:47:44.799274: 
epoch:  316
2022-05-27 13:49:16.240222: train loss : -0.8230
2022-05-27 13:49:25.532540: validation loss: -0.7202
2022-05-27 13:49:25.560794: Average global foreground Dice: [0.7983]
2022-05-27 13:49:25.567814: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:49:26.100936: lr: 0.004047
2022-05-27 13:49:26.105144: This epoch took 101.303632 s

2022-05-27 13:49:26.108479: 
epoch:  317
2022-05-27 13:50:58.499530: train loss : -0.8170
2022-05-27 13:51:06.804132: validation loss: -0.7789
2022-05-27 13:51:06.813971: Average global foreground Dice: [0.8127]
2022-05-27 13:51:06.823954: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:51:07.341137: lr: 0.004027
2022-05-27 13:51:07.347091: This epoch took 101.236036 s

2022-05-27 13:51:07.354607: 
epoch:  318
2022-05-27 13:52:38.665563: train loss : -0.8154
2022-05-27 13:52:47.576859: validation loss: -0.7407
2022-05-27 13:52:47.589893: Average global foreground Dice: [0.792]
2022-05-27 13:52:47.605526: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:52:48.092050: lr: 0.004007
2022-05-27 13:52:48.117453: This epoch took 100.737375 s

2022-05-27 13:52:48.156318: 
epoch:  319
2022-05-27 13:54:27.072547: train loss : -0.8108
2022-05-27 13:54:35.489074: validation loss: -0.7837
2022-05-27 13:54:35.502454: Average global foreground Dice: [0.8239]
2022-05-27 13:54:35.505296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:54:35.987253: lr: 0.003987
2022-05-27 13:54:35.989680: This epoch took 107.830453 s

2022-05-27 13:54:35.991941: 
epoch:  320
2022-05-27 13:56:10.007581: train loss : -0.8012
2022-05-27 13:56:19.208061: validation loss: -0.7201
2022-05-27 13:56:19.214832: Average global foreground Dice: [0.7739]
2022-05-27 13:56:19.218027: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:56:19.669430: lr: 0.003967
2022-05-27 13:56:19.671585: This epoch took 103.677513 s

2022-05-27 13:56:19.673362: 
epoch:  321
2022-05-27 13:57:50.216764: train loss : -0.8117
2022-05-27 13:57:57.407281: validation loss: -0.7764
2022-05-27 13:57:57.410918: Average global foreground Dice: [0.817]
2022-05-27 13:57:57.413527: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:57:57.928075: lr: 0.003947
2022-05-27 13:57:57.946769: This epoch took 98.271496 s

2022-05-27 13:57:57.959976: 
epoch:  322
2022-05-27 13:59:28.738340: train loss : -0.8249
2022-05-27 13:59:35.326988: validation loss: -0.7778
2022-05-27 13:59:35.338327: Average global foreground Dice: [0.818]
2022-05-27 13:59:35.340526: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 13:59:35.809504: lr: 0.003927
2022-05-27 13:59:35.811613: This epoch took 97.839005 s

2022-05-27 13:59:35.813676: 
epoch:  323
2022-05-27 14:01:06.802212: train loss : -0.7976
2022-05-27 14:01:15.588354: validation loss: -0.7636
2022-05-27 14:01:15.592230: Average global foreground Dice: [0.8099]
2022-05-27 14:01:15.594894: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:01:16.122978: lr: 0.003907
2022-05-27 14:01:16.134400: This epoch took 100.318948 s

2022-05-27 14:01:16.137015: 
epoch:  324
2022-05-27 14:02:50.292665: train loss : -0.8021
2022-05-27 14:02:58.433448: validation loss: -0.7273
2022-05-27 14:02:58.452392: Average global foreground Dice: [0.7981]
2022-05-27 14:02:58.456264: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:02:59.144747: lr: 0.003887
2022-05-27 14:02:59.169151: This epoch took 103.029521 s

2022-05-27 14:02:59.183831: 
epoch:  325
2022-05-27 14:04:31.036399: train loss : -0.7990
2022-05-27 14:04:37.700802: validation loss: -0.7505
2022-05-27 14:04:37.703942: Average global foreground Dice: [0.8014]
2022-05-27 14:04:37.705862: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:04:38.203409: lr: 0.003867
2022-05-27 14:04:38.205445: This epoch took 99.019426 s

2022-05-27 14:04:38.207350: 
epoch:  326
2022-05-27 14:06:09.836964: train loss : -0.8105
2022-05-27 14:06:17.836157: validation loss: -0.7649
2022-05-27 14:06:17.839197: Average global foreground Dice: [0.8004]
2022-05-27 14:06:17.841494: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:06:18.315418: lr: 0.003847
2022-05-27 14:06:18.317708: This epoch took 100.108416 s

2022-05-27 14:06:18.319734: 
epoch:  327
2022-05-27 14:07:50.217554: train loss : -0.8205
2022-05-27 14:07:57.829912: validation loss: -0.7495
2022-05-27 14:07:57.833884: Average global foreground Dice: [0.792]
2022-05-27 14:07:57.835875: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:07:58.301756: lr: 0.003827
2022-05-27 14:07:58.303988: This epoch took 99.981913 s

2022-05-27 14:07:58.306265: 
epoch:  328
2022-05-27 14:09:29.669311: train loss : -0.8221
2022-05-27 14:09:39.779601: validation loss: -0.7494
2022-05-27 14:09:39.783308: Average global foreground Dice: [0.7957]
2022-05-27 14:09:39.786005: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:09:40.289872: lr: 0.003807
2022-05-27 14:09:40.292198: This epoch took 101.984061 s

2022-05-27 14:09:40.294163: 
epoch:  329
2022-05-27 14:11:11.834340: train loss : -0.8171
2022-05-27 14:11:21.560260: validation loss: -0.7448
2022-05-27 14:11:21.594658: Average global foreground Dice: [0.7947]
2022-05-27 14:11:21.617307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:11:22.299581: lr: 0.003787
2022-05-27 14:11:22.310970: This epoch took 102.014804 s

2022-05-27 14:11:22.314150: 
epoch:  330
2022-05-27 14:12:56.097290: train loss : -0.8111
2022-05-27 14:13:07.286031: validation loss: -0.7344
2022-05-27 14:13:07.289487: Average global foreground Dice: [0.7909]
2022-05-27 14:13:07.292023: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:13:07.759711: lr: 0.003767
2022-05-27 14:13:07.761930: This epoch took 105.445592 s

2022-05-27 14:13:07.763836: 
epoch:  331
2022-05-27 14:14:40.664932: train loss : -0.8173
2022-05-27 14:14:49.995979: validation loss: -0.7641
2022-05-27 14:14:50.002454: Average global foreground Dice: [0.8114]
2022-05-27 14:14:50.004880: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:14:50.530874: lr: 0.003747
2022-05-27 14:14:50.534652: This epoch took 102.768886 s

2022-05-27 14:14:50.537199: 
epoch:  332
2022-05-27 14:16:21.774077: train loss : -0.8283
2022-05-27 14:16:30.117951: validation loss: -0.7816
2022-05-27 14:16:30.121432: Average global foreground Dice: [0.8284]
2022-05-27 14:16:30.124462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:16:30.638152: lr: 0.003727
2022-05-27 14:16:30.662328: This epoch took 100.122753 s

2022-05-27 14:16:30.692286: 
epoch:  333
2022-05-27 14:18:03.030393: train loss : -0.8199
2022-05-27 14:18:10.652836: validation loss: -0.7343
2022-05-27 14:18:10.655820: Average global foreground Dice: [0.7958]
2022-05-27 14:18:10.657789: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:18:11.129205: lr: 0.003707
2022-05-27 14:18:11.131599: This epoch took 100.412268 s

2022-05-27 14:18:11.134196: 
epoch:  334
2022-05-27 14:19:41.536596: train loss : -0.8337
2022-05-27 14:19:48.712037: validation loss: -0.7807
2022-05-27 14:19:48.715652: Average global foreground Dice: [0.8177]
2022-05-27 14:19:48.717614: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:19:49.215112: lr: 0.003687
2022-05-27 14:19:49.217375: This epoch took 98.080715 s

2022-05-27 14:19:49.219530: 
epoch:  335
2022-05-27 14:21:22.224801: train loss : -0.8364
2022-05-27 14:21:31.934095: validation loss: -0.7515
2022-05-27 14:21:31.937458: Average global foreground Dice: [0.8117]
2022-05-27 14:21:31.940750: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:21:32.616559: lr: 0.003667
2022-05-27 14:21:32.622092: This epoch took 103.400462 s

2022-05-27 14:21:32.635115: 
epoch:  336
2022-05-27 14:23:06.282340: train loss : -0.8278
2022-05-27 14:23:15.059927: validation loss: -0.7617
2022-05-27 14:23:15.094685: Average global foreground Dice: [0.8053]
2022-05-27 14:23:15.117303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:23:15.936394: lr: 0.003647
2022-05-27 14:23:15.969399: This epoch took 103.331224 s

2022-05-27 14:23:15.989288: 
epoch:  337
2022-05-27 14:24:50.299897: train loss : -0.8115
2022-05-27 14:25:01.777917: validation loss: -0.7702
2022-05-27 14:25:01.781451: Average global foreground Dice: [0.8079]
2022-05-27 14:25:01.783567: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:25:02.465200: lr: 0.003627
2022-05-27 14:25:02.472301: This epoch took 106.468021 s

2022-05-27 14:25:02.483301: 
epoch:  338
2022-05-27 14:26:35.406515: train loss : -0.8172
2022-05-27 14:26:45.314007: validation loss: -0.7500
2022-05-27 14:26:45.335689: Average global foreground Dice: [0.795]
2022-05-27 14:26:45.352352: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:26:45.923737: lr: 0.003606
2022-05-27 14:26:45.926581: This epoch took 103.420286 s

2022-05-27 14:26:45.929556: 
epoch:  339
2022-05-27 14:28:17.585957: train loss : -0.8152
2022-05-27 14:28:25.221520: validation loss: -0.7566
2022-05-27 14:28:25.232770: Average global foreground Dice: [0.8148]
2022-05-27 14:28:25.251675: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:28:25.908770: lr: 0.003586
2022-05-27 14:28:25.920324: This epoch took 99.988374 s

2022-05-27 14:28:25.944529: 
epoch:  340
2022-05-27 14:29:56.037147: train loss : -0.8371
2022-05-27 14:30:03.098165: validation loss: -0.7536
2022-05-27 14:30:03.101409: Average global foreground Dice: [0.8005]
2022-05-27 14:30:03.104285: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:30:03.572687: lr: 0.003566
2022-05-27 14:30:03.575082: This epoch took 97.623635 s

2022-05-27 14:30:03.577293: 
epoch:  341
2022-05-27 14:31:36.783113: train loss : -0.8320
2022-05-27 14:31:46.366185: validation loss: -0.7490
2022-05-27 14:31:46.369147: Average global foreground Dice: [0.8027]
2022-05-27 14:31:46.371125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:31:46.827223: lr: 0.003546
2022-05-27 14:31:46.829808: This epoch took 103.250200 s

2022-05-27 14:31:46.832127: 
epoch:  342
2022-05-27 14:33:23.151079: train loss : -0.8131
2022-05-27 14:33:31.702385: validation loss: -0.7701
2022-05-27 14:33:31.706584: Average global foreground Dice: [0.8186]
2022-05-27 14:33:31.708989: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:33:32.396771: lr: 0.003526
2022-05-27 14:33:32.399226: This epoch took 105.564923 s

2022-05-27 14:33:32.401791: 
epoch:  343
2022-05-27 14:35:03.976743: train loss : -0.8205
2022-05-27 14:35:11.753639: validation loss: -0.7725
2022-05-27 14:35:11.756935: Average global foreground Dice: [0.8076]
2022-05-27 14:35:11.759045: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:35:12.291062: lr: 0.003505
2022-05-27 14:35:12.293255: This epoch took 99.889065 s

2022-05-27 14:35:12.295183: 
epoch:  344
2022-05-27 14:36:43.102280: train loss : -0.8294
2022-05-27 14:36:53.497247: validation loss: -0.7705
2022-05-27 14:36:53.500757: Average global foreground Dice: [0.8155]
2022-05-27 14:36:53.503577: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:36:53.980747: lr: 0.003485
2022-05-27 14:36:53.982919: This epoch took 101.685586 s

2022-05-27 14:36:53.984964: 
epoch:  345
2022-05-27 14:38:33.061594: train loss : -0.8223
2022-05-27 14:38:43.286104: validation loss: -0.7632
2022-05-27 14:38:43.289327: Average global foreground Dice: [0.8094]
2022-05-27 14:38:43.291549: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:38:43.785141: lr: 0.003465
2022-05-27 14:38:43.787643: This epoch took 109.800803 s

2022-05-27 14:38:43.790030: 
epoch:  346
2022-05-27 14:40:14.656666: train loss : -0.8154
2022-05-27 14:40:20.875028: validation loss: -0.7291
2022-05-27 14:40:20.878661: Average global foreground Dice: [0.8022]
2022-05-27 14:40:20.880749: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:40:21.327344: lr: 0.003445
2022-05-27 14:40:21.329613: This epoch took 97.537310 s

2022-05-27 14:40:21.331449: 
epoch:  347
2022-05-27 14:41:52.498522: train loss : -0.8340
2022-05-27 14:42:01.313121: validation loss: -0.7764
2022-05-27 14:42:01.316419: Average global foreground Dice: [0.8229]
2022-05-27 14:42:01.318634: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:42:01.773462: lr: 0.003424
2022-05-27 14:42:01.812116: saving checkpoint...
2022-05-27 14:42:02.792171: done, saving took 1.02 seconds
2022-05-27 14:42:02.807275: This epoch took 101.473921 s

2022-05-27 14:42:02.809290: 
epoch:  348
2022-05-27 14:43:34.642744: train loss : -0.8418
2022-05-27 14:43:44.142648: validation loss: -0.7451
2022-05-27 14:43:44.168712: Average global foreground Dice: [0.7989]
2022-05-27 14:43:44.189353: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:43:44.674315: lr: 0.003404
2022-05-27 14:43:44.677178: This epoch took 101.865872 s

2022-05-27 14:43:44.679573: 
epoch:  349
2022-05-27 14:45:15.411842: train loss : -0.8501
2022-05-27 14:45:22.954290: validation loss: -0.7492
2022-05-27 14:45:22.957646: Average global foreground Dice: [0.8073]
2022-05-27 14:45:22.959843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:45:23.411494: lr: 0.003384
2022-05-27 14:45:23.414860: saving scheduled checkpoint file...
2022-05-27 14:45:23.469044: saving checkpoint...
2022-05-27 14:45:24.583217: done, saving took 1.17 seconds
2022-05-27 14:45:24.602147: done
2022-05-27 14:45:24.604110: This epoch took 99.922397 s

2022-05-27 14:45:24.606105: 
epoch:  350
2022-05-27 14:46:56.270667: train loss : -0.8353
2022-05-27 14:47:04.389223: validation loss: -0.7503
2022-05-27 14:47:04.393364: Average global foreground Dice: [0.7999]
2022-05-27 14:47:04.399830: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:47:04.864853: lr: 0.003364
2022-05-27 14:47:04.867065: This epoch took 100.258815 s

2022-05-27 14:47:04.869136: 
epoch:  351
2022-05-27 14:48:38.841074: train loss : -0.8250
2022-05-27 14:48:48.470767: validation loss: -0.7566
2022-05-27 14:48:48.498689: Average global foreground Dice: [0.8081]
2022-05-27 14:48:48.514428: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:48:49.012269: lr: 0.003343
2022-05-27 14:48:49.015666: This epoch took 104.144650 s

2022-05-27 14:48:49.018847: 
epoch:  352
2022-05-27 14:50:21.639178: train loss : -0.8199
2022-05-27 14:50:31.909518: validation loss: -0.7831
2022-05-27 14:50:31.912571: Average global foreground Dice: [0.8237]
2022-05-27 14:50:31.914642: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:50:32.435274: lr: 0.003323
2022-05-27 14:50:32.480975: saving checkpoint...
2022-05-27 14:50:33.468132: done, saving took 1.03 seconds
2022-05-27 14:50:33.482755: This epoch took 104.461915 s

2022-05-27 14:50:33.485626: 
epoch:  353
2022-05-27 14:52:04.181828: train loss : -0.8333
2022-05-27 14:52:10.724163: validation loss: -0.7786
2022-05-27 14:52:10.727977: Average global foreground Dice: [0.8094]
2022-05-27 14:52:10.730514: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:52:11.216835: lr: 0.003303
2022-05-27 14:52:11.266491: saving checkpoint...
2022-05-27 14:52:12.220704: done, saving took 1.00 seconds
2022-05-27 14:52:12.235275: This epoch took 98.747009 s

2022-05-27 14:52:12.237295: 
epoch:  354
2022-05-27 14:53:45.612624: train loss : -0.8367
2022-05-27 14:53:55.437447: validation loss: -0.7652
2022-05-27 14:53:55.441228: Average global foreground Dice: [0.8205]
2022-05-27 14:53:55.443580: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:53:55.981334: lr: 0.003282
2022-05-27 14:53:56.030336: saving checkpoint...
2022-05-27 14:53:57.058278: done, saving took 1.07 seconds
2022-05-27 14:53:57.072071: This epoch took 104.832837 s

2022-05-27 14:53:57.073990: 
epoch:  355
2022-05-27 14:55:29.248873: train loss : -0.8422
2022-05-27 14:55:38.088535: validation loss: -0.7560
2022-05-27 14:55:38.113371: Average global foreground Dice: [0.8127]
2022-05-27 14:55:38.116031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:55:38.600327: lr: 0.003262
2022-05-27 14:55:38.652484: saving checkpoint...
2022-05-27 14:55:39.744145: done, saving took 1.14 seconds
2022-05-27 14:55:39.760427: This epoch took 102.684374 s

2022-05-27 14:55:39.762776: 
epoch:  356
2022-05-27 14:57:16.705371: train loss : -0.8319
2022-05-27 14:57:24.024955: validation loss: -0.7643
2022-05-27 14:57:24.028487: Average global foreground Dice: [0.8155]
2022-05-27 14:57:24.030853: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:57:24.549048: lr: 0.003241
2022-05-27 14:57:24.580071: saving checkpoint...
2022-05-27 14:57:25.524447: done, saving took 0.97 seconds
2022-05-27 14:57:25.538403: This epoch took 105.773434 s

2022-05-27 14:57:25.540809: 
epoch:  357
2022-05-27 14:58:56.876697: train loss : -0.8365
2022-05-27 14:59:06.243955: validation loss: -0.7601
2022-05-27 14:59:06.247674: Average global foreground Dice: [0.8089]
2022-05-27 14:59:06.250170: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 14:59:06.717361: lr: 0.003221
2022-05-27 14:59:06.735894: This epoch took 101.192934 s

2022-05-27 14:59:06.739187: 
epoch:  358
2022-05-27 15:00:37.902529: train loss : -0.8197
2022-05-27 15:00:45.452828: validation loss: -0.7511
2022-05-27 15:00:45.482870: Average global foreground Dice: [0.8053]
2022-05-27 15:00:45.506308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:00:46.071923: lr: 0.003201
2022-05-27 15:00:46.091327: This epoch took 99.347270 s

2022-05-27 15:00:46.107297: 
epoch:  359
2022-05-27 15:02:22.059771: train loss : -0.8249
2022-05-27 15:02:29.616721: validation loss: -0.7589
2022-05-27 15:02:29.620001: Average global foreground Dice: [0.8214]
2022-05-27 15:02:29.622174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:02:30.098949: lr: 0.00318
2022-05-27 15:02:30.143593: saving checkpoint...
2022-05-27 15:02:31.159430: done, saving took 1.06 seconds
2022-05-27 15:02:31.175060: This epoch took 105.054397 s

2022-05-27 15:02:31.178790: 
epoch:  360
2022-05-27 15:04:01.768509: train loss : -0.8387
2022-05-27 15:04:09.279706: validation loss: -0.7557
2022-05-27 15:04:09.282975: Average global foreground Dice: [0.8159]
2022-05-27 15:04:09.287102: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:04:09.760732: lr: 0.00316
2022-05-27 15:04:09.818732: saving checkpoint...
2022-05-27 15:04:10.740616: done, saving took 0.98 seconds
2022-05-27 15:04:10.755186: This epoch took 99.574421 s

2022-05-27 15:04:10.757511: 
epoch:  361
2022-05-27 15:05:44.776474: train loss : -0.8270
2022-05-27 15:05:56.137259: validation loss: -0.7715
2022-05-27 15:05:56.140842: Average global foreground Dice: [0.8173]
2022-05-27 15:05:56.143189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:05:56.600780: lr: 0.003139
2022-05-27 15:05:56.648980: saving checkpoint...
2022-05-27 15:05:57.769639: done, saving took 1.17 seconds
2022-05-27 15:05:57.784645: This epoch took 107.024765 s

2022-05-27 15:05:57.787011: 
epoch:  362
2022-05-27 15:07:39.242626: train loss : -0.8410
2022-05-27 15:07:47.520454: validation loss: -0.7269
2022-05-27 15:07:47.527082: Average global foreground Dice: [0.8019]
2022-05-27 15:07:47.537721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:07:48.013716: lr: 0.003119
2022-05-27 15:07:48.016098: This epoch took 110.226926 s

2022-05-27 15:07:48.018477: 
epoch:  363
2022-05-27 15:09:20.109852: train loss : -0.8297
2022-05-27 15:09:30.746278: validation loss: -0.7492
2022-05-27 15:09:30.750650: Average global foreground Dice: [0.7995]
2022-05-27 15:09:30.753357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:09:31.264451: lr: 0.003098
2022-05-27 15:09:31.267495: This epoch took 103.246891 s

2022-05-27 15:09:31.269912: 
epoch:  364
2022-05-27 15:11:02.063299: train loss : -0.8180
2022-05-27 15:11:11.139207: validation loss: -0.7515
2022-05-27 15:11:11.143133: Average global foreground Dice: [0.7878]
2022-05-27 15:11:11.148689: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:11:11.716864: lr: 0.003078
2022-05-27 15:11:11.719663: This epoch took 100.447184 s

2022-05-27 15:11:11.732033: 
epoch:  365
2022-05-27 15:12:43.608592: train loss : -0.8297
2022-05-27 15:12:54.905125: validation loss: -0.7571
2022-05-27 15:12:54.908976: Average global foreground Dice: [0.8035]
2022-05-27 15:12:54.913506: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:12:55.374846: lr: 0.003057
2022-05-27 15:12:55.390502: This epoch took 103.652387 s

2022-05-27 15:12:55.413506: 
epoch:  366
2022-05-27 15:14:27.105201: train loss : -0.8226
2022-05-27 15:14:36.337101: validation loss: -0.7651
2022-05-27 15:14:36.340305: Average global foreground Dice: [0.812]
2022-05-27 15:14:36.342310: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:14:36.810969: lr: 0.003037
2022-05-27 15:14:36.813483: This epoch took 101.394334 s

2022-05-27 15:14:36.815747: 
epoch:  367
2022-05-27 15:16:09.382465: train loss : -0.8311
2022-05-27 15:16:19.882957: validation loss: -0.7485
2022-05-27 15:16:19.885906: Average global foreground Dice: [0.8045]
2022-05-27 15:16:19.887995: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:16:20.370389: lr: 0.003016
2022-05-27 15:16:20.373313: This epoch took 103.555316 s

2022-05-27 15:16:20.375240: 
epoch:  368
2022-05-27 15:17:51.602351: train loss : -0.8079
2022-05-27 15:18:02.305592: validation loss: -0.7455
2022-05-27 15:18:02.308624: Average global foreground Dice: [0.7922]
2022-05-27 15:18:02.311003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:18:02.799604: lr: 0.002996
2022-05-27 15:18:02.802412: This epoch took 102.423773 s

2022-05-27 15:18:02.805830: 
epoch:  369
2022-05-27 15:19:33.591656: train loss : -0.8217
2022-05-27 15:19:43.513077: validation loss: -0.7574
2022-05-27 15:19:43.519690: Average global foreground Dice: [0.8142]
2022-05-27 15:19:43.544455: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:19:44.037695: lr: 0.002975
2022-05-27 15:19:44.040385: This epoch took 101.231702 s

2022-05-27 15:19:44.043108: 
epoch:  370
2022-05-27 15:21:14.201529: train loss : -0.8311
2022-05-27 15:21:22.672139: validation loss: -0.7604
2022-05-27 15:21:22.676924: Average global foreground Dice: [0.7982]
2022-05-27 15:21:22.679436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:21:23.143572: lr: 0.002954
2022-05-27 15:21:23.146106: This epoch took 99.099398 s

2022-05-27 15:21:23.148271: 
epoch:  371
2022-05-27 15:22:54.261750: train loss : -0.8236
2022-05-27 15:23:02.929350: validation loss: -0.7505
2022-05-27 15:23:02.944892: Average global foreground Dice: [0.8048]
2022-05-27 15:23:02.955072: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:23:03.463000: lr: 0.002934
2022-05-27 15:23:03.465212: This epoch took 100.314787 s

2022-05-27 15:23:03.467118: 
epoch:  372
2022-05-27 15:24:34.793069: train loss : -0.8334
2022-05-27 15:24:43.727744: validation loss: -0.7434
2022-05-27 15:24:43.732849: Average global foreground Dice: [0.7883]
2022-05-27 15:24:43.762394: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:24:44.289529: lr: 0.002913
2022-05-27 15:24:44.300962: This epoch took 100.831844 s

2022-05-27 15:24:44.320703: 
epoch:  373
2022-05-27 15:26:15.552400: train loss : -0.8296
2022-05-27 15:26:25.242200: validation loss: -0.7346
2022-05-27 15:26:25.245556: Average global foreground Dice: [0.7835]
2022-05-27 15:26:25.273292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:26:25.766233: lr: 0.002892
2022-05-27 15:26:25.768737: This epoch took 101.420451 s

2022-05-27 15:26:25.770639: 
epoch:  374
2022-05-27 15:27:56.667469: train loss : -0.8240
2022-05-27 15:28:06.228534: validation loss: -0.7755
2022-05-27 15:28:06.252756: Average global foreground Dice: [0.8064]
2022-05-27 15:28:06.255036: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:28:06.887703: lr: 0.002872
2022-05-27 15:28:06.920309: This epoch took 101.147830 s

2022-05-27 15:28:06.939271: 
epoch:  375
2022-05-27 15:29:38.806781: train loss : -0.8302
2022-05-27 15:29:49.346977: validation loss: -0.7532
2022-05-27 15:29:49.355664: Average global foreground Dice: [0.8058]
2022-05-27 15:29:49.357965: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:29:49.850543: lr: 0.002851
2022-05-27 15:29:49.852884: This epoch took 102.890598 s

2022-05-27 15:29:49.855214: 
epoch:  376
2022-05-27 15:31:21.106173: train loss : -0.8278
2022-05-27 15:31:28.792735: validation loss: -0.7417
2022-05-27 15:31:28.796295: Average global foreground Dice: [0.8002]
2022-05-27 15:31:28.798648: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:31:29.278077: lr: 0.00283
2022-05-27 15:31:29.280296: This epoch took 99.403904 s

2022-05-27 15:31:29.282265: 
epoch:  377
2022-05-27 15:33:04.845666: train loss : -0.8399
2022-05-27 15:33:14.230848: validation loss: -0.7566
2022-05-27 15:33:14.234480: Average global foreground Dice: [0.809]
2022-05-27 15:33:14.236207: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:33:14.704162: lr: 0.00281
2022-05-27 15:33:14.706920: This epoch took 105.422657 s

2022-05-27 15:33:14.709110: 
epoch:  378
2022-05-27 15:34:44.976310: train loss : -0.8303
2022-05-27 15:34:53.588653: validation loss: -0.7472
2022-05-27 15:34:53.603473: Average global foreground Dice: [0.8064]
2022-05-27 15:34:53.615708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:34:54.117380: lr: 0.002789
2022-05-27 15:34:54.120544: This epoch took 99.409460 s

2022-05-27 15:34:54.123030: 
epoch:  379
2022-05-27 15:36:26.444832: train loss : -0.8170
2022-05-27 15:36:36.178600: validation loss: -0.7615
2022-05-27 15:36:36.182513: Average global foreground Dice: [0.8172]
2022-05-27 15:36:36.184677: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:36:36.731738: lr: 0.002768
2022-05-27 15:36:36.734282: This epoch took 102.608565 s

2022-05-27 15:36:36.736438: 
epoch:  380
2022-05-27 15:38:13.264276: train loss : -0.8438
2022-05-27 15:38:22.542287: validation loss: -0.7261
2022-05-27 15:38:22.545569: Average global foreground Dice: [0.8118]
2022-05-27 15:38:22.548282: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:38:23.015617: lr: 0.002747
2022-05-27 15:38:23.017832: This epoch took 106.279359 s

2022-05-27 15:38:23.019729: 
epoch:  381
2022-05-27 15:39:54.244965: train loss : -0.8333
2022-05-27 15:40:04.095275: validation loss: -0.7574
2022-05-27 15:40:04.137763: Average global foreground Dice: [0.8103]
2022-05-27 15:40:04.151846: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:40:04.629691: lr: 0.002727
2022-05-27 15:40:04.632157: This epoch took 101.610234 s

2022-05-27 15:40:04.634567: 
epoch:  382
2022-05-27 15:41:41.664418: train loss : -0.8291
2022-05-27 15:41:51.680982: validation loss: -0.7479
2022-05-27 15:41:51.683800: Average global foreground Dice: [0.8089]
2022-05-27 15:41:51.685782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:41:52.156748: lr: 0.002706
2022-05-27 15:41:52.162343: This epoch took 107.518460 s

2022-05-27 15:41:52.165218: 
epoch:  383
2022-05-27 15:43:22.791460: train loss : -0.8349
2022-05-27 15:43:29.522061: validation loss: -0.7558
2022-05-27 15:43:29.525579: Average global foreground Dice: [0.7996]
2022-05-27 15:43:29.527718: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:43:29.978623: lr: 0.002685
2022-05-27 15:43:29.980661: This epoch took 97.812018 s

2022-05-27 15:43:29.982524: 
epoch:  384
2022-05-27 15:45:00.984751: train loss : -0.8442
2022-05-27 15:45:07.820394: validation loss: -0.7477
2022-05-27 15:45:07.824127: Average global foreground Dice: [0.7993]
2022-05-27 15:45:07.827797: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:45:08.284329: lr: 0.002664
2022-05-27 15:45:08.286818: This epoch took 98.302402 s

2022-05-27 15:45:08.289086: 
epoch:  385
2022-05-27 15:46:39.577296: train loss : -0.8387
2022-05-27 15:46:49.878019: validation loss: -0.7636
2022-05-27 15:46:49.902065: Average global foreground Dice: [0.816]
2022-05-27 15:46:49.921578: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:46:50.677933: lr: 0.002643
2022-05-27 15:46:50.685497: This epoch took 102.394282 s

2022-05-27 15:46:50.692044: 
epoch:  386
2022-05-27 15:48:23.180528: train loss : -0.8329
2022-05-27 15:48:31.912014: validation loss: -0.7449
2022-05-27 15:48:31.915550: Average global foreground Dice: [0.8078]
2022-05-27 15:48:31.917599: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:48:32.384800: lr: 0.002622
2022-05-27 15:48:32.387059: This epoch took 101.688052 s

2022-05-27 15:48:32.388954: 
epoch:  387
2022-05-27 15:50:06.542854: train loss : -0.8295
2022-05-27 15:50:16.113702: validation loss: -0.7620
2022-05-27 15:50:16.123374: Average global foreground Dice: [0.8067]
2022-05-27 15:50:16.126410: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:50:16.590387: lr: 0.002601
2022-05-27 15:50:16.592690: This epoch took 104.201639 s

2022-05-27 15:50:16.594528: 
epoch:  388
2022-05-27 15:51:47.312027: train loss : -0.8381
2022-05-27 15:51:55.093090: validation loss: -0.7683
2022-05-27 15:51:55.096134: Average global foreground Dice: [0.8115]
2022-05-27 15:51:55.104927: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:51:55.639201: lr: 0.002581
2022-05-27 15:51:55.642897: This epoch took 99.046484 s

2022-05-27 15:51:55.646173: 
epoch:  389
2022-05-27 15:53:26.737907: train loss : -0.8408
2022-05-27 15:53:34.372098: validation loss: -0.7444
2022-05-27 15:53:34.375329: Average global foreground Dice: [0.8031]
2022-05-27 15:53:34.377406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:53:34.839425: lr: 0.00256
2022-05-27 15:53:34.841699: This epoch took 99.192589 s

2022-05-27 15:53:34.843840: 
epoch:  390
2022-05-27 15:55:08.456360: train loss : -0.8432
2022-05-27 15:55:16.529921: validation loss: -0.7563
2022-05-27 15:55:16.556202: Average global foreground Dice: [0.8034]
2022-05-27 15:55:16.565321: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:55:17.159670: lr: 0.002539
2022-05-27 15:55:17.162594: This epoch took 102.316794 s

2022-05-27 15:55:17.179211: 
epoch:  391
2022-05-27 15:56:49.813002: train loss : -0.8360
2022-05-27 15:56:59.714383: validation loss: -0.7652
2022-05-27 15:56:59.717624: Average global foreground Dice: [0.8034]
2022-05-27 15:56:59.719640: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:57:00.220764: lr: 0.002518
2022-05-27 15:57:00.222949: This epoch took 103.040637 s

2022-05-27 15:57:00.224824: 
epoch:  392
2022-05-27 15:58:31.297148: train loss : -0.8402
2022-05-27 15:58:40.168846: validation loss: -0.7408
2022-05-27 15:58:40.174769: Average global foreground Dice: [0.8087]
2022-05-27 15:58:40.177175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 15:58:40.673526: lr: 0.002497
2022-05-27 15:58:40.676251: This epoch took 100.449474 s

2022-05-27 15:58:40.678466: 
epoch:  393
2022-05-27 16:00:13.200809: train loss : -0.8440
2022-05-27 16:00:21.005891: validation loss: -0.7439
2022-05-27 16:00:21.014898: Average global foreground Dice: [0.7976]
2022-05-27 16:00:21.019798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:00:21.489830: lr: 0.002476
2022-05-27 16:00:21.492100: This epoch took 100.811639 s

2022-05-27 16:00:21.494101: 
epoch:  394
2022-05-27 16:01:51.830326: train loss : -0.8338
2022-05-27 16:01:59.948563: validation loss: -0.7473
2022-05-27 16:01:59.973653: Average global foreground Dice: [0.8023]
2022-05-27 16:01:59.996297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:02:00.504742: lr: 0.002455
2022-05-27 16:02:00.507090: This epoch took 99.011085 s

2022-05-27 16:02:00.513320: 
epoch:  395
2022-05-27 16:03:31.682795: train loss : -0.8330
2022-05-27 16:03:39.611769: validation loss: -0.7780
2022-05-27 16:03:39.621386: Average global foreground Dice: [0.8165]
2022-05-27 16:03:39.623505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:03:40.096398: lr: 0.002434
2022-05-27 16:03:40.098790: This epoch took 99.577970 s

2022-05-27 16:03:40.101172: 
epoch:  396
2022-05-27 16:05:10.539999: train loss : -0.8351
2022-05-27 16:05:17.607477: validation loss: -0.7591
2022-05-27 16:05:17.610399: Average global foreground Dice: [0.8041]
2022-05-27 16:05:17.612594: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:05:18.074044: lr: 0.002413
2022-05-27 16:05:18.076896: This epoch took 97.973469 s

2022-05-27 16:05:18.078946: 
epoch:  397
2022-05-27 16:06:49.909369: train loss : -0.8277
2022-05-27 16:06:59.696802: validation loss: -0.7359
2022-05-27 16:06:59.699677: Average global foreground Dice: [0.8044]
2022-05-27 16:06:59.701711: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:07:00.209437: lr: 0.002391
2022-05-27 16:07:00.211480: This epoch took 102.130558 s

2022-05-27 16:07:00.213388: 
epoch:  398
2022-05-27 16:08:31.319356: train loss : -0.8530
2022-05-27 16:08:37.678942: validation loss: -0.7397
2022-05-27 16:08:37.683250: Average global foreground Dice: [0.7966]
2022-05-27 16:08:37.685383: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:08:38.187078: lr: 0.00237
2022-05-27 16:08:38.189332: This epoch took 97.958937 s

2022-05-27 16:08:38.191337: 
epoch:  399
2022-05-27 16:10:08.291842: train loss : -0.8407
2022-05-27 16:10:14.302967: validation loss: -0.7650
2022-05-27 16:10:14.306870: Average global foreground Dice: [0.8133]
2022-05-27 16:10:14.308944: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:10:14.821327: lr: 0.002349
2022-05-27 16:10:14.823671: saving scheduled checkpoint file...
2022-05-27 16:10:14.878888: saving checkpoint...
2022-05-27 16:10:16.017104: done, saving took 1.19 seconds
2022-05-27 16:10:16.032607: done
2022-05-27 16:10:16.034953: This epoch took 97.841492 s

2022-05-27 16:10:16.037160: 
epoch:  400
2022-05-27 16:11:47.357490: train loss : -0.8300
2022-05-27 16:11:57.472474: validation loss: -0.7723
2022-05-27 16:11:57.499676: Average global foreground Dice: [0.8183]
2022-05-27 16:11:57.514820: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:11:58.018687: lr: 0.002328
2022-05-27 16:11:58.021055: This epoch took 101.981476 s

2022-05-27 16:11:58.023268: 
epoch:  401
2022-05-27 16:13:33.402398: train loss : -0.8409
2022-05-27 16:13:41.950259: validation loss: -0.7724
2022-05-27 16:13:41.953732: Average global foreground Dice: [0.8034]
2022-05-27 16:13:41.956409: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:13:42.439815: lr: 0.002307
2022-05-27 16:13:42.447124: This epoch took 104.421308 s

2022-05-27 16:13:42.458648: 
epoch:  402
2022-05-27 16:15:13.932678: train loss : -0.8417
2022-05-27 16:15:21.046360: validation loss: -0.7707
2022-05-27 16:15:21.060109: Average global foreground Dice: [0.818]
2022-05-27 16:15:21.078310: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:15:21.646155: lr: 0.002286
2022-05-27 16:15:21.652105: This epoch took 99.188679 s

2022-05-27 16:15:21.659984: 
epoch:  403
2022-05-27 16:16:52.145325: train loss : -0.8447
2022-05-27 16:16:58.963636: validation loss: -0.7519
2022-05-27 16:16:58.967597: Average global foreground Dice: [0.8093]
2022-05-27 16:16:58.970120: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:16:59.432767: lr: 0.002264
2022-05-27 16:16:59.435870: This epoch took 97.773028 s

2022-05-27 16:16:59.438976: 
epoch:  404
2022-05-27 16:18:30.386558: train loss : -0.8441
2022-05-27 16:18:38.674232: validation loss: -0.7479
2022-05-27 16:18:38.705677: Average global foreground Dice: [0.8043]
2022-05-27 16:18:38.738307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:18:39.265846: lr: 0.002243
2022-05-27 16:18:39.268117: This epoch took 99.827219 s

2022-05-27 16:18:39.270193: 
epoch:  405
2022-05-27 16:20:10.545495: train loss : -0.8512
2022-05-27 16:20:19.735475: validation loss: -0.7512
2022-05-27 16:20:19.738646: Average global foreground Dice: [0.8085]
2022-05-27 16:20:19.740911: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:20:20.237424: lr: 0.002222
2022-05-27 16:20:20.247458: This epoch took 100.974729 s

2022-05-27 16:20:20.263283: 
epoch:  406
2022-05-27 16:21:50.529926: train loss : -0.8440
2022-05-27 16:21:57.854790: validation loss: -0.7656
2022-05-27 16:21:57.858884: Average global foreground Dice: [0.818]
2022-05-27 16:21:57.860945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:21:58.328947: lr: 0.002201
2022-05-27 16:21:58.331474: This epoch took 98.065859 s

2022-05-27 16:21:58.333708: 
epoch:  407
2022-05-27 16:23:29.587783: train loss : -0.8308
2022-05-27 16:23:41.240795: validation loss: -0.7505
2022-05-27 16:23:41.243825: Average global foreground Dice: [0.8128]
2022-05-27 16:23:41.245815: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:23:41.759731: lr: 0.002179
2022-05-27 16:23:41.761999: This epoch took 103.425861 s

2022-05-27 16:23:41.764147: 
epoch:  408
2022-05-27 16:25:11.281666: train loss : -0.8338
2022-05-27 16:25:19.550597: validation loss: -0.7802
2022-05-27 16:25:19.553779: Average global foreground Dice: [0.8088]
2022-05-27 16:25:19.555933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:25:20.042978: lr: 0.002158
2022-05-27 16:25:20.045348: This epoch took 98.279095 s

2022-05-27 16:25:20.047469: 
epoch:  409
2022-05-27 16:26:51.895664: train loss : -0.8493
2022-05-27 16:27:00.268681: validation loss: -0.7556
2022-05-27 16:27:00.271967: Average global foreground Dice: [0.8138]
2022-05-27 16:27:00.273981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:27:00.782145: lr: 0.002137
2022-05-27 16:27:00.789712: This epoch took 100.740132 s

2022-05-27 16:27:00.800199: 
epoch:  410
2022-05-27 16:28:31.957433: train loss : -0.8377
2022-05-27 16:28:41.015067: validation loss: -0.7476
2022-05-27 16:28:41.018804: Average global foreground Dice: [0.7981]
2022-05-27 16:28:41.020959: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:28:41.472647: lr: 0.002115
2022-05-27 16:28:41.474928: This epoch took 100.665639 s

2022-05-27 16:28:41.476783: 
epoch:  411
2022-05-27 16:30:11.999001: train loss : -0.8366
2022-05-27 16:30:21.403134: validation loss: -0.7418
2022-05-27 16:30:21.421219: Average global foreground Dice: [0.8048]
2022-05-27 16:30:21.427181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:30:21.940406: lr: 0.002094
2022-05-27 16:30:21.944705: This epoch took 100.466009 s

2022-05-27 16:30:21.948029: 
epoch:  412
2022-05-27 16:31:52.302761: train loss : -0.8332
2022-05-27 16:31:59.741396: validation loss: -0.7431
2022-05-27 16:31:59.744470: Average global foreground Dice: [0.8016]
2022-05-27 16:31:59.746616: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:32:00.197665: lr: 0.002072
2022-05-27 16:32:00.199844: This epoch took 98.249466 s

2022-05-27 16:32:00.201954: 
epoch:  413
2022-05-27 16:33:34.189491: train loss : -0.8369
2022-05-27 16:33:42.399683: validation loss: -0.7157
2022-05-27 16:33:42.403174: Average global foreground Dice: [0.8038]
2022-05-27 16:33:42.405661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:33:42.898940: lr: 0.002051
2022-05-27 16:33:42.901858: This epoch took 102.697674 s

2022-05-27 16:33:42.903900: 
epoch:  414
2022-05-27 16:35:20.403483: train loss : -0.8403
2022-05-27 16:35:30.975491: validation loss: -0.7252
2022-05-27 16:35:30.979501: Average global foreground Dice: [0.7989]
2022-05-27 16:35:30.981882: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:35:31.435159: lr: 0.00203
2022-05-27 16:35:31.437550: This epoch took 108.531459 s

2022-05-27 16:35:31.441965: 
epoch:  415
2022-05-27 16:37:03.525122: train loss : -0.8390
2022-05-27 16:37:12.102327: validation loss: -0.7453
2022-05-27 16:37:12.105540: Average global foreground Dice: [0.7995]
2022-05-27 16:37:12.107642: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:37:12.645951: lr: 0.002008
2022-05-27 16:37:12.663350: This epoch took 101.218954 s

2022-05-27 16:37:12.686293: 
epoch:  416
2022-05-27 16:38:43.496089: train loss : -0.8548
2022-05-27 16:38:50.276878: validation loss: -0.7677
2022-05-27 16:38:50.280898: Average global foreground Dice: [0.8071]
2022-05-27 16:38:50.282957: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:38:50.756238: lr: 0.001987
2022-05-27 16:38:50.758546: This epoch took 98.037235 s

2022-05-27 16:38:50.760702: 
epoch:  417
2022-05-27 16:40:21.906525: train loss : -0.8434
2022-05-27 16:40:31.208409: validation loss: -0.7520
2022-05-27 16:40:31.211658: Average global foreground Dice: [0.7994]
2022-05-27 16:40:31.214553: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:40:31.754998: lr: 0.001965
2022-05-27 16:40:31.795320: This epoch took 101.032756 s

2022-05-27 16:40:31.826508: 
epoch:  418
2022-05-27 16:42:07.718206: train loss : -0.8344
2022-05-27 16:42:18.577496: validation loss: -0.7871
2022-05-27 16:42:18.580934: Average global foreground Dice: [0.8226]
2022-05-27 16:42:18.586442: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:42:19.159805: lr: 0.001943
2022-05-27 16:42:19.187352: This epoch took 107.340707 s

2022-05-27 16:42:19.195153: 
epoch:  419
2022-05-27 16:43:57.069335: train loss : -0.8381
2022-05-27 16:44:06.366659: validation loss: -0.7460
2022-05-27 16:44:06.403363: Average global foreground Dice: [0.8172]
2022-05-27 16:44:06.411009: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:44:07.031853: lr: 0.001922
2022-05-27 16:44:07.034341: This epoch took 107.836005 s

2022-05-27 16:44:07.036320: 
epoch:  420
2022-05-27 16:45:37.724843: train loss : -0.8489
2022-05-27 16:45:48.776335: validation loss: -0.7962
2022-05-27 16:45:48.820846: Average global foreground Dice: [0.8304]
2022-05-27 16:45:48.840637: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:45:49.331076: lr: 0.0019
2022-05-27 16:45:49.333535: This epoch took 102.295200 s

2022-05-27 16:45:49.335454: 
epoch:  421
2022-05-27 16:47:20.745325: train loss : -0.8445
2022-05-27 16:47:30.103310: validation loss: -0.7629
2022-05-27 16:47:30.106602: Average global foreground Dice: [0.8087]
2022-05-27 16:47:30.109203: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:47:30.604849: lr: 0.001879
2022-05-27 16:47:30.607658: This epoch took 101.270075 s

2022-05-27 16:47:30.609807: 
epoch:  422
2022-05-27 16:49:02.796359: train loss : -0.8455
2022-05-27 16:49:11.559051: validation loss: -0.7598
2022-05-27 16:49:11.562900: Average global foreground Dice: [0.8067]
2022-05-27 16:49:11.566038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:49:12.040697: lr: 0.001857
2022-05-27 16:49:12.043171: This epoch took 101.430909 s

2022-05-27 16:49:12.045199: 
epoch:  423
2022-05-27 16:50:43.087927: train loss : -0.8442
2022-05-27 16:50:52.617661: validation loss: -0.7740
2022-05-27 16:50:52.627496: Average global foreground Dice: [0.8181]
2022-05-27 16:50:52.630225: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:50:53.463198: lr: 0.001835
2022-05-27 16:50:53.465688: This epoch took 101.418234 s

2022-05-27 16:50:53.467945: 
epoch:  424
2022-05-27 16:52:33.619578: train loss : -0.8400
2022-05-27 16:52:41.687650: validation loss: -0.7697
2022-05-27 16:52:41.690850: Average global foreground Dice: [0.8157]
2022-05-27 16:52:41.693291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:52:42.147889: lr: 0.001813
2022-05-27 16:52:42.151149: This epoch took 108.680877 s

2022-05-27 16:52:42.153630: 
epoch:  425
2022-05-27 16:54:14.079565: train loss : -0.8430
2022-05-27 16:54:25.284228: validation loss: -0.7658
2022-05-27 16:54:25.309208: Average global foreground Dice: [0.8065]
2022-05-27 16:54:25.311273: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:54:25.935546: lr: 0.001792
2022-05-27 16:54:25.938470: This epoch took 103.781711 s

2022-05-27 16:54:25.940754: 
epoch:  426
2022-05-27 16:55:57.132201: train loss : -0.8389
2022-05-27 16:56:07.709539: validation loss: -0.7552
2022-05-27 16:56:07.712552: Average global foreground Dice: [0.8155]
2022-05-27 16:56:07.714608: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:56:08.175382: lr: 0.00177
2022-05-27 16:56:08.178647: This epoch took 102.235244 s

2022-05-27 16:56:08.182193: 
epoch:  427
2022-05-27 16:57:39.608502: train loss : -0.8446
2022-05-27 16:57:48.626685: validation loss: -0.7539
2022-05-27 16:57:48.629893: Average global foreground Dice: [0.8152]
2022-05-27 16:57:48.643279: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:57:49.172826: lr: 0.001748
2022-05-27 16:57:49.178617: This epoch took 100.993911 s

2022-05-27 16:57:49.194988: 
epoch:  428
2022-05-27 16:59:19.392864: train loss : -0.8538
2022-05-27 16:59:25.325806: validation loss: -0.7549
2022-05-27 16:59:25.329058: Average global foreground Dice: [0.8102]
2022-05-27 16:59:25.331048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 16:59:25.772914: lr: 0.001726
2022-05-27 16:59:25.775141: This epoch took 96.577923 s

2022-05-27 16:59:25.777018: 
epoch:  429
2022-05-27 17:00:56.367845: train loss : -0.8504
2022-05-27 17:01:03.694806: validation loss: -0.7589
2022-05-27 17:01:03.699343: Average global foreground Dice: [0.8054]
2022-05-27 17:01:03.701534: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:01:04.318014: lr: 0.001704
2022-05-27 17:01:04.326616: This epoch took 98.547812 s

2022-05-27 17:01:04.347566: 
epoch:  430
2022-05-27 17:02:39.250754: train loss : -0.8493
2022-05-27 17:02:51.716476: validation loss: -0.7440
2022-05-27 17:02:51.734672: Average global foreground Dice: [0.8109]
2022-05-27 17:02:51.741376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:02:52.529641: lr: 0.001682
2022-05-27 17:02:52.551593: This epoch took 108.189781 s

2022-05-27 17:02:52.574290: 
epoch:  431
2022-05-27 17:04:23.296931: train loss : -0.8500
2022-05-27 17:04:30.821568: validation loss: -0.7558
2022-05-27 17:04:30.825323: Average global foreground Dice: [0.8068]
2022-05-27 17:04:30.827606: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:04:31.311841: lr: 0.00166
2022-05-27 17:04:31.314545: This epoch took 98.710254 s

2022-05-27 17:04:31.317222: 
epoch:  432
2022-05-27 17:06:01.502541: train loss : -0.8421
2022-05-27 17:06:07.663765: validation loss: -0.7688
2022-05-27 17:06:07.668274: Average global foreground Dice: [0.813]
2022-05-27 17:06:07.670840: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:06:08.127518: lr: 0.001638
2022-05-27 17:06:08.130166: This epoch took 96.810793 s

2022-05-27 17:06:08.137465: 
epoch:  433
2022-05-27 17:07:39.172283: train loss : -0.8387
2022-05-27 17:07:49.731010: validation loss: -0.7648
2022-05-27 17:07:49.776715: Average global foreground Dice: [0.8085]
2022-05-27 17:07:49.794289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:07:50.679436: lr: 0.001616
2022-05-27 17:07:50.711344: This epoch took 102.571924 s

2022-05-27 17:07:50.732336: 
epoch:  434
2022-05-27 17:09:26.070688: train loss : -0.8381
2022-05-27 17:09:35.425105: validation loss: -0.7221
2022-05-27 17:09:35.447868: Average global foreground Dice: [0.8118]
2022-05-27 17:09:35.460320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:09:35.993107: lr: 0.001594
2022-05-27 17:09:35.995809: This epoch took 105.246066 s

2022-05-27 17:09:35.998231: 
epoch:  435
2022-05-27 17:11:07.223014: train loss : -0.8432
2022-05-27 17:11:15.264357: validation loss: -0.7686
2022-05-27 17:11:15.309154: Average global foreground Dice: [0.8086]
2022-05-27 17:11:15.329792: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:11:15.864938: lr: 0.001572
2022-05-27 17:11:15.867241: This epoch took 99.866533 s

2022-05-27 17:11:15.871968: 
epoch:  436
2022-05-27 17:12:45.781758: train loss : -0.8483
2022-05-27 17:12:51.649775: validation loss: -0.7735
2022-05-27 17:12:51.652965: Average global foreground Dice: [0.8245]
2022-05-27 17:12:51.655420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:12:52.142680: lr: 0.00155
2022-05-27 17:12:52.145187: This epoch took 96.259580 s

2022-05-27 17:12:52.146936: 
epoch:  437
2022-05-27 17:14:22.901119: train loss : -0.8462
2022-05-27 17:14:33.355558: validation loss: -0.7688
2022-05-27 17:14:33.359495: Average global foreground Dice: [0.8107]
2022-05-27 17:14:33.362054: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:14:33.845833: lr: 0.001528
2022-05-27 17:14:33.848260: This epoch took 101.699327 s

2022-05-27 17:14:33.850317: 
epoch:  438
2022-05-27 17:16:04.888463: train loss : -0.8493
2022-05-27 17:16:13.401363: validation loss: -0.7276
2022-05-27 17:16:13.420735: Average global foreground Dice: [0.7893]
2022-05-27 17:16:13.440457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:16:14.049840: lr: 0.001506
2022-05-27 17:16:14.063323: This epoch took 100.211167 s

2022-05-27 17:16:14.066633: 
epoch:  439
2022-05-27 17:17:45.411538: train loss : -0.8528
2022-05-27 17:17:54.877898: validation loss: -0.7680
2022-05-27 17:17:54.882356: Average global foreground Dice: [0.8126]
2022-05-27 17:17:54.885510: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:17:55.341369: lr: 0.001483
2022-05-27 17:17:55.344040: This epoch took 101.275200 s

2022-05-27 17:17:55.346678: 
epoch:  440
2022-05-27 17:19:27.179145: train loss : -0.8390
2022-05-27 17:19:35.922585: validation loss: -0.7607
2022-05-27 17:19:35.941433: Average global foreground Dice: [0.8172]
2022-05-27 17:19:35.946371: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:19:36.712103: lr: 0.001461
2022-05-27 17:19:36.746315: This epoch took 101.396965 s

2022-05-27 17:19:36.764286: 
epoch:  441
2022-05-27 17:21:09.679357: train loss : -0.8459
2022-05-27 17:21:17.359700: validation loss: -0.7817
2022-05-27 17:21:17.363494: Average global foreground Dice: [0.8097]
2022-05-27 17:21:17.365670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:21:17.835070: lr: 0.001439
2022-05-27 17:21:17.837416: This epoch took 101.048121 s

2022-05-27 17:21:17.839331: 
epoch:  442
2022-05-27 17:22:48.484572: train loss : -0.8565
2022-05-27 17:22:55.057495: validation loss: -0.7686
2022-05-27 17:22:55.061347: Average global foreground Dice: [0.8069]
2022-05-27 17:22:55.063671: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:22:55.530586: lr: 0.001416
2022-05-27 17:22:55.533567: This epoch took 97.692325 s

2022-05-27 17:22:55.535659: 
epoch:  443
2022-05-27 17:24:27.108215: train loss : -0.8533
2022-05-27 17:24:33.949238: validation loss: -0.7490
2022-05-27 17:24:33.952426: Average global foreground Dice: [0.8068]
2022-05-27 17:24:33.958246: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:24:34.467977: lr: 0.001394
2022-05-27 17:24:34.470253: This epoch took 98.932375 s

2022-05-27 17:24:34.472470: 
epoch:  444
2022-05-27 17:26:06.235607: train loss : -0.8459
2022-05-27 17:26:14.455925: validation loss: -0.7407
2022-05-27 17:26:14.459362: Average global foreground Dice: [0.8099]
2022-05-27 17:26:14.461845: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:26:14.918439: lr: 0.001372
2022-05-27 17:26:14.922589: This epoch took 100.447884 s

2022-05-27 17:26:14.925633: 
epoch:  445
2022-05-27 17:27:46.178782: train loss : -0.8468
2022-05-27 17:27:55.118421: validation loss: -0.7581
2022-05-27 17:27:55.122648: Average global foreground Dice: [0.8141]
2022-05-27 17:27:55.126346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:27:55.602537: lr: 0.001349
2022-05-27 17:27:55.604898: This epoch took 100.675067 s

2022-05-27 17:27:55.606786: 
epoch:  446
2022-05-27 17:29:27.468059: train loss : -0.8546
2022-05-27 17:29:36.407588: validation loss: -0.7724
2022-05-27 17:29:36.411132: Average global foreground Dice: [0.8074]
2022-05-27 17:29:36.413845: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:29:36.865417: lr: 0.001327
2022-05-27 17:29:36.868408: This epoch took 101.259492 s

2022-05-27 17:29:36.870568: 
epoch:  447
2022-05-27 17:31:10.670182: train loss : -0.8462
2022-05-27 17:31:20.690638: validation loss: -0.7726
2022-05-27 17:31:20.693853: Average global foreground Dice: [0.8086]
2022-05-27 17:31:20.696157: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:31:21.185886: lr: 0.001304
2022-05-27 17:31:21.187961: This epoch took 104.315280 s

2022-05-27 17:31:21.189969: 
epoch:  448
2022-05-27 17:32:57.482740: train loss : -0.8622
2022-05-27 17:33:04.612919: validation loss: -0.7496
2022-05-27 17:33:04.616130: Average global foreground Dice: [0.8096]
2022-05-27 17:33:04.618149: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:33:05.089900: lr: 0.001282
2022-05-27 17:33:05.092314: This epoch took 103.899235 s

2022-05-27 17:33:05.094556: 
epoch:  449
2022-05-27 17:34:37.325337: train loss : -0.8577
2022-05-27 17:34:46.513314: validation loss: -0.7357
2022-05-27 17:34:46.517191: Average global foreground Dice: [0.8088]
2022-05-27 17:34:46.520000: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:34:47.025598: lr: 0.001259
2022-05-27 17:34:47.027915: saving scheduled checkpoint file...
2022-05-27 17:34:47.078066: saving checkpoint...
2022-05-27 17:34:48.091356: done, saving took 1.06 seconds
2022-05-27 17:34:48.107999: done
2022-05-27 17:34:48.110309: This epoch took 103.013695 s

2022-05-27 17:34:48.112362: 
epoch:  450
2022-05-27 17:36:19.345607: train loss : -0.8574
2022-05-27 17:36:29.884722: validation loss: -0.7668
2022-05-27 17:36:29.915708: Average global foreground Dice: [0.8044]
2022-05-27 17:36:29.934280: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:36:30.871326: lr: 0.001236
2022-05-27 17:36:30.873871: This epoch took 102.759304 s

2022-05-27 17:36:30.876241: 
epoch:  451
2022-05-27 17:38:02.504192: train loss : -0.8599
2022-05-27 17:38:11.683155: validation loss: -0.7665
2022-05-27 17:38:11.686263: Average global foreground Dice: [0.8066]
2022-05-27 17:38:11.688309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:38:12.163285: lr: 0.001214
2022-05-27 17:38:12.165546: This epoch took 101.286913 s

2022-05-27 17:38:12.167470: 
epoch:  452
2022-05-27 17:39:43.190958: train loss : -0.8513
2022-05-27 17:39:51.837725: validation loss: -0.7514
2022-05-27 17:39:51.841749: Average global foreground Dice: [0.8024]
2022-05-27 17:39:51.847071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:39:52.348006: lr: 0.001191
2022-05-27 17:39:52.350289: This epoch took 100.180778 s

2022-05-27 17:39:52.370528: 
epoch:  453
2022-05-27 17:41:30.582147: train loss : -0.8471
2022-05-27 17:41:38.901568: validation loss: -0.7667
2022-05-27 17:41:38.904700: Average global foreground Dice: [0.8177]
2022-05-27 17:41:38.906888: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:41:39.360405: lr: 0.001168
2022-05-27 17:41:39.363380: This epoch took 106.986015 s

2022-05-27 17:41:39.365548: 
epoch:  454
2022-05-27 17:43:10.434312: train loss : -0.8591
2022-05-27 17:43:19.491452: validation loss: -0.7609
2022-05-27 17:43:19.512203: Average global foreground Dice: [0.8134]
2022-05-27 17:43:19.535324: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:43:20.121226: lr: 0.001145
2022-05-27 17:43:20.123661: This epoch took 100.755850 s

2022-05-27 17:43:20.126167: 
epoch:  455
2022-05-27 17:44:50.369495: train loss : -0.8516
2022-05-27 17:44:57.860949: validation loss: -0.7733
2022-05-27 17:44:57.864493: Average global foreground Dice: [0.8139]
2022-05-27 17:44:57.866986: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:44:58.478769: lr: 0.001122
2022-05-27 17:44:58.481353: This epoch took 98.352803 s

2022-05-27 17:44:58.483774: 
epoch:  456
2022-05-27 17:46:29.593871: train loss : -0.8530
2022-05-27 17:46:37.995486: validation loss: -0.7743
2022-05-27 17:46:37.999823: Average global foreground Dice: [0.8125]
2022-05-27 17:46:38.005301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:46:38.594106: lr: 0.001099
2022-05-27 17:46:38.615864: This epoch took 100.129634 s

2022-05-27 17:46:38.638323: 
epoch:  457
2022-05-27 17:48:10.960441: train loss : -0.8382
2022-05-27 17:48:19.415530: validation loss: -0.7603
2022-05-27 17:48:19.431952: Average global foreground Dice: [0.8016]
2022-05-27 17:48:19.438748: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:48:20.054616: lr: 0.001076
2022-05-27 17:48:20.087318: This epoch took 101.424896 s

2022-05-27 17:48:20.109286: 
epoch:  458
2022-05-27 17:49:51.169911: train loss : -0.8505
2022-05-27 17:50:00.025118: validation loss: -0.7686
2022-05-27 17:50:00.028556: Average global foreground Dice: [0.817]
2022-05-27 17:50:00.030824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:50:01.084772: lr: 0.001053
2022-05-27 17:50:01.094971: This epoch took 100.952691 s

2022-05-27 17:50:01.101791: 
epoch:  459
2022-05-27 17:51:37.893392: train loss : -0.8520
2022-05-27 17:51:46.486801: validation loss: -0.7757
2022-05-27 17:51:46.493034: Average global foreground Dice: [0.8216]
2022-05-27 17:51:46.502674: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:51:47.028588: lr: 0.00103
2022-05-27 17:51:47.030939: This epoch took 105.904359 s

2022-05-27 17:51:47.032954: 
epoch:  460
2022-05-27 17:53:20.027087: train loss : -0.8399
2022-05-27 17:53:29.902615: validation loss: -0.7895
2022-05-27 17:53:29.905959: Average global foreground Dice: [0.8163]
2022-05-27 17:53:29.908898: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:53:30.420966: lr: 0.001007
2022-05-27 17:53:30.424158: This epoch took 103.389124 s

2022-05-27 17:53:30.427598: 
epoch:  461
2022-05-27 17:55:01.371985: train loss : -0.8533
2022-05-27 17:55:09.486784: validation loss: -0.7672
2022-05-27 17:55:09.495064: Average global foreground Dice: [0.8082]
2022-05-27 17:55:09.503139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:55:09.987562: lr: 0.000983
2022-05-27 17:55:09.989879: This epoch took 99.559660 s

2022-05-27 17:55:09.991898: 
epoch:  462
2022-05-27 17:56:41.315130: train loss : -0.8488
2022-05-27 17:56:49.159945: validation loss: -0.7697
2022-05-27 17:56:49.166522: Average global foreground Dice: [0.8084]
2022-05-27 17:56:49.168804: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:56:49.629902: lr: 0.00096
2022-05-27 17:56:49.632252: This epoch took 99.638203 s

2022-05-27 17:56:49.634127: 
epoch:  463
2022-05-27 17:58:21.345817: train loss : -0.8557
2022-05-27 17:58:30.732549: validation loss: -0.7756
2022-05-27 17:58:30.758861: Average global foreground Dice: [0.8187]
2022-05-27 17:58:30.780284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 17:58:31.381621: lr: 0.000937
2022-05-27 17:58:31.383962: This epoch took 101.747684 s

2022-05-27 17:58:31.386402: 
epoch:  464
2022-05-27 18:00:02.863566: train loss : -0.8435
2022-05-27 18:00:11.157480: validation loss: -0.7438
2022-05-27 18:00:11.160698: Average global foreground Dice: [0.807]
2022-05-27 18:00:11.162941: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:00:11.621210: lr: 0.000913
2022-05-27 18:00:11.623535: This epoch took 100.234992 s

2022-05-27 18:00:11.626224: 
epoch:  465
2022-05-27 18:01:46.074827: train loss : -0.8423
2022-05-27 18:01:56.648216: validation loss: -0.7599
2022-05-27 18:01:56.651420: Average global foreground Dice: [0.8173]
2022-05-27 18:01:56.653403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:01:57.121490: lr: 0.00089
2022-05-27 18:01:57.123777: This epoch took 105.494110 s

2022-05-27 18:01:57.125693: 
epoch:  466
2022-05-27 18:03:32.574706: train loss : -0.8565
2022-05-27 18:03:43.568355: validation loss: -0.7501
2022-05-27 18:03:43.571740: Average global foreground Dice: [0.8021]
2022-05-27 18:03:43.574126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:03:44.038036: lr: 0.000866
2022-05-27 18:03:44.040403: This epoch took 106.905687 s

2022-05-27 18:03:44.042621: 
epoch:  467
2022-05-27 18:05:15.049058: train loss : -0.8445
2022-05-27 18:05:23.369881: validation loss: -0.7373
2022-05-27 18:05:23.373115: Average global foreground Dice: [0.798]
2022-05-27 18:05:23.375353: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:05:23.824518: lr: 0.000842
2022-05-27 18:05:23.827037: This epoch took 99.782178 s

2022-05-27 18:05:23.829560: 
epoch:  468
2022-05-27 18:06:56.929716: train loss : -0.8554
2022-05-27 18:07:07.060101: validation loss: -0.7703
2022-05-27 18:07:07.080774: Average global foreground Dice: [0.8156]
2022-05-27 18:07:07.093771: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:07:07.565082: lr: 0.000819
2022-05-27 18:07:07.567342: This epoch took 103.735780 s

2022-05-27 18:07:07.569495: 
epoch:  469
2022-05-27 18:08:41.143052: train loss : -0.8490
2022-05-27 18:08:51.831572: validation loss: -0.7660
2022-05-27 18:08:51.873873: Average global foreground Dice: [0.8206]
2022-05-27 18:08:51.888165: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:08:52.418084: lr: 0.000795
2022-05-27 18:08:52.438334: This epoch took 104.866683 s

2022-05-27 18:08:52.471291: 
epoch:  470
2022-05-27 18:10:23.528940: train loss : -0.8573
2022-05-27 18:10:33.199271: validation loss: -0.7585
2022-05-27 18:10:33.204823: Average global foreground Dice: [0.8115]
2022-05-27 18:10:33.207125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:10:33.701117: lr: 0.000771
2022-05-27 18:10:33.703291: This epoch took 101.206001 s

2022-05-27 18:10:33.705190: 
epoch:  471
2022-05-27 18:12:03.918121: train loss : -0.8482
2022-05-27 18:12:12.717147: validation loss: -0.7521
2022-05-27 18:12:12.721355: Average global foreground Dice: [0.8122]
2022-05-27 18:12:12.723431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:12:13.232434: lr: 0.000747
2022-05-27 18:12:13.234612: This epoch took 99.527406 s

2022-05-27 18:12:13.236545: 
epoch:  472
2022-05-27 18:13:43.706548: train loss : -0.8635
2022-05-27 18:13:51.328729: validation loss: -0.7449
2022-05-27 18:13:51.335932: Average global foreground Dice: [0.7943]
2022-05-27 18:13:51.360461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:13:51.848279: lr: 0.000723
2022-05-27 18:13:51.850371: This epoch took 98.611615 s

2022-05-27 18:13:51.852359: 
epoch:  473
2022-05-27 18:15:22.918433: train loss : -0.8578
2022-05-27 18:15:29.740142: validation loss: -0.7532
2022-05-27 18:15:29.744263: Average global foreground Dice: [0.8168]
2022-05-27 18:15:29.748166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:15:30.199534: lr: 0.000699
2022-05-27 18:15:30.208620: This epoch took 98.354355 s

2022-05-27 18:15:30.224284: 
epoch:  474
2022-05-27 18:17:01.756722: train loss : -0.8588
2022-05-27 18:17:08.965582: validation loss: -0.7583
2022-05-27 18:17:08.969309: Average global foreground Dice: [0.8162]
2022-05-27 18:17:08.971295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:17:09.432557: lr: 0.000675
2022-05-27 18:17:09.435368: This epoch took 99.208689 s

2022-05-27 18:17:09.438180: 
epoch:  475
2022-05-27 18:18:40.354698: train loss : -0.8513
2022-05-27 18:18:48.839684: validation loss: -0.7578
2022-05-27 18:18:48.843214: Average global foreground Dice: [0.7907]
2022-05-27 18:18:48.846071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:18:49.300725: lr: 0.00065
2022-05-27 18:18:49.303318: This epoch took 99.861968 s

2022-05-27 18:18:49.305485: 
epoch:  476
2022-05-27 18:20:22.529923: train loss : -0.8512
2022-05-27 18:20:30.094794: validation loss: -0.7630
2022-05-27 18:20:30.098432: Average global foreground Dice: [0.814]
2022-05-27 18:20:30.101077: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:20:30.691198: lr: 0.000626
2022-05-27 18:20:30.694128: This epoch took 101.386076 s

2022-05-27 18:20:30.696927: 
epoch:  477
2022-05-27 18:22:02.320043: train loss : -0.8614
2022-05-27 18:22:11.056329: validation loss: -0.7392
2022-05-27 18:22:11.059730: Average global foreground Dice: [0.802]
2022-05-27 18:22:11.062056: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:22:11.586426: lr: 0.000601
2022-05-27 18:22:11.589373: This epoch took 100.889713 s

2022-05-27 18:22:11.591475: 
epoch:  478
2022-05-27 18:23:45.308726: train loss : -0.8494
2022-05-27 18:23:54.700523: validation loss: -0.7539
2022-05-27 18:23:54.704123: Average global foreground Dice: [0.7956]
2022-05-27 18:23:54.706507: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:23:55.407297: lr: 0.000577
2022-05-27 18:23:55.409198: This epoch took 103.815873 s

2022-05-27 18:23:55.410906: 
epoch:  479
2022-05-27 18:25:27.876818: train loss : -0.8601
2022-05-27 18:25:36.468930: validation loss: -0.7664
2022-05-27 18:25:36.474486: Average global foreground Dice: [0.8133]
2022-05-27 18:25:36.477415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:25:36.976512: lr: 0.000552
2022-05-27 18:25:36.978826: This epoch took 101.566197 s

2022-05-27 18:25:36.981287: 
epoch:  480
2022-05-27 18:27:07.709762: train loss : -0.8539
2022-05-27 18:27:16.633579: validation loss: -0.7464
2022-05-27 18:27:16.659668: Average global foreground Dice: [0.798]
2022-05-27 18:27:16.686334: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:27:17.242924: lr: 0.000527
2022-05-27 18:27:17.250498: This epoch took 100.267027 s

2022-05-27 18:27:17.253604: 
epoch:  481
2022-05-27 18:28:50.128075: train loss : -0.8649
2022-05-27 18:28:58.861507: validation loss: -0.7644
2022-05-27 18:28:58.886796: Average global foreground Dice: [0.8148]
2022-05-27 18:28:58.919305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:28:59.411140: lr: 0.000502
2022-05-27 18:28:59.440518: This epoch took 102.184825 s

2022-05-27 18:28:59.463283: 
epoch:  482
2022-05-27 18:30:30.490673: train loss : -0.8455
2022-05-27 18:30:40.610238: validation loss: -0.7544
2022-05-27 18:30:40.613281: Average global foreground Dice: [0.8024]
2022-05-27 18:30:40.615283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:30:41.084470: lr: 0.000477
2022-05-27 18:30:41.086563: This epoch took 101.605752 s

2022-05-27 18:30:41.097443: 
epoch:  483
2022-05-27 18:32:11.664232: train loss : -0.8487
2022-05-27 18:32:20.959094: validation loss: -0.7463
2022-05-27 18:32:20.962510: Average global foreground Dice: [0.8061]
2022-05-27 18:32:20.972318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:32:21.485432: lr: 0.000451
2022-05-27 18:32:21.487942: This epoch took 100.388343 s

2022-05-27 18:32:21.490231: 
epoch:  484
2022-05-27 18:33:52.841275: train loss : -0.8525
2022-05-27 18:34:01.538637: validation loss: -0.7622
2022-05-27 18:34:01.544311: Average global foreground Dice: [0.817]
2022-05-27 18:34:01.547000: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:34:02.044264: lr: 0.000426
2022-05-27 18:34:02.079383: This epoch took 100.586864 s

2022-05-27 18:34:02.101298: 
epoch:  485
2022-05-27 18:35:32.942601: train loss : -0.8496
2022-05-27 18:35:41.292361: validation loss: -0.7761
2022-05-27 18:35:41.295855: Average global foreground Dice: [0.8074]
2022-05-27 18:35:41.298113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:35:41.776418: lr: 0.0004
2022-05-27 18:35:41.778879: This epoch took 99.655591 s

2022-05-27 18:35:41.781250: 
epoch:  486
2022-05-27 18:37:20.740224: train loss : -0.8675
2022-05-27 18:37:28.710668: validation loss: -0.7582
2022-05-27 18:37:28.714635: Average global foreground Dice: [0.8182]
2022-05-27 18:37:28.716773: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:37:29.200064: lr: 0.000375
2022-05-27 18:37:29.202376: This epoch took 107.418745 s

2022-05-27 18:37:29.204951: 
epoch:  487
2022-05-27 18:38:59.914821: train loss : -0.8432
2022-05-27 18:39:08.366250: validation loss: -0.7466
2022-05-27 18:39:08.369692: Average global foreground Dice: [0.8054]
2022-05-27 18:39:08.371920: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:39:08.862310: lr: 0.000348
2022-05-27 18:39:08.864527: This epoch took 99.657507 s

2022-05-27 18:39:08.866598: 
epoch:  488
2022-05-27 18:40:46.285362: train loss : -0.8652
2022-05-27 18:40:52.182827: validation loss: -0.7665
2022-05-27 18:40:52.186035: Average global foreground Dice: [0.8009]
2022-05-27 18:40:52.188694: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:40:52.723480: lr: 0.000322
2022-05-27 18:40:52.725662: This epoch took 103.856864 s

2022-05-27 18:40:52.727809: 
epoch:  489
2022-05-27 18:42:24.343240: train loss : -0.8591
2022-05-27 18:42:32.285120: validation loss: -0.7528
2022-05-27 18:42:32.306921: Average global foreground Dice: [0.8113]
2022-05-27 18:42:32.328324: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:42:32.915681: lr: 0.000296
2022-05-27 18:42:32.917872: This epoch took 100.188022 s

2022-05-27 18:42:32.920159: 
epoch:  490
2022-05-27 18:44:04.477710: train loss : -0.8596
2022-05-27 18:44:12.104903: validation loss: -0.7623
2022-05-27 18:44:12.118501: Average global foreground Dice: [0.8164]
2022-05-27 18:44:12.148376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:44:12.748888: lr: 0.000269
2022-05-27 18:44:12.763444: This epoch took 99.841259 s

2022-05-27 18:44:12.785517: 
epoch:  491
2022-05-27 18:45:48.389233: train loss : -0.8625
2022-05-27 18:45:56.778909: validation loss: -0.7451
2022-05-27 18:45:56.783154: Average global foreground Dice: [0.8029]
2022-05-27 18:45:56.785608: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:45:57.321392: lr: 0.000242
2022-05-27 18:45:57.330791: This epoch took 104.538511 s

2022-05-27 18:45:57.334136: 
epoch:  492
2022-05-27 18:47:30.258520: train loss : -0.8647
2022-05-27 18:47:38.814767: validation loss: -0.7846
2022-05-27 18:47:38.818074: Average global foreground Dice: [0.8205]
2022-05-27 18:47:38.820264: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:47:39.322718: lr: 0.000215
2022-05-27 18:47:39.345340: This epoch took 102.006935 s

2022-05-27 18:47:39.360101: 
epoch:  493
2022-05-27 18:49:10.271056: train loss : -0.8613
2022-05-27 18:49:18.746300: validation loss: -0.7449
2022-05-27 18:49:18.749841: Average global foreground Dice: [0.802]
2022-05-27 18:49:18.752214: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:49:19.232713: lr: 0.000187
2022-05-27 18:49:19.235478: This epoch took 99.873323 s

2022-05-27 18:49:19.240289: 
epoch:  494
2022-05-27 18:50:50.194426: train loss : -0.8514
2022-05-27 18:51:00.901011: validation loss: -0.7602
2022-05-27 18:51:00.904127: Average global foreground Dice: [0.8041]
2022-05-27 18:51:00.906546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:51:01.365398: lr: 0.000158
2022-05-27 18:51:01.367740: This epoch took 102.120303 s

2022-05-27 18:51:01.370024: 
epoch:  495
2022-05-27 18:52:42.816866: train loss : -0.8469
2022-05-27 18:52:51.280642: validation loss: -0.7214
2022-05-27 18:52:51.283885: Average global foreground Dice: [0.7922]
2022-05-27 18:52:51.286237: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:52:51.748637: lr: 0.00013
2022-05-27 18:52:51.750967: This epoch took 110.377990 s

2022-05-27 18:52:51.753297: 
epoch:  496
2022-05-27 18:54:22.258352: train loss : -0.8589
2022-05-27 18:54:30.204143: validation loss: -0.7672
2022-05-27 18:54:30.213181: Average global foreground Dice: [0.8147]
2022-05-27 18:54:30.220930: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:54:30.729451: lr: 0.0001
2022-05-27 18:54:30.732352: This epoch took 98.976850 s

2022-05-27 18:54:30.734837: 
epoch:  497
2022-05-27 18:56:06.703707: train loss : -0.8617
2022-05-27 18:56:14.621443: validation loss: -0.7700
2022-05-27 18:56:14.656010: Average global foreground Dice: [0.8164]
2022-05-27 18:56:14.669208: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:56:15.183066: lr: 6.9e-05
2022-05-27 18:56:15.185503: This epoch took 104.448596 s

2022-05-27 18:56:15.187576: 
epoch:  498
2022-05-27 18:57:47.971730: train loss : -0.8583
2022-05-27 18:57:56.871486: validation loss: -0.7530
2022-05-27 18:57:56.889303: Average global foreground Dice: [0.8071]
2022-05-27 18:57:56.907512: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:57:57.403835: lr: 3.7e-05
2022-05-27 18:57:57.405888: This epoch took 102.216326 s

2022-05-27 18:57:57.407809: 
epoch:  499
2022-05-27 18:59:28.037893: train loss : -0.8611
2022-05-27 18:59:36.548240: validation loss: -0.7701
2022-05-27 18:59:36.551745: Average global foreground Dice: [0.8121]
2022-05-27 18:59:36.554028: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 18:59:37.024788: lr: 0.0
2022-05-27 18:59:37.027419: saving scheduled checkpoint file...
2022-05-27 18:59:37.062131: saving checkpoint...
2022-05-27 18:59:38.039557: done, saving took 1.01 seconds
2022-05-27 18:59:38.055882: done
2022-05-27 18:59:38.058178: This epoch took 100.648530 s

2022-05-27 18:59:38.081892: saving checkpoint...
2022-05-27 18:59:38.997043: done, saving took 0.94 seconds
panc_025 (2, 73, 277, 277)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 277, 277)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 85], [0, 85]]
number of tiles: 8
computing Gaussian
done
prediction done
panc_035 (2, 71, 243, 243)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 243, 243)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 51], [0, 51]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_041 (2, 80, 316, 316)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 62, 124], [0, 62, 124]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_045 (2, 80, 323, 323)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 66, 131], [0, 66, 131]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_052 (2, 86, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_056 (2, 82, 303, 303)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_078 (2, 74, 280, 280)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 88], [0, 88]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_091 (2, 69, 323, 323)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 69, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 5], [0, 66, 131], [0, 66, 131]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_103 (2, 87, 262, 262)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 262, 262)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 70], [0, 70]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_106 (2, 80, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_114 (2, 95, 280, 280)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 88], [0, 88]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_117 (2, 156, 261, 261)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 156, 261, 261)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 61, 92], [0, 69], [0, 69]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_125 (2, 99, 369, 369)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 369, 369)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 88, 177], [0, 88, 177]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_135 (2, 116, 286, 286)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 116, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52], [0, 94], [0, 94]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_140 (2, 109, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 109, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 45], [0, 66, 133], [0, 66, 133]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_166 (2, 92, 366, 366)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 366, 366)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 87, 174], [0, 87, 174]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_178 (2, 107, 317, 317)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 317, 317)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 62, 125], [0, 62, 125]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_187 (2, 92, 332, 332)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_199 (2, 92, 318, 318)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 63, 126], [0, 63, 126]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_200 (2, 86, 372, 372)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 372, 372)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 90, 180], [0, 90, 180]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_249 (2, 119, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 119, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 55], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_262 (2, 74, 297, 297)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 297, 297)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 52, 105], [0, 52, 105]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_264 (2, 106, 331, 331)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 331, 331)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 70, 139], [0, 70, 139]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_266 (2, 94, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_269 (2, 110, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 58, 116], [0, 58, 116]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_280 (2, 94, 367, 367)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 88, 175], [0, 88, 175]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_283 (2, 104, 280, 280)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 88], [0, 88]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_293 (2, 104, 354, 354)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 354, 354)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 81, 162], [0, 81, 162]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_301 (2, 81, 330, 330)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 330, 330)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 69, 138], [0, 69, 138]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_310 (2, 79, 365, 365)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 365, 365)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 86, 173], [0, 86, 173]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_312 (2, 73, 367, 367)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 88, 175], [0, 88, 175]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_313 (2, 92, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_323 (2, 92, 379, 379)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 379, 379)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 94, 187], [0, 94, 187]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_329 (2, 77, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 77, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 13], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_342 (2, 114, 324, 324)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 324, 324)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 66, 132], [0, 66, 132]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_343 (2, 83, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_351 (2, 85, 267, 267)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_354 (2, 157, 328, 328)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 157, 328, 328)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 62, 93], [0, 68, 136], [0, 68, 136]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_358 (2, 173, 288, 288)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 173, 288, 288)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27, 54, 82, 109], [0, 96], [0, 96]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_361 (2, 132, 247, 247)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 132, 247, 247)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 45, 68], [0, 55], [0, 55]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_366 (2, 117, 349, 349)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 349, 349)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 78, 157], [0, 78, 157]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_370 (2, 177, 267, 267)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 177, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 85, 113], [0, 75], [0, 75]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_380 (2, 122, 353, 353)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 122, 353, 353)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58], [0, 80, 161], [0, 80, 161]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_388 (2, 111, 352, 352)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 111, 352, 352)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 47], [0, 80, 160], [0, 80, 160]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_389 (2, 115, 337, 337)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 115, 337, 337)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 51], [0, 72, 145], [0, 72, 145]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_405 (2, 86, 321, 321)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_414 (2, 82, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_421 (2, 102, 385, 385)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 385, 385)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 64, 129, 193], [0, 64, 129, 193]]
number of tiles: 48
using precomputed Gaussian
prediction done
2022-05-27 19:07:28.493993: finished prediction
2022-05-27 19:07:28.497303: evaluation of raw predictions
2022-05-27 19:07:38.625356: determining postprocessing
Foreground vs background
before: 0.8120560662226849
after:  0.8120954212293556
Removing all but the largest foreground region improved results!
for_which_classes [1]
min_valid_object_sizes None
Only one class present, no need to do each class separately as this is covered in fg vs bg
done
for which classes:
[[1]]
min_object_sizes
None
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
done
predicting segmentations for the next stage of the cascade
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
panc_025
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 277, 277)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 85], [0, 85]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_035
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 243, 243)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 51], [0, 51]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_041
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 62, 124], [0, 62, 124]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_045
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 66, 131], [0, 66, 131]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_052
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_056
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_078
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 88], [0, 88]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_091
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 69, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 5], [0, 66, 131], [0, 66, 131]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_103
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 262, 262)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 70], [0, 70]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_106
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_114
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 88], [0, 88]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_117
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 156, 261, 261)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 61, 92], [0, 69], [0, 69]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_125
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 369, 369)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 88, 177], [0, 88, 177]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_135
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 116, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52], [0, 94], [0, 94]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_140
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 109, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 45], [0, 66, 133], [0, 66, 133]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_166
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 366, 366)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 87, 174], [0, 87, 174]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_178
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 317, 317)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 62, 125], [0, 62, 125]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_187
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_199
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 63, 126], [0, 63, 126]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_200
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 372, 372)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 90, 180], [0, 90, 180]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_249
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 119, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 55], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_262
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 297, 297)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 52, 105], [0, 52, 105]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_264
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 331, 331)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 70, 139], [0, 70, 139]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_266
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_269
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 58, 116], [0, 58, 116]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_280
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 88, 175], [0, 88, 175]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_283
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 88], [0, 88]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_293
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 354, 354)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 81, 162], [0, 81, 162]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_301
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 330, 330)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 69, 138], [0, 69, 138]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_310
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 365, 365)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 86, 173], [0, 86, 173]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_312
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 88, 175], [0, 88, 175]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_313
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_323
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 379, 379)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 94, 187], [0, 94, 187]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_329
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 77, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 13], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_342
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 324, 324)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 66, 132], [0, 66, 132]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_343
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_351
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_354
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 157, 328, 328)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 62, 93], [0, 68, 136], [0, 68, 136]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_358
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 173, 288, 288)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27, 54, 82, 109], [0, 96], [0, 96]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_361
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 132, 247, 247)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 45, 68], [0, 55], [0, 55]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_366
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 349, 349)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 78, 157], [0, 78, 157]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_370
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 177, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 85, 113], [0, 75], [0, 75]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_380
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 122, 353, 353)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58], [0, 80, 161], [0, 80, 161]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_388
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 111, 352, 352)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 47], [0, 80, 160], [0, 80, 160]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_389
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 115, 337, 337)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 51], [0, 72, 145], [0, 72, 145]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_405
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_414
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_421
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 385, 385)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 64, 129, 193], [0, 64, 129, 193]]
number of tiles: 48
using precomputed Gaussian
prediction done


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_lowres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 93, 318, 318]), 'current_spacing': array([2.5757525 , 1.29418872, 1.29418872]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 40, 224, 224]), 'median_patient_size_in_voxels': array([ 96, 512, 512]), 'current_spacing': array([2.5       , 0.80273402, 0.80273402]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-05-27 19:17:07.284215: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/splits_final.pkl
2022-05-27 19:17:07.310720: The split file contains 5 splits.
2022-05-27 19:17:07.313097: Desired fold for training: 2
2022-05-27 19:17:07.315135: This split has 191 training and 48 validation cases.
unpacking dataset
done
Susy hier
Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-27 19:17:10.886646: lr: 0.01
using pin_memory on device 0
using pin_memory on device 0
2022-05-27 19:17:20.955234: Unable to plot network architecture:
2022-05-27 19:17:20.960765: No module named 'hiddenlayer'
2022-05-27 19:17:20.963689: 
printing the network instead:

2022-05-27 19:17:20.974175: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-27 19:17:20.995112: 

2022-05-27 19:17:21.017395: 
epoch:  0
2022-05-27 19:19:05.916573: train loss : 0.0076
2022-05-27 19:19:14.114612: validation loss: -0.1777
2022-05-27 19:19:14.169053: Average global foreground Dice: [0.1883]
2022-05-27 19:19:14.213318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:19:15.681918: lr: 0.009982
2022-05-27 19:19:15.718394: This epoch took 114.681368 s

2022-05-27 19:19:15.748324: 
epoch:  1
2022-05-27 19:20:48.762305: train loss : -0.2123
2022-05-27 19:20:55.733454: validation loss: -0.2590
2022-05-27 19:20:55.766180: Average global foreground Dice: [0.3472]
2022-05-27 19:20:55.788132: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:20:56.540177: lr: 0.009964
2022-05-27 19:20:56.660604: saving checkpoint...
2022-05-27 19:20:57.921673: done, saving took 1.35 seconds
2022-05-27 19:20:57.941072: This epoch took 102.190629 s

2022-05-27 19:20:57.943939: 
epoch:  2
2022-05-27 19:22:30.995104: train loss : -0.2864
2022-05-27 19:22:39.456756: validation loss: -0.3941
2022-05-27 19:22:39.490757: Average global foreground Dice: [0.4774]
2022-05-27 19:22:39.513294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:22:40.347153: lr: 0.009946
2022-05-27 19:22:40.431173: saving checkpoint...
2022-05-27 19:22:41.632926: done, saving took 1.25 seconds
2022-05-27 19:22:41.669620: This epoch took 103.723406 s

2022-05-27 19:22:41.672227: 
epoch:  3
2022-05-27 19:24:13.990645: train loss : -0.3759
2022-05-27 19:24:22.044359: validation loss: -0.4753
2022-05-27 19:24:22.061819: Average global foreground Dice: [0.5505]
2022-05-27 19:24:22.078465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:24:22.554628: lr: 0.009928
2022-05-27 19:24:22.605058: saving checkpoint...
2022-05-27 19:24:23.570174: done, saving took 1.01 seconds
2022-05-27 19:24:23.585081: This epoch took 101.910902 s

2022-05-27 19:24:23.587364: 
epoch:  4
2022-05-27 19:25:55.602830: train loss : -0.4403
2022-05-27 19:26:03.240272: validation loss: -0.5191
2022-05-27 19:26:03.270274: Average global foreground Dice: [0.5881]
2022-05-27 19:26:03.297306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:26:04.251014: lr: 0.00991
2022-05-27 19:26:04.372044: saving checkpoint...
2022-05-27 19:26:05.810390: done, saving took 1.54 seconds
2022-05-27 19:26:05.892302: This epoch took 102.302831 s

2022-05-27 19:26:05.927287: 
epoch:  5
2022-05-27 19:27:38.245681: train loss : -0.4566
2022-05-27 19:27:44.860228: validation loss: -0.5396
2022-05-27 19:27:44.870332: Average global foreground Dice: [0.6096]
2022-05-27 19:27:44.897765: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:27:45.494163: lr: 0.009892
2022-05-27 19:27:45.633348: saving checkpoint...
2022-05-27 19:27:46.829583: done, saving took 1.25 seconds
2022-05-27 19:27:46.845047: This epoch took 100.894756 s

2022-05-27 19:27:46.847029: 
epoch:  6
2022-05-27 19:29:18.755078: train loss : -0.4838
2022-05-27 19:29:25.650558: validation loss: -0.4975
2022-05-27 19:29:25.654064: Average global foreground Dice: [0.5664]
2022-05-27 19:29:25.656577: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:29:26.090130: lr: 0.009874
2022-05-27 19:29:26.146579: saving checkpoint...
2022-05-27 19:29:27.085552: done, saving took 0.99 seconds
2022-05-27 19:29:27.100253: This epoch took 100.251292 s

2022-05-27 19:29:27.102290: 
epoch:  7
2022-05-27 19:30:58.066399: train loss : -0.4814
2022-05-27 19:31:04.422841: validation loss: -0.5897
2022-05-27 19:31:04.426448: Average global foreground Dice: [0.6589]
2022-05-27 19:31:04.428917: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:31:04.865551: lr: 0.009856
2022-05-27 19:31:04.918669: saving checkpoint...
2022-05-27 19:31:05.949412: done, saving took 1.08 seconds
2022-05-27 19:31:05.964909: This epoch took 98.860752 s

2022-05-27 19:31:05.967018: 
epoch:  8
2022-05-27 19:32:43.253686: train loss : -0.5204
2022-05-27 19:32:51.169089: validation loss: -0.5771
2022-05-27 19:32:51.172550: Average global foreground Dice: [0.6438]
2022-05-27 19:32:51.174763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:32:51.724197: lr: 0.009838
2022-05-27 19:32:51.761610: saving checkpoint...
2022-05-27 19:32:52.718613: done, saving took 0.99 seconds
2022-05-27 19:32:52.731466: This epoch took 106.762638 s

2022-05-27 19:32:52.733557: 
epoch:  9
2022-05-27 19:34:24.831185: train loss : -0.5209
2022-05-27 19:34:34.274551: validation loss: -0.6060
2022-05-27 19:34:34.279126: Average global foreground Dice: [0.667]
2022-05-27 19:34:34.281169: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:34:34.910162: lr: 0.00982
2022-05-27 19:34:34.989260: saving checkpoint...
2022-05-27 19:34:36.153145: done, saving took 1.22 seconds
2022-05-27 19:34:36.166698: This epoch took 103.430784 s

2022-05-27 19:34:36.168892: 
epoch:  10
2022-05-27 19:36:08.302654: train loss : -0.5267
2022-05-27 19:36:18.011229: validation loss: -0.6184
2022-05-27 19:36:18.029873: Average global foreground Dice: [0.6916]
2022-05-27 19:36:18.050602: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:36:18.595967: lr: 0.009802
2022-05-27 19:36:18.681942: saving checkpoint...
2022-05-27 19:36:19.702354: done, saving took 1.06 seconds
2022-05-27 19:36:19.720774: This epoch took 103.549214 s

2022-05-27 19:36:19.722840: 
epoch:  11
2022-05-27 19:37:55.612757: train loss : -0.5876
2022-05-27 19:38:04.396894: validation loss: -0.6064
2022-05-27 19:38:04.419306: Average global foreground Dice: [0.6708]
2022-05-27 19:38:04.443355: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:38:05.239524: lr: 0.009784
2022-05-27 19:38:05.340487: saving checkpoint...
2022-05-27 19:38:06.714922: done, saving took 1.45 seconds
2022-05-27 19:38:06.729057: This epoch took 107.004394 s

2022-05-27 19:38:06.731472: 
epoch:  12
2022-05-27 19:39:40.842548: train loss : -0.5714
2022-05-27 19:39:47.725801: validation loss: -0.6174
2022-05-27 19:39:47.756746: Average global foreground Dice: [0.6977]
2022-05-27 19:39:47.772316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:39:48.403786: lr: 0.009766
2022-05-27 19:39:48.495423: saving checkpoint...
2022-05-27 19:39:49.722564: done, saving took 1.27 seconds
2022-05-27 19:39:49.745443: This epoch took 103.011652 s

2022-05-27 19:39:49.747623: 
epoch:  13
2022-05-27 19:41:22.865428: train loss : -0.6070
2022-05-27 19:41:30.807697: validation loss: -0.6332
2022-05-27 19:41:30.825703: Average global foreground Dice: [0.7045]
2022-05-27 19:41:30.841534: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:41:31.330703: lr: 0.009748
2022-05-27 19:41:31.403061: saving checkpoint...
2022-05-27 19:41:32.505687: done, saving took 1.15 seconds
2022-05-27 19:41:32.520306: This epoch took 102.770675 s

2022-05-27 19:41:32.522615: 
epoch:  14
2022-05-27 19:43:04.594104: train loss : -0.5792
2022-05-27 19:43:12.551455: validation loss: -0.6090
2022-05-27 19:43:12.591501: Average global foreground Dice: [0.6711]
2022-05-27 19:43:12.615435: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:43:13.309992: lr: 0.00973
2022-05-27 19:43:13.411084: saving checkpoint...
2022-05-27 19:43:14.443431: done, saving took 1.11 seconds
2022-05-27 19:43:14.457922: This epoch took 101.933093 s

2022-05-27 19:43:14.459993: 
epoch:  15
2022-05-27 19:44:50.094241: train loss : -0.5963
2022-05-27 19:44:57.193731: validation loss: -0.6549
2022-05-27 19:44:57.218998: Average global foreground Dice: [0.7317]
2022-05-27 19:44:57.252311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:44:57.939916: lr: 0.009712
2022-05-27 19:44:58.035256: saving checkpoint...
2022-05-27 19:44:59.270233: done, saving took 1.30 seconds
2022-05-27 19:44:59.285911: This epoch took 104.823909 s

2022-05-27 19:44:59.288064: 
epoch:  16
2022-05-27 19:46:32.412912: train loss : -0.6226
2022-05-27 19:46:41.544379: validation loss: -0.6427
2022-05-27 19:46:41.557784: Average global foreground Dice: [0.7042]
2022-05-27 19:46:41.570765: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:46:42.081440: lr: 0.009693
2022-05-27 19:46:42.131319: saving checkpoint...
2022-05-27 19:46:43.082888: done, saving took 1.00 seconds
2022-05-27 19:46:43.096345: This epoch took 103.806378 s

2022-05-27 19:46:43.098505: 
epoch:  17
2022-05-27 19:48:15.233241: train loss : -0.6060
2022-05-27 19:48:22.548888: validation loss: -0.6318
2022-05-27 19:48:22.579684: Average global foreground Dice: [0.6769]
2022-05-27 19:48:22.612308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:48:23.219063: lr: 0.009675
2022-05-27 19:48:23.256126: saving checkpoint...
2022-05-27 19:48:24.246480: done, saving took 1.02 seconds
2022-05-27 19:48:24.307701: This epoch took 101.207029 s

2022-05-27 19:48:24.310389: 
epoch:  18
2022-05-27 19:50:00.219884: train loss : -0.6256
2022-05-27 19:50:07.271091: validation loss: -0.6789
2022-05-27 19:50:07.312003: Average global foreground Dice: [0.7321]
2022-05-27 19:50:07.331775: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:50:08.015767: lr: 0.009657
2022-05-27 19:50:08.129632: saving checkpoint...
2022-05-27 19:50:09.172403: done, saving took 1.14 seconds
2022-05-27 19:50:09.243374: This epoch took 104.929621 s

2022-05-27 19:50:09.276297: 
epoch:  19
2022-05-27 19:51:42.139768: train loss : -0.6194
2022-05-27 19:51:50.524654: validation loss: -0.6750
2022-05-27 19:51:50.536799: Average global foreground Dice: [0.7322]
2022-05-27 19:51:50.549228: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:51:51.233375: lr: 0.009639
2022-05-27 19:51:51.292345: saving checkpoint...
2022-05-27 19:51:52.444325: done, saving took 1.21 seconds
2022-05-27 19:51:52.460428: This epoch took 103.147072 s

2022-05-27 19:51:52.462566: 
epoch:  20
2022-05-27 19:53:24.316766: train loss : -0.6273
2022-05-27 19:53:33.063283: validation loss: -0.6568
2022-05-27 19:53:33.093735: Average global foreground Dice: [0.7285]
2022-05-27 19:53:33.116378: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:53:33.920820: lr: 0.009621
2022-05-27 19:53:34.025717: saving checkpoint...
2022-05-27 19:53:34.979349: done, saving took 1.03 seconds
2022-05-27 19:53:34.995283: This epoch took 102.530679 s

2022-05-27 19:53:34.997308: 
epoch:  21
2022-05-27 19:55:09.637519: train loss : -0.6464
2022-05-27 19:55:16.901299: validation loss: -0.6584
2022-05-27 19:55:16.928962: Average global foreground Dice: [0.721]
2022-05-27 19:55:16.942291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:55:17.580137: lr: 0.009603
2022-05-27 19:55:17.650579: saving checkpoint...
2022-05-27 19:55:19.061679: done, saving took 1.46 seconds
2022-05-27 19:55:19.106577: This epoch took 104.107414 s

2022-05-27 19:55:19.108743: 
epoch:  22
2022-05-27 19:56:51.439442: train loss : -0.6335
2022-05-27 19:57:00.099011: validation loss: -0.6628
2022-05-27 19:57:00.180266: Average global foreground Dice: [0.7329]
2022-05-27 19:57:00.191652: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:57:00.890924: lr: 0.009585
2022-05-27 19:57:00.971128: saving checkpoint...
2022-05-27 19:57:02.352867: done, saving took 1.46 seconds
2022-05-27 19:57:02.371326: This epoch took 103.260335 s

2022-05-27 19:57:02.380823: 
epoch:  23
2022-05-27 19:58:34.076504: train loss : -0.6513
2022-05-27 19:58:40.115868: validation loss: -0.6866
2022-05-27 19:58:40.125446: Average global foreground Dice: [0.7338]
2022-05-27 19:58:40.130480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 19:58:40.580631: lr: 0.009567
2022-05-27 19:58:40.629559: saving checkpoint...
2022-05-27 19:58:41.621210: done, saving took 1.04 seconds
2022-05-27 19:58:41.636126: This epoch took 99.252180 s

2022-05-27 19:58:41.638506: 
epoch:  24
2022-05-27 20:00:16.435638: train loss : -0.6606
2022-05-27 20:00:25.606981: validation loss: -0.6706
2022-05-27 20:00:25.639761: Average global foreground Dice: [0.7245]
2022-05-27 20:00:25.661320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:00:26.245081: lr: 0.009549
2022-05-27 20:00:26.321954: saving checkpoint...
2022-05-27 20:00:27.446086: done, saving took 1.18 seconds
2022-05-27 20:00:27.461664: This epoch took 105.821295 s

2022-05-27 20:00:27.463785: 
epoch:  25
2022-05-27 20:01:59.755393: train loss : -0.6690
2022-05-27 20:02:07.437618: validation loss: -0.6822
2022-05-27 20:02:07.469667: Average global foreground Dice: [0.7412]
2022-05-27 20:02:07.488645: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:02:08.003638: lr: 0.009531
2022-05-27 20:02:08.045987: saving checkpoint...
2022-05-27 20:02:09.075516: done, saving took 1.07 seconds
2022-05-27 20:02:09.118290: This epoch took 101.652562 s

2022-05-27 20:02:09.121784: 
epoch:  26
2022-05-27 20:03:44.145201: train loss : -0.6433
2022-05-27 20:03:52.243502: validation loss: -0.6914
2022-05-27 20:03:52.271117: Average global foreground Dice: [0.743]
2022-05-27 20:03:52.305306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:03:52.946815: lr: 0.009513
2022-05-27 20:03:52.989341: saving checkpoint...
2022-05-27 20:03:54.047383: done, saving took 1.10 seconds
2022-05-27 20:03:54.061557: This epoch took 104.933469 s

2022-05-27 20:03:54.063618: 
epoch:  27
2022-05-27 20:05:26.269589: train loss : -0.6629
2022-05-27 20:05:33.885463: validation loss: -0.7070
2022-05-27 20:05:33.917904: Average global foreground Dice: [0.7534]
2022-05-27 20:05:33.951418: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:05:34.537008: lr: 0.009495
2022-05-27 20:05:34.627528: saving checkpoint...
2022-05-27 20:05:35.766523: done, saving took 1.21 seconds
2022-05-27 20:05:35.782844: This epoch took 101.717324 s

2022-05-27 20:05:35.785428: 
epoch:  28
2022-05-27 20:07:07.362380: train loss : -0.6697
2022-05-27 20:07:13.505057: validation loss: -0.6789
2022-05-27 20:07:13.508905: Average global foreground Dice: [0.7351]
2022-05-27 20:07:13.511001: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:07:13.965274: lr: 0.009476
2022-05-27 20:07:14.008357: saving checkpoint...
2022-05-27 20:07:15.089133: done, saving took 1.12 seconds
2022-05-27 20:07:15.104323: This epoch took 99.316978 s

2022-05-27 20:07:15.106557: 
epoch:  29
2022-05-27 20:08:46.394627: train loss : -0.6683
2022-05-27 20:08:55.259830: validation loss: -0.6742
2022-05-27 20:08:55.281330: Average global foreground Dice: [0.7425]
2022-05-27 20:08:55.294519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:08:56.042176: lr: 0.009458
2022-05-27 20:08:56.072830: saving checkpoint...
2022-05-27 20:08:57.103285: done, saving took 1.06 seconds
2022-05-27 20:08:57.115959: This epoch took 102.007335 s

2022-05-27 20:08:57.117924: 
epoch:  30
2022-05-27 20:10:29.295109: train loss : -0.6742
2022-05-27 20:10:38.086605: validation loss: -0.6887
2022-05-27 20:10:38.113290: Average global foreground Dice: [0.7432]
2022-05-27 20:10:38.131357: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:10:38.696885: lr: 0.00944
2022-05-27 20:10:38.787591: saving checkpoint...
2022-05-27 20:10:39.925235: done, saving took 1.20 seconds
2022-05-27 20:10:39.969013: This epoch took 102.849219 s

2022-05-27 20:10:39.998309: 
epoch:  31
2022-05-27 20:12:13.901891: train loss : -0.6659
2022-05-27 20:12:23.881373: validation loss: -0.6861
2022-05-27 20:12:23.907720: Average global foreground Dice: [0.7452]
2022-05-27 20:12:23.937304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:12:24.455145: lr: 0.009422
2022-05-27 20:12:24.499743: saving checkpoint...
2022-05-27 20:12:25.463914: done, saving took 1.01 seconds
2022-05-27 20:12:25.478525: This epoch took 105.457207 s

2022-05-27 20:12:25.480688: 
epoch:  32
2022-05-27 20:13:57.133829: train loss : -0.6633
2022-05-27 20:14:06.218102: validation loss: -0.6948
2022-05-27 20:14:06.221489: Average global foreground Dice: [0.7483]
2022-05-27 20:14:06.223833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:14:06.804586: lr: 0.009404
2022-05-27 20:14:06.879048: saving checkpoint...
2022-05-27 20:14:08.002929: done, saving took 1.17 seconds
2022-05-27 20:14:08.016712: This epoch took 102.533989 s

2022-05-27 20:14:08.018739: 
epoch:  33
2022-05-27 20:15:43.966065: train loss : -0.6540
2022-05-27 20:15:52.614163: validation loss: -0.7072
2022-05-27 20:15:52.636801: Average global foreground Dice: [0.7553]
2022-05-27 20:15:52.655906: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:15:53.192275: lr: 0.009386
2022-05-27 20:15:53.280303: saving checkpoint...
2022-05-27 20:15:54.827777: done, saving took 1.61 seconds
2022-05-27 20:15:54.869201: This epoch took 106.848522 s

2022-05-27 20:15:54.874311: 
epoch:  34
2022-05-27 20:17:27.509439: train loss : -0.6789
2022-05-27 20:17:36.712111: validation loss: -0.7047
2022-05-27 20:17:36.743782: Average global foreground Dice: [0.7443]
2022-05-27 20:17:36.763306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:17:37.419894: lr: 0.009368
2022-05-27 20:17:37.484391: saving checkpoint...
2022-05-27 20:17:38.512918: done, saving took 1.08 seconds
2022-05-27 20:17:38.575371: This epoch took 103.669058 s

2022-05-27 20:17:38.597296: 
epoch:  35
2022-05-27 20:19:10.171874: train loss : -0.6835
2022-05-27 20:19:17.249899: validation loss: -0.7032
2022-05-27 20:19:17.277053: Average global foreground Dice: [0.7481]
2022-05-27 20:19:17.300356: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:19:17.826722: lr: 0.00935
2022-05-27 20:19:17.898278: saving checkpoint...
2022-05-27 20:19:19.067571: done, saving took 1.21 seconds
2022-05-27 20:19:19.082274: This epoch took 100.464980 s

2022-05-27 20:19:19.084435: 
epoch:  36
2022-05-27 20:20:49.729290: train loss : -0.6812
2022-05-27 20:20:58.048335: validation loss: -0.7154
2022-05-27 20:20:58.092863: Average global foreground Dice: [0.7576]
2022-05-27 20:20:58.115290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:20:58.675549: lr: 0.009331
2022-05-27 20:20:58.727013: saving checkpoint...
2022-05-27 20:20:59.733045: done, saving took 1.03 seconds
2022-05-27 20:20:59.745298: This epoch took 100.658972 s

2022-05-27 20:20:59.747224: 
epoch:  37
2022-05-27 20:22:31.663306: train loss : -0.6970
2022-05-27 20:22:39.541313: validation loss: -0.7140
2022-05-27 20:22:39.560643: Average global foreground Dice: [0.7642]
2022-05-27 20:22:39.587300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:22:40.313376: lr: 0.009313
2022-05-27 20:22:40.367872: saving checkpoint...
2022-05-27 20:22:41.346206: done, saving took 1.03 seconds
2022-05-27 20:22:41.361376: This epoch took 101.612325 s

2022-05-27 20:22:41.363482: 
epoch:  38
2022-05-27 20:24:13.130103: train loss : -0.7059
2022-05-27 20:24:21.869684: validation loss: -0.7183
2022-05-27 20:24:21.897858: Average global foreground Dice: [0.7571]
2022-05-27 20:24:21.918317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:24:22.861650: lr: 0.009295
2022-05-27 20:24:22.949709: saving checkpoint...
2022-05-27 20:24:23.986392: done, saving took 1.10 seconds
2022-05-27 20:24:24.040442: This epoch took 102.675017 s

2022-05-27 20:24:24.048292: 
epoch:  39
2022-05-27 20:25:55.617967: train loss : -0.6841
2022-05-27 20:26:03.062800: validation loss: -0.7146
2022-05-27 20:26:03.076269: Average global foreground Dice: [0.77]
2022-05-27 20:26:03.099318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:26:03.599788: lr: 0.009277
2022-05-27 20:26:03.643942: saving checkpoint...
2022-05-27 20:26:04.661342: done, saving took 1.06 seconds
2022-05-27 20:26:04.676226: This epoch took 100.604923 s

2022-05-27 20:26:04.678230: 
epoch:  40
2022-05-27 20:27:36.865690: train loss : -0.6822
2022-05-27 20:27:44.817589: validation loss: -0.7199
2022-05-27 20:27:44.853711: Average global foreground Dice: [0.7726]
2022-05-27 20:27:44.875299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:27:45.639566: lr: 0.009259
2022-05-27 20:27:45.712252: saving checkpoint...
2022-05-27 20:27:46.806484: done, saving took 1.13 seconds
2022-05-27 20:27:46.853580: This epoch took 102.173452 s

2022-05-27 20:27:46.855779: 
epoch:  41
2022-05-27 20:29:20.035359: train loss : -0.6990
2022-05-27 20:29:28.807078: validation loss: -0.7250
2022-05-27 20:29:28.831667: Average global foreground Dice: [0.7749]
2022-05-27 20:29:28.846411: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:29:29.776592: lr: 0.009241
2022-05-27 20:29:29.879391: saving checkpoint...
2022-05-27 20:29:30.976648: done, saving took 1.18 seconds
2022-05-27 20:29:30.990216: This epoch took 104.132422 s

2022-05-27 20:29:30.992260: 
epoch:  42
2022-05-27 20:31:08.670373: train loss : -0.6874
2022-05-27 20:31:16.166107: validation loss: -0.6987
2022-05-27 20:31:16.197653: Average global foreground Dice: [0.7468]
2022-05-27 20:31:16.291290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:31:17.067741: lr: 0.009223
2022-05-27 20:31:17.126302: saving checkpoint...
2022-05-27 20:31:18.238035: done, saving took 1.15 seconds
2022-05-27 20:31:18.252752: This epoch took 107.258505 s

2022-05-27 20:31:18.254859: 
epoch:  43
2022-05-27 20:32:50.146621: train loss : -0.6986
2022-05-27 20:33:00.204284: validation loss: -0.7361
2022-05-27 20:33:00.215424: Average global foreground Dice: [0.7786]
2022-05-27 20:33:00.222285: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:33:00.671615: lr: 0.009204
2022-05-27 20:33:00.721761: saving checkpoint...
2022-05-27 20:33:01.638599: done, saving took 0.96 seconds
2022-05-27 20:33:01.651945: This epoch took 103.395106 s

2022-05-27 20:33:01.654007: 
epoch:  44
2022-05-27 20:34:32.308558: train loss : -0.7090
2022-05-27 20:34:38.656382: validation loss: -0.6906
2022-05-27 20:34:38.659328: Average global foreground Dice: [0.7501]
2022-05-27 20:34:38.661391: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:34:39.099679: lr: 0.009186
2022-05-27 20:34:39.144657: saving checkpoint...
2022-05-27 20:34:40.060373: done, saving took 0.96 seconds
2022-05-27 20:34:40.074795: This epoch took 98.418926 s

2022-05-27 20:34:40.076974: 
epoch:  45
2022-05-27 20:36:13.594651: train loss : -0.7016
2022-05-27 20:36:21.023098: validation loss: -0.7057
2022-05-27 20:36:21.094851: Average global foreground Dice: [0.7504]
2022-05-27 20:36:21.116310: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:36:21.805598: lr: 0.009168
2022-05-27 20:36:21.870667: saving checkpoint...
2022-05-27 20:36:22.940407: done, saving took 1.13 seconds
2022-05-27 20:36:22.991304: This epoch took 102.912314 s

2022-05-27 20:36:23.004031: 
epoch:  46
2022-05-27 20:37:56.335125: train loss : -0.6978
2022-05-27 20:38:04.419590: validation loss: -0.7230
2022-05-27 20:38:04.425898: Average global foreground Dice: [0.7804]
2022-05-27 20:38:04.444211: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:38:05.189488: lr: 0.00915
2022-05-27 20:38:05.304568: saving checkpoint...
2022-05-27 20:38:06.328199: done, saving took 1.12 seconds
2022-05-27 20:38:06.342487: This epoch took 103.330304 s

2022-05-27 20:38:06.344598: 
epoch:  47
2022-05-27 20:39:37.927928: train loss : -0.7054
2022-05-27 20:39:46.937624: validation loss: -0.7278
2022-05-27 20:39:46.941678: Average global foreground Dice: [0.7725]
2022-05-27 20:39:46.944092: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:39:47.416167: lr: 0.009132
2022-05-27 20:39:47.466646: saving checkpoint...
2022-05-27 20:39:48.420766: done, saving took 1.00 seconds
2022-05-27 20:39:48.435656: This epoch took 102.089040 s

2022-05-27 20:39:48.438149: 
epoch:  48
2022-05-27 20:41:21.253361: train loss : -0.7016
2022-05-27 20:41:27.985807: validation loss: -0.6878
2022-05-27 20:41:28.001379: Average global foreground Dice: [0.7507]
2022-05-27 20:41:28.006956: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:41:28.743578: lr: 0.009114
2022-05-27 20:41:28.748284: This epoch took 100.307971 s

2022-05-27 20:41:28.752705: 
epoch:  49
2022-05-27 20:43:00.601717: train loss : -0.7032
2022-05-27 20:43:07.777178: validation loss: -0.7367
2022-05-27 20:43:07.783341: Average global foreground Dice: [0.7832]
2022-05-27 20:43:07.805579: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:43:08.294083: lr: 0.009095
2022-05-27 20:43:08.296144: saving scheduled checkpoint file...
2022-05-27 20:43:08.331048: saving checkpoint...
2022-05-27 20:43:09.276027: done, saving took 0.98 seconds
2022-05-27 20:43:09.289882: done
2022-05-27 20:43:09.318367: saving checkpoint...
2022-05-27 20:43:10.314376: done, saving took 1.02 seconds
2022-05-27 20:43:10.330751: This epoch took 101.563927 s

2022-05-27 20:43:10.333042: 
epoch:  50
2022-05-27 20:44:41.773803: train loss : -0.7101
2022-05-27 20:44:47.904721: validation loss: -0.7561
2022-05-27 20:44:47.908328: Average global foreground Dice: [0.7913]
2022-05-27 20:44:47.910697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:44:48.358298: lr: 0.009077
2022-05-27 20:44:48.402007: saving checkpoint...
2022-05-27 20:44:49.357444: done, saving took 1.00 seconds
2022-05-27 20:44:49.370879: This epoch took 99.035422 s

2022-05-27 20:44:49.372797: 
epoch:  51
2022-05-27 20:46:26.293744: train loss : -0.7043
2022-05-27 20:46:34.377602: validation loss: -0.7158
2022-05-27 20:46:34.382531: Average global foreground Dice: [0.7767]
2022-05-27 20:46:34.392866: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:46:34.943900: lr: 0.009059
2022-05-27 20:46:34.989880: saving checkpoint...
2022-05-27 20:46:36.019396: done, saving took 1.07 seconds
2022-05-27 20:46:36.033571: This epoch took 106.658548 s

2022-05-27 20:46:36.035650: 
epoch:  52
2022-05-27 20:48:08.488954: train loss : -0.7224
2022-05-27 20:48:14.721592: validation loss: -0.7193
2022-05-27 20:48:14.732835: Average global foreground Dice: [0.7806]
2022-05-27 20:48:14.735007: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:48:15.183115: lr: 0.009041
2022-05-27 20:48:15.231717: saving checkpoint...
2022-05-27 20:48:16.310498: done, saving took 1.11 seconds
2022-05-27 20:48:16.323015: This epoch took 100.285339 s

2022-05-27 20:48:16.325106: 
epoch:  53
2022-05-27 20:49:49.455145: train loss : -0.7133
2022-05-27 20:49:57.765275: validation loss: -0.7248
2022-05-27 20:49:57.796586: Average global foreground Dice: [0.7732]
2022-05-27 20:49:57.818410: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:49:58.554949: lr: 0.009023
2022-05-27 20:49:58.613607: saving checkpoint...
2022-05-27 20:49:59.796527: done, saving took 1.22 seconds
2022-05-27 20:49:59.810233: This epoch took 103.483097 s

2022-05-27 20:49:59.812432: 
epoch:  54
2022-05-27 20:51:30.751067: train loss : -0.7249
2022-05-27 20:51:39.354736: validation loss: -0.7368
2022-05-27 20:51:39.375834: Average global foreground Dice: [0.7792]
2022-05-27 20:51:39.378394: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:51:39.828843: lr: 0.009004
2022-05-27 20:51:39.881504: saving checkpoint...
2022-05-27 20:51:41.112440: done, saving took 1.28 seconds
2022-05-27 20:51:41.128111: This epoch took 101.313603 s

2022-05-27 20:51:41.130560: 
epoch:  55
2022-05-27 20:53:13.394695: train loss : -0.7192
2022-05-27 20:53:21.080637: validation loss: -0.7288
2022-05-27 20:53:21.084074: Average global foreground Dice: [0.7709]
2022-05-27 20:53:21.086566: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:53:21.520347: lr: 0.008986
2022-05-27 20:53:21.555404: saving checkpoint...
2022-05-27 20:53:22.572065: done, saving took 1.05 seconds
2022-05-27 20:53:22.584519: This epoch took 101.451627 s

2022-05-27 20:53:22.586731: 
epoch:  56
2022-05-27 20:54:54.082588: train loss : -0.7095
2022-05-27 20:55:00.092307: validation loss: -0.7288
2022-05-27 20:55:00.096444: Average global foreground Dice: [0.7703]
2022-05-27 20:55:00.100408: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:55:00.546894: lr: 0.008968
2022-05-27 20:55:00.608140: saving checkpoint...
2022-05-27 20:55:01.592034: done, saving took 1.03 seconds
2022-05-27 20:55:01.606284: This epoch took 99.017615 s

2022-05-27 20:55:01.608223: 
epoch:  57
2022-05-27 20:56:34.091475: train loss : -0.7202
2022-05-27 20:56:41.822457: validation loss: -0.7202
2022-05-27 20:56:41.837051: Average global foreground Dice: [0.774]
2022-05-27 20:56:41.856497: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:56:42.614589: lr: 0.00895
2022-05-27 20:56:42.718233: saving checkpoint...
2022-05-27 20:56:43.733977: done, saving took 1.10 seconds
2022-05-27 20:56:43.748651: This epoch took 102.138606 s

2022-05-27 20:56:43.750779: 
epoch:  58
2022-05-27 20:58:16.330406: train loss : -0.7197
2022-05-27 20:58:25.882519: validation loss: -0.7202
2022-05-27 20:58:25.907842: Average global foreground Dice: [0.7652]
2022-05-27 20:58:25.950142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 20:58:26.439080: lr: 0.008931
2022-05-27 20:58:26.441765: This epoch took 102.689043 s

2022-05-27 20:58:26.443771: 
epoch:  59
2022-05-27 20:59:57.241051: train loss : -0.7301
2022-05-27 21:00:03.351269: validation loss: -0.7127
2022-05-27 21:00:03.354502: Average global foreground Dice: [0.762]
2022-05-27 21:00:03.356375: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:00:03.798122: lr: 0.008913
2022-05-27 21:00:03.800337: This epoch took 97.354375 s

2022-05-27 21:00:03.802208: 
epoch:  60
2022-05-27 21:01:35.571935: train loss : -0.7114
2022-05-27 21:01:43.726066: validation loss: -0.7141
2022-05-27 21:01:43.731766: Average global foreground Dice: [0.7767]
2022-05-27 21:01:43.733889: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:01:44.313373: lr: 0.008895
2022-05-27 21:01:44.409753: saving checkpoint...
2022-05-27 21:01:45.392372: done, saving took 1.06 seconds
2022-05-27 21:01:45.450194: This epoch took 101.646032 s

2022-05-27 21:01:45.452281: 
epoch:  61
2022-05-27 21:03:18.218637: train loss : -0.7237
2022-05-27 21:03:27.187795: validation loss: -0.7137
2022-05-27 21:03:27.191028: Average global foreground Dice: [0.769]
2022-05-27 21:03:27.193125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:03:27.843763: lr: 0.008877
2022-05-27 21:03:27.872854: saving checkpoint...
2022-05-27 21:03:28.824489: done, saving took 0.98 seconds
2022-05-27 21:03:28.842409: This epoch took 103.388380 s

2022-05-27 21:03:28.844384: 
epoch:  62
2022-05-27 21:05:00.522062: train loss : -0.7182
2022-05-27 21:05:09.006337: validation loss: -0.7431
2022-05-27 21:05:09.044689: Average global foreground Dice: [0.7819]
2022-05-27 21:05:09.063319: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:05:09.632702: lr: 0.008859
2022-05-27 21:05:09.710433: saving checkpoint...
2022-05-27 21:05:10.983742: done, saving took 1.34 seconds
2022-05-27 21:05:10.996778: This epoch took 102.150230 s

2022-05-27 21:05:10.998975: 
epoch:  63
2022-05-27 21:06:42.655222: train loss : -0.7174
2022-05-27 21:06:51.270160: validation loss: -0.7043
2022-05-27 21:06:51.296805: Average global foreground Dice: [0.7465]
2022-05-27 21:06:51.315521: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:06:51.878491: lr: 0.00884
2022-05-27 21:06:51.881265: This epoch took 100.871979 s

2022-05-27 21:06:51.900436: 
epoch:  64
2022-05-27 21:08:23.613049: train loss : -0.7182
2022-05-27 21:08:32.515032: validation loss: -0.7049
2022-05-27 21:08:32.518538: Average global foreground Dice: [0.7564]
2022-05-27 21:08:32.532312: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:08:33.228665: lr: 0.008822
2022-05-27 21:08:33.235726: This epoch took 101.315218 s

2022-05-27 21:08:33.239535: 
epoch:  65
2022-05-27 21:10:04.982070: train loss : -0.7210
2022-05-27 21:10:13.999811: validation loss: -0.7332
2022-05-27 21:10:14.031752: Average global foreground Dice: [0.7788]
2022-05-27 21:10:14.050252: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:10:14.879220: lr: 0.008804
2022-05-27 21:10:14.888635: This epoch took 101.646867 s

2022-05-27 21:10:14.905083: 
epoch:  66
2022-05-27 21:11:48.939448: train loss : -0.7082
2022-05-27 21:11:57.588374: validation loss: -0.7222
2022-05-27 21:11:57.591729: Average global foreground Dice: [0.7741]
2022-05-27 21:11:57.602307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:11:58.266993: lr: 0.008785
2022-05-27 21:11:58.271625: This epoch took 103.331658 s

2022-05-27 21:11:58.273949: 
epoch:  67
2022-05-27 21:13:29.555445: train loss : -0.7331
2022-05-27 21:13:36.709808: validation loss: -0.7391
2022-05-27 21:13:36.739723: Average global foreground Dice: [0.7849]
2022-05-27 21:13:36.764290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:13:37.443828: lr: 0.008767
2022-05-27 21:13:37.531640: saving checkpoint...
2022-05-27 21:13:38.678269: done, saving took 1.21 seconds
2022-05-27 21:13:38.692215: This epoch took 100.392889 s

2022-05-27 21:13:38.694431: 
epoch:  68
2022-05-27 21:15:09.783909: train loss : -0.7350
2022-05-27 21:15:16.941498: validation loss: -0.7219
2022-05-27 21:15:16.946465: Average global foreground Dice: [0.7609]
2022-05-27 21:15:16.949003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:15:17.406218: lr: 0.008749
2022-05-27 21:15:17.408325: This epoch took 98.711826 s

2022-05-27 21:15:17.410237: 
epoch:  69
2022-05-27 21:16:52.832208: train loss : -0.7106
2022-05-27 21:17:01.809195: validation loss: -0.7569
2022-05-27 21:17:01.813020: Average global foreground Dice: [0.7864]
2022-05-27 21:17:01.822728: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:17:02.280376: lr: 0.008731
2022-05-27 21:17:02.315058: saving checkpoint...
2022-05-27 21:17:03.255380: done, saving took 0.97 seconds
2022-05-27 21:17:03.268345: This epoch took 105.856188 s

2022-05-27 21:17:03.270348: 
epoch:  70
2022-05-27 21:18:40.273553: train loss : -0.7077
2022-05-27 21:18:50.535809: validation loss: -0.7457
2022-05-27 21:18:50.568852: Average global foreground Dice: [0.7892]
2022-05-27 21:18:50.590205: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:18:51.197096: lr: 0.008712
2022-05-27 21:18:51.231510: saving checkpoint...
2022-05-27 21:18:52.245250: done, saving took 1.05 seconds
2022-05-27 21:18:52.259285: This epoch took 108.987071 s

2022-05-27 21:18:52.261758: 
epoch:  71
2022-05-27 21:20:23.898077: train loss : -0.7079
2022-05-27 21:20:31.000374: validation loss: -0.7341
2022-05-27 21:20:31.004450: Average global foreground Dice: [0.7773]
2022-05-27 21:20:31.006768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:20:31.453828: lr: 0.008694
2022-05-27 21:20:31.489111: saving checkpoint...
2022-05-27 21:20:32.419611: done, saving took 0.96 seconds
2022-05-27 21:20:32.433191: This epoch took 100.169234 s

2022-05-27 21:20:32.435056: 
epoch:  72
2022-05-27 21:22:05.449125: train loss : -0.7265
2022-05-27 21:22:14.655721: validation loss: -0.7300
2022-05-27 21:22:14.675836: Average global foreground Dice: [0.7739]
2022-05-27 21:22:14.700956: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:22:15.295557: lr: 0.008676
2022-05-27 21:22:15.356162: saving checkpoint...
2022-05-27 21:22:16.271109: done, saving took 0.95 seconds
2022-05-27 21:22:16.286437: This epoch took 103.849585 s

2022-05-27 21:22:16.288532: 
epoch:  73
2022-05-27 21:23:47.900918: train loss : -0.7025
2022-05-27 21:23:56.952961: validation loss: -0.7188
2022-05-27 21:23:56.984758: Average global foreground Dice: [0.7555]
2022-05-27 21:23:57.009414: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:23:57.856281: lr: 0.008658
2022-05-27 21:23:57.867382: This epoch took 101.576683 s

2022-05-27 21:23:57.884290: 
epoch:  74
2022-05-27 21:25:31.723744: train loss : -0.7306
2022-05-27 21:25:40.594527: validation loss: -0.7310
2022-05-27 21:25:40.602086: Average global foreground Dice: [0.782]
2022-05-27 21:25:40.604117: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:25:41.430326: lr: 0.008639
2022-05-27 21:25:41.436897: This epoch took 103.519574 s

2022-05-27 21:25:41.439420: 
epoch:  75
2022-05-27 21:27:13.994478: train loss : -0.7210
2022-05-27 21:27:22.775318: validation loss: -0.7152
2022-05-27 21:27:22.801702: Average global foreground Dice: [0.7722]
2022-05-27 21:27:22.817446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:27:23.395755: lr: 0.008621
2022-05-27 21:27:23.416071: This epoch took 101.973096 s

2022-05-27 21:27:23.417992: 
epoch:  76
2022-05-27 21:29:01.412488: train loss : -0.7306
2022-05-27 21:29:10.543340: validation loss: -0.7355
2022-05-27 21:29:10.565644: Average global foreground Dice: [0.7838]
2022-05-27 21:29:10.578459: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:29:11.101776: lr: 0.008603
2022-05-27 21:29:11.144821: saving checkpoint...
2022-05-27 21:29:12.184209: done, saving took 1.07 seconds
2022-05-27 21:29:12.197408: This epoch took 108.772369 s

2022-05-27 21:29:12.199438: 
epoch:  77
2022-05-27 21:30:43.865520: train loss : -0.7019
2022-05-27 21:30:50.669634: validation loss: -0.7227
2022-05-27 21:30:50.673778: Average global foreground Dice: [0.7806]
2022-05-27 21:30:50.675717: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:30:51.194755: lr: 0.008584
2022-05-27 21:30:51.322637: saving checkpoint...
2022-05-27 21:30:52.376393: done, saving took 1.13 seconds
2022-05-27 21:30:52.391878: This epoch took 100.190379 s

2022-05-27 21:30:52.394253: 
epoch:  78
2022-05-27 21:32:23.434241: train loss : -0.7352
2022-05-27 21:32:30.090844: validation loss: -0.7344
2022-05-27 21:32:30.106774: Average global foreground Dice: [0.7752]
2022-05-27 21:32:30.116261: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:32:30.575788: lr: 0.008566
2022-05-27 21:32:30.628443: saving checkpoint...
2022-05-27 21:32:31.593894: done, saving took 1.02 seconds
2022-05-27 21:32:31.609563: This epoch took 99.213211 s

2022-05-27 21:32:31.611744: 
epoch:  79
2022-05-27 21:34:06.929081: train loss : -0.7356
2022-05-27 21:34:16.967144: validation loss: -0.7148
2022-05-27 21:34:17.057822: Average global foreground Dice: [0.7575]
2022-05-27 21:34:17.078466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:34:17.663494: lr: 0.008548
2022-05-27 21:34:17.670850: This epoch took 106.057263 s

2022-05-27 21:34:17.673187: 
epoch:  80
2022-05-27 21:35:48.714455: train loss : -0.7152
2022-05-27 21:35:54.600094: validation loss: -0.7360
2022-05-27 21:35:54.604078: Average global foreground Dice: [0.772]
2022-05-27 21:35:54.606229: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:35:55.071971: lr: 0.008529
2022-05-27 21:35:55.074216: This epoch took 97.398478 s

2022-05-27 21:35:55.076454: 
epoch:  81
2022-05-27 21:37:26.573395: train loss : -0.7254
2022-05-27 21:37:33.116533: validation loss: -0.7323
2022-05-27 21:37:33.135464: Average global foreground Dice: [0.7888]
2022-05-27 21:37:33.140055: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:37:33.757115: lr: 0.008511
2022-05-27 21:37:33.759632: This epoch took 98.681211 s

2022-05-27 21:37:33.761726: 
epoch:  82
2022-05-27 21:39:05.250688: train loss : -0.7324
2022-05-27 21:39:12.946965: validation loss: -0.7499
2022-05-27 21:39:12.950309: Average global foreground Dice: [0.7947]
2022-05-27 21:39:12.965812: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:39:13.680173: lr: 0.008493
2022-05-27 21:39:13.785658: saving checkpoint...
2022-05-27 21:39:14.739560: done, saving took 1.01 seconds
2022-05-27 21:39:14.753754: This epoch took 100.989805 s

2022-05-27 21:39:14.755915: 
epoch:  83
2022-05-27 21:40:47.175696: train loss : -0.7205
2022-05-27 21:40:55.439415: validation loss: -0.7518
2022-05-27 21:40:55.446465: Average global foreground Dice: [0.7929]
2022-05-27 21:40:55.448516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:40:55.902911: lr: 0.008474
2022-05-27 21:40:55.953991: saving checkpoint...
2022-05-27 21:40:56.935675: done, saving took 1.03 seconds
2022-05-27 21:40:56.951000: This epoch took 102.193131 s

2022-05-27 21:40:56.953159: 
epoch:  84
2022-05-27 21:42:28.606675: train loss : -0.7350
2022-05-27 21:42:35.597101: validation loss: -0.7286
2022-05-27 21:42:35.600523: Average global foreground Dice: [0.7757]
2022-05-27 21:42:35.603106: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:42:36.210183: lr: 0.008456
2022-05-27 21:42:36.212528: This epoch took 99.257356 s

2022-05-27 21:42:36.214450: 
epoch:  85
2022-05-27 21:44:06.720678: train loss : -0.7368
2022-05-27 21:44:13.018934: validation loss: -0.7251
2022-05-27 21:44:13.022887: Average global foreground Dice: [0.7782]
2022-05-27 21:44:13.027782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:44:13.489535: lr: 0.008438
2022-05-27 21:44:13.491747: This epoch took 97.275326 s

2022-05-27 21:44:13.493619: 
epoch:  86
2022-05-27 21:45:45.319234: train loss : -0.7364
2022-05-27 21:45:54.264479: validation loss: -0.7333
2022-05-27 21:45:54.267820: Average global foreground Dice: [0.7686]
2022-05-27 21:45:54.269911: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:45:54.723412: lr: 0.008419
2022-05-27 21:45:54.725741: This epoch took 101.230210 s

2022-05-27 21:45:54.727778: 
epoch:  87
2022-05-27 21:47:36.490804: train loss : -0.7403
2022-05-27 21:47:43.768568: validation loss: -0.7679
2022-05-27 21:47:43.797880: Average global foreground Dice: [0.8036]
2022-05-27 21:47:43.818263: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:47:44.603019: lr: 0.008401
2022-05-27 21:47:44.691303: saving checkpoint...
2022-05-27 21:47:45.752901: done, saving took 1.12 seconds
2022-05-27 21:47:45.802298: This epoch took 111.072332 s

2022-05-27 21:47:45.820626: 
epoch:  88
2022-05-27 21:49:18.229970: train loss : -0.7388
2022-05-27 21:49:26.943674: validation loss: -0.7360
2022-05-27 21:49:26.952812: Average global foreground Dice: [0.7756]
2022-05-27 21:49:26.955706: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:49:27.424217: lr: 0.008383
2022-05-27 21:49:27.426465: This epoch took 101.579184 s

2022-05-27 21:49:27.428325: 
epoch:  89
2022-05-27 21:51:00.179881: train loss : -0.7340
2022-05-27 21:51:08.524116: validation loss: -0.7373
2022-05-27 21:51:08.555129: Average global foreground Dice: [0.7829]
2022-05-27 21:51:08.574597: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:51:09.413474: lr: 0.008364
2022-05-27 21:51:09.440318: This epoch took 102.009947 s

2022-05-27 21:51:09.459285: 
epoch:  90
2022-05-27 21:52:41.226738: train loss : -0.7234
2022-05-27 21:52:48.467575: validation loss: -0.7581
2022-05-27 21:52:48.502282: Average global foreground Dice: [0.7944]
2022-05-27 21:52:48.505331: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:52:49.001977: lr: 0.008346
2022-05-27 21:52:49.039517: saving checkpoint...
2022-05-27 21:52:50.000989: done, saving took 1.00 seconds
2022-05-27 21:52:50.015570: This epoch took 100.523271 s

2022-05-27 21:52:50.017833: 
epoch:  91
2022-05-27 21:54:22.570365: train loss : -0.7198
2022-05-27 21:54:29.810500: validation loss: -0.7563
2022-05-27 21:54:29.814549: Average global foreground Dice: [0.7887]
2022-05-27 21:54:29.816617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:54:30.409312: lr: 0.008328
2022-05-27 21:54:30.496319: saving checkpoint...
2022-05-27 21:54:31.598447: done, saving took 1.15 seconds
2022-05-27 21:54:31.621647: This epoch took 101.601795 s

2022-05-27 21:54:31.624724: 
epoch:  92
2022-05-27 21:56:02.912396: train loss : -0.7389
2022-05-27 21:56:09.824645: validation loss: -0.7418
2022-05-27 21:56:09.828106: Average global foreground Dice: [0.7796]
2022-05-27 21:56:09.830436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:56:10.322724: lr: 0.008309
2022-05-27 21:56:10.324944: This epoch took 98.683209 s

2022-05-27 21:56:10.326892: 
epoch:  93
2022-05-27 21:57:41.393016: train loss : -0.7561
2022-05-27 21:57:48.217351: validation loss: -0.7343
2022-05-27 21:57:48.248883: Average global foreground Dice: [0.777]
2022-05-27 21:57:48.273326: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:57:48.750009: lr: 0.008291
2022-05-27 21:57:48.752198: This epoch took 98.423494 s

2022-05-27 21:57:48.755120: 
epoch:  94
2022-05-27 21:59:27.567045: train loss : -0.7185
2022-05-27 21:59:35.498999: validation loss: -0.7402
2022-05-27 21:59:35.540745: Average global foreground Dice: [0.7727]
2022-05-27 21:59:35.562420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 21:59:36.511292: lr: 0.008272
2022-05-27 21:59:36.541351: This epoch took 107.783445 s

2022-05-27 21:59:36.561429: 
epoch:  95
2022-05-27 22:01:08.319504: train loss : -0.7270
2022-05-27 22:01:17.806462: validation loss: -0.7466
2022-05-27 22:01:17.815957: Average global foreground Dice: [0.774]
2022-05-27 22:01:17.821642: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:01:18.320911: lr: 0.008254
2022-05-27 22:01:18.340417: This epoch took 101.767434 s

2022-05-27 22:01:18.363276: 
epoch:  96
2022-05-27 22:02:49.867196: train loss : -0.7164
2022-05-27 22:02:58.293226: validation loss: -0.7258
2022-05-27 22:02:58.320658: Average global foreground Dice: [0.7741]
2022-05-27 22:02:58.323174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:02:58.861144: lr: 0.008236
2022-05-27 22:02:58.863493: This epoch took 100.477973 s

2022-05-27 22:02:58.865587: 
epoch:  97
2022-05-27 22:04:30.352875: train loss : -0.7185
2022-05-27 22:04:37.989063: validation loss: -0.7453
2022-05-27 22:04:37.993518: Average global foreground Dice: [0.7832]
2022-05-27 22:04:37.996026: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:04:38.462426: lr: 0.008217
2022-05-27 22:04:38.464958: This epoch took 99.582879 s

2022-05-27 22:04:38.467215: 
epoch:  98
2022-05-27 22:06:10.773351: train loss : -0.7275
2022-05-27 22:06:17.301562: validation loss: -0.7398
2022-05-27 22:06:17.305634: Average global foreground Dice: [0.7697]
2022-05-27 22:06:17.310743: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:06:17.802797: lr: 0.008199
2022-05-27 22:06:17.805380: This epoch took 99.336018 s

2022-05-27 22:06:17.807706: 
epoch:  99
2022-05-27 22:07:50.266100: train loss : -0.7381
2022-05-27 22:07:59.855127: validation loss: -0.7538
2022-05-27 22:07:59.859352: Average global foreground Dice: [0.7995]
2022-05-27 22:07:59.869937: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:08:00.374378: lr: 0.008181
2022-05-27 22:08:00.395301: saving scheduled checkpoint file...
2022-05-27 22:08:00.495956: saving checkpoint...
2022-05-27 22:08:01.581739: done, saving took 1.16 seconds
2022-05-27 22:08:01.598147: done
2022-05-27 22:08:01.600207: This epoch took 103.790371 s

2022-05-27 22:08:01.602442: 
epoch:  100
2022-05-27 22:09:36.401018: train loss : -0.7455
2022-05-27 22:09:44.174122: validation loss: -0.7624
2022-05-27 22:09:44.208325: Average global foreground Dice: [0.7919]
2022-05-27 22:09:44.218659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:09:44.746653: lr: 0.008162
2022-05-27 22:09:44.753547: This epoch took 103.149060 s

2022-05-27 22:09:44.758806: 
epoch:  101
2022-05-27 22:11:16.784807: train loss : -0.7350
2022-05-27 22:11:23.497436: validation loss: -0.7373
2022-05-27 22:11:23.519717: Average global foreground Dice: [0.7945]
2022-05-27 22:11:23.522425: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:11:23.984885: lr: 0.008144
2022-05-27 22:11:24.035190: saving checkpoint...
2022-05-27 22:11:25.017430: done, saving took 1.03 seconds
2022-05-27 22:11:25.032405: This epoch took 100.267093 s

2022-05-27 22:11:25.034824: 
epoch:  102
2022-05-27 22:12:57.912582: train loss : -0.7387
2022-05-27 22:13:05.833615: validation loss: -0.7723
2022-05-27 22:13:05.852840: Average global foreground Dice: [0.8092]
2022-05-27 22:13:05.876285: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:13:06.370076: lr: 0.008125
2022-05-27 22:13:06.489700: saving checkpoint...
2022-05-27 22:13:07.584726: done, saving took 1.18 seconds
2022-05-27 22:13:07.599731: This epoch took 102.562483 s

2022-05-27 22:13:07.601853: 
epoch:  103
2022-05-27 22:14:41.413876: train loss : -0.7433
2022-05-27 22:14:49.684038: validation loss: -0.7514
2022-05-27 22:14:49.710780: Average global foreground Dice: [0.7775]
2022-05-27 22:14:49.728295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:14:50.407850: lr: 0.008107
2022-05-27 22:14:50.410387: This epoch took 102.806408 s

2022-05-27 22:14:50.412391: 
epoch:  104
2022-05-27 22:16:25.771116: train loss : -0.7410
2022-05-27 22:16:35.287706: validation loss: -0.7391
2022-05-27 22:16:35.291272: Average global foreground Dice: [0.794]
2022-05-27 22:16:35.293677: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:16:35.730679: lr: 0.008088
2022-05-27 22:16:35.764923: saving checkpoint...
2022-05-27 22:16:36.723559: done, saving took 0.99 seconds
2022-05-27 22:16:36.737270: This epoch took 106.311648 s

2022-05-27 22:16:36.739431: 
epoch:  105
2022-05-27 22:18:11.763131: train loss : -0.7429
2022-05-27 22:18:21.907634: validation loss: -0.7599
2022-05-27 22:18:21.910997: Average global foreground Dice: [0.7881]
2022-05-27 22:18:21.913547: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:18:22.358731: lr: 0.00807
2022-05-27 22:18:22.390663: saving checkpoint...
2022-05-27 22:18:23.326492: done, saving took 0.97 seconds
2022-05-27 22:18:23.340104: This epoch took 106.598616 s

2022-05-27 22:18:23.342252: 
epoch:  106
2022-05-27 22:19:54.138502: train loss : -0.7404
2022-05-27 22:20:02.438508: validation loss: -0.7288
2022-05-27 22:20:02.442404: Average global foreground Dice: [0.8004]
2022-05-27 22:20:02.444688: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:20:02.912687: lr: 0.008052
2022-05-27 22:20:02.937238: saving checkpoint...
2022-05-27 22:20:03.916769: done, saving took 1.00 seconds
2022-05-27 22:20:03.931005: This epoch took 100.586761 s

2022-05-27 22:20:03.933154: 
epoch:  107
2022-05-27 22:21:34.741273: train loss : -0.7373
2022-05-27 22:21:44.732827: validation loss: -0.7356
2022-05-27 22:21:44.742337: Average global foreground Dice: [0.7878]
2022-05-27 22:21:44.745914: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:21:45.192145: lr: 0.008033
2022-05-27 22:21:45.250569: saving checkpoint...
2022-05-27 22:21:46.269994: done, saving took 1.07 seconds
2022-05-27 22:21:46.284635: This epoch took 102.349499 s

2022-05-27 22:21:46.286853: 
epoch:  108
2022-05-27 22:23:18.525863: train loss : -0.7413
2022-05-27 22:23:29.696952: validation loss: -0.7421
2022-05-27 22:23:29.700348: Average global foreground Dice: [0.7703]
2022-05-27 22:23:29.702920: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:23:30.190052: lr: 0.008015
2022-05-27 22:23:30.192497: This epoch took 103.903521 s

2022-05-27 22:23:30.194860: 
epoch:  109
2022-05-27 22:25:00.341996: train loss : -0.7357
2022-05-27 22:25:07.447955: validation loss: -0.7354
2022-05-27 22:25:07.451353: Average global foreground Dice: [0.7731]
2022-05-27 22:25:07.453657: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:25:07.898094: lr: 0.007996
2022-05-27 22:25:07.900647: This epoch took 97.703700 s

2022-05-27 22:25:07.904267: 
epoch:  110
2022-05-27 22:26:40.591334: train loss : -0.7307
2022-05-27 22:26:48.838236: validation loss: -0.7537
2022-05-27 22:26:48.841576: Average global foreground Dice: [0.7859]
2022-05-27 22:26:48.843755: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:26:49.284167: lr: 0.007978
2022-05-27 22:26:49.286944: This epoch took 101.378928 s

2022-05-27 22:26:49.289511: 
epoch:  111
2022-05-27 22:28:21.027669: train loss : -0.7442
2022-05-27 22:28:27.858861: validation loss: -0.7328
2022-05-27 22:28:27.869861: Average global foreground Dice: [0.7777]
2022-05-27 22:28:27.872261: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:28:28.393159: lr: 0.007959
2022-05-27 22:28:28.398636: This epoch took 99.106834 s

2022-05-27 22:28:28.400660: 
epoch:  112
2022-05-27 22:30:01.347165: train loss : -0.7276
2022-05-27 22:30:10.555622: validation loss: -0.7578
2022-05-27 22:30:10.584715: Average global foreground Dice: [0.7869]
2022-05-27 22:30:10.622606: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:30:11.217804: lr: 0.007941
2022-05-27 22:30:11.254770: This epoch took 102.851879 s

2022-05-27 22:30:11.271317: 
epoch:  113
2022-05-27 22:31:43.853514: train loss : -0.7299
2022-05-27 22:31:53.173890: validation loss: -0.7421
2022-05-27 22:31:53.177573: Average global foreground Dice: [0.7729]
2022-05-27 22:31:53.180115: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:31:53.635728: lr: 0.007922
2022-05-27 22:31:53.658317: This epoch took 102.364864 s

2022-05-27 22:31:53.681286: 
epoch:  114
2022-05-27 22:33:27.077457: train loss : -0.7352
2022-05-27 22:33:36.609674: validation loss: -0.7452
2022-05-27 22:33:36.613228: Average global foreground Dice: [0.7752]
2022-05-27 22:33:36.619971: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:33:37.095774: lr: 0.007904
2022-05-27 22:33:37.117340: This epoch took 103.413042 s

2022-05-27 22:33:37.139301: 
epoch:  115
2022-05-27 22:35:08.478092: train loss : -0.7372
2022-05-27 22:35:15.795270: validation loss: -0.7443
2022-05-27 22:35:15.799076: Average global foreground Dice: [0.7846]
2022-05-27 22:35:15.801513: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:35:16.263669: lr: 0.007885
2022-05-27 22:35:16.266341: This epoch took 99.106051 s

2022-05-27 22:35:16.268596: 
epoch:  116
2022-05-27 22:36:50.042707: train loss : -0.7334
2022-05-27 22:36:59.066376: validation loss: -0.7670
2022-05-27 22:36:59.076493: Average global foreground Dice: [0.7994]
2022-05-27 22:36:59.079427: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:36:59.592314: lr: 0.007867
2022-05-27 22:36:59.620971: This epoch took 103.349587 s

2022-05-27 22:36:59.641286: 
epoch:  117
2022-05-27 22:38:30.293998: train loss : -0.7256
2022-05-27 22:38:37.871839: validation loss: -0.7688
2022-05-27 22:38:37.875626: Average global foreground Dice: [0.7973]
2022-05-27 22:38:37.877992: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:38:38.331505: lr: 0.007848
2022-05-27 22:38:38.333740: This epoch took 98.676131 s

2022-05-27 22:38:38.335601: 
epoch:  118
2022-05-27 22:40:15.051152: train loss : -0.7530
2022-05-27 22:40:23.074980: validation loss: -0.7474
2022-05-27 22:40:23.087685: Average global foreground Dice: [0.7834]
2022-05-27 22:40:23.091020: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:40:23.543286: lr: 0.00783
2022-05-27 22:40:23.545600: This epoch took 105.208014 s

2022-05-27 22:40:23.548188: 
epoch:  119
2022-05-27 22:41:57.541906: train loss : -0.7631
2022-05-27 22:42:06.510837: validation loss: -0.7529
2022-05-27 22:42:06.515489: Average global foreground Dice: [0.7827]
2022-05-27 22:42:06.517697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:42:06.981913: lr: 0.007811
2022-05-27 22:42:07.010508: This epoch took 103.460190 s

2022-05-27 22:42:07.030425: 
epoch:  120
2022-05-27 22:43:39.926302: train loss : -0.7580
2022-05-27 22:43:49.410362: validation loss: -0.7701
2022-05-27 22:43:49.436779: Average global foreground Dice: [0.7929]
2022-05-27 22:43:49.455802: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:43:50.277715: lr: 0.007793
2022-05-27 22:43:50.300930: This epoch took 103.248416 s

2022-05-27 22:43:50.306269: 
epoch:  121
2022-05-27 22:45:23.050629: train loss : -0.7639
2022-05-27 22:45:33.945718: validation loss: -0.7395
2022-05-27 22:45:33.949088: Average global foreground Dice: [0.7774]
2022-05-27 22:45:33.966407: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:45:34.500099: lr: 0.007774
2022-05-27 22:45:34.503700: This epoch took 104.182402 s

2022-05-27 22:45:34.505704: 
epoch:  122
2022-05-27 22:47:06.593393: train loss : -0.7488
2022-05-27 22:47:16.434632: validation loss: -0.7453
2022-05-27 22:47:16.438247: Average global foreground Dice: [0.7855]
2022-05-27 22:47:16.440781: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:47:17.031910: lr: 0.007756
2022-05-27 22:47:17.045335: This epoch took 102.536917 s

2022-05-27 22:47:17.063110: 
epoch:  123
2022-05-27 22:48:47.582069: train loss : -0.7463
2022-05-27 22:48:54.618523: validation loss: -0.7421
2022-05-27 22:48:54.621754: Average global foreground Dice: [0.7871]
2022-05-27 22:48:54.624040: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:48:55.074078: lr: 0.007737
2022-05-27 22:48:55.076572: This epoch took 97.998297 s

2022-05-27 22:48:55.078665: 
epoch:  124
2022-05-27 22:50:33.754249: train loss : -0.7211
2022-05-27 22:50:41.705492: validation loss: -0.7609
2022-05-27 22:50:41.745902: Average global foreground Dice: [0.7995]
2022-05-27 22:50:41.766341: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:50:42.446848: lr: 0.007719
2022-05-27 22:50:42.460114: This epoch took 107.379468 s

2022-05-27 22:50:42.473323: 
epoch:  125
2022-05-27 22:52:13.309834: train loss : -0.7392
2022-05-27 22:52:19.158360: validation loss: -0.7388
2022-05-27 22:52:19.162238: Average global foreground Dice: [0.7796]
2022-05-27 22:52:19.164541: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:52:19.627143: lr: 0.0077
2022-05-27 22:52:19.629301: This epoch took 97.153525 s

2022-05-27 22:52:19.631392: 
epoch:  126
2022-05-27 22:53:55.683232: train loss : -0.7476
2022-05-27 22:54:04.362678: validation loss: -0.7688
2022-05-27 22:54:04.366352: Average global foreground Dice: [0.797]
2022-05-27 22:54:04.368652: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:54:04.840885: lr: 0.007682
2022-05-27 22:54:04.849341: This epoch took 105.216003 s

2022-05-27 22:54:04.851816: 
epoch:  127
2022-05-27 22:55:37.709932: train loss : -0.7456
2022-05-27 22:55:48.642376: validation loss: -0.7567
2022-05-27 22:55:48.665259: Average global foreground Dice: [0.7938]
2022-05-27 22:55:48.673565: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:55:49.196781: lr: 0.007663
2022-05-27 22:55:49.249270: saving checkpoint...
2022-05-27 22:55:50.259346: done, saving took 1.06 seconds
2022-05-27 22:55:50.274965: This epoch took 105.420748 s

2022-05-27 22:55:50.277032: 
epoch:  128
2022-05-27 22:57:22.213140: train loss : -0.7369
2022-05-27 22:57:30.078784: validation loss: -0.7396
2022-05-27 22:57:30.119411: Average global foreground Dice: [0.7758]
2022-05-27 22:57:30.122799: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:57:30.658384: lr: 0.007645
2022-05-27 22:57:30.663036: This epoch took 100.383919 s

2022-05-27 22:57:30.678289: 
epoch:  129
2022-05-27 22:59:03.934779: train loss : -0.7404
2022-05-27 22:59:13.208360: validation loss: -0.7469
2022-05-27 22:59:13.212062: Average global foreground Dice: [0.7939]
2022-05-27 22:59:13.231780: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 22:59:13.742163: lr: 0.007626
2022-05-27 22:59:13.745032: This epoch took 103.060884 s

2022-05-27 22:59:13.747270: 
epoch:  130
2022-05-27 23:00:46.337470: train loss : -0.7555
2022-05-27 23:00:54.074630: validation loss: -0.7642
2022-05-27 23:00:54.109802: Average global foreground Dice: [0.789]
2022-05-27 23:00:54.132364: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:00:54.859781: lr: 0.007608
2022-05-27 23:00:54.889292: This epoch took 101.139938 s

2022-05-27 23:00:54.919283: 
epoch:  131
2022-05-27 23:02:26.192436: train loss : -0.7556
2022-05-27 23:02:35.361962: validation loss: -0.7496
2022-05-27 23:02:35.384708: Average global foreground Dice: [0.8075]
2022-05-27 23:02:35.397140: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:02:36.098761: lr: 0.007589
2022-05-27 23:02:36.157181: saving checkpoint...
2022-05-27 23:02:37.494606: done, saving took 1.37 seconds
2022-05-27 23:02:37.551398: This epoch took 102.609927 s

2022-05-27 23:02:37.584292: 
epoch:  132
2022-05-27 23:04:13.998585: train loss : -0.7604
2022-05-27 23:04:27.004694: validation loss: -0.7579
2022-05-27 23:04:27.008187: Average global foreground Dice: [0.7976]
2022-05-27 23:04:27.010798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:04:27.453588: lr: 0.007571
2022-05-27 23:04:27.501209: saving checkpoint...
2022-05-27 23:04:28.475306: done, saving took 1.02 seconds
2022-05-27 23:04:28.491210: This epoch took 110.894929 s

2022-05-27 23:04:28.493403: 
epoch:  133
2022-05-27 23:06:01.584302: train loss : -0.7466
2022-05-27 23:06:11.415546: validation loss: -0.7567
2022-05-27 23:06:11.438408: Average global foreground Dice: [0.7849]
2022-05-27 23:06:11.444175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:06:11.923774: lr: 0.007552
2022-05-27 23:06:11.929172: This epoch took 103.433660 s

2022-05-27 23:06:11.936610: 
epoch:  134
2022-05-27 23:07:47.419099: train loss : -0.7496
2022-05-27 23:07:55.421312: validation loss: -0.7594
2022-05-27 23:07:55.433030: Average global foreground Dice: [0.7994]
2022-05-27 23:07:55.435505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:07:56.116097: lr: 0.007533
2022-05-27 23:07:56.198446: saving checkpoint...
2022-05-27 23:07:57.616959: done, saving took 1.47 seconds
2022-05-27 23:07:57.681309: This epoch took 105.737832 s

2022-05-27 23:07:57.718193: 
epoch:  135
2022-05-27 23:09:31.126729: train loss : -0.7319
2022-05-27 23:09:38.407194: validation loss: -0.7496
2022-05-27 23:09:38.440719: Average global foreground Dice: [0.7944]
2022-05-27 23:09:38.451854: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:09:39.172830: lr: 0.007515
2022-05-27 23:09:39.230547: saving checkpoint...
2022-05-27 23:09:40.260493: done, saving took 1.08 seconds
2022-05-27 23:09:40.302496: This epoch took 102.554211 s

2022-05-27 23:09:40.305118: 
epoch:  136
2022-05-27 23:11:11.319628: train loss : -0.7586
2022-05-27 23:11:21.032702: validation loss: -0.7717
2022-05-27 23:11:21.036270: Average global foreground Dice: [0.8001]
2022-05-27 23:11:21.038740: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:11:21.499263: lr: 0.007496
2022-05-27 23:11:21.530181: saving checkpoint...
2022-05-27 23:11:22.618103: done, saving took 1.11 seconds
2022-05-27 23:11:22.633540: This epoch took 102.326350 s

2022-05-27 23:11:22.636479: 
epoch:  137
2022-05-27 23:12:53.780685: train loss : -0.7322
2022-05-27 23:13:01.637496: validation loss: -0.7608
2022-05-27 23:13:01.641465: Average global foreground Dice: [0.8009]
2022-05-27 23:13:01.644345: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:13:02.174383: lr: 0.007478
2022-05-27 23:13:02.204502: saving checkpoint...
2022-05-27 23:13:03.200679: done, saving took 1.02 seconds
2022-05-27 23:13:03.213551: This epoch took 100.574784 s

2022-05-27 23:13:03.215678: 
epoch:  138
2022-05-27 23:14:39.033324: train loss : -0.7278
2022-05-27 23:14:46.229204: validation loss: -0.7625
2022-05-27 23:14:46.261972: Average global foreground Dice: [0.7994]
2022-05-27 23:14:46.278284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:14:46.888830: lr: 0.007459
2022-05-27 23:14:46.922403: saving checkpoint...
2022-05-27 23:14:48.172511: done, saving took 1.28 seconds
2022-05-27 23:14:48.186753: This epoch took 104.969030 s

2022-05-27 23:14:48.188882: 
epoch:  139
2022-05-27 23:16:19.730170: train loss : -0.7494
2022-05-27 23:16:28.001896: validation loss: -0.7684
2022-05-27 23:16:28.025890: Average global foreground Dice: [0.7969]
2022-05-27 23:16:28.028212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:16:28.730559: lr: 0.00744
2022-05-27 23:16:28.778074: saving checkpoint...
2022-05-27 23:16:29.806380: done, saving took 1.07 seconds
2022-05-27 23:16:29.821814: This epoch took 101.630831 s

2022-05-27 23:16:29.823964: 
epoch:  140
2022-05-27 23:18:01.897138: train loss : -0.7473
2022-05-27 23:18:10.861122: validation loss: -0.7804
2022-05-27 23:18:10.865303: Average global foreground Dice: [0.8185]
2022-05-27 23:18:10.869292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:18:11.369570: lr: 0.007422
2022-05-27 23:18:11.410631: saving checkpoint...
2022-05-27 23:18:12.519389: done, saving took 1.15 seconds
2022-05-27 23:18:12.533660: This epoch took 102.707607 s

2022-05-27 23:18:12.535838: 
epoch:  141
2022-05-27 23:19:43.536646: train loss : -0.7691
2022-05-27 23:19:49.307732: validation loss: -0.7469
2022-05-27 23:19:49.346013: Average global foreground Dice: [0.7935]
2022-05-27 23:19:49.365317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:19:49.824872: lr: 0.007403
2022-05-27 23:19:49.827125: This epoch took 97.289177 s

2022-05-27 23:19:49.829839: 
epoch:  142
2022-05-27 23:21:23.656142: train loss : -0.7630
2022-05-27 23:21:32.153235: validation loss: -0.7322
2022-05-27 23:21:32.161548: Average global foreground Dice: [0.7836]
2022-05-27 23:21:32.163838: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:21:32.629556: lr: 0.007385
2022-05-27 23:21:32.632150: This epoch took 102.800248 s

2022-05-27 23:21:32.634251: 
epoch:  143
2022-05-27 23:23:06.520015: train loss : -0.7665
2022-05-27 23:23:17.529494: validation loss: -0.7631
2022-05-27 23:23:17.555634: Average global foreground Dice: [0.8007]
2022-05-27 23:23:17.576292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:23:18.092700: lr: 0.007366
2022-05-27 23:23:18.095403: This epoch took 105.459119 s

2022-05-27 23:23:18.097635: 
epoch:  144
2022-05-27 23:24:49.306251: train loss : -0.7439
2022-05-27 23:24:59.776840: validation loss: -0.7569
2022-05-27 23:24:59.780233: Average global foreground Dice: [0.7987]
2022-05-27 23:24:59.782587: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:25:00.260165: lr: 0.007347
2022-05-27 23:25:00.262417: This epoch took 102.162582 s

2022-05-27 23:25:00.264524: 
epoch:  145
2022-05-27 23:26:31.325162: train loss : -0.7584
2022-05-27 23:26:41.484956: validation loss: -0.7265
2022-05-27 23:26:41.502140: Average global foreground Dice: [0.7764]
2022-05-27 23:26:41.515446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:26:42.481676: lr: 0.007329
2022-05-27 23:26:42.504294: This epoch took 102.237637 s

2022-05-27 23:26:42.533646: 
epoch:  146
2022-05-27 23:28:15.218302: train loss : -0.7602
2022-05-27 23:28:26.915277: validation loss: -0.7687
2022-05-27 23:28:26.924315: Average global foreground Dice: [0.8104]
2022-05-27 23:28:26.929162: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:28:27.714736: lr: 0.00731
2022-05-27 23:28:27.717067: This epoch took 105.163247 s

2022-05-27 23:28:27.719228: 
epoch:  147
2022-05-27 23:30:02.767894: train loss : -0.7562
2022-05-27 23:30:09.942792: validation loss: -0.7741
2022-05-27 23:30:09.946772: Average global foreground Dice: [0.8083]
2022-05-27 23:30:09.949317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:30:10.450675: lr: 0.007291
2022-05-27 23:30:10.504231: saving checkpoint...
2022-05-27 23:30:11.645757: done, saving took 1.19 seconds
2022-05-27 23:30:11.663313: This epoch took 103.938245 s

2022-05-27 23:30:11.665613: 
epoch:  148
2022-05-27 23:31:45.822231: train loss : -0.7459
2022-05-27 23:31:52.834100: validation loss: -0.7592
2022-05-27 23:31:52.838603: Average global foreground Dice: [0.8001]
2022-05-27 23:31:52.841121: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:31:53.327389: lr: 0.007273
2022-05-27 23:31:53.388052: saving checkpoint...
2022-05-27 23:31:54.449024: done, saving took 1.12 seconds
2022-05-27 23:31:54.463722: This epoch took 102.795974 s

2022-05-27 23:31:54.465906: 
epoch:  149
2022-05-27 23:33:34.145792: train loss : -0.7679
2022-05-27 23:33:42.931760: validation loss: -0.7500
2022-05-27 23:33:42.935294: Average global foreground Dice: [0.7913]
2022-05-27 23:33:42.937738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:33:43.384869: lr: 0.007254
2022-05-27 23:33:43.391731: saving scheduled checkpoint file...
2022-05-27 23:33:43.434988: saving checkpoint...
2022-05-27 23:33:44.445632: done, saving took 1.05 seconds
2022-05-27 23:33:44.461021: done
2022-05-27 23:33:44.463299: This epoch took 109.995106 s

2022-05-27 23:33:44.465292: 
epoch:  150
2022-05-27 23:35:18.191753: train loss : -0.7660
2022-05-27 23:35:28.168488: validation loss: -0.7507
2022-05-27 23:35:28.203772: Average global foreground Dice: [0.7784]
2022-05-27 23:35:28.229303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:35:28.715220: lr: 0.007236
2022-05-27 23:35:28.718043: This epoch took 104.250692 s

2022-05-27 23:35:28.720644: 
epoch:  151
2022-05-27 23:37:00.014029: train loss : -0.7526
2022-05-27 23:37:09.583956: validation loss: -0.7551
2022-05-27 23:37:09.587582: Average global foreground Dice: [0.7814]
2022-05-27 23:37:09.589764: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:37:10.043546: lr: 0.007217
2022-05-27 23:37:10.046283: This epoch took 101.323389 s

2022-05-27 23:37:10.048789: 
epoch:  152
2022-05-27 23:38:43.263956: train loss : -0.7689
2022-05-27 23:38:50.258822: validation loss: -0.7647
2022-05-27 23:38:50.263011: Average global foreground Dice: [0.803]
2022-05-27 23:38:50.265320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:38:50.733385: lr: 0.007198
2022-05-27 23:38:50.736104: This epoch took 100.680024 s

2022-05-27 23:38:50.738179: 
epoch:  153
2022-05-27 23:40:25.876954: train loss : -0.7717
2022-05-27 23:40:35.472602: validation loss: -0.7313
2022-05-27 23:40:35.477424: Average global foreground Dice: [0.7873]
2022-05-27 23:40:35.480870: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:40:36.021811: lr: 0.00718
2022-05-27 23:40:36.044349: This epoch took 105.303787 s

2022-05-27 23:40:36.046755: 
epoch:  154
2022-05-27 23:42:16.188853: train loss : -0.7781
2022-05-27 23:42:22.954843: validation loss: -0.7572
2022-05-27 23:42:22.958759: Average global foreground Dice: [0.8006]
2022-05-27 23:42:22.960954: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:42:23.465749: lr: 0.007161
2022-05-27 23:42:23.467875: This epoch took 107.418983 s

2022-05-27 23:42:23.470036: 
epoch:  155
2022-05-27 23:43:55.499670: train loss : -0.7604
2022-05-27 23:44:05.229671: validation loss: -0.7719
2022-05-27 23:44:05.261775: Average global foreground Dice: [0.8133]
2022-05-27 23:44:05.291314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:44:05.794696: lr: 0.007142
2022-05-27 23:44:05.797492: This epoch took 102.326025 s

2022-05-27 23:44:05.799762: 
epoch:  156
2022-05-27 23:45:41.679362: train loss : -0.7760
2022-05-27 23:45:50.093876: validation loss: -0.7416
2022-05-27 23:45:50.125635: Average global foreground Dice: [0.7868]
2022-05-27 23:45:50.148309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:45:50.650913: lr: 0.007123
2022-05-27 23:45:50.657189: This epoch took 104.855250 s

2022-05-27 23:45:50.660037: 
epoch:  157
2022-05-27 23:47:29.303758: train loss : -0.7648
2022-05-27 23:47:39.036529: validation loss: -0.7485
2022-05-27 23:47:39.039802: Average global foreground Dice: [0.7961]
2022-05-27 23:47:39.042861: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:47:39.531723: lr: 0.007105
2022-05-27 23:47:39.534592: This epoch took 108.872267 s

2022-05-27 23:47:39.536863: 
epoch:  158
2022-05-27 23:49:10.601289: train loss : -0.7738
2022-05-27 23:49:20.397898: validation loss: -0.7765
2022-05-27 23:49:20.424143: Average global foreground Dice: [0.8008]
2022-05-27 23:49:20.443405: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:49:21.238028: lr: 0.007086
2022-05-27 23:49:21.260619: This epoch took 101.721660 s

2022-05-27 23:49:21.265209: 
epoch:  159
2022-05-27 23:50:53.230961: train loss : -0.7639
2022-05-27 23:50:59.955258: validation loss: -0.7730
2022-05-27 23:50:59.961170: Average global foreground Dice: [0.811]
2022-05-27 23:50:59.963454: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:51:00.421802: lr: 0.007067
2022-05-27 23:51:00.474863: saving checkpoint...
2022-05-27 23:51:01.592072: done, saving took 1.17 seconds
2022-05-27 23:51:01.608306: This epoch took 100.335405 s

2022-05-27 23:51:01.610580: 
epoch:  160
2022-05-27 23:52:32.988289: train loss : -0.7572
2022-05-27 23:52:40.103301: validation loss: -0.7495
2022-05-27 23:52:40.106818: Average global foreground Dice: [0.7978]
2022-05-27 23:52:40.109206: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:52:40.560512: lr: 0.007049
2022-05-27 23:52:40.599902: saving checkpoint...
2022-05-27 23:52:41.737718: done, saving took 1.17 seconds
2022-05-27 23:52:41.750986: This epoch took 100.138004 s

2022-05-27 23:52:41.753145: 
epoch:  161
2022-05-27 23:54:13.790696: train loss : -0.7474
2022-05-27 23:54:20.489542: validation loss: -0.7225
2022-05-27 23:54:20.495046: Average global foreground Dice: [0.7721]
2022-05-27 23:54:20.500444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:54:20.963076: lr: 0.00703
2022-05-27 23:54:20.965638: This epoch took 99.210310 s

2022-05-27 23:54:20.967607: 
epoch:  162
2022-05-27 23:55:55.515983: train loss : -0.7636
2022-05-27 23:56:04.337412: validation loss: -0.7598
2022-05-27 23:56:04.340883: Average global foreground Dice: [0.7914]
2022-05-27 23:56:04.343268: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:56:04.836231: lr: 0.007011
2022-05-27 23:56:04.838482: This epoch took 103.868756 s

2022-05-27 23:56:04.840705: 
epoch:  163
2022-05-27 23:57:36.918212: train loss : -0.7687
2022-05-27 23:57:48.720648: validation loss: -0.7408
2022-05-27 23:57:48.724521: Average global foreground Dice: [0.7895]
2022-05-27 23:57:48.727490: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:57:49.269547: lr: 0.006992
2022-05-27 23:57:49.301320: This epoch took 104.458524 s

2022-05-27 23:57:49.317274: 
epoch:  164
2022-05-27 23:59:25.215012: train loss : -0.7788
2022-05-27 23:59:35.900421: validation loss: -0.7488
2022-05-27 23:59:35.904903: Average global foreground Dice: [0.8014]
2022-05-27 23:59:35.907447: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-27 23:59:36.383573: lr: 0.006974
2022-05-27 23:59:36.386049: This epoch took 107.045323 s

2022-05-27 23:59:36.388149: 
epoch:  165
2022-05-28 00:01:09.453877: train loss : -0.7543
2022-05-28 00:01:20.948023: validation loss: -0.7553
2022-05-28 00:01:20.963952: Average global foreground Dice: [0.806]
2022-05-28 00:01:20.984368: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:01:21.562083: lr: 0.006955
2022-05-28 00:01:21.564423: This epoch took 105.174204 s

2022-05-28 00:01:21.566529: 
epoch:  166
2022-05-28 00:02:56.519020: train loss : -0.7615
2022-05-28 00:03:07.123273: validation loss: -0.7790
2022-05-28 00:03:07.132624: Average global foreground Dice: [0.805]
2022-05-28 00:03:07.156837: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:03:07.676461: lr: 0.006936
2022-05-28 00:03:07.693338: This epoch took 106.124394 s

2022-05-28 00:03:07.697405: 
epoch:  167
2022-05-28 00:04:38.409793: train loss : -0.7610
2022-05-28 00:04:46.673167: validation loss: -0.7449
2022-05-28 00:04:46.677883: Average global foreground Dice: [0.7747]
2022-05-28 00:04:46.680334: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:04:47.174958: lr: 0.006918
2022-05-28 00:04:47.178110: This epoch took 99.477771 s

2022-05-28 00:04:47.180548: 
epoch:  168
2022-05-28 00:06:17.685837: train loss : -0.7778
2022-05-28 00:06:23.961317: validation loss: -0.7757
2022-05-28 00:06:23.964887: Average global foreground Dice: [0.8126]
2022-05-28 00:06:23.967209: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:06:24.463624: lr: 0.006899
2022-05-28 00:06:24.465953: This epoch took 97.283329 s

2022-05-28 00:06:24.467923: 
epoch:  169
2022-05-28 00:07:55.913807: train loss : -0.7584
2022-05-28 00:08:06.325558: validation loss: -0.7529
2022-05-28 00:08:06.353788: Average global foreground Dice: [0.8019]
2022-05-28 00:08:06.375306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:08:06.886389: lr: 0.00688
2022-05-28 00:08:06.896135: This epoch took 102.426150 s

2022-05-28 00:08:06.916484: 
epoch:  170
2022-05-28 00:09:38.470718: train loss : -0.7679
2022-05-28 00:09:46.525064: validation loss: -0.7615
2022-05-28 00:09:46.528488: Average global foreground Dice: [0.8037]
2022-05-28 00:09:46.530835: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:09:46.978378: lr: 0.006861
2022-05-28 00:09:47.039616: saving checkpoint...
2022-05-28 00:09:48.081683: done, saving took 1.10 seconds
2022-05-28 00:09:48.098889: This epoch took 101.171522 s

2022-05-28 00:09:48.101235: 
epoch:  171
2022-05-28 00:11:23.727649: train loss : -0.7691
2022-05-28 00:11:33.387722: validation loss: -0.7468
2022-05-28 00:11:33.394858: Average global foreground Dice: [0.7673]
2022-05-28 00:11:33.397314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:11:33.966201: lr: 0.006842
2022-05-28 00:11:33.988334: This epoch took 105.884807 s

2022-05-28 00:11:34.010289: 
epoch:  172
2022-05-28 00:13:06.908484: train loss : -0.7253
2022-05-28 00:13:16.956575: validation loss: -0.7697
2022-05-28 00:13:16.960506: Average global foreground Dice: [0.799]
2022-05-28 00:13:16.963162: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:13:17.672668: lr: 0.006824
2022-05-28 00:13:17.676006: This epoch took 103.642717 s

2022-05-28 00:13:17.678708: 
epoch:  173
2022-05-28 00:14:53.555992: train loss : -0.7437
2022-05-28 00:15:01.517180: validation loss: -0.7654
2022-05-28 00:15:01.536752: Average global foreground Dice: [0.8052]
2022-05-28 00:15:01.552377: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:15:02.295117: lr: 0.006805
2022-05-28 00:15:02.306086: This epoch took 104.624757 s

2022-05-28 00:15:02.308450: 
epoch:  174
2022-05-28 00:16:38.665141: train loss : -0.7483
2022-05-28 00:16:47.731381: validation loss: -0.7696
2022-05-28 00:16:47.763783: Average global foreground Dice: [0.8067]
2022-05-28 00:16:47.782635: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:16:48.289912: lr: 0.006786
2022-05-28 00:16:48.298434: This epoch took 105.987654 s

2022-05-28 00:16:48.302019: 
epoch:  175
2022-05-28 00:18:23.614534: train loss : -0.7574
2022-05-28 00:18:33.342261: validation loss: -0.7468
2022-05-28 00:18:33.354805: Average global foreground Dice: [0.791]
2022-05-28 00:18:33.376314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:18:33.966215: lr: 0.006767
2022-05-28 00:18:33.969106: This epoch took 105.664837 s

2022-05-28 00:18:33.971579: 
epoch:  176
2022-05-28 00:20:05.186195: train loss : -0.7628
2022-05-28 00:20:14.016373: validation loss: -0.7676
2022-05-28 00:20:14.027058: Average global foreground Dice: [0.801]
2022-05-28 00:20:14.041339: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:20:14.693401: lr: 0.006749
2022-05-28 00:20:14.718411: This epoch took 100.744560 s

2022-05-28 00:20:14.744120: 
epoch:  177
2022-05-28 00:21:45.608230: train loss : -0.7561
2022-05-28 00:21:54.573662: validation loss: -0.7507
2022-05-28 00:21:54.578041: Average global foreground Dice: [0.8037]
2022-05-28 00:21:54.581210: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:21:55.079637: lr: 0.00673
2022-05-28 00:21:55.135432: saving checkpoint...
2022-05-28 00:21:56.162543: done, saving took 1.08 seconds
2022-05-28 00:21:56.178538: This epoch took 101.427085 s

2022-05-28 00:21:56.180707: 
epoch:  178
2022-05-28 00:23:29.160254: train loss : -0.7561
2022-05-28 00:23:38.615220: validation loss: -0.7516
2022-05-28 00:23:38.639577: Average global foreground Dice: [0.7869]
2022-05-28 00:23:38.642573: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:23:39.297536: lr: 0.006711
2022-05-28 00:23:39.309217: This epoch took 103.126449 s

2022-05-28 00:23:39.313737: 
epoch:  179
2022-05-28 00:25:15.533231: train loss : -0.7739
2022-05-28 00:25:21.588107: validation loss: -0.7704
2022-05-28 00:25:21.632186: Average global foreground Dice: [0.801]
2022-05-28 00:25:21.652261: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:25:22.291113: lr: 0.006692
2022-05-28 00:25:22.312307: This epoch took 102.992388 s

2022-05-28 00:25:22.334358: 
epoch:  180
2022-05-28 00:27:01.343425: train loss : -0.7616
2022-05-28 00:27:09.543515: validation loss: -0.7614
2022-05-28 00:27:09.558055: Average global foreground Dice: [0.8]
2022-05-28 00:27:09.562497: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:27:10.360987: lr: 0.006673
2022-05-28 00:27:10.363609: This epoch took 108.006330 s

2022-05-28 00:27:10.365758: 
epoch:  181
2022-05-28 00:28:42.256178: train loss : -0.7710
2022-05-28 00:28:50.312178: validation loss: -0.7670
2022-05-28 00:28:50.366727: Average global foreground Dice: [0.8143]
2022-05-28 00:28:50.384363: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:28:51.422897: lr: 0.006654
2022-05-28 00:28:51.513842: saving checkpoint...
2022-05-28 00:28:52.831486: done, saving took 1.39 seconds
2022-05-28 00:28:52.890047: This epoch took 102.522134 s

2022-05-28 00:28:52.906385: 
epoch:  182
2022-05-28 00:30:25.272109: train loss : -0.7553
2022-05-28 00:30:35.128960: validation loss: -0.7793
2022-05-28 00:30:35.132064: Average global foreground Dice: [0.8018]
2022-05-28 00:30:35.134108: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:30:35.615360: lr: 0.006636
2022-05-28 00:30:35.665872: saving checkpoint...
2022-05-28 00:30:36.762853: done, saving took 1.15 seconds
2022-05-28 00:30:36.780087: This epoch took 103.866692 s

2022-05-28 00:30:36.782582: 
epoch:  183
2022-05-28 00:32:07.160707: train loss : -0.7629
2022-05-28 00:32:14.297321: validation loss: -0.7596
2022-05-28 00:32:14.300646: Average global foreground Dice: [0.7969]
2022-05-28 00:32:14.302918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:32:14.784240: lr: 0.006617
2022-05-28 00:32:14.786659: This epoch took 98.001623 s

2022-05-28 00:32:14.788702: 
epoch:  184
2022-05-28 00:33:50.386943: train loss : -0.7585
2022-05-28 00:34:00.702657: validation loss: -0.7472
2022-05-28 00:34:00.737689: Average global foreground Dice: [0.7911]
2022-05-28 00:34:00.759341: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:34:01.710505: lr: 0.006598
2022-05-28 00:34:01.723277: This epoch took 106.932502 s

2022-05-28 00:34:01.725318: 
epoch:  185
2022-05-28 00:35:35.112864: train loss : -0.7674
2022-05-28 00:35:42.673216: validation loss: -0.7556
2022-05-28 00:35:42.707772: Average global foreground Dice: [0.7878]
2022-05-28 00:35:42.723291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:35:43.376271: lr: 0.006579
2022-05-28 00:35:43.385049: This epoch took 101.657658 s

2022-05-28 00:35:43.387681: 
epoch:  186
2022-05-28 00:37:18.283525: train loss : -0.7791
2022-05-28 00:37:26.771040: validation loss: -0.7759
2022-05-28 00:37:26.789719: Average global foreground Dice: [0.7981]
2022-05-28 00:37:26.793060: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:37:27.269194: lr: 0.00656
2022-05-28 00:37:27.273552: This epoch took 103.883249 s

2022-05-28 00:37:27.276194: 
epoch:  187
2022-05-28 00:38:59.089697: train loss : -0.7765
2022-05-28 00:39:08.712820: validation loss: -0.7502
2022-05-28 00:39:08.731457: Average global foreground Dice: [0.8035]
2022-05-28 00:39:08.736838: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:39:09.238647: lr: 0.006541
2022-05-28 00:39:09.241333: This epoch took 101.962251 s

2022-05-28 00:39:09.243791: 
epoch:  188
2022-05-28 00:40:45.630820: train loss : -0.7635
2022-05-28 00:40:54.380808: validation loss: -0.7729
2022-05-28 00:40:54.385667: Average global foreground Dice: [0.7986]
2022-05-28 00:40:54.390007: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:40:54.858890: lr: 0.006522
2022-05-28 00:40:54.861715: This epoch took 105.615105 s

2022-05-28 00:40:54.863969: 
epoch:  189
2022-05-28 00:42:29.951353: train loss : -0.7639
2022-05-28 00:42:36.208979: validation loss: -0.7401
2022-05-28 00:42:36.219010: Average global foreground Dice: [0.8033]
2022-05-28 00:42:36.221786: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:42:36.713038: lr: 0.006504
2022-05-28 00:42:36.735325: This epoch took 101.868937 s

2022-05-28 00:42:36.762574: 
epoch:  190
2022-05-28 00:44:10.995059: train loss : -0.7612
2022-05-28 00:44:18.076319: validation loss: -0.7484
2022-05-28 00:44:18.088334: Average global foreground Dice: [0.8068]
2022-05-28 00:44:18.108289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:44:18.604669: lr: 0.006485
2022-05-28 00:44:18.661346: saving checkpoint...
2022-05-28 00:44:19.905538: done, saving took 1.30 seconds
2022-05-28 00:44:19.921593: This epoch took 103.141289 s

2022-05-28 00:44:19.923886: 
epoch:  191
2022-05-28 00:45:54.753869: train loss : -0.7741
2022-05-28 00:46:04.544041: validation loss: -0.7480
2022-05-28 00:46:04.573017: Average global foreground Dice: [0.7841]
2022-05-28 00:46:04.592616: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:46:05.466933: lr: 0.006466
2022-05-28 00:46:05.469252: This epoch took 105.542993 s

2022-05-28 00:46:05.471253: 
epoch:  192
2022-05-28 00:47:36.746919: train loss : -0.7776
2022-05-28 00:47:43.317650: validation loss: -0.7665
2022-05-28 00:47:43.321462: Average global foreground Dice: [0.805]
2022-05-28 00:47:43.323758: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:47:43.805024: lr: 0.006447
2022-05-28 00:47:43.807585: This epoch took 98.334296 s

2022-05-28 00:47:43.809675: 
epoch:  193
2022-05-28 00:49:16.796722: train loss : -0.7766
2022-05-28 00:49:26.097472: validation loss: -0.7592
2022-05-28 00:49:26.100989: Average global foreground Dice: [0.8036]
2022-05-28 00:49:26.103399: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:49:26.621837: lr: 0.006428
2022-05-28 00:49:26.624189: This epoch took 102.811763 s

2022-05-28 00:49:26.626403: 
epoch:  194
2022-05-28 00:50:57.715349: train loss : -0.7908
2022-05-28 00:51:06.729583: validation loss: -0.7730
2022-05-28 00:51:06.733576: Average global foreground Dice: [0.8155]
2022-05-28 00:51:06.737038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:51:07.228309: lr: 0.006409
2022-05-28 00:51:07.283457: saving checkpoint...
2022-05-28 00:51:08.323321: done, saving took 1.09 seconds
2022-05-28 00:51:08.337899: This epoch took 101.709301 s

2022-05-28 00:51:08.340169: 
epoch:  195
2022-05-28 00:52:42.585214: train loss : -0.7880
2022-05-28 00:52:53.366664: validation loss: -0.7783
2022-05-28 00:52:53.394845: Average global foreground Dice: [0.8039]
2022-05-28 00:52:53.411295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:52:54.076316: lr: 0.00639
2022-05-28 00:52:54.132659: saving checkpoint...
2022-05-28 00:52:55.186235: done, saving took 1.10 seconds
2022-05-28 00:52:55.202407: This epoch took 106.860065 s

2022-05-28 00:52:55.204740: 
epoch:  196
2022-05-28 00:54:27.533919: train loss : -0.7892
2022-05-28 00:54:34.930360: validation loss: -0.7650
2022-05-28 00:54:34.934548: Average global foreground Dice: [0.8047]
2022-05-28 00:54:34.936940: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:54:35.390997: lr: 0.006371
2022-05-28 00:54:35.440135: saving checkpoint...
2022-05-28 00:54:36.596231: done, saving took 1.20 seconds
2022-05-28 00:54:36.611130: This epoch took 101.404293 s

2022-05-28 00:54:36.613594: 
epoch:  197
2022-05-28 00:56:09.509050: train loss : -0.7950
2022-05-28 00:56:20.622487: validation loss: -0.7773
2022-05-28 00:56:20.632435: Average global foreground Dice: [0.7992]
2022-05-28 00:56:20.648127: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:56:21.095940: lr: 0.006352
2022-05-28 00:56:21.098537: This epoch took 104.482644 s

2022-05-28 00:56:21.100675: 
epoch:  198
2022-05-28 00:57:51.102693: train loss : -0.7801
2022-05-28 00:57:59.066009: validation loss: -0.7806
2022-05-28 00:57:59.069372: Average global foreground Dice: [0.8038]
2022-05-28 00:57:59.071771: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:57:59.563977: lr: 0.006333
2022-05-28 00:57:59.597461: saving checkpoint...
2022-05-28 00:58:00.719215: done, saving took 1.15 seconds
2022-05-28 00:58:00.734592: This epoch took 99.631678 s

2022-05-28 00:58:00.737116: 
epoch:  199
2022-05-28 00:59:36.036084: train loss : -0.7786
2022-05-28 00:59:44.562982: validation loss: -0.7740
2022-05-28 00:59:44.566146: Average global foreground Dice: [0.8001]
2022-05-28 00:59:44.568524: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 00:59:45.019535: lr: 0.006314
2022-05-28 00:59:45.022019: saving scheduled checkpoint file...
2022-05-28 00:59:45.049117: saving checkpoint...
2022-05-28 00:59:46.311861: done, saving took 1.29 seconds
2022-05-28 00:59:46.327198: done
2022-05-28 00:59:46.329683: This epoch took 105.590242 s

2022-05-28 00:59:46.331760: 
epoch:  200
2022-05-28 01:01:17.076482: train loss : -0.7724
2022-05-28 01:01:25.160542: validation loss: -0.7710
2022-05-28 01:01:25.180800: Average global foreground Dice: [0.7968]
2022-05-28 01:01:25.204301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:01:25.900838: lr: 0.006296
2022-05-28 01:01:25.928844: This epoch took 99.594859 s

2022-05-28 01:01:25.949335: 
epoch:  201
2022-05-28 01:03:00.136212: train loss : -0.7937
2022-05-28 01:03:09.726064: validation loss: -0.7698
2022-05-28 01:03:09.732077: Average global foreground Dice: [0.8034]
2022-05-28 01:03:09.734325: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:03:10.241037: lr: 0.006277
2022-05-28 01:03:10.244090: This epoch took 104.277806 s

2022-05-28 01:03:10.246613: 
epoch:  202
2022-05-28 01:04:40.885635: train loss : -0.7919
2022-05-28 01:04:48.939697: validation loss: -0.7490
2022-05-28 01:04:48.944892: Average global foreground Dice: [0.7902]
2022-05-28 01:04:48.946945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:04:49.398631: lr: 0.006258
2022-05-28 01:04:49.401283: This epoch took 99.152177 s

2022-05-28 01:04:49.403972: 
epoch:  203
2022-05-28 01:06:24.906370: train loss : -0.7868
2022-05-28 01:06:33.046504: validation loss: -0.7565
2022-05-28 01:06:33.050793: Average global foreground Dice: [0.7944]
2022-05-28 01:06:33.053885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:06:33.520037: lr: 0.006239
2022-05-28 01:06:33.522547: This epoch took 104.116176 s

2022-05-28 01:06:33.524908: 
epoch:  204
2022-05-28 01:08:08.350291: train loss : -0.7733
2022-05-28 01:08:18.237081: validation loss: -0.7640
2022-05-28 01:08:18.254327: Average global foreground Dice: [0.7926]
2022-05-28 01:08:18.272436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:08:18.812272: lr: 0.00622
2022-05-28 01:08:18.814935: This epoch took 105.287884 s

2022-05-28 01:08:18.817271: 
epoch:  205
2022-05-28 01:09:51.954860: train loss : -0.7726
2022-05-28 01:09:59.897336: validation loss: -0.7659
2022-05-28 01:09:59.902022: Average global foreground Dice: [0.8045]
2022-05-28 01:09:59.904789: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:10:00.404174: lr: 0.006201
2022-05-28 01:10:00.407233: This epoch took 101.587579 s

2022-05-28 01:10:00.409841: 
epoch:  206
2022-05-28 01:11:33.041616: train loss : -0.7794
2022-05-28 01:11:43.973495: validation loss: -0.7655
2022-05-28 01:11:44.004760: Average global foreground Dice: [0.7983]
2022-05-28 01:11:44.024307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:11:45.136422: lr: 0.006182
2022-05-28 01:11:45.170329: This epoch took 104.758152 s

2022-05-28 01:11:45.189277: 
epoch:  207
2022-05-28 01:13:16.149233: train loss : -0.7760
2022-05-28 01:13:24.199914: validation loss: -0.7801
2022-05-28 01:13:24.204562: Average global foreground Dice: [0.8085]
2022-05-28 01:13:24.210518: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:13:24.687335: lr: 0.006163
2022-05-28 01:13:24.689929: This epoch took 99.476864 s

2022-05-28 01:13:24.692040: 
epoch:  208
2022-05-28 01:14:56.002210: train loss : -0.7841
2022-05-28 01:15:06.728299: validation loss: -0.7529
2022-05-28 01:15:06.731732: Average global foreground Dice: [0.8011]
2022-05-28 01:15:06.734131: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:15:07.214337: lr: 0.006144
2022-05-28 01:15:07.239455: This epoch took 102.545387 s

2022-05-28 01:15:07.262343: 
epoch:  209
2022-05-28 01:16:43.656956: train loss : -0.7837
2022-05-28 01:16:51.915134: validation loss: -0.7606
2022-05-28 01:16:51.918820: Average global foreground Dice: [0.7951]
2022-05-28 01:16:51.935833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:16:52.405258: lr: 0.006125
2022-05-28 01:16:52.407990: This epoch took 105.125688 s

2022-05-28 01:16:52.410845: 
epoch:  210
2022-05-28 01:18:26.202793: train loss : -0.7795
2022-05-28 01:18:35.495629: validation loss: -0.7548
2022-05-28 01:18:35.499928: Average global foreground Dice: [0.7899]
2022-05-28 01:18:35.503349: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:18:36.192925: lr: 0.006106
2022-05-28 01:18:36.196001: This epoch took 103.769616 s

2022-05-28 01:18:36.198184: 
epoch:  211
2022-05-28 01:20:07.786738: train loss : -0.7697
2022-05-28 01:20:14.519543: validation loss: -0.7335
2022-05-28 01:20:14.529965: Average global foreground Dice: [0.7708]
2022-05-28 01:20:14.534421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:20:15.015720: lr: 0.006087
2022-05-28 01:20:15.018693: This epoch took 98.818408 s

2022-05-28 01:20:15.020788: 
epoch:  212
2022-05-28 01:21:46.999002: train loss : -0.7719
2022-05-28 01:21:56.465157: validation loss: -0.7630
2022-05-28 01:21:56.470354: Average global foreground Dice: [0.8127]
2022-05-28 01:21:56.478099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:21:57.060930: lr: 0.006068
2022-05-28 01:21:57.063583: This epoch took 102.040270 s

2022-05-28 01:21:57.066255: 
epoch:  213
2022-05-28 01:23:28.031495: train loss : -0.7871
2022-05-28 01:23:35.937802: validation loss: -0.7827
2022-05-28 01:23:35.957987: Average global foreground Dice: [0.8204]
2022-05-28 01:23:35.976346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:23:36.697378: lr: 0.006049
2022-05-28 01:23:36.718447: This epoch took 99.648690 s

2022-05-28 01:23:36.740768: 
epoch:  214
2022-05-28 01:25:07.636972: train loss : -0.7818
2022-05-28 01:25:17.172704: validation loss: -0.7738
2022-05-28 01:25:17.206265: Average global foreground Dice: [0.8153]
2022-05-28 01:25:17.228328: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:25:17.720848: lr: 0.00603
2022-05-28 01:25:17.765259: saving checkpoint...
2022-05-28 01:25:18.877662: done, saving took 1.15 seconds
2022-05-28 01:25:18.912361: This epoch took 102.161065 s

2022-05-28 01:25:18.919294: 
epoch:  215
2022-05-28 01:26:50.712734: train loss : -0.7767
2022-05-28 01:27:01.149742: validation loss: -0.7620
2022-05-28 01:27:01.153116: Average global foreground Dice: [0.8058]
2022-05-28 01:27:01.155300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:27:01.621188: lr: 0.006011
2022-05-28 01:27:01.671500: saving checkpoint...
2022-05-28 01:27:02.828076: done, saving took 1.20 seconds
2022-05-28 01:27:02.841220: This epoch took 103.893916 s

2022-05-28 01:27:02.843170: 
epoch:  216
2022-05-28 01:28:34.899937: train loss : -0.7784
2022-05-28 01:28:45.455133: validation loss: -0.7719
2022-05-28 01:28:45.479520: Average global foreground Dice: [0.8039]
2022-05-28 01:28:45.494651: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:28:46.072011: lr: 0.005991
2022-05-28 01:28:46.121127: saving checkpoint...
2022-05-28 01:28:47.195567: done, saving took 1.12 seconds
2022-05-28 01:28:47.211915: This epoch took 104.366759 s

2022-05-28 01:28:47.214313: 
epoch:  217
2022-05-28 01:30:16.873385: train loss : -0.7790
2022-05-28 01:30:23.785460: validation loss: -0.7606
2022-05-28 01:30:23.789215: Average global foreground Dice: [0.7953]
2022-05-28 01:30:23.791634: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:30:24.264114: lr: 0.005972
2022-05-28 01:30:24.266628: This epoch took 97.050236 s

2022-05-28 01:30:24.268678: 
epoch:  218
2022-05-28 01:31:56.338986: train loss : -0.7867
2022-05-28 01:32:06.690058: validation loss: -0.7813
2022-05-28 01:32:06.694106: Average global foreground Dice: [0.8108]
2022-05-28 01:32:06.696314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:32:07.271249: lr: 0.005953
2022-05-28 01:32:07.305429: saving checkpoint...
2022-05-28 01:32:08.305978: done, saving took 1.03 seconds
2022-05-28 01:32:08.319561: This epoch took 104.048922 s

2022-05-28 01:32:08.322003: 
epoch:  219
2022-05-28 01:33:39.936880: train loss : -0.7841
2022-05-28 01:33:47.634647: validation loss: -0.7641
2022-05-28 01:33:47.638384: Average global foreground Dice: [0.7952]
2022-05-28 01:33:47.640557: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:33:48.090863: lr: 0.005934
2022-05-28 01:33:48.093611: This epoch took 99.769328 s

2022-05-28 01:33:48.096107: 
epoch:  220
2022-05-28 01:35:19.556020: train loss : -0.7826
2022-05-28 01:35:27.552486: validation loss: -0.7834
2022-05-28 01:35:27.576188: Average global foreground Dice: [0.8129]
2022-05-28 01:35:27.611239: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:35:28.287640: lr: 0.005915
2022-05-28 01:35:28.361557: saving checkpoint...
2022-05-28 01:35:29.487945: done, saving took 1.19 seconds
2022-05-28 01:35:29.505052: This epoch took 101.406644 s

2022-05-28 01:35:29.507949: 
epoch:  221
2022-05-28 01:37:01.113149: train loss : -0.7883
2022-05-28 01:37:10.107108: validation loss: -0.7702
2022-05-28 01:37:10.124453: Average global foreground Dice: [0.7961]
2022-05-28 01:37:10.136952: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:37:10.642896: lr: 0.005896
2022-05-28 01:37:10.645536: This epoch took 101.134798 s

2022-05-28 01:37:10.648214: 
epoch:  222
2022-05-28 01:38:41.779094: train loss : -0.7806
2022-05-28 01:38:49.364302: validation loss: -0.7758
2022-05-28 01:38:49.408285: Average global foreground Dice: [0.8117]
2022-05-28 01:38:49.425733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:38:49.981361: lr: 0.005877
2022-05-28 01:38:50.024381: saving checkpoint...
2022-05-28 01:38:51.183083: done, saving took 1.20 seconds
2022-05-28 01:38:51.203152: This epoch took 100.552294 s

2022-05-28 01:38:51.206625: 
epoch:  223
2022-05-28 01:40:21.754385: train loss : -0.7905
2022-05-28 01:40:29.986111: validation loss: -0.7693
2022-05-28 01:40:29.989523: Average global foreground Dice: [0.8022]
2022-05-28 01:40:29.992345: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:40:30.435424: lr: 0.005858
2022-05-28 01:40:30.438347: This epoch took 99.229311 s

2022-05-28 01:40:30.440919: 
epoch:  224
2022-05-28 01:42:00.673978: train loss : -0.7857
2022-05-28 01:42:07.089802: validation loss: -0.7628
2022-05-28 01:42:07.116571: Average global foreground Dice: [0.8023]
2022-05-28 01:42:07.118819: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:42:07.576225: lr: 0.005839
2022-05-28 01:42:07.578429: This epoch took 97.135539 s

2022-05-28 01:42:07.580502: 
epoch:  225
2022-05-28 01:43:39.498266: train loss : -0.7941
2022-05-28 01:43:49.989366: validation loss: -0.7600
2022-05-28 01:43:49.992806: Average global foreground Dice: [0.8013]
2022-05-28 01:43:49.995126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:43:50.617288: lr: 0.00582
2022-05-28 01:43:50.619172: This epoch took 103.036628 s

2022-05-28 01:43:50.622018: 
epoch:  226
2022-05-28 01:45:25.183236: train loss : -0.7711
2022-05-28 01:45:34.624465: validation loss: -0.7652
2022-05-28 01:45:34.630739: Average global foreground Dice: [0.8049]
2022-05-28 01:45:34.633016: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:45:35.119370: lr: 0.005801
2022-05-28 01:45:35.121737: This epoch took 104.483492 s

2022-05-28 01:45:35.124354: 
epoch:  227
2022-05-28 01:47:09.382071: train loss : -0.7841
2022-05-28 01:47:19.342261: validation loss: -0.7597
2022-05-28 01:47:19.360321: Average global foreground Dice: [0.7957]
2022-05-28 01:47:19.366175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:47:19.890211: lr: 0.005781
2022-05-28 01:47:19.898584: This epoch took 104.771757 s

2022-05-28 01:47:19.902112: 
epoch:  228
2022-05-28 01:48:53.839358: train loss : -0.7872
2022-05-28 01:49:02.592038: validation loss: -0.7566
2022-05-28 01:49:02.598992: Average global foreground Dice: [0.7968]
2022-05-28 01:49:02.611366: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:49:03.168899: lr: 0.005762
2022-05-28 01:49:03.189359: This epoch took 103.283516 s

2022-05-28 01:49:03.210295: 
epoch:  229
2022-05-28 01:50:33.833256: train loss : -0.7977
2022-05-28 01:50:40.407844: validation loss: -0.7853
2022-05-28 01:50:40.411305: Average global foreground Dice: [0.8111]
2022-05-28 01:50:40.413856: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:50:40.882693: lr: 0.005743
2022-05-28 01:50:40.885128: This epoch took 97.657308 s

2022-05-28 01:50:40.887428: 
epoch:  230
2022-05-28 01:52:12.099082: train loss : -0.7902
2022-05-28 01:52:20.102586: validation loss: -0.7806
2022-05-28 01:52:20.106276: Average global foreground Dice: [0.8131]
2022-05-28 01:52:20.108475: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:52:20.587429: lr: 0.005724
2022-05-28 01:52:20.636454: saving checkpoint...
2022-05-28 01:52:21.666056: done, saving took 1.08 seconds
2022-05-28 01:52:21.682297: This epoch took 100.792643 s

2022-05-28 01:52:21.684536: 
epoch:  231
2022-05-28 01:53:53.157043: train loss : -0.7903
2022-05-28 01:54:01.792684: validation loss: -0.7657
2022-05-28 01:54:01.806371: Average global foreground Dice: [0.7945]
2022-05-28 01:54:01.834062: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:54:02.345254: lr: 0.005705
2022-05-28 01:54:02.347806: This epoch took 100.661211 s

2022-05-28 01:54:02.350996: 
epoch:  232
2022-05-28 01:55:34.013013: train loss : -0.7839
2022-05-28 01:55:43.912690: validation loss: -0.7547
2022-05-28 01:55:43.940765: Average global foreground Dice: [0.7937]
2022-05-28 01:55:43.965861: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:55:44.451517: lr: 0.005686
2022-05-28 01:55:44.453695: This epoch took 102.099492 s

2022-05-28 01:55:44.455642: 
epoch:  233
2022-05-28 01:57:17.070588: train loss : -0.7821
2022-05-28 01:57:27.395061: validation loss: -0.7784
2022-05-28 01:57:27.398899: Average global foreground Dice: [0.8113]
2022-05-28 01:57:27.402287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:57:28.244078: lr: 0.005667
2022-05-28 01:57:28.246377: This epoch took 103.788665 s

2022-05-28 01:57:28.248541: 
epoch:  234
2022-05-28 01:58:59.439738: train loss : -0.7902
2022-05-28 01:59:07.216155: validation loss: -0.7826
2022-05-28 01:59:07.221735: Average global foreground Dice: [0.8134]
2022-05-28 01:59:07.229113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 01:59:07.704424: lr: 0.005647
2022-05-28 01:59:07.741670: saving checkpoint...
2022-05-28 01:59:08.877694: done, saving took 1.17 seconds
2022-05-28 01:59:08.892958: This epoch took 100.642402 s

2022-05-28 01:59:08.895545: 
epoch:  235
2022-05-28 02:00:42.531342: train loss : -0.7838
2022-05-28 02:00:52.279742: validation loss: -0.7545
2022-05-28 02:00:52.309873: Average global foreground Dice: [0.7798]
2022-05-28 02:00:52.324753: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:00:52.795825: lr: 0.005628
2022-05-28 02:00:52.798274: This epoch took 103.900208 s

2022-05-28 02:00:52.800355: 
epoch:  236
2022-05-28 02:02:24.357761: train loss : -0.7973
2022-05-28 02:02:32.526467: validation loss: -0.7644
2022-05-28 02:02:32.530220: Average global foreground Dice: [0.8211]
2022-05-28 02:02:32.535306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:02:33.064356: lr: 0.005609
2022-05-28 02:02:33.067082: This epoch took 100.264714 s

2022-05-28 02:02:33.069386: 
epoch:  237
2022-05-28 02:04:06.605487: train loss : -0.7952
2022-05-28 02:04:16.200546: validation loss: -0.7545
2022-05-28 02:04:16.240015: Average global foreground Dice: [0.784]
2022-05-28 02:04:16.282292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:04:17.102309: lr: 0.00559
2022-05-28 02:04:17.114325: This epoch took 104.038917 s

2022-05-28 02:04:17.139441: 
epoch:  238
2022-05-28 02:05:48.317429: train loss : -0.7837
2022-05-28 02:05:55.616424: validation loss: -0.7735
2022-05-28 02:05:55.623097: Average global foreground Dice: [0.8136]
2022-05-28 02:05:55.628055: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:05:56.096724: lr: 0.005571
2022-05-28 02:05:56.099301: This epoch took 98.931013 s

2022-05-28 02:05:56.101713: 
epoch:  239
2022-05-28 02:07:27.398811: train loss : -0.7878
2022-05-28 02:07:35.904196: validation loss: -0.7777
2022-05-28 02:07:35.907908: Average global foreground Dice: [0.8085]
2022-05-28 02:07:35.910641: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:07:36.399653: lr: 0.005551
2022-05-28 02:07:36.402332: This epoch took 100.297037 s

2022-05-28 02:07:36.404644: 
epoch:  240
2022-05-28 02:09:07.551755: train loss : -0.7948
2022-05-28 02:09:17.301492: validation loss: -0.7762
2022-05-28 02:09:17.339020: Average global foreground Dice: [0.8152]
2022-05-28 02:09:17.358093: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:09:18.017898: lr: 0.005532
2022-05-28 02:09:18.068698: saving checkpoint...
2022-05-28 02:09:19.251354: done, saving took 1.23 seconds
2022-05-28 02:09:19.268777: This epoch took 102.861917 s

2022-05-28 02:09:19.271620: 
epoch:  241
2022-05-28 02:10:50.182965: train loss : -0.7969
2022-05-28 02:10:59.259446: validation loss: -0.7859
2022-05-28 02:10:59.280853: Average global foreground Dice: [0.8187]
2022-05-28 02:10:59.302485: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:10:59.818986: lr: 0.005513
2022-05-28 02:10:59.855078: saving checkpoint...
2022-05-28 02:11:01.093336: done, saving took 1.27 seconds
2022-05-28 02:11:01.107458: This epoch took 101.832391 s

2022-05-28 02:11:01.109897: 
epoch:  242
2022-05-28 02:12:35.023810: train loss : -0.7978
2022-05-28 02:12:46.067623: validation loss: -0.7430
2022-05-28 02:12:46.070987: Average global foreground Dice: [0.7899]
2022-05-28 02:12:46.073182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:12:46.571840: lr: 0.005494
2022-05-28 02:12:46.574928: This epoch took 105.463028 s

2022-05-28 02:12:46.590703: 
epoch:  243
2022-05-28 02:14:19.063670: train loss : -0.8049
2022-05-28 02:14:28.102188: validation loss: -0.7592
2022-05-28 02:14:28.106602: Average global foreground Dice: [0.7987]
2022-05-28 02:14:28.109300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:14:28.595305: lr: 0.005474
2022-05-28 02:14:28.598115: This epoch took 102.005159 s

2022-05-28 02:14:28.600351: 
epoch:  244
2022-05-28 02:16:00.178730: train loss : -0.7837
2022-05-28 02:16:11.264092: validation loss: -0.7478
2022-05-28 02:16:11.293756: Average global foreground Dice: [0.7909]
2022-05-28 02:16:11.316531: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:16:11.804286: lr: 0.005455
2022-05-28 02:16:11.815208: This epoch took 103.212675 s

2022-05-28 02:16:11.824738: 
epoch:  245
2022-05-28 02:17:43.490446: train loss : -0.7797
2022-05-28 02:17:51.753102: validation loss: -0.7608
2022-05-28 02:17:51.763168: Average global foreground Dice: [0.8084]
2022-05-28 02:17:51.765511: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:17:52.232632: lr: 0.005436
2022-05-28 02:17:52.235496: This epoch took 100.399856 s

2022-05-28 02:17:52.238522: 
epoch:  246
2022-05-28 02:19:23.329495: train loss : -0.7935
2022-05-28 02:19:31.050847: validation loss: -0.7771
2022-05-28 02:19:31.054754: Average global foreground Dice: [0.8081]
2022-05-28 02:19:31.057062: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:19:31.530123: lr: 0.005417
2022-05-28 02:19:31.532535: This epoch took 99.291986 s

2022-05-28 02:19:31.534880: 
epoch:  247
2022-05-28 02:21:12.041706: train loss : -0.7846
2022-05-28 02:21:20.156991: validation loss: -0.7579
2022-05-28 02:21:20.161313: Average global foreground Dice: [0.7867]
2022-05-28 02:21:20.167439: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:21:20.688682: lr: 0.005397
2022-05-28 02:21:20.691261: This epoch took 109.154456 s

2022-05-28 02:21:20.693252: 
epoch:  248
2022-05-28 02:22:52.460074: train loss : -0.7784
2022-05-28 02:23:02.000902: validation loss: -0.7678
2022-05-28 02:23:02.004494: Average global foreground Dice: [0.8231]
2022-05-28 02:23:02.006633: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:23:02.515950: lr: 0.005378
2022-05-28 02:23:02.518298: This epoch took 101.822911 s

2022-05-28 02:23:02.520496: 
epoch:  249
2022-05-28 02:24:36.709134: train loss : -0.7740
2022-05-28 02:24:44.335791: validation loss: -0.7682
2022-05-28 02:24:44.364917: Average global foreground Dice: [0.7982]
2022-05-28 02:24:44.389885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:24:45.472541: lr: 0.005359
2022-05-28 02:24:45.492356: saving scheduled checkpoint file...
2022-05-28 02:24:45.570159: saving checkpoint...
2022-05-28 02:24:46.788872: done, saving took 1.29 seconds
2022-05-28 02:24:46.805039: done
2022-05-28 02:24:46.807360: This epoch took 104.284845 s

2022-05-28 02:24:46.809360: 
epoch:  250
2022-05-28 02:26:19.232489: train loss : -0.7911
2022-05-28 02:26:26.074912: validation loss: -0.7489
2022-05-28 02:26:26.105682: Average global foreground Dice: [0.7819]
2022-05-28 02:26:26.127101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:26:26.686651: lr: 0.00534
2022-05-28 02:26:26.689792: This epoch took 99.878283 s

2022-05-28 02:26:26.692010: 
epoch:  251
2022-05-28 02:27:58.335094: train loss : -0.7820
2022-05-28 02:28:06.121117: validation loss: -0.7520
2022-05-28 02:28:06.125502: Average global foreground Dice: [0.7963]
2022-05-28 02:28:06.128170: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:28:06.621085: lr: 0.00532
2022-05-28 02:28:06.623688: This epoch took 99.929513 s

2022-05-28 02:28:06.625816: 
epoch:  252
2022-05-28 02:29:41.045799: train loss : -0.7891
2022-05-28 02:29:49.751183: validation loss: -0.7399
2022-05-28 02:29:49.759075: Average global foreground Dice: [0.7944]
2022-05-28 02:29:49.761660: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:29:50.233349: lr: 0.005301
2022-05-28 02:29:50.235687: This epoch took 103.607517 s

2022-05-28 02:29:50.238679: 
epoch:  253
2022-05-28 02:31:25.379216: train loss : -0.7914
2022-05-28 02:31:32.895833: validation loss: -0.7538
2022-05-28 02:31:32.900429: Average global foreground Dice: [0.807]
2022-05-28 02:31:32.903382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:31:33.397797: lr: 0.005282
2022-05-28 02:31:33.405404: This epoch took 103.164274 s

2022-05-28 02:31:33.418221: 
epoch:  254
2022-05-28 02:33:07.858319: train loss : -0.7777
2022-05-28 02:33:18.470955: validation loss: -0.7447
2022-05-28 02:33:18.474602: Average global foreground Dice: [0.788]
2022-05-28 02:33:18.476892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:33:18.940727: lr: 0.005262
2022-05-28 02:33:18.944061: This epoch took 105.523461 s

2022-05-28 02:33:18.946465: 
epoch:  255
2022-05-28 02:34:55.087237: train loss : -0.7923
2022-05-28 02:35:04.826033: validation loss: -0.7671
2022-05-28 02:35:04.829310: Average global foreground Dice: [0.8142]
2022-05-28 02:35:04.843318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:35:05.435879: lr: 0.005243
2022-05-28 02:35:05.438220: This epoch took 106.489443 s

2022-05-28 02:35:05.440593: 
epoch:  256
2022-05-28 02:36:37.291044: train loss : -0.7855
2022-05-28 02:36:45.773865: validation loss: -0.7619
2022-05-28 02:36:45.777584: Average global foreground Dice: [0.8012]
2022-05-28 02:36:45.780110: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:36:46.269246: lr: 0.005224
2022-05-28 02:36:46.272782: This epoch took 100.829050 s

2022-05-28 02:36:46.275609: 
epoch:  257
2022-05-28 02:38:17.795147: train loss : -0.8001
2022-05-28 02:38:24.983887: validation loss: -0.7928
2022-05-28 02:38:24.998300: Average global foreground Dice: [0.818]
2022-05-28 02:38:25.000922: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:38:25.472450: lr: 0.005204
2022-05-28 02:38:25.488358: This epoch took 99.210680 s

2022-05-28 02:38:25.495866: 
epoch:  258
2022-05-28 02:40:00.554777: train loss : -0.8020
2022-05-28 02:40:08.705028: validation loss: -0.7264
2022-05-28 02:40:08.708781: Average global foreground Dice: [0.7779]
2022-05-28 02:40:08.711105: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:40:09.175891: lr: 0.005185
2022-05-28 02:40:09.178878: This epoch took 103.657575 s

2022-05-28 02:40:09.182507: 
epoch:  259
2022-05-28 02:41:40.587311: train loss : -0.7829
2022-05-28 02:41:48.271020: validation loss: -0.7779
2022-05-28 02:41:48.277426: Average global foreground Dice: [0.8033]
2022-05-28 02:41:48.280612: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:41:48.745211: lr: 0.005166
2022-05-28 02:41:48.747649: This epoch took 99.562927 s

2022-05-28 02:41:48.749658: 
epoch:  260
2022-05-28 02:43:20.271215: train loss : -0.8089
2022-05-28 02:43:28.147231: validation loss: -0.7456
2022-05-28 02:43:28.153425: Average global foreground Dice: [0.795]
2022-05-28 02:43:28.156076: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:43:28.727090: lr: 0.005146
2022-05-28 02:43:28.729654: This epoch took 99.978040 s

2022-05-28 02:43:28.731740: 
epoch:  261
2022-05-28 02:45:04.266351: train loss : -0.8040
2022-05-28 02:45:13.824021: validation loss: -0.7866
2022-05-28 02:45:13.827724: Average global foreground Dice: [0.8134]
2022-05-28 02:45:13.830030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:45:14.320630: lr: 0.005127
2022-05-28 02:45:14.323237: This epoch took 105.589496 s

2022-05-28 02:45:14.325454: 
epoch:  262
2022-05-28 02:46:45.934841: train loss : -0.8010
2022-05-28 02:46:55.327305: validation loss: -0.7889
2022-05-28 02:46:55.368715: Average global foreground Dice: [0.809]
2022-05-28 02:46:55.390309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:46:56.321680: lr: 0.005107
2022-05-28 02:46:56.351342: This epoch took 102.023786 s

2022-05-28 02:46:56.373303: 
epoch:  263
2022-05-28 02:48:26.828799: train loss : -0.7895
2022-05-28 02:48:34.580212: validation loss: -0.7737
2022-05-28 02:48:34.583547: Average global foreground Dice: [0.8106]
2022-05-28 02:48:34.585915: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:48:35.068717: lr: 0.005088
2022-05-28 02:48:35.071574: This epoch took 98.678288 s

2022-05-28 02:48:35.073918: 
epoch:  264
2022-05-28 02:50:06.276663: train loss : -0.8045
2022-05-28 02:50:14.723566: validation loss: -0.7844
2022-05-28 02:50:14.741514: Average global foreground Dice: [0.8107]
2022-05-28 02:50:14.760489: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:50:15.538769: lr: 0.005069
2022-05-28 02:50:15.546843: This epoch took 100.470463 s

2022-05-28 02:50:15.549030: 
epoch:  265
2022-05-28 02:51:46.866674: train loss : -0.8033
2022-05-28 02:51:54.883696: validation loss: -0.7751
2022-05-28 02:51:54.887248: Average global foreground Dice: [0.8075]
2022-05-28 02:51:54.889254: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:51:55.359953: lr: 0.005049
2022-05-28 02:51:55.362936: This epoch took 99.811833 s

2022-05-28 02:51:55.365378: 
epoch:  266
2022-05-28 02:53:27.034271: train loss : -0.7833
2022-05-28 02:53:35.970843: validation loss: -0.7633
2022-05-28 02:53:35.974212: Average global foreground Dice: [0.8082]
2022-05-28 02:53:35.976959: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:53:36.465085: lr: 0.00503
2022-05-28 02:53:36.467499: This epoch took 101.099994 s

2022-05-28 02:53:36.469869: 
epoch:  267
2022-05-28 02:55:08.607318: train loss : -0.7822
2022-05-28 02:55:17.629302: validation loss: -0.7630
2022-05-28 02:55:17.632663: Average global foreground Dice: [0.7984]
2022-05-28 02:55:17.663604: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:55:18.245412: lr: 0.00501
2022-05-28 02:55:18.248443: This epoch took 101.776649 s

2022-05-28 02:55:18.251104: 
epoch:  268
2022-05-28 02:56:49.882796: train loss : -0.7897
2022-05-28 02:57:00.770624: validation loss: -0.7232
2022-05-28 02:57:00.774777: Average global foreground Dice: [0.794]
2022-05-28 02:57:00.777112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:57:01.320111: lr: 0.004991
2022-05-28 02:57:01.322838: This epoch took 103.069028 s

2022-05-28 02:57:01.325353: 
epoch:  269
2022-05-28 02:58:34.333007: train loss : -0.7851
2022-05-28 02:58:42.317698: validation loss: -0.7543
2022-05-28 02:58:42.343733: Average global foreground Dice: [0.8027]
2022-05-28 02:58:42.368415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 02:58:43.017549: lr: 0.004971
2022-05-28 02:58:43.035021: This epoch took 101.707354 s

2022-05-28 02:58:43.060292: 
epoch:  270
2022-05-28 03:00:15.096909: train loss : -0.7827
2022-05-28 03:00:25.908038: validation loss: -0.7743
2022-05-28 03:00:25.933710: Average global foreground Dice: [0.7993]
2022-05-28 03:00:25.955232: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:00:26.488862: lr: 0.004952
2022-05-28 03:00:26.491490: This epoch took 103.409199 s

2022-05-28 03:00:26.493839: 
epoch:  271
2022-05-28 03:02:03.752842: train loss : -0.7835
2022-05-28 03:02:13.493705: validation loss: -0.7628
2022-05-28 03:02:13.516850: Average global foreground Dice: [0.8125]
2022-05-28 03:02:13.519914: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:02:13.994213: lr: 0.004933
2022-05-28 03:02:13.999098: This epoch took 107.502937 s

2022-05-28 03:02:14.001554: 
epoch:  272
2022-05-28 03:03:44.434279: train loss : -0.7787
2022-05-28 03:03:52.138219: validation loss: -0.7754
2022-05-28 03:03:52.142746: Average global foreground Dice: [0.8087]
2022-05-28 03:03:52.145352: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:03:52.698381: lr: 0.004913
2022-05-28 03:03:52.701087: This epoch took 98.697212 s

2022-05-28 03:03:52.704653: 
epoch:  273
2022-05-28 03:05:28.754918: train loss : -0.7951
2022-05-28 03:05:39.188420: validation loss: -0.7515
2022-05-28 03:05:39.205003: Average global foreground Dice: [0.7948]
2022-05-28 03:05:39.225394: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:05:39.728915: lr: 0.004894
2022-05-28 03:05:39.731712: This epoch took 107.009604 s

2022-05-28 03:05:39.734088: 
epoch:  274
2022-05-28 03:07:14.845946: train loss : -0.7943
2022-05-28 03:07:23.653123: validation loss: -0.7485
2022-05-28 03:07:23.657429: Average global foreground Dice: [0.7937]
2022-05-28 03:07:23.660131: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:07:24.171428: lr: 0.004874
2022-05-28 03:07:24.173885: This epoch took 104.437011 s

2022-05-28 03:07:24.175993: 
epoch:  275
2022-05-28 03:08:56.892482: train loss : -0.8026
2022-05-28 03:09:06.593230: validation loss: -0.7625
2022-05-28 03:09:06.596892: Average global foreground Dice: [0.7983]
2022-05-28 03:09:06.599387: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:09:07.067609: lr: 0.004855
2022-05-28 03:09:07.070369: This epoch took 102.892298 s

2022-05-28 03:09:07.072480: 
epoch:  276
2022-05-28 03:10:37.792543: train loss : -0.7935
2022-05-28 03:10:45.018988: validation loss: -0.7621
2022-05-28 03:10:45.022284: Average global foreground Dice: [0.8169]
2022-05-28 03:10:45.024480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:10:45.476532: lr: 0.004835
2022-05-28 03:10:45.478755: This epoch took 98.404112 s

2022-05-28 03:10:45.481066: 
epoch:  277
2022-05-28 03:12:16.529761: train loss : -0.7890
2022-05-28 03:12:23.870800: validation loss: -0.7486
2022-05-28 03:12:23.874649: Average global foreground Dice: [0.7852]
2022-05-28 03:12:23.877253: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:12:24.363417: lr: 0.004816
2022-05-28 03:12:24.366067: This epoch took 98.883012 s

2022-05-28 03:12:24.368317: 
epoch:  278
2022-05-28 03:13:55.614472: train loss : -0.7962
2022-05-28 03:14:02.229336: validation loss: -0.7727
2022-05-28 03:14:02.233615: Average global foreground Dice: [0.8056]
2022-05-28 03:14:02.236817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:14:02.704015: lr: 0.004796
2022-05-28 03:14:02.706297: This epoch took 98.335733 s

2022-05-28 03:14:02.708385: 
epoch:  279
2022-05-28 03:15:38.077289: train loss : -0.7973
2022-05-28 03:15:48.924422: validation loss: -0.7683
2022-05-28 03:15:48.928292: Average global foreground Dice: [0.8019]
2022-05-28 03:15:48.930527: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:15:49.383019: lr: 0.004776
2022-05-28 03:15:49.386139: This epoch took 106.675559 s

2022-05-28 03:15:49.389221: 
epoch:  280
2022-05-28 03:17:20.127697: train loss : -0.7844
2022-05-28 03:17:28.111337: validation loss: -0.7649
2022-05-28 03:17:28.135695: Average global foreground Dice: [0.801]
2022-05-28 03:17:28.155306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:17:28.701239: lr: 0.004757
2022-05-28 03:17:28.704168: This epoch took 99.312295 s

2022-05-28 03:17:28.708262: 
epoch:  281
2022-05-28 03:19:00.451265: train loss : -0.7915
2022-05-28 03:19:09.564852: validation loss: -0.7848
2022-05-28 03:19:09.568666: Average global foreground Dice: [0.8221]
2022-05-28 03:19:09.571408: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:19:10.040686: lr: 0.004737
2022-05-28 03:19:10.062324: This epoch took 101.351440 s

2022-05-28 03:19:10.078919: 
epoch:  282
2022-05-28 03:20:42.043884: train loss : -0.8083
2022-05-28 03:20:51.834420: validation loss: -0.7685
2022-05-28 03:20:51.843886: Average global foreground Dice: [0.8169]
2022-05-28 03:20:51.869301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:20:52.546835: lr: 0.004718
2022-05-28 03:20:52.562418: This epoch took 102.481099 s

2022-05-28 03:20:52.565015: 
epoch:  283
2022-05-28 03:22:24.301607: train loss : -0.8080
2022-05-28 03:22:33.865959: validation loss: -0.7858
2022-05-28 03:22:33.884513: Average global foreground Dice: [0.8247]
2022-05-28 03:22:33.916487: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:22:34.763408: lr: 0.004698
2022-05-28 03:22:34.823015: saving checkpoint...
2022-05-28 03:22:36.039808: done, saving took 1.26 seconds
2022-05-28 03:22:36.074634: This epoch took 103.507038 s

2022-05-28 03:22:36.092690: 
epoch:  284
2022-05-28 03:24:09.220319: train loss : -0.7849
2022-05-28 03:24:16.344398: validation loss: -0.7827
2022-05-28 03:24:16.348333: Average global foreground Dice: [0.8022]
2022-05-28 03:24:16.352761: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:24:16.814292: lr: 0.004679
2022-05-28 03:24:16.817239: This epoch took 100.697572 s

2022-05-28 03:24:16.819577: 
epoch:  285
2022-05-28 03:25:48.720391: train loss : -0.8099
2022-05-28 03:25:55.315376: validation loss: -0.7907
2022-05-28 03:25:55.319012: Average global foreground Dice: [0.8147]
2022-05-28 03:25:55.321251: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:25:55.781645: lr: 0.004659
2022-05-28 03:25:55.832874: saving checkpoint...
2022-05-28 03:25:56.999950: done, saving took 1.22 seconds
2022-05-28 03:25:57.025068: This epoch took 100.203311 s

2022-05-28 03:25:57.027369: 
epoch:  286
2022-05-28 03:27:28.060132: train loss : -0.8018
2022-05-28 03:27:36.056502: validation loss: -0.7506
2022-05-28 03:27:36.059586: Average global foreground Dice: [0.8133]
2022-05-28 03:27:36.061805: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:27:36.580099: lr: 0.004639
2022-05-28 03:27:36.637851: saving checkpoint...
2022-05-28 03:27:37.666663: done, saving took 1.08 seconds
2022-05-28 03:27:37.679926: This epoch took 100.650385 s

2022-05-28 03:27:37.682397: 
epoch:  287
2022-05-28 03:29:08.639063: train loss : -0.8008
2022-05-28 03:29:19.147677: validation loss: -0.7832
2022-05-28 03:29:19.151695: Average global foreground Dice: [0.8081]
2022-05-28 03:29:19.158020: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:29:19.646428: lr: 0.00462
2022-05-28 03:29:19.695920: saving checkpoint...
2022-05-28 03:29:20.797016: done, saving took 1.15 seconds
2022-05-28 03:29:20.812382: This epoch took 103.127841 s

2022-05-28 03:29:20.814722: 
epoch:  288
2022-05-28 03:30:53.845566: train loss : -0.8076
2022-05-28 03:31:03.595825: validation loss: -0.7837
2022-05-28 03:31:03.616786: Average global foreground Dice: [0.8115]
2022-05-28 03:31:03.643314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:31:04.413912: lr: 0.0046
2022-05-28 03:31:04.496347: saving checkpoint...
2022-05-28 03:31:05.561574: done, saving took 1.12 seconds
2022-05-28 03:31:05.575027: This epoch took 104.758009 s

2022-05-28 03:31:05.577581: 
epoch:  289
2022-05-28 03:32:40.774597: train loss : -0.8074
2022-05-28 03:32:49.515099: validation loss: -0.7776
2022-05-28 03:32:49.532653: Average global foreground Dice: [0.8014]
2022-05-28 03:32:49.555367: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:32:50.169624: lr: 0.004581
2022-05-28 03:32:50.172565: This epoch took 104.592688 s

2022-05-28 03:32:50.175011: 
epoch:  290
2022-05-28 03:34:22.456293: train loss : -0.8024
2022-05-28 03:34:30.879457: validation loss: -0.7828
2022-05-28 03:34:30.882846: Average global foreground Dice: [0.8062]
2022-05-28 03:34:30.885023: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:34:31.346718: lr: 0.004561
2022-05-28 03:34:31.349508: This epoch took 101.172026 s

2022-05-28 03:34:31.352503: 
epoch:  291
2022-05-28 03:36:02.679816: train loss : -0.7924
2022-05-28 03:36:11.715727: validation loss: -0.7641
2022-05-28 03:36:11.719218: Average global foreground Dice: [0.8123]
2022-05-28 03:36:11.721900: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:36:12.210451: lr: 0.004541
2022-05-28 03:36:12.213316: This epoch took 100.858161 s

2022-05-28 03:36:12.216449: 
epoch:  292
2022-05-28 03:37:43.804201: train loss : -0.8040
2022-05-28 03:37:53.604992: validation loss: -0.7592
2022-05-28 03:37:53.608846: Average global foreground Dice: [0.8044]
2022-05-28 03:37:53.611275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:37:54.106436: lr: 0.004522
2022-05-28 03:37:54.108954: This epoch took 101.890127 s

2022-05-28 03:37:54.111062: 
epoch:  293
2022-05-28 03:39:24.761515: train loss : -0.8013
2022-05-28 03:39:30.778258: validation loss: -0.7728
2022-05-28 03:39:30.782711: Average global foreground Dice: [0.8066]
2022-05-28 03:39:30.784967: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:39:31.253563: lr: 0.004502
2022-05-28 03:39:31.255943: This epoch took 97.142565 s

2022-05-28 03:39:31.257984: 
epoch:  294
2022-05-28 03:41:02.805654: train loss : -0.8061
2022-05-28 03:41:11.959917: validation loss: -0.7891
2022-05-28 03:41:11.981663: Average global foreground Dice: [0.8121]
2022-05-28 03:41:11.984010: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:41:12.491993: lr: 0.004482
2022-05-28 03:41:12.494731: This epoch took 101.234817 s

2022-05-28 03:41:12.497431: 
epoch:  295
2022-05-28 03:42:46.450716: train loss : -0.8095
2022-05-28 03:42:54.783523: validation loss: -0.7681
2022-05-28 03:42:54.845384: Average global foreground Dice: [0.8191]
2022-05-28 03:42:54.858942: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:42:55.582159: lr: 0.004463
2022-05-28 03:42:55.633996: saving checkpoint...
2022-05-28 03:42:57.003431: done, saving took 1.41 seconds
2022-05-28 03:42:57.063641: This epoch took 104.563651 s

2022-05-28 03:42:57.083291: 
epoch:  296
2022-05-28 03:44:28.677820: train loss : -0.8036
2022-05-28 03:44:37.504434: validation loss: -0.7400
2022-05-28 03:44:37.509087: Average global foreground Dice: [0.7872]
2022-05-28 03:44:37.511466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:44:38.037648: lr: 0.004443
2022-05-28 03:44:38.069664: This epoch took 100.976347 s

2022-05-28 03:44:38.082343: 
epoch:  297
2022-05-28 03:46:09.677520: train loss : -0.8021
2022-05-28 03:46:15.551635: validation loss: -0.7602
2022-05-28 03:46:15.555514: Average global foreground Dice: [0.7995]
2022-05-28 03:46:15.558036: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:46:16.019000: lr: 0.004423
2022-05-28 03:46:16.021350: This epoch took 97.923341 s

2022-05-28 03:46:16.023465: 
epoch:  298
2022-05-28 03:47:50.956185: train loss : -0.8132
2022-05-28 03:47:58.822958: validation loss: -0.7811
2022-05-28 03:47:58.828526: Average global foreground Dice: [0.815]
2022-05-28 03:47:58.831266: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:47:59.316932: lr: 0.004404
2022-05-28 03:47:59.319749: This epoch took 103.293900 s

2022-05-28 03:47:59.322109: 
epoch:  299
2022-05-28 03:49:30.239995: train loss : -0.8085
2022-05-28 03:49:36.070320: validation loss: -0.7822
2022-05-28 03:49:36.074783: Average global foreground Dice: [0.8036]
2022-05-28 03:49:36.077072: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:49:36.525598: lr: 0.004384
2022-05-28 03:49:36.527927: saving scheduled checkpoint file...
2022-05-28 03:49:36.582489: saving checkpoint...
2022-05-28 03:49:37.610151: done, saving took 1.08 seconds
2022-05-28 03:49:37.627013: done
2022-05-28 03:49:37.629299: This epoch took 98.304976 s

2022-05-28 03:49:37.631644: 
epoch:  300
2022-05-28 03:51:08.956799: train loss : -0.8039
2022-05-28 03:51:17.324390: validation loss: -0.7585
2022-05-28 03:51:17.328193: Average global foreground Dice: [0.8055]
2022-05-28 03:51:17.330511: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:51:17.802490: lr: 0.004364
2022-05-28 03:51:17.805738: This epoch took 100.171943 s

2022-05-28 03:51:17.807935: 
epoch:  301
2022-05-28 03:52:47.838206: train loss : -0.8101
2022-05-28 03:52:56.161732: validation loss: -0.7815
2022-05-28 03:52:56.166167: Average global foreground Dice: [0.8107]
2022-05-28 03:52:56.168721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:52:56.617126: lr: 0.004344
2022-05-28 03:52:56.619486: This epoch took 98.809416 s

2022-05-28 03:52:56.621494: 
epoch:  302
2022-05-28 03:54:28.160650: train loss : -0.7955
2022-05-28 03:54:36.562609: validation loss: -0.7609
2022-05-28 03:54:36.566913: Average global foreground Dice: [0.8029]
2022-05-28 03:54:36.570162: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:54:37.043292: lr: 0.004325
2022-05-28 03:54:37.046284: This epoch took 100.422922 s

2022-05-28 03:54:37.049132: 
epoch:  303
2022-05-28 03:56:08.771791: train loss : -0.7932
2022-05-28 03:56:16.774383: validation loss: -0.7666
2022-05-28 03:56:16.778301: Average global foreground Dice: [0.7898]
2022-05-28 03:56:16.780581: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:56:17.233661: lr: 0.004305
2022-05-28 03:56:17.236515: This epoch took 100.184952 s

2022-05-28 03:56:17.239622: 
epoch:  304
2022-05-28 03:57:50.817231: train loss : -0.7945
2022-05-28 03:58:00.641098: validation loss: -0.7924
2022-05-28 03:58:00.655366: Average global foreground Dice: [0.8129]
2022-05-28 03:58:00.674413: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:58:01.328585: lr: 0.004285
2022-05-28 03:58:01.330384: This epoch took 104.087807 s

2022-05-28 03:58:01.333079: 
epoch:  305
2022-05-28 03:59:33.232016: train loss : -0.8023
2022-05-28 03:59:41.358787: validation loss: -0.7817
2022-05-28 03:59:41.362148: Average global foreground Dice: [0.8177]
2022-05-28 03:59:41.364290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 03:59:41.811074: lr: 0.004265
2022-05-28 03:59:41.813343: This epoch took 100.478147 s

2022-05-28 03:59:41.815422: 
epoch:  306
2022-05-28 04:01:14.093697: train loss : -0.7998
2022-05-28 04:01:21.328552: validation loss: -0.7569
2022-05-28 04:01:21.332029: Average global foreground Dice: [0.8059]
2022-05-28 04:01:21.334661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:01:21.827564: lr: 0.004245
2022-05-28 04:01:21.830145: This epoch took 100.012339 s

2022-05-28 04:01:21.837040: 
epoch:  307
2022-05-28 04:02:53.350842: train loss : -0.8049
2022-05-28 04:03:01.672453: validation loss: -0.7573
2022-05-28 04:03:01.705753: Average global foreground Dice: [0.7951]
2022-05-28 04:03:01.727307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:03:02.393756: lr: 0.004226
2022-05-28 04:03:02.415392: This epoch took 100.574715 s

2022-05-28 04:03:02.422628: 
epoch:  308
2022-05-28 04:04:33.649309: train loss : -0.8190
2022-05-28 04:04:43.945874: validation loss: -0.7681
2022-05-28 04:04:43.988868: Average global foreground Dice: [0.7942]
2022-05-28 04:04:44.008406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:04:44.858871: lr: 0.004206
2022-05-28 04:04:44.881325: This epoch took 102.456121 s

2022-05-28 04:04:44.904297: 
epoch:  309
2022-05-28 04:06:16.410130: train loss : -0.8009
2022-05-28 04:06:25.414013: validation loss: -0.7827
2022-05-28 04:06:25.420265: Average global foreground Dice: [0.8178]
2022-05-28 04:06:25.423363: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:06:25.888604: lr: 0.004186
2022-05-28 04:06:25.891210: This epoch took 100.965860 s

2022-05-28 04:06:25.893601: 
epoch:  310
2022-05-28 04:07:58.559652: train loss : -0.8015
2022-05-28 04:08:08.261123: validation loss: -0.7562
2022-05-28 04:08:08.271202: Average global foreground Dice: [0.7928]
2022-05-28 04:08:08.273515: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:08:08.793338: lr: 0.004166
2022-05-28 04:08:08.796483: This epoch took 102.900734 s

2022-05-28 04:08:08.819295: 
epoch:  311
2022-05-28 04:09:44.204873: train loss : -0.7965
2022-05-28 04:09:51.008837: validation loss: -0.7757
2022-05-28 04:09:51.012451: Average global foreground Dice: [0.8037]
2022-05-28 04:09:51.015247: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:09:51.626188: lr: 0.004146
2022-05-28 04:09:51.629350: This epoch took 102.807212 s

2022-05-28 04:09:51.637299: 
epoch:  312
2022-05-28 04:11:24.653687: train loss : -0.8067
2022-05-28 04:11:34.610756: validation loss: -0.7738
2022-05-28 04:11:34.615213: Average global foreground Dice: [0.8128]
2022-05-28 04:11:34.618020: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:11:35.432139: lr: 0.004127
2022-05-28 04:11:35.443380: This epoch took 103.799880 s

2022-05-28 04:11:35.445671: 
epoch:  313
2022-05-28 04:13:10.546233: train loss : -0.8160
2022-05-28 04:13:21.687732: validation loss: -0.7550
2022-05-28 04:13:21.694983: Average global foreground Dice: [0.7987]
2022-05-28 04:13:21.730398: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:13:22.271329: lr: 0.004107
2022-05-28 04:13:22.274161: This epoch took 106.825884 s

2022-05-28 04:13:22.276839: 
epoch:  314
2022-05-28 04:14:57.284112: train loss : -0.8074
2022-05-28 04:15:05.919575: validation loss: -0.7852
2022-05-28 04:15:05.960462: Average global foreground Dice: [0.807]
2022-05-28 04:15:05.962888: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:15:06.430276: lr: 0.004087
2022-05-28 04:15:06.433028: This epoch took 104.154009 s

2022-05-28 04:15:06.435301: 
epoch:  315
2022-05-28 04:16:38.169145: train loss : -0.7910
2022-05-28 04:16:46.475266: validation loss: -0.7688
2022-05-28 04:16:46.540311: Average global foreground Dice: [0.7981]
2022-05-28 04:16:46.562457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:16:47.080739: lr: 0.004067
2022-05-28 04:16:47.092706: This epoch took 100.638380 s

2022-05-28 04:16:47.110387: 
epoch:  316
2022-05-28 04:18:19.448017: train loss : -0.8033
2022-05-28 04:18:28.640697: validation loss: -0.7558
2022-05-28 04:18:28.644356: Average global foreground Dice: [0.7971]
2022-05-28 04:18:28.648342: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:18:29.102996: lr: 0.004047
2022-05-28 04:18:29.106616: This epoch took 101.977741 s

2022-05-28 04:18:29.112400: 
epoch:  317
2022-05-28 04:20:00.870626: train loss : -0.7950
2022-05-28 04:20:09.199075: validation loss: -0.7397
2022-05-28 04:20:09.204676: Average global foreground Dice: [0.7917]
2022-05-28 04:20:09.207540: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:20:09.688132: lr: 0.004027
2022-05-28 04:20:09.690691: This epoch took 100.575235 s

2022-05-28 04:20:09.693049: 
epoch:  318
2022-05-28 04:21:44.032668: train loss : -0.7952
2022-05-28 04:21:52.084855: validation loss: -0.7626
2022-05-28 04:21:52.090656: Average global foreground Dice: [0.8127]
2022-05-28 04:21:52.093021: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:21:52.597152: lr: 0.004007
2022-05-28 04:21:52.599531: This epoch took 102.903795 s

2022-05-28 04:21:52.601890: 
epoch:  319
2022-05-28 04:23:25.066481: train loss : -0.8098
2022-05-28 04:23:34.432753: validation loss: -0.7750
2022-05-28 04:23:34.464770: Average global foreground Dice: [0.8021]
2022-05-28 04:23:34.486343: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:23:35.747224: lr: 0.003987
2022-05-28 04:23:35.779346: This epoch took 103.175133 s

2022-05-28 04:23:35.801294: 
epoch:  320
2022-05-28 04:25:07.076560: train loss : -0.7911
2022-05-28 04:25:16.493913: validation loss: -0.7529
2022-05-28 04:25:16.497190: Average global foreground Dice: [0.8026]
2022-05-28 04:25:16.499354: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:25:17.021599: lr: 0.003967
2022-05-28 04:25:17.024207: This epoch took 101.191538 s

2022-05-28 04:25:17.026721: 
epoch:  321
2022-05-28 04:26:49.399620: train loss : -0.8053
2022-05-28 04:26:58.479555: validation loss: -0.7853
2022-05-28 04:26:58.511697: Average global foreground Dice: [0.8061]
2022-05-28 04:26:58.545294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:26:59.067027: lr: 0.003947
2022-05-28 04:26:59.070067: This epoch took 102.040985 s

2022-05-28 04:26:59.072462: 
epoch:  322
2022-05-28 04:28:30.978466: train loss : -0.7946
2022-05-28 04:28:39.899750: validation loss: -0.7670
2022-05-28 04:28:39.926632: Average global foreground Dice: [0.8052]
2022-05-28 04:28:39.948308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:28:40.451975: lr: 0.003927
2022-05-28 04:28:40.454494: This epoch took 101.378096 s

2022-05-28 04:28:40.457214: 
epoch:  323
2022-05-28 04:30:10.748874: train loss : -0.8218
2022-05-28 04:30:18.223423: validation loss: -0.7559
2022-05-28 04:30:18.229087: Average global foreground Dice: [0.8021]
2022-05-28 04:30:18.231602: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:30:18.684564: lr: 0.003907
2022-05-28 04:30:18.687148: This epoch took 98.227565 s

2022-05-28 04:30:18.689582: 
epoch:  324
2022-05-28 04:31:51.414044: train loss : -0.7882
2022-05-28 04:32:00.307422: validation loss: -0.7893
2022-05-28 04:32:00.319167: Average global foreground Dice: [0.8139]
2022-05-28 04:32:00.350614: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:32:00.985401: lr: 0.003887
2022-05-28 04:32:00.987929: This epoch took 102.295746 s

2022-05-28 04:32:01.012426: 
epoch:  325
2022-05-28 04:33:36.127259: train loss : -0.8034
2022-05-28 04:33:46.739938: validation loss: -0.7690
2022-05-28 04:33:46.744022: Average global foreground Dice: [0.8239]
2022-05-28 04:33:46.746267: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:33:47.239407: lr: 0.003867
2022-05-28 04:33:47.243213: This epoch took 106.198920 s

2022-05-28 04:33:47.247335: 
epoch:  326
2022-05-28 04:35:18.073704: train loss : -0.8089
2022-05-28 04:35:26.391628: validation loss: -0.7556
2022-05-28 04:35:26.395334: Average global foreground Dice: [0.82]
2022-05-28 04:35:26.398237: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:35:26.854466: lr: 0.003847
2022-05-28 04:35:26.857913: This epoch took 99.607558 s

2022-05-28 04:35:26.862132: 
epoch:  327
2022-05-28 04:36:58.069808: train loss : -0.8097
2022-05-28 04:37:07.354286: validation loss: -0.7656
2022-05-28 04:37:07.358227: Average global foreground Dice: [0.8074]
2022-05-28 04:37:07.360567: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:37:07.818896: lr: 0.003827
2022-05-28 04:37:07.848332: This epoch took 100.983527 s

2022-05-28 04:37:07.881288: 
epoch:  328
2022-05-28 04:38:47.442068: train loss : -0.8137
2022-05-28 04:38:57.584770: validation loss: -0.7696
2022-05-28 04:38:57.588898: Average global foreground Dice: [0.7955]
2022-05-28 04:38:57.591491: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:38:58.045414: lr: 0.003807
2022-05-28 04:38:58.057447: This epoch took 110.153147 s

2022-05-28 04:38:58.063606: 
epoch:  329
2022-05-28 04:40:32.303767: train loss : -0.8098
2022-05-28 04:40:43.921686: validation loss: -0.8014
2022-05-28 04:40:43.950854: Average global foreground Dice: [0.8259]
2022-05-28 04:40:43.975354: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:40:44.595963: lr: 0.003787
2022-05-28 04:40:44.598269: This epoch took 106.521159 s

2022-05-28 04:40:44.600349: 
epoch:  330
2022-05-28 04:42:16.170261: train loss : -0.8129
2022-05-28 04:42:23.567197: validation loss: -0.7680
2022-05-28 04:42:23.576774: Average global foreground Dice: [0.7942]
2022-05-28 04:42:23.581280: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:42:24.113661: lr: 0.003767
2022-05-28 04:42:24.116627: This epoch took 99.514320 s

2022-05-28 04:42:24.123887: 
epoch:  331
2022-05-28 04:43:55.142455: train loss : -0.8173
2022-05-28 04:44:04.509183: validation loss: -0.7584
2022-05-28 04:44:04.512534: Average global foreground Dice: [0.7922]
2022-05-28 04:44:04.514746: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:44:04.963035: lr: 0.003747
2022-05-28 04:44:04.965330: This epoch took 100.838898 s

2022-05-28 04:44:04.967409: 
epoch:  332
2022-05-28 04:45:42.316741: train loss : -0.8011
2022-05-28 04:45:50.046035: validation loss: -0.7714
2022-05-28 04:45:50.087843: Average global foreground Dice: [0.8016]
2022-05-28 04:45:50.090507: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:45:50.848607: lr: 0.003727
2022-05-28 04:45:50.861809: This epoch took 105.891984 s

2022-05-28 04:45:50.892562: 
epoch:  333
2022-05-28 04:47:28.022650: train loss : -0.8126
2022-05-28 04:47:34.752030: validation loss: -0.7626
2022-05-28 04:47:34.755429: Average global foreground Dice: [0.8078]
2022-05-28 04:47:34.757257: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:47:35.199557: lr: 0.003707
2022-05-28 04:47:35.202415: This epoch took 104.299114 s

2022-05-28 04:47:35.205019: 
epoch:  334
2022-05-28 04:49:06.485738: train loss : -0.8157
2022-05-28 04:49:16.971666: validation loss: -0.7820
2022-05-28 04:49:16.975310: Average global foreground Dice: [0.8205]
2022-05-28 04:49:16.978080: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:49:17.443508: lr: 0.003687
2022-05-28 04:49:17.446134: This epoch took 102.238684 s

2022-05-28 04:49:17.448717: 
epoch:  335
2022-05-28 04:50:50.753657: train loss : -0.8076
2022-05-28 04:51:00.986978: validation loss: -0.7564
2022-05-28 04:51:00.990304: Average global foreground Dice: [0.8073]
2022-05-28 04:51:00.992692: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:51:01.464456: lr: 0.003667
2022-05-28 04:51:01.467209: This epoch took 104.016114 s

2022-05-28 04:51:01.469465: 
epoch:  336
2022-05-28 04:52:38.518334: train loss : -0.8099
2022-05-28 04:52:48.966437: validation loss: -0.7822
2022-05-28 04:52:49.001795: Average global foreground Dice: [0.812]
2022-05-28 04:52:49.022301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:52:49.733214: lr: 0.003647
2022-05-28 04:52:49.752650: This epoch took 108.281065 s

2022-05-28 04:52:49.777316: 
epoch:  337
2022-05-28 04:54:23.336958: train loss : -0.8086
2022-05-28 04:54:33.336995: validation loss: -0.7881
2022-05-28 04:54:33.349380: Average global foreground Dice: [0.8117]
2022-05-28 04:54:33.351975: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:54:33.972755: lr: 0.003627
2022-05-28 04:54:33.975289: This epoch took 104.182667 s

2022-05-28 04:54:33.977490: 
epoch:  338
2022-05-28 04:56:06.125990: train loss : -0.8202
2022-05-28 04:56:16.898067: validation loss: -0.7803
2022-05-28 04:56:16.936697: Average global foreground Dice: [0.81]
2022-05-28 04:56:16.956975: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:56:17.421483: lr: 0.003606
2022-05-28 04:56:17.430053: This epoch took 103.450442 s

2022-05-28 04:56:17.434125: 
epoch:  339
2022-05-28 04:57:48.413056: train loss : -0.8227
2022-05-28 04:57:58.335090: validation loss: -0.7908
2022-05-28 04:57:58.341135: Average global foreground Dice: [0.8143]
2022-05-28 04:57:58.343596: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:57:58.828744: lr: 0.003586
2022-05-28 04:57:58.831352: This epoch took 101.388364 s

2022-05-28 04:57:58.833649: 
epoch:  340
2022-05-28 04:59:31.818710: train loss : -0.8184
2022-05-28 04:59:42.716877: validation loss: -0.7737
2022-05-28 04:59:42.720546: Average global foreground Dice: [0.8014]
2022-05-28 04:59:42.722841: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 04:59:43.181198: lr: 0.003566
2022-05-28 04:59:43.183625: This epoch took 104.347845 s

2022-05-28 04:59:43.185887: 
epoch:  341
2022-05-28 05:01:20.176747: train loss : -0.8231
2022-05-28 05:01:27.718647: validation loss: -0.7629
2022-05-28 05:01:27.722029: Average global foreground Dice: [0.8016]
2022-05-28 05:01:27.724776: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:01:28.221043: lr: 0.003546
2022-05-28 05:01:28.224670: This epoch took 105.036575 s

2022-05-28 05:01:28.227273: 
epoch:  342
2022-05-28 05:03:02.723137: train loss : -0.8148
2022-05-28 05:03:11.298094: validation loss: -0.7906
2022-05-28 05:03:11.301716: Average global foreground Dice: [0.8129]
2022-05-28 05:03:11.304349: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:03:11.778461: lr: 0.003526
2022-05-28 05:03:11.781591: This epoch took 103.552120 s

2022-05-28 05:03:11.783919: 
epoch:  343
2022-05-28 05:04:43.375927: train loss : -0.8192
2022-05-28 05:04:53.390039: validation loss: -0.7863
2022-05-28 05:04:53.394447: Average global foreground Dice: [0.8172]
2022-05-28 05:04:53.397100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:04:53.912526: lr: 0.003505
2022-05-28 05:04:53.916276: This epoch took 102.130127 s

2022-05-28 05:04:53.919772: 
epoch:  344
2022-05-28 05:06:31.053825: train loss : -0.8263
2022-05-28 05:06:40.982862: validation loss: -0.7538
2022-05-28 05:06:40.986474: Average global foreground Dice: [0.7803]
2022-05-28 05:06:40.988942: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:06:41.451249: lr: 0.003485
2022-05-28 05:06:41.454050: This epoch took 107.532379 s

2022-05-28 05:06:41.456502: 
epoch:  345
2022-05-28 05:08:12.286546: train loss : -0.8247
2022-05-28 05:08:20.520404: validation loss: -0.7965
2022-05-28 05:08:20.524602: Average global foreground Dice: [0.832]
2022-05-28 05:08:20.530852: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:08:21.026384: lr: 0.003465
2022-05-28 05:08:21.029380: This epoch took 99.570663 s

2022-05-28 05:08:21.031865: 
epoch:  346
2022-05-28 05:09:50.947714: train loss : -0.8269
2022-05-28 05:09:57.522662: validation loss: -0.7832
2022-05-28 05:09:57.531371: Average global foreground Dice: [0.8111]
2022-05-28 05:09:57.533748: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:09:57.994871: lr: 0.003445
2022-05-28 05:09:57.997573: This epoch took 96.963101 s

2022-05-28 05:09:57.999846: 
epoch:  347
2022-05-28 05:11:29.520356: train loss : -0.8151
2022-05-28 05:11:37.824192: validation loss: -0.7873
2022-05-28 05:11:37.833954: Average global foreground Dice: [0.8186]
2022-05-28 05:11:37.846008: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:11:38.341345: lr: 0.003424
2022-05-28 05:11:38.401801: saving checkpoint...
2022-05-28 05:11:39.622885: done, saving took 1.28 seconds
2022-05-28 05:11:39.640358: This epoch took 101.638276 s

2022-05-28 05:11:39.642599: 
epoch:  348
2022-05-28 05:13:10.631208: train loss : -0.8292
2022-05-28 05:13:20.621659: validation loss: -0.7979
2022-05-28 05:13:20.653141: Average global foreground Dice: [0.8262]
2022-05-28 05:13:20.660030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:13:21.141496: lr: 0.003404
2022-05-28 05:13:21.178401: saving checkpoint...
2022-05-28 05:13:22.235084: done, saving took 1.09 seconds
2022-05-28 05:13:22.248568: This epoch took 102.603754 s

2022-05-28 05:13:22.251239: 
epoch:  349
2022-05-28 05:14:53.341410: train loss : -0.8089
2022-05-28 05:15:04.726536: validation loss: -0.7659
2022-05-28 05:15:04.743784: Average global foreground Dice: [0.8114]
2022-05-28 05:15:04.771581: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:15:05.300097: lr: 0.003384
2022-05-28 05:15:05.322290: saving scheduled checkpoint file...
2022-05-28 05:15:05.377415: saving checkpoint...
2022-05-28 05:15:06.650723: done, saving took 1.31 seconds
2022-05-28 05:15:06.665518: done
2022-05-28 05:15:06.667962: This epoch took 104.412525 s

2022-05-28 05:15:06.671419: 
epoch:  350
2022-05-28 05:16:38.537027: train loss : -0.8168
2022-05-28 05:16:47.158491: validation loss: -0.7872
2022-05-28 05:16:47.184829: Average global foreground Dice: [0.8194]
2022-05-28 05:16:47.191778: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:16:47.843239: lr: 0.003364
2022-05-28 05:16:47.910022: saving checkpoint...
2022-05-28 05:16:49.105315: done, saving took 1.24 seconds
2022-05-28 05:16:49.124221: This epoch took 102.450533 s

2022-05-28 05:16:49.126894: 
epoch:  351
2022-05-28 05:18:26.299565: train loss : -0.8142
2022-05-28 05:18:35.349800: validation loss: -0.7816
2022-05-28 05:18:35.376760: Average global foreground Dice: [0.804]
2022-05-28 05:18:35.424552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:18:36.600730: lr: 0.003343
2022-05-28 05:18:36.639287: This epoch took 107.509781 s

2022-05-28 05:18:36.659409: 
epoch:  352
2022-05-28 05:20:08.579616: train loss : -0.8066
2022-05-28 05:20:16.858487: validation loss: -0.7693
2022-05-28 05:20:16.862174: Average global foreground Dice: [0.8092]
2022-05-28 05:20:16.864439: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:20:17.320741: lr: 0.003323
2022-05-28 05:20:17.338032: This epoch took 100.651733 s

2022-05-28 05:20:17.343762: 
epoch:  353
2022-05-28 05:21:49.393148: train loss : -0.8014
2022-05-28 05:22:00.614785: validation loss: -0.7659
2022-05-28 05:22:00.652606: Average global foreground Dice: [0.8003]
2022-05-28 05:22:00.673813: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:22:01.453828: lr: 0.003303
2022-05-28 05:22:01.478162: This epoch took 104.131611 s

2022-05-28 05:22:01.508280: 
epoch:  354
2022-05-28 05:23:42.066967: train loss : -0.8063
2022-05-28 05:23:52.077151: validation loss: -0.7742
2022-05-28 05:23:52.084287: Average global foreground Dice: [0.8047]
2022-05-28 05:23:52.087017: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:23:52.536263: lr: 0.003282
2022-05-28 05:23:52.539467: This epoch took 111.009168 s

2022-05-28 05:23:52.542240: 
epoch:  355
2022-05-28 05:25:31.191841: train loss : -0.8042
2022-05-28 05:25:39.481349: validation loss: -0.7741
2022-05-28 05:25:39.494868: Average global foreground Dice: [0.7979]
2022-05-28 05:25:39.497416: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:25:39.979231: lr: 0.003262
2022-05-28 05:25:39.996332: This epoch took 107.451287 s

2022-05-28 05:25:40.012609: 
epoch:  356
2022-05-28 05:27:12.055907: train loss : -0.8135
2022-05-28 05:27:20.599008: validation loss: -0.7767
2022-05-28 05:27:20.602789: Average global foreground Dice: [0.8122]
2022-05-28 05:27:20.604996: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:27:21.049633: lr: 0.003241
2022-05-28 05:27:21.052165: This epoch took 101.019466 s

2022-05-28 05:27:21.054346: 
epoch:  357
2022-05-28 05:28:52.603767: train loss : -0.8206
2022-05-28 05:29:01.403824: validation loss: -0.7837
2022-05-28 05:29:01.412765: Average global foreground Dice: [0.813]
2022-05-28 05:29:01.445260: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:29:02.066976: lr: 0.003221
2022-05-28 05:29:02.089352: This epoch took 101.032856 s

2022-05-28 05:29:02.103138: 
epoch:  358
2022-05-28 05:30:32.816297: train loss : -0.8313
2022-05-28 05:30:41.683820: validation loss: -0.7764
2022-05-28 05:30:41.715684: Average global foreground Dice: [0.8073]
2022-05-28 05:30:41.742277: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:30:42.281917: lr: 0.003201
2022-05-28 05:30:42.316305: This epoch took 100.203374 s

2022-05-28 05:30:42.366189: 
epoch:  359
2022-05-28 05:32:15.492399: train loss : -0.8123
2022-05-28 05:32:23.010437: validation loss: -0.7830
2022-05-28 05:32:23.020770: Average global foreground Dice: [0.8159]
2022-05-28 05:32:23.023410: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:32:23.714569: lr: 0.00318
2022-05-28 05:32:23.734324: This epoch took 101.319028 s

2022-05-28 05:32:23.752014: 
epoch:  360
2022-05-28 05:33:57.664741: train loss : -0.8225
2022-05-28 05:34:06.802688: validation loss: -0.7875
2022-05-28 05:34:06.818329: Average global foreground Dice: [0.8202]
2022-05-28 05:34:06.848417: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:34:07.580720: lr: 0.00316
2022-05-28 05:34:07.611437: This epoch took 103.857193 s

2022-05-28 05:34:07.631316: 
epoch:  361
2022-05-28 05:35:38.751198: train loss : -0.8235
2022-05-28 05:35:45.587604: validation loss: -0.7732
2022-05-28 05:35:45.598432: Average global foreground Dice: [0.8037]
2022-05-28 05:35:45.601289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:35:46.057704: lr: 0.003139
2022-05-28 05:35:46.059806: This epoch took 98.403378 s

2022-05-28 05:35:46.061778: 
epoch:  362
2022-05-28 05:37:17.552718: train loss : -0.8230
2022-05-28 05:37:28.369250: validation loss: -0.7393
2022-05-28 05:37:28.382372: Average global foreground Dice: [0.7933]
2022-05-28 05:37:28.418330: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:37:29.277299: lr: 0.003119
2022-05-28 05:37:29.288340: This epoch took 103.224664 s

2022-05-28 05:37:29.300295: 
epoch:  363
2022-05-28 05:38:59.052924: train loss : -0.8108
2022-05-28 05:39:06.588260: validation loss: -0.7854
2022-05-28 05:39:06.592679: Average global foreground Dice: [0.8046]
2022-05-28 05:39:06.595170: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:39:07.071549: lr: 0.003098
2022-05-28 05:39:07.074007: This epoch took 97.766204 s

2022-05-28 05:39:07.075999: 
epoch:  364
2022-05-28 05:40:42.374934: train loss : -0.8206
2022-05-28 05:40:52.850917: validation loss: -0.7845
2022-05-28 05:40:52.855562: Average global foreground Dice: [0.8184]
2022-05-28 05:40:52.858118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:40:53.328365: lr: 0.003078
2022-05-28 05:40:53.330844: This epoch took 106.252749 s

2022-05-28 05:40:53.337919: 
epoch:  365
2022-05-28 05:42:24.820454: train loss : -0.8289
2022-05-28 05:42:33.530640: validation loss: -0.8048
2022-05-28 05:42:33.560775: Average global foreground Dice: [0.8238]
2022-05-28 05:42:33.588461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:42:34.258715: lr: 0.003057
2022-05-28 05:42:34.261391: This epoch took 100.921040 s

2022-05-28 05:42:34.263717: 
epoch:  366
2022-05-28 05:44:08.811628: train loss : -0.8280
2022-05-28 05:44:17.171837: validation loss: -0.7705
2022-05-28 05:44:17.182492: Average global foreground Dice: [0.8106]
2022-05-28 05:44:17.184738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:44:17.713573: lr: 0.003037
2022-05-28 05:44:17.716666: This epoch took 103.450369 s

2022-05-28 05:44:17.719006: 
epoch:  367
2022-05-28 05:45:48.333275: train loss : -0.8157
2022-05-28 05:45:56.364435: validation loss: -0.7609
2022-05-28 05:45:56.367653: Average global foreground Dice: [0.7954]
2022-05-28 05:45:56.370118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:45:56.861199: lr: 0.003016
2022-05-28 05:45:56.863617: This epoch took 99.142326 s

2022-05-28 05:45:56.866134: 
epoch:  368
2022-05-28 05:47:31.524996: train loss : -0.8227
2022-05-28 05:47:40.411767: validation loss: -0.7776
2022-05-28 05:47:40.417415: Average global foreground Dice: [0.8118]
2022-05-28 05:47:40.419714: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:47:41.018857: lr: 0.002996
2022-05-28 05:47:41.040331: This epoch took 104.169266 s

2022-05-28 05:47:41.060572: 
epoch:  369
2022-05-28 05:49:14.526006: train loss : -0.8226
2022-05-28 05:49:24.320616: validation loss: -0.7685
2022-05-28 05:49:24.323964: Average global foreground Dice: [0.8085]
2022-05-28 05:49:24.326274: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:49:24.822682: lr: 0.002975
2022-05-28 05:49:24.828193: This epoch took 103.747528 s

2022-05-28 05:49:24.832315: 
epoch:  370
2022-05-28 05:51:03.771668: train loss : -0.8235
2022-05-28 05:51:12.459803: validation loss: -0.7639
2022-05-28 05:51:12.463471: Average global foreground Dice: [0.8206]
2022-05-28 05:51:12.465905: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:51:12.936765: lr: 0.002954
2022-05-28 05:51:12.939205: This epoch took 108.104733 s

2022-05-28 05:51:12.941421: 
epoch:  371
2022-05-28 05:52:50.474086: train loss : -0.8195
2022-05-28 05:53:00.723618: validation loss: -0.7711
2022-05-28 05:53:00.727429: Average global foreground Dice: [0.803]
2022-05-28 05:53:00.729940: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:53:01.252885: lr: 0.002934
2022-05-28 05:53:01.255603: This epoch took 108.312055 s

2022-05-28 05:53:01.258032: 
epoch:  372
2022-05-28 05:54:34.235154: train loss : -0.8295
2022-05-28 05:54:42.415249: validation loss: -0.7725
2022-05-28 05:54:42.445778: Average global foreground Dice: [0.8201]
2022-05-28 05:54:42.471568: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:54:43.352079: lr: 0.002913
2022-05-28 05:54:43.354750: This epoch took 102.093897 s

2022-05-28 05:54:43.356939: 
epoch:  373
2022-05-28 05:56:19.914768: train loss : -0.8268
2022-05-28 05:56:29.413187: validation loss: -0.7818
2022-05-28 05:56:29.416784: Average global foreground Dice: [0.814]
2022-05-28 05:56:29.422296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:56:29.928883: lr: 0.002892
2022-05-28 05:56:29.932362: This epoch took 106.560335 s

2022-05-28 05:56:29.935082: 
epoch:  374
2022-05-28 05:58:01.433630: train loss : -0.8293
2022-05-28 05:58:10.189154: validation loss: -0.7911
2022-05-28 05:58:10.192958: Average global foreground Dice: [0.8129]
2022-05-28 05:58:10.195565: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:58:10.655871: lr: 0.002872
2022-05-28 05:58:10.658289: This epoch took 100.720210 s

2022-05-28 05:58:10.662906: 
epoch:  375
2022-05-28 05:59:45.915504: train loss : -0.8342
2022-05-28 05:59:55.071198: validation loss: -0.7739
2022-05-28 05:59:55.095141: Average global foreground Dice: [0.8252]
2022-05-28 05:59:55.123372: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 05:59:55.757021: lr: 0.002851
2022-05-28 05:59:55.815068: saving checkpoint...
2022-05-28 05:59:57.108000: done, saving took 1.35 seconds
2022-05-28 05:59:57.134914: This epoch took 106.469631 s

2022-05-28 05:59:57.137193: 
epoch:  376
2022-05-28 06:01:28.956550: train loss : -0.8379
2022-05-28 06:01:36.942108: validation loss: -0.7929
2022-05-28 06:01:36.945757: Average global foreground Dice: [0.8215]
2022-05-28 06:01:36.948155: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:01:37.424271: lr: 0.00283
2022-05-28 06:01:37.467966: saving checkpoint...
2022-05-28 06:01:38.605266: done, saving took 1.17 seconds
2022-05-28 06:01:38.621334: This epoch took 101.481569 s

2022-05-28 06:01:38.623847: 
epoch:  377
2022-05-28 06:03:09.868741: train loss : -0.8251
2022-05-28 06:03:17.616523: validation loss: -0.7870
2022-05-28 06:03:17.627910: Average global foreground Dice: [0.81]
2022-05-28 06:03:17.630722: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:03:18.177943: lr: 0.00281
2022-05-28 06:03:18.199334: This epoch took 99.568902 s

2022-05-28 06:03:18.221293: 
epoch:  378
2022-05-28 06:04:49.928639: train loss : -0.8302
2022-05-28 06:04:58.570804: validation loss: -0.7867
2022-05-28 06:04:58.590882: Average global foreground Dice: [0.8148]
2022-05-28 06:04:58.597218: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:04:59.222751: lr: 0.002789
2022-05-28 06:04:59.228633: This epoch took 100.993696 s

2022-05-28 06:04:59.233334: 
epoch:  379
2022-05-28 06:06:36.676554: train loss : -0.8350
2022-05-28 06:06:45.193020: validation loss: -0.7803
2022-05-28 06:06:45.196573: Average global foreground Dice: [0.8139]
2022-05-28 06:06:45.198781: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:06:45.683352: lr: 0.002768
2022-05-28 06:06:45.686011: This epoch took 106.450528 s

2022-05-28 06:06:45.688277: 
epoch:  380
2022-05-28 06:08:18.450183: train loss : -0.8295
2022-05-28 06:08:27.672394: validation loss: -0.7787
2022-05-28 06:08:27.675973: Average global foreground Dice: [0.8163]
2022-05-28 06:08:27.678976: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:08:28.149536: lr: 0.002747
2022-05-28 06:08:28.198232: saving checkpoint...
2022-05-28 06:08:29.294235: done, saving took 1.14 seconds
2022-05-28 06:08:29.310063: This epoch took 103.619676 s

2022-05-28 06:08:29.313870: 
epoch:  381
2022-05-28 06:10:02.164980: train loss : -0.8210
2022-05-28 06:10:10.976097: validation loss: -0.7628
2022-05-28 06:10:10.980832: Average global foreground Dice: [0.7926]
2022-05-28 06:10:10.994450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:10:11.606439: lr: 0.002727
2022-05-28 06:10:11.635526: This epoch took 102.317866 s

2022-05-28 06:10:11.647141: 
epoch:  382
2022-05-28 06:11:44.462724: train loss : -0.8309
2022-05-28 06:11:53.370871: validation loss: -0.7750
2022-05-28 06:11:53.374994: Average global foreground Dice: [0.814]
2022-05-28 06:11:53.377550: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:11:53.857839: lr: 0.002706
2022-05-28 06:11:53.860300: This epoch took 102.197008 s

2022-05-28 06:11:53.862673: 
epoch:  383
2022-05-28 06:13:25.973094: train loss : -0.8176
2022-05-28 06:13:33.584595: validation loss: -0.7911
2022-05-28 06:13:33.588305: Average global foreground Dice: [0.8211]
2022-05-28 06:13:33.601496: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:13:34.070412: lr: 0.002685
2022-05-28 06:13:34.100502: This epoch took 100.235510 s

2022-05-28 06:13:34.119323: 
epoch:  384
2022-05-28 06:15:12.141605: train loss : -0.8277
2022-05-28 06:15:20.692307: validation loss: -0.7930
2022-05-28 06:15:20.715839: Average global foreground Dice: [0.8193]
2022-05-28 06:15:20.734307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:15:21.717914: lr: 0.002664
2022-05-28 06:15:21.761334: This epoch took 107.619039 s

2022-05-28 06:15:21.794289: 
epoch:  385
2022-05-28 06:16:53.483809: train loss : -0.8366
2022-05-28 06:17:04.447098: validation loss: -0.7859
2022-05-28 06:17:04.477031: Average global foreground Dice: [0.8222]
2022-05-28 06:17:04.482270: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:17:04.981548: lr: 0.002643
2022-05-28 06:17:05.037395: saving checkpoint...
2022-05-28 06:17:06.045848: done, saving took 1.06 seconds
2022-05-28 06:17:06.060362: This epoch took 104.230063 s

2022-05-28 06:17:06.062564: 
epoch:  386
2022-05-28 06:18:43.624608: train loss : -0.8184
2022-05-28 06:18:54.905552: validation loss: -0.7702
2022-05-28 06:18:54.909275: Average global foreground Dice: [0.806]
2022-05-28 06:18:54.911686: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:18:55.359524: lr: 0.002622
2022-05-28 06:18:55.361981: This epoch took 109.297176 s

2022-05-28 06:18:55.364160: 
epoch:  387
2022-05-28 06:20:30.131098: train loss : -0.8371
2022-05-28 06:20:39.788474: validation loss: -0.7858
2022-05-28 06:20:39.792365: Average global foreground Dice: [0.8166]
2022-05-28 06:20:39.795514: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:20:40.264536: lr: 0.002601
2022-05-28 06:20:40.269191: This epoch took 104.902746 s

2022-05-28 06:20:40.270981: 
epoch:  388
2022-05-28 06:22:11.462406: train loss : -0.8265
2022-05-28 06:22:21.315321: validation loss: -0.8127
2022-05-28 06:22:21.333397: Average global foreground Dice: [0.8355]
2022-05-28 06:22:21.336108: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:22:21.867277: lr: 0.002581
2022-05-28 06:22:21.950176: saving checkpoint...
2022-05-28 06:22:23.062671: done, saving took 1.19 seconds
2022-05-28 06:22:23.079479: This epoch took 102.805050 s

2022-05-28 06:22:23.081938: 
epoch:  389
2022-05-28 06:23:56.356651: train loss : -0.8340
2022-05-28 06:24:05.981711: validation loss: -0.7813
2022-05-28 06:24:05.985324: Average global foreground Dice: [0.8138]
2022-05-28 06:24:05.987993: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:24:06.473895: lr: 0.00256
2022-05-28 06:24:06.476287: This epoch took 103.392044 s

2022-05-28 06:24:06.478773: 
epoch:  390
2022-05-28 06:25:38.016723: train loss : -0.8342
2022-05-28 06:25:48.670532: validation loss: -0.8046
2022-05-28 06:25:48.674327: Average global foreground Dice: [0.8289]
2022-05-28 06:25:48.676972: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:25:49.149718: lr: 0.002539
2022-05-28 06:25:49.205509: saving checkpoint...
2022-05-28 06:25:50.397522: done, saving took 1.24 seconds
2022-05-28 06:25:50.412858: This epoch took 103.931564 s

2022-05-28 06:25:50.415566: 
epoch:  391
2022-05-28 06:27:21.030412: train loss : -0.8360
2022-05-28 06:27:30.620252: validation loss: -0.7876
2022-05-28 06:27:30.624606: Average global foreground Dice: [0.8135]
2022-05-28 06:27:30.627427: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:27:31.100010: lr: 0.002518
2022-05-28 06:27:31.102656: This epoch took 100.684685 s

2022-05-28 06:27:31.106392: 
epoch:  392
2022-05-28 06:29:07.317750: train loss : -0.8373
2022-05-28 06:29:17.761153: validation loss: -0.7907
2022-05-28 06:29:17.765340: Average global foreground Dice: [0.81]
2022-05-28 06:29:17.768324: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:29:18.277507: lr: 0.002497
2022-05-28 06:29:18.279951: This epoch took 107.169596 s

2022-05-28 06:29:18.282517: 
epoch:  393
2022-05-28 06:31:00.522489: train loss : -0.8189
2022-05-28 06:31:10.617413: validation loss: -0.7586
2022-05-28 06:31:10.621120: Average global foreground Dice: [0.7967]
2022-05-28 06:31:10.623464: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:31:11.153968: lr: 0.002476
2022-05-28 06:31:11.165153: This epoch took 112.880474 s

2022-05-28 06:31:11.168435: 
epoch:  394
2022-05-28 06:32:46.314100: train loss : -0.8268
2022-05-28 06:32:56.265815: validation loss: -0.7659
2022-05-28 06:32:56.275076: Average global foreground Dice: [0.8088]
2022-05-28 06:32:56.281674: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:32:56.776467: lr: 0.002455
2022-05-28 06:32:56.780510: This epoch took 105.609368 s

2022-05-28 06:32:56.790614: 
epoch:  395
2022-05-28 06:34:28.118767: train loss : -0.8324
2022-05-28 06:34:38.322671: validation loss: -0.7723
2022-05-28 06:34:38.326390: Average global foreground Dice: [0.8219]
2022-05-28 06:34:38.328514: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:34:38.812391: lr: 0.002434
2022-05-28 06:34:38.814748: This epoch took 102.004668 s

2022-05-28 06:34:38.816923: 
epoch:  396
2022-05-28 06:36:08.832588: train loss : -0.8451
2022-05-28 06:36:14.626740: validation loss: -0.7678
2022-05-28 06:36:14.630250: Average global foreground Dice: [0.8289]
2022-05-28 06:36:14.632519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:36:15.093618: lr: 0.002413
2022-05-28 06:36:15.096225: This epoch took 96.277158 s

2022-05-28 06:36:15.098649: 
epoch:  397
2022-05-28 06:37:52.601395: train loss : -0.8254
2022-05-28 06:38:02.314437: validation loss: -0.7643
2022-05-28 06:38:02.318038: Average global foreground Dice: [0.8099]
2022-05-28 06:38:02.321297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:38:02.843235: lr: 0.002391
2022-05-28 06:38:02.845829: This epoch took 107.744888 s

2022-05-28 06:38:02.848317: 
epoch:  398
2022-05-28 06:39:35.402363: train loss : -0.8459
2022-05-28 06:39:44.435208: validation loss: -0.7802
2022-05-28 06:39:44.466759: Average global foreground Dice: [0.8104]
2022-05-28 06:39:44.496307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:39:45.293938: lr: 0.00237
2022-05-28 06:39:45.296603: This epoch took 102.445839 s

2022-05-28 06:39:45.298937: 
epoch:  399
2022-05-28 06:41:16.958693: train loss : -0.8261
2022-05-28 06:41:26.602103: validation loss: -0.7756
2022-05-28 06:41:26.607422: Average global foreground Dice: [0.8131]
2022-05-28 06:41:26.609601: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:41:27.152718: lr: 0.002349
2022-05-28 06:41:27.161879: saving scheduled checkpoint file...
2022-05-28 06:41:27.210006: saving checkpoint...
2022-05-28 06:41:28.214018: done, saving took 1.04 seconds
2022-05-28 06:41:28.232044: done
2022-05-28 06:41:28.234593: This epoch took 102.920086 s

2022-05-28 06:41:28.236725: 
epoch:  400
2022-05-28 06:42:58.693357: train loss : -0.8284
2022-05-28 06:43:06.496210: validation loss: -0.7784
2022-05-28 06:43:06.499421: Average global foreground Dice: [0.8096]
2022-05-28 06:43:06.501468: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:43:06.964713: lr: 0.002328
2022-05-28 06:43:06.967416: This epoch took 98.728586 s

2022-05-28 06:43:06.969811: 
epoch:  401
2022-05-28 06:44:38.634063: train loss : -0.8353
2022-05-28 06:44:48.351895: validation loss: -0.7671
2022-05-28 06:44:48.355480: Average global foreground Dice: [0.8034]
2022-05-28 06:44:48.357662: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:44:48.837363: lr: 0.002307
2022-05-28 06:44:48.839797: This epoch took 101.867663 s

2022-05-28 06:44:48.841782: 
epoch:  402
2022-05-28 06:46:19.823519: train loss : -0.8343
2022-05-28 06:46:27.299055: validation loss: -0.8038
2022-05-28 06:46:27.307079: Average global foreground Dice: [0.8326]
2022-05-28 06:46:27.310147: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:46:27.799402: lr: 0.002286
2022-05-28 06:46:27.801999: This epoch took 98.958379 s

2022-05-28 06:46:27.804377: 
epoch:  403
2022-05-28 06:47:57.971892: train loss : -0.8368
2022-05-28 06:48:03.801953: validation loss: -0.7709
2022-05-28 06:48:03.805403: Average global foreground Dice: [0.8226]
2022-05-28 06:48:03.809848: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:48:04.296144: lr: 0.002264
2022-05-28 06:48:04.299651: This epoch took 96.466357 s

2022-05-28 06:48:04.302484: 
epoch:  404
2022-05-28 06:49:35.726926: train loss : -0.8380
2022-05-28 06:49:45.541054: validation loss: -0.7932
2022-05-28 06:49:45.544746: Average global foreground Dice: [0.8159]
2022-05-28 06:49:45.568561: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:49:46.062939: lr: 0.002243
2022-05-28 06:49:46.069346: This epoch took 101.764318 s

2022-05-28 06:49:46.072509: 
epoch:  405
2022-05-28 06:51:23.408284: train loss : -0.8296
2022-05-28 06:51:33.053542: validation loss: -0.7709
2022-05-28 06:51:33.057275: Average global foreground Dice: [0.8125]
2022-05-28 06:51:33.059533: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:51:33.522594: lr: 0.002222
2022-05-28 06:51:33.524803: This epoch took 107.446883 s

2022-05-28 06:51:33.526940: 
epoch:  406
2022-05-28 06:53:07.788539: train loss : -0.8333
2022-05-28 06:53:17.342846: validation loss: -0.7996
2022-05-28 06:53:17.348534: Average global foreground Dice: [0.8245]
2022-05-28 06:53:17.350594: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:53:17.807131: lr: 0.002201
2022-05-28 06:53:17.809483: This epoch took 104.280576 s

2022-05-28 06:53:17.811483: 
epoch:  407
2022-05-28 06:54:48.727010: train loss : -0.8449
2022-05-28 06:54:57.252325: validation loss: -0.7742
2022-05-28 06:54:57.256008: Average global foreground Dice: [0.818]
2022-05-28 06:54:57.258265: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:54:57.756399: lr: 0.002179
2022-05-28 06:54:57.758596: This epoch took 99.945249 s

2022-05-28 06:54:57.760784: 
epoch:  408
2022-05-28 06:56:28.825597: train loss : -0.8308
2022-05-28 06:56:36.694917: validation loss: -0.7748
2022-05-28 06:56:36.698459: Average global foreground Dice: [0.8115]
2022-05-28 06:56:36.700717: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:56:37.174508: lr: 0.002158
2022-05-28 06:56:37.176959: This epoch took 99.414034 s

2022-05-28 06:56:37.179341: 
epoch:  409
2022-05-28 06:58:10.682677: train loss : -0.8238
2022-05-28 06:58:22.168766: validation loss: -0.7840
2022-05-28 06:58:22.185993: Average global foreground Dice: [0.8143]
2022-05-28 06:58:22.188264: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 06:58:22.686134: lr: 0.002137
2022-05-28 06:58:22.746700: This epoch took 105.565189 s

2022-05-28 06:58:22.749190: 
epoch:  410
2022-05-28 06:59:55.059654: train loss : -0.8251
2022-05-28 07:00:04.852621: validation loss: -0.7580
2022-05-28 07:00:04.858579: Average global foreground Dice: [0.8031]
2022-05-28 07:00:04.872319: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:00:05.320341: lr: 0.002115
2022-05-28 07:00:05.322635: This epoch took 102.571302 s

2022-05-28 07:00:05.324777: 
epoch:  411
2022-05-28 07:01:39.159814: train loss : -0.8306
2022-05-28 07:01:47.495310: validation loss: -0.7968
2022-05-28 07:01:47.498586: Average global foreground Dice: [0.8188]
2022-05-28 07:01:47.500479: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:01:48.013581: lr: 0.002094
2022-05-28 07:01:48.024112: This epoch took 102.697463 s

2022-05-28 07:01:48.026713: 
epoch:  412
2022-05-28 07:03:23.186875: train loss : -0.8377
2022-05-28 07:03:32.134745: validation loss: -0.7916
2022-05-28 07:03:32.156897: Average global foreground Dice: [0.8204]
2022-05-28 07:03:32.182389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:03:32.831602: lr: 0.002072
2022-05-28 07:03:32.854343: This epoch took 104.825578 s

2022-05-28 07:03:32.887295: 
epoch:  413
2022-05-28 07:05:12.981975: train loss : -0.8338
2022-05-28 07:05:20.295449: validation loss: -0.7646
2022-05-28 07:05:20.301087: Average global foreground Dice: [0.8078]
2022-05-28 07:05:20.303736: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:05:20.815824: lr: 0.002051
2022-05-28 07:05:20.818590: This epoch took 107.908291 s

2022-05-28 07:05:20.821919: 
epoch:  414
2022-05-28 07:06:54.232364: train loss : -0.8309
2022-05-28 07:07:04.888586: validation loss: -0.7643
2022-05-28 07:07:04.893554: Average global foreground Dice: [0.8118]
2022-05-28 07:07:04.895692: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:07:05.501003: lr: 0.00203
2022-05-28 07:07:05.509584: This epoch took 104.685295 s

2022-05-28 07:07:05.513184: 
epoch:  415
2022-05-28 07:08:38.548772: train loss : -0.8428
2022-05-28 07:08:48.954585: validation loss: -0.7833
2022-05-28 07:08:48.958324: Average global foreground Dice: [0.8124]
2022-05-28 07:08:48.960713: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:08:49.442972: lr: 0.002008
2022-05-28 07:08:49.445456: This epoch took 103.929324 s

2022-05-28 07:08:49.447792: 
epoch:  416
2022-05-28 07:10:24.930627: train loss : -0.8414
2022-05-28 07:10:32.759028: validation loss: -0.7862
2022-05-28 07:10:32.763229: Average global foreground Dice: [0.827]
2022-05-28 07:10:32.765495: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:10:33.289693: lr: 0.001987
2022-05-28 07:10:33.292582: This epoch took 103.842530 s

2022-05-28 07:10:33.299294: 
epoch:  417
2022-05-28 07:12:08.887316: train loss : -0.8347
2022-05-28 07:12:16.881308: validation loss: -0.7854
2022-05-28 07:12:16.907129: Average global foreground Dice: [0.8154]
2022-05-28 07:12:16.926905: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:12:17.560704: lr: 0.001965
2022-05-28 07:12:17.562773: This epoch took 104.261348 s

2022-05-28 07:12:17.564753: 
epoch:  418
2022-05-28 07:13:48.229026: train loss : -0.8389
2022-05-28 07:13:56.818236: validation loss: -0.7853
2022-05-28 07:13:56.822493: Average global foreground Dice: [0.8223]
2022-05-28 07:13:56.824875: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:13:57.306587: lr: 0.001943
2022-05-28 07:13:57.309550: This epoch took 99.742967 s

2022-05-28 07:13:57.316468: 
epoch:  419
2022-05-28 07:15:31.669219: train loss : -0.8421
2022-05-28 07:15:40.601263: validation loss: -0.7688
2022-05-28 07:15:40.605555: Average global foreground Dice: [0.8102]
2022-05-28 07:15:40.608112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:15:41.134042: lr: 0.001922
2022-05-28 07:15:41.155412: This epoch took 103.836392 s

2022-05-28 07:15:41.184457: 
epoch:  420
2022-05-28 07:17:15.238317: train loss : -0.8316
2022-05-28 07:17:24.521389: validation loss: -0.8032
2022-05-28 07:17:24.525356: Average global foreground Dice: [0.8307]
2022-05-28 07:17:24.527640: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:17:25.041938: lr: 0.0019
2022-05-28 07:17:25.103832: saving checkpoint...
2022-05-28 07:17:26.253783: done, saving took 1.21 seconds
2022-05-28 07:17:26.270567: This epoch took 105.055932 s

2022-05-28 07:17:26.272863: 
epoch:  421
2022-05-28 07:18:59.764571: train loss : -0.8366
2022-05-28 07:19:08.925635: validation loss: -0.7903
2022-05-28 07:19:08.931035: Average global foreground Dice: [0.8103]
2022-05-28 07:19:08.933475: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:19:09.392540: lr: 0.001879
2022-05-28 07:19:09.395612: This epoch took 103.120340 s

2022-05-28 07:19:09.399218: 
epoch:  422
2022-05-28 07:20:45.741019: train loss : -0.8357
2022-05-28 07:20:58.052178: validation loss: -0.7768
2022-05-28 07:20:58.057528: Average global foreground Dice: [0.8099]
2022-05-28 07:20:58.059828: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:20:58.536058: lr: 0.001857
2022-05-28 07:20:58.538336: This epoch took 109.136800 s

2022-05-28 07:20:58.540479: 
epoch:  423
2022-05-28 07:22:29.709784: train loss : -0.8163
2022-05-28 07:22:39.333497: validation loss: -0.7945
2022-05-28 07:22:39.346890: Average global foreground Dice: [0.8173]
2022-05-28 07:22:39.373150: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:22:39.883854: lr: 0.001835
2022-05-28 07:22:39.886485: This epoch took 101.344050 s

2022-05-28 07:22:39.888754: 
epoch:  424
2022-05-28 07:24:11.314931: train loss : -0.8338
2022-05-28 07:24:20.602261: validation loss: -0.7962
2022-05-28 07:24:20.606293: Average global foreground Dice: [0.8184]
2022-05-28 07:24:20.608295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:24:21.117054: lr: 0.001813
2022-05-28 07:24:21.119461: This epoch took 101.228532 s

2022-05-28 07:24:21.121558: 
epoch:  425
2022-05-28 07:25:53.987145: train loss : -0.8393
2022-05-28 07:26:02.118386: validation loss: -0.7922
2022-05-28 07:26:02.146063: Average global foreground Dice: [0.8288]
2022-05-28 07:26:02.168301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:26:02.726229: lr: 0.001792
2022-05-28 07:26:02.798132: saving checkpoint...
2022-05-28 07:26:03.958594: done, saving took 1.22 seconds
2022-05-28 07:26:03.973680: This epoch took 102.850077 s

2022-05-28 07:26:03.976029: 
epoch:  426
2022-05-28 07:27:33.391946: train loss : -0.8460
2022-05-28 07:27:40.125320: validation loss: -0.8033
2022-05-28 07:27:40.128673: Average global foreground Dice: [0.8308]
2022-05-28 07:27:40.131850: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:27:40.609892: lr: 0.00177
2022-05-28 07:27:40.662849: saving checkpoint...
2022-05-28 07:27:41.677178: done, saving took 1.06 seconds
2022-05-28 07:27:41.692235: This epoch took 97.713929 s

2022-05-28 07:27:41.694247: 
epoch:  427
2022-05-28 07:29:11.649872: train loss : -0.8327
2022-05-28 07:29:18.881527: validation loss: -0.7731
2022-05-28 07:29:18.885006: Average global foreground Dice: [0.8165]
2022-05-28 07:29:18.887199: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:29:19.432306: lr: 0.001748
2022-05-28 07:29:19.434853: This epoch took 97.738384 s

2022-05-28 07:29:19.436832: 
epoch:  428
2022-05-28 07:30:58.726002: train loss : -0.8273
2022-05-28 07:31:06.405781: validation loss: -0.8057
2022-05-28 07:31:06.408952: Average global foreground Dice: [0.8282]
2022-05-28 07:31:06.410859: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:31:06.916513: lr: 0.001726
2022-05-28 07:31:06.963357: saving checkpoint...
2022-05-28 07:31:08.144351: done, saving took 1.23 seconds
2022-05-28 07:31:08.160201: This epoch took 108.720356 s

2022-05-28 07:31:08.162731: 
epoch:  429
2022-05-28 07:32:38.804749: train loss : -0.8361
2022-05-28 07:32:46.982169: validation loss: -0.8012
2022-05-28 07:32:47.006735: Average global foreground Dice: [0.8238]
2022-05-28 07:32:47.013952: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:32:47.587429: lr: 0.001704
2022-05-28 07:32:47.678889: saving checkpoint...
2022-05-28 07:32:48.734623: done, saving took 1.13 seconds
2022-05-28 07:32:48.748456: This epoch took 100.582671 s

2022-05-28 07:32:48.750407: 
epoch:  430
2022-05-28 07:34:21.680176: train loss : -0.8332
2022-05-28 07:34:33.976578: validation loss: -0.7974
2022-05-28 07:34:34.018739: Average global foreground Dice: [0.8183]
2022-05-28 07:34:34.041075: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:34:34.553079: lr: 0.001682
2022-05-28 07:34:34.555850: This epoch took 105.803500 s

2022-05-28 07:34:34.558170: 
epoch:  431
2022-05-28 07:36:05.752553: train loss : -0.8473
2022-05-28 07:36:20.363027: validation loss: -0.7810
2022-05-28 07:36:20.367102: Average global foreground Dice: [0.8034]
2022-05-28 07:36:20.370004: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:36:20.879342: lr: 0.00166
2022-05-28 07:36:20.881948: This epoch took 106.321555 s

2022-05-28 07:36:20.883810: 
epoch:  432
2022-05-28 07:37:52.624958: train loss : -0.8416
2022-05-28 07:38:02.314529: validation loss: -0.7684
2022-05-28 07:38:02.318126: Average global foreground Dice: [0.7965]
2022-05-28 07:38:02.320269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:38:02.846773: lr: 0.001638
2022-05-28 07:38:02.849550: This epoch took 101.963907 s

2022-05-28 07:38:02.851644: 
epoch:  433
2022-05-28 07:39:34.192745: train loss : -0.8503
2022-05-28 07:39:43.546415: validation loss: -0.7689
2022-05-28 07:39:43.562882: Average global foreground Dice: [0.8195]
2022-05-28 07:39:43.576193: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:39:44.128842: lr: 0.001616
2022-05-28 07:39:44.132325: This epoch took 101.270751 s

2022-05-28 07:39:44.134280: 
epoch:  434
2022-05-28 07:41:16.239265: train loss : -0.8482
2022-05-28 07:41:25.504464: validation loss: -0.7915
2022-05-28 07:41:25.527511: Average global foreground Dice: [0.8264]
2022-05-28 07:41:25.546360: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:41:26.055742: lr: 0.001594
2022-05-28 07:41:26.058126: This epoch took 101.921450 s

2022-05-28 07:41:26.060034: 
epoch:  435
2022-05-28 07:42:59.634638: train loss : -0.8495
2022-05-28 07:43:07.885091: validation loss: -0.7884
2022-05-28 07:43:07.889437: Average global foreground Dice: [0.8049]
2022-05-28 07:43:07.891534: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:43:08.365041: lr: 0.001572
2022-05-28 07:43:08.367458: This epoch took 102.305186 s

2022-05-28 07:43:08.370016: 
epoch:  436
2022-05-28 07:44:39.132432: train loss : -0.8549
2022-05-28 07:44:46.859131: validation loss: -0.7621
2022-05-28 07:44:46.862548: Average global foreground Dice: [0.8201]
2022-05-28 07:44:46.864519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:44:47.325588: lr: 0.00155
2022-05-28 07:44:47.327883: This epoch took 98.955739 s

2022-05-28 07:44:47.330289: 
epoch:  437
2022-05-28 07:46:18.280756: train loss : -0.8315
2022-05-28 07:46:24.789094: validation loss: -0.7828
2022-05-28 07:46:24.792353: Average global foreground Dice: [0.8138]
2022-05-28 07:46:24.794432: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:46:25.265926: lr: 0.001528
2022-05-28 07:46:25.268805: This epoch took 97.936516 s

2022-05-28 07:46:25.271209: 
epoch:  438
2022-05-28 07:47:58.225379: train loss : -0.8461
2022-05-28 07:48:07.658105: validation loss: -0.7887
2022-05-28 07:48:07.662763: Average global foreground Dice: [0.8154]
2022-05-28 07:48:07.665045: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:48:08.123933: lr: 0.001506
2022-05-28 07:48:08.126365: This epoch took 102.853056 s

2022-05-28 07:48:08.128650: 
epoch:  439
2022-05-28 07:49:38.364352: train loss : -0.8420
2022-05-28 07:49:47.228053: validation loss: -0.7989
2022-05-28 07:49:47.257664: Average global foreground Dice: [0.8227]
2022-05-28 07:49:47.277292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:49:47.845285: lr: 0.001483
2022-05-28 07:49:47.847768: This epoch took 99.716715 s

2022-05-28 07:49:47.849951: 
epoch:  440
2022-05-28 07:51:19.459862: train loss : -0.8467
2022-05-28 07:51:27.875032: validation loss: -0.7653
2022-05-28 07:51:27.888975: Average global foreground Dice: [0.8124]
2022-05-28 07:51:27.904382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:51:28.633356: lr: 0.001461
2022-05-28 07:51:28.660076: This epoch took 100.808001 s

2022-05-28 07:51:28.662290: 
epoch:  441
2022-05-28 07:53:02.334820: train loss : -0.8518
2022-05-28 07:53:11.769942: validation loss: -0.7927
2022-05-28 07:53:11.773930: Average global foreground Dice: [0.8177]
2022-05-28 07:53:11.780346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:53:12.267924: lr: 0.001439
2022-05-28 07:53:12.284324: This epoch took 103.619905 s

2022-05-28 07:53:12.307290: 
epoch:  442
2022-05-28 07:54:43.148109: train loss : -0.8503
2022-05-28 07:54:53.741037: validation loss: -0.7611
2022-05-28 07:54:53.744625: Average global foreground Dice: [0.7949]
2022-05-28 07:54:53.746881: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:54:54.212098: lr: 0.001416
2022-05-28 07:54:54.214949: This epoch took 101.885650 s

2022-05-28 07:54:54.217368: 
epoch:  443
2022-05-28 07:56:25.798027: train loss : -0.8426
2022-05-28 07:56:36.711596: validation loss: -0.7743
2022-05-28 07:56:36.715708: Average global foreground Dice: [0.8135]
2022-05-28 07:56:36.717591: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:56:37.201562: lr: 0.001394
2022-05-28 07:56:37.203779: This epoch took 102.982899 s

2022-05-28 07:56:37.205648: 
epoch:  444
2022-05-28 07:58:13.362970: train loss : -0.8446
2022-05-28 07:58:21.643283: validation loss: -0.8041
2022-05-28 07:58:21.664479: Average global foreground Dice: [0.8295]
2022-05-28 07:58:21.678523: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 07:58:22.171419: lr: 0.001372
2022-05-28 07:58:22.173603: This epoch took 104.965619 s

2022-05-28 07:58:22.177948: 
epoch:  445
2022-05-28 07:59:52.432773: train loss : -0.8574
2022-05-28 08:00:00.246967: validation loss: -0.7974
2022-05-28 08:00:00.250349: Average global foreground Dice: [0.8283]
2022-05-28 08:00:00.252662: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:00:00.713919: lr: 0.001349
2022-05-28 08:00:00.716280: This epoch took 98.529430 s

2022-05-28 08:00:00.718309: 
epoch:  446
2022-05-28 08:01:37.293829: train loss : -0.8438
2022-05-28 08:01:47.811398: validation loss: -0.7876
2022-05-28 08:01:47.845675: Average global foreground Dice: [0.8189]
2022-05-28 08:01:47.868286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:01:48.457757: lr: 0.001327
2022-05-28 08:01:48.460483: This epoch took 107.740070 s

2022-05-28 08:01:48.462703: 
epoch:  447
2022-05-28 08:03:22.886635: train loss : -0.8476
2022-05-28 08:03:35.126413: validation loss: -0.8001
2022-05-28 08:03:35.130881: Average global foreground Dice: [0.8274]
2022-05-28 08:03:35.134233: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:03:35.591068: lr: 0.001304
2022-05-28 08:03:35.593303: This epoch took 107.128560 s

2022-05-28 08:03:35.595780: 
epoch:  448
2022-05-28 08:05:05.629843: train loss : -0.8526
2022-05-28 08:05:11.431638: validation loss: -0.7932
2022-05-28 08:05:11.435658: Average global foreground Dice: [0.8167]
2022-05-28 08:05:11.438013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:05:11.909881: lr: 0.001282
2022-05-28 08:05:11.912652: This epoch took 96.314815 s

2022-05-28 08:05:11.914678: 
epoch:  449
2022-05-28 08:06:46.923643: train loss : -0.8373
2022-05-28 08:06:55.735560: validation loss: -0.8080
2022-05-28 08:06:55.740594: Average global foreground Dice: [0.8304]
2022-05-28 08:06:55.744541: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:06:56.223689: lr: 0.001259
2022-05-28 08:06:56.225839: saving scheduled checkpoint file...
2022-05-28 08:06:56.280777: saving checkpoint...
2022-05-28 08:06:57.276711: done, saving took 1.05 seconds
2022-05-28 08:06:57.292548: done
2022-05-28 08:06:57.294545: This epoch took 105.377383 s

2022-05-28 08:06:57.296276: 
epoch:  450
2022-05-28 08:08:28.195923: train loss : -0.8425
2022-05-28 08:08:35.243550: validation loss: -0.7619
2022-05-28 08:08:35.246732: Average global foreground Dice: [0.8125]
2022-05-28 08:08:35.248770: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:08:35.729517: lr: 0.001236
2022-05-28 08:08:35.739334: This epoch took 98.441241 s

2022-05-28 08:08:35.742446: 
epoch:  451
2022-05-28 08:10:10.960851: train loss : -0.8508
2022-05-28 08:10:18.943664: validation loss: -0.7959
2022-05-28 08:10:18.955036: Average global foreground Dice: [0.8217]
2022-05-28 08:10:18.987337: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:10:19.674709: lr: 0.001214
2022-05-28 08:10:19.688463: This epoch took 103.923120 s

2022-05-28 08:10:19.718147: 
epoch:  452
2022-05-28 08:11:51.116214: train loss : -0.8453
2022-05-28 08:12:00.695542: validation loss: -0.7921
2022-05-28 08:12:00.700098: Average global foreground Dice: [0.8224]
2022-05-28 08:12:00.702379: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:12:01.268612: lr: 0.001191
2022-05-28 08:12:01.271092: This epoch took 101.533034 s

2022-05-28 08:12:01.273494: 
epoch:  453
2022-05-28 08:13:32.103019: train loss : -0.8443
2022-05-28 08:13:41.120611: validation loss: -0.7849
2022-05-28 08:13:41.151697: Average global foreground Dice: [0.8228]
2022-05-28 08:13:41.175305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:13:41.751528: lr: 0.001168
2022-05-28 08:13:41.753911: This epoch took 100.478195 s

2022-05-28 08:13:41.756265: 
epoch:  454
2022-05-28 08:15:12.693842: train loss : -0.8514
2022-05-28 08:15:19.578675: validation loss: -0.7671
2022-05-28 08:15:19.582153: Average global foreground Dice: [0.8245]
2022-05-28 08:15:19.584346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:15:20.065782: lr: 0.001145
2022-05-28 08:15:20.113343: saving checkpoint...
2022-05-28 08:15:21.081860: done, saving took 1.01 seconds
2022-05-28 08:15:21.098537: This epoch took 99.339687 s

2022-05-28 08:15:21.100454: 
epoch:  455
2022-05-28 08:16:53.716965: train loss : -0.8476
2022-05-28 08:17:04.188591: validation loss: -0.8007
2022-05-28 08:17:04.204993: Average global foreground Dice: [0.8246]
2022-05-28 08:17:04.208252: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:17:04.755470: lr: 0.001122
2022-05-28 08:17:04.804951: saving checkpoint...
2022-05-28 08:17:05.799386: done, saving took 1.04 seconds
2022-05-28 08:17:05.814485: This epoch took 104.712099 s

2022-05-28 08:17:05.816599: 
epoch:  456
2022-05-28 08:18:36.248201: train loss : -0.8531
2022-05-28 08:18:44.410522: validation loss: -0.7824
2022-05-28 08:18:44.414637: Average global foreground Dice: [0.8218]
2022-05-28 08:18:44.416847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:18:44.955400: lr: 0.001099
2022-05-28 08:18:45.005615: saving checkpoint...
2022-05-28 08:18:45.999070: done, saving took 1.04 seconds
2022-05-28 08:18:46.014085: This epoch took 100.195621 s

2022-05-28 08:18:46.016143: 
epoch:  457
2022-05-28 08:20:16.925879: train loss : -0.8406
2022-05-28 08:20:25.524601: validation loss: -0.7944
2022-05-28 08:20:25.537083: Average global foreground Dice: [0.8254]
2022-05-28 08:20:25.552301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:20:26.023638: lr: 0.001076
2022-05-28 08:20:26.072707: saving checkpoint...
2022-05-28 08:20:27.052401: done, saving took 1.03 seconds
2022-05-28 08:20:27.067883: This epoch took 101.049671 s

2022-05-28 08:20:27.070847: 
epoch:  458
2022-05-28 08:22:05.800686: train loss : -0.8356
2022-05-28 08:22:16.301033: validation loss: -0.7785
2022-05-28 08:22:16.304787: Average global foreground Dice: [0.8132]
2022-05-28 08:22:16.306892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:22:16.912860: lr: 0.001053
2022-05-28 08:22:16.921998: This epoch took 109.848805 s

2022-05-28 08:22:16.924591: 
epoch:  459
2022-05-28 08:23:47.738276: train loss : -0.8515
2022-05-28 08:23:54.875399: validation loss: -0.7802
2022-05-28 08:23:54.900743: Average global foreground Dice: [0.8179]
2022-05-28 08:23:54.922308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:23:55.500051: lr: 0.00103
2022-05-28 08:23:55.520439: This epoch took 98.593683 s

2022-05-28 08:23:55.539404: 
epoch:  460
2022-05-28 08:25:27.382431: train loss : -0.8540
2022-05-28 08:25:35.345008: validation loss: -0.7927
2022-05-28 08:25:35.348288: Average global foreground Dice: [0.8248]
2022-05-28 08:25:35.350269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:25:35.845680: lr: 0.001007
2022-05-28 08:25:35.848011: This epoch took 100.291632 s

2022-05-28 08:25:35.850500: 
epoch:  461
2022-05-28 08:27:06.495502: train loss : -0.8440
2022-05-28 08:27:14.453411: validation loss: -0.7867
2022-05-28 08:27:14.484971: Average global foreground Dice: [0.8185]
2022-05-28 08:27:14.504436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:27:14.982900: lr: 0.000983
2022-05-28 08:27:14.986880: This epoch took 99.134112 s

2022-05-28 08:27:14.990467: 
epoch:  462
2022-05-28 08:28:46.576563: train loss : -0.8538
2022-05-28 08:28:55.473862: validation loss: -0.7713
2022-05-28 08:28:55.478825: Average global foreground Dice: [0.8181]
2022-05-28 08:28:55.481802: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:28:55.946965: lr: 0.00096
2022-05-28 08:28:55.957991: This epoch took 100.965000 s

2022-05-28 08:28:55.975181: 
epoch:  463
2022-05-28 08:30:27.036966: train loss : -0.8473
2022-05-28 08:30:33.560572: validation loss: -0.7585
2022-05-28 08:30:33.564203: Average global foreground Dice: [0.813]
2022-05-28 08:30:33.570478: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:30:34.045852: lr: 0.000937
2022-05-28 08:30:34.048163: This epoch took 98.059434 s

2022-05-28 08:30:34.050189: 
epoch:  464
2022-05-28 08:32:05.276843: train loss : -0.8527
2022-05-28 08:32:14.105568: validation loss: -0.7867
2022-05-28 08:32:14.111015: Average global foreground Dice: [0.8206]
2022-05-28 08:32:14.113091: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:32:14.601407: lr: 0.000913
2022-05-28 08:32:14.605750: This epoch took 100.553433 s

2022-05-28 08:32:14.611038: 
epoch:  465
2022-05-28 08:33:46.603863: train loss : -0.8343
2022-05-28 08:33:54.965773: validation loss: -0.7699
2022-05-28 08:33:54.972702: Average global foreground Dice: [0.8142]
2022-05-28 08:33:54.975123: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:33:55.513001: lr: 0.00089
2022-05-28 08:33:55.515844: This epoch took 100.902374 s

2022-05-28 08:33:55.518381: 
epoch:  466
2022-05-28 08:35:26.089775: train loss : -0.8527
2022-05-28 08:35:36.056965: validation loss: -0.7794
2022-05-28 08:35:36.091878: Average global foreground Dice: [0.8236]
2022-05-28 08:35:36.111484: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:35:36.692158: lr: 0.000866
2022-05-28 08:35:36.719325: This epoch took 101.198164 s

2022-05-28 08:35:36.742285: 
epoch:  467
2022-05-28 08:37:10.640123: train loss : -0.8480
2022-05-28 08:37:18.761667: validation loss: -0.7745
2022-05-28 08:37:18.793357: Average global foreground Dice: [0.8168]
2022-05-28 08:37:18.819101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:37:19.295351: lr: 0.000842
2022-05-28 08:37:19.297554: This epoch took 102.535144 s

2022-05-28 08:37:19.299627: 
epoch:  468
2022-05-28 08:38:50.422520: train loss : -0.8595
2022-05-28 08:38:57.280210: validation loss: -0.7853
2022-05-28 08:38:57.285591: Average global foreground Dice: [0.8151]
2022-05-28 08:38:57.287903: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:38:57.784829: lr: 0.000819
2022-05-28 08:38:57.798873: This epoch took 98.497395 s

2022-05-28 08:38:57.801320: 
epoch:  469
2022-05-28 08:40:28.921108: train loss : -0.8313
2022-05-28 08:40:38.700199: validation loss: -0.7907
2022-05-28 08:40:38.704204: Average global foreground Dice: [0.8266]
2022-05-28 08:40:38.707832: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:40:39.181337: lr: 0.000795
2022-05-28 08:40:39.183705: This epoch took 101.380125 s

2022-05-28 08:40:39.185566: 
epoch:  470
2022-05-28 08:42:11.967110: train loss : -0.8538
2022-05-28 08:42:20.377886: validation loss: -0.8129
2022-05-28 08:42:20.388137: Average global foreground Dice: [0.8324]
2022-05-28 08:42:20.392788: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:42:20.881511: lr: 0.000771
2022-05-28 08:42:20.884291: This epoch took 101.697341 s

2022-05-28 08:42:20.886600: 
epoch:  471
2022-05-28 08:43:51.627317: train loss : -0.8536
2022-05-28 08:44:01.822875: validation loss: -0.7800
2022-05-28 08:44:01.829430: Average global foreground Dice: [0.8191]
2022-05-28 08:44:01.832457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:44:02.366872: lr: 0.000747
2022-05-28 08:44:02.369376: This epoch took 101.480647 s

2022-05-28 08:44:02.371927: 
epoch:  472
2022-05-28 08:45:33.242218: train loss : -0.8502
2022-05-28 08:45:41.804731: validation loss: -0.7849
2022-05-28 08:45:41.808420: Average global foreground Dice: [0.8226]
2022-05-28 08:45:41.810754: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:45:42.254446: lr: 0.000723
2022-05-28 08:45:42.257015: This epoch took 99.882880 s

2022-05-28 08:45:42.259076: 
epoch:  473
2022-05-28 08:47:13.081413: train loss : -0.8651
2022-05-28 08:47:23.027054: validation loss: -0.7887
2022-05-28 08:47:23.030635: Average global foreground Dice: [0.8283]
2022-05-28 08:47:23.033270: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:47:23.503629: lr: 0.000699
2022-05-28 08:47:23.566418: saving checkpoint...
2022-05-28 08:47:24.619834: done, saving took 1.11 seconds
2022-05-28 08:47:24.638253: This epoch took 102.377071 s

2022-05-28 08:47:24.642088: 
epoch:  474
2022-05-28 08:48:55.103263: train loss : -0.8544
2022-05-28 08:49:02.565696: validation loss: -0.7891
2022-05-28 08:49:02.569815: Average global foreground Dice: [0.8197]
2022-05-28 08:49:02.572003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:49:03.034952: lr: 0.000675
2022-05-28 08:49:03.038050: This epoch took 98.392498 s

2022-05-28 08:49:03.040041: 
epoch:  475
2022-05-28 08:50:34.468426: train loss : -0.8519
2022-05-28 08:50:45.514115: validation loss: -0.7838
2022-05-28 08:50:45.517574: Average global foreground Dice: [0.8285]
2022-05-28 08:50:45.524079: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:50:46.049462: lr: 0.00065
2022-05-28 08:50:46.135180: saving checkpoint...
2022-05-28 08:50:47.255275: done, saving took 1.18 seconds
2022-05-28 08:50:47.271133: This epoch took 104.229020 s

2022-05-28 08:50:47.273921: 
epoch:  476
2022-05-28 08:52:17.997793: train loss : -0.8408
2022-05-28 08:52:27.160536: validation loss: -0.8023
2022-05-28 08:52:27.183737: Average global foreground Dice: [0.8337]
2022-05-28 08:52:27.208340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:52:27.927592: lr: 0.000626
2022-05-28 08:52:27.977585: saving checkpoint...
2022-05-28 08:52:29.045767: done, saving took 1.10 seconds
2022-05-28 08:52:29.061421: This epoch took 101.785044 s

2022-05-28 08:52:29.064093: 
epoch:  477
2022-05-28 08:54:06.102039: train loss : -0.8601
2022-05-28 08:54:16.632806: validation loss: -0.7961
2022-05-28 08:54:16.640801: Average global foreground Dice: [0.834]
2022-05-28 08:54:16.658373: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:54:17.499233: lr: 0.000601
2022-05-28 08:54:17.552506: saving checkpoint...
2022-05-28 08:54:18.605467: done, saving took 1.08 seconds
2022-05-28 08:54:18.666292: This epoch took 109.599828 s

2022-05-28 08:54:18.673774: 
epoch:  478
2022-05-28 08:55:48.175875: train loss : -0.8439
2022-05-28 08:55:55.050873: validation loss: -0.7969
2022-05-28 08:55:55.054577: Average global foreground Dice: [0.8286]
2022-05-28 08:55:55.057078: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:55:55.573112: lr: 0.000577
2022-05-28 08:55:55.622851: saving checkpoint...
2022-05-28 08:55:56.648267: done, saving took 1.07 seconds
2022-05-28 08:55:56.662740: This epoch took 97.986836 s

2022-05-28 08:55:56.664885: 
epoch:  479
2022-05-28 08:57:27.228049: train loss : -0.8597
2022-05-28 08:57:36.175827: validation loss: -0.8130
2022-05-28 08:57:36.197108: Average global foreground Dice: [0.8395]
2022-05-28 08:57:36.215292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:57:36.712139: lr: 0.000552
2022-05-28 08:57:36.754105: saving checkpoint...
2022-05-28 08:57:37.765018: done, saving took 1.05 seconds
2022-05-28 08:57:37.779203: This epoch took 101.112524 s

2022-05-28 08:57:37.781337: 
epoch:  480
2022-05-28 08:59:10.288865: train loss : -0.8458
2022-05-28 08:59:19.266842: validation loss: -0.7782
2022-05-28 08:59:19.300751: Average global foreground Dice: [0.8203]
2022-05-28 08:59:19.322338: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 08:59:19.995843: lr: 0.000527
2022-05-28 08:59:20.006317: This epoch took 102.222769 s

2022-05-28 08:59:20.018444: 
epoch:  481
2022-05-28 09:00:52.092352: train loss : -0.8506
2022-05-28 09:01:00.616461: validation loss: -0.7903
2022-05-28 09:01:00.624842: Average global foreground Dice: [0.8284]
2022-05-28 09:01:00.626998: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:01:01.141613: lr: 0.000502
2022-05-28 09:01:01.143963: This epoch took 101.113088 s

2022-05-28 09:01:01.146033: 
epoch:  482
2022-05-28 09:02:32.490289: train loss : -0.8512
2022-05-28 09:02:42.030636: validation loss: -0.7956
2022-05-28 09:02:42.048605: Average global foreground Dice: [0.8277]
2022-05-28 09:02:42.069298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:02:42.648267: lr: 0.000477
2022-05-28 09:02:42.651078: This epoch took 101.503103 s

2022-05-28 09:02:42.653287: 
epoch:  483
2022-05-28 09:04:15.416370: train loss : -0.8527
2022-05-28 09:04:24.939975: validation loss: -0.7888
2022-05-28 09:04:24.943431: Average global foreground Dice: [0.8256]
2022-05-28 09:04:24.945720: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:04:25.506392: lr: 0.000451
2022-05-28 09:04:25.508818: This epoch took 102.852834 s

2022-05-28 09:04:25.510955: 
epoch:  484
2022-05-28 09:05:58.208765: train loss : -0.8516
2022-05-28 09:06:07.167940: validation loss: -0.7724
2022-05-28 09:06:07.173338: Average global foreground Dice: [0.8181]
2022-05-28 09:06:07.179107: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:06:07.659694: lr: 0.000426
2022-05-28 09:06:07.681395: This epoch took 102.168372 s

2022-05-28 09:06:07.710648: 
epoch:  485
2022-05-28 09:07:42.837691: train loss : -0.8423
2022-05-28 09:07:51.563635: validation loss: -0.7890
2022-05-28 09:07:51.571972: Average global foreground Dice: [0.8135]
2022-05-28 09:07:51.574125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:07:52.317786: lr: 0.0004
2022-05-28 09:07:52.352307: This epoch took 104.638646 s

2022-05-28 09:07:52.379291: 
epoch:  486
2022-05-28 09:09:22.967310: train loss : -0.8570
2022-05-28 09:09:31.008005: validation loss: -0.8055
2022-05-28 09:09:31.038794: Average global foreground Dice: [0.8332]
2022-05-28 09:09:31.057301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:09:31.637446: lr: 0.000375
2022-05-28 09:09:31.640317: This epoch took 99.235026 s

2022-05-28 09:09:31.642827: 
epoch:  487
2022-05-28 09:11:04.804119: train loss : -0.8509
2022-05-28 09:11:13.056555: validation loss: -0.7830
2022-05-28 09:11:13.069347: Average global foreground Dice: [0.8185]
2022-05-28 09:11:13.071733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:11:13.577449: lr: 0.000348
2022-05-28 09:11:13.590276: This epoch took 101.945267 s

2022-05-28 09:11:13.607299: 
epoch:  488
2022-05-28 09:12:49.381387: train loss : -0.8482
2022-05-28 09:12:58.036966: validation loss: -0.8076
2022-05-28 09:12:58.040982: Average global foreground Dice: [0.8284]
2022-05-28 09:12:58.042831: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:12:58.504685: lr: 0.000322
2022-05-28 09:12:58.506905: This epoch took 104.895450 s

2022-05-28 09:12:58.519273: 
epoch:  489
2022-05-28 09:14:29.783254: train loss : -0.8496
2022-05-28 09:14:39.973636: validation loss: -0.8074
2022-05-28 09:14:39.995474: Average global foreground Dice: [0.8369]
2022-05-28 09:14:39.998264: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:14:40.895404: lr: 0.000296
2022-05-28 09:14:40.916404: This epoch took 102.391714 s

2022-05-28 09:14:40.943301: 
epoch:  490
2022-05-28 09:16:15.592687: train loss : -0.8510
2022-05-28 09:16:25.075683: validation loss: -0.7963
2022-05-28 09:16:25.079283: Average global foreground Dice: [0.8302]
2022-05-28 09:16:25.082356: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:16:25.543784: lr: 0.000269
2022-05-28 09:16:25.580400: saving checkpoint...
2022-05-28 09:16:26.565273: done, saving took 1.02 seconds
2022-05-28 09:16:26.578391: This epoch took 105.605102 s

2022-05-28 09:16:26.580423: 
epoch:  491
2022-05-28 09:18:00.457973: train loss : -0.8476
2022-05-28 09:18:09.702609: validation loss: -0.7909
2022-05-28 09:18:09.707122: Average global foreground Dice: [0.8278]
2022-05-28 09:18:09.709947: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:18:10.162524: lr: 0.000242
2022-05-28 09:18:10.203128: saving checkpoint...
2022-05-28 09:18:11.302815: done, saving took 1.14 seconds
2022-05-28 09:18:11.316895: This epoch took 104.734369 s

2022-05-28 09:18:11.319098: 
epoch:  492
2022-05-28 09:19:42.774775: train loss : -0.8519
2022-05-28 09:19:53.216621: validation loss: -0.8021
2022-05-28 09:19:53.220342: Average global foreground Dice: [0.8262]
2022-05-28 09:19:53.223183: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:19:53.683906: lr: 0.000215
2022-05-28 09:19:53.686389: This epoch took 102.365366 s

2022-05-28 09:19:53.688934: 
epoch:  493
2022-05-28 09:21:29.711260: train loss : -0.8606
2022-05-28 09:21:41.251145: validation loss: -0.7954
2022-05-28 09:21:41.261847: Average global foreground Dice: [0.8168]
2022-05-28 09:21:41.289301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:21:41.933081: lr: 0.000187
2022-05-28 09:21:41.939039: This epoch took 108.247730 s

2022-05-28 09:21:41.942309: 
epoch:  494
2022-05-28 09:23:13.023429: train loss : -0.8421
2022-05-28 09:23:23.098055: validation loss: -0.8197
2022-05-28 09:23:23.101371: Average global foreground Dice: [0.8389]
2022-05-28 09:23:23.103652: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:23:23.590188: lr: 0.000158
2022-05-28 09:23:23.632206: saving checkpoint...
2022-05-28 09:23:24.703649: done, saving took 1.11 seconds
2022-05-28 09:23:24.717427: This epoch took 102.772325 s

2022-05-28 09:23:24.719588: 
epoch:  495
2022-05-28 09:24:56.146076: train loss : -0.8454
2022-05-28 09:25:06.990209: validation loss: -0.8104
2022-05-28 09:25:06.998201: Average global foreground Dice: [0.8371]
2022-05-28 09:25:07.000118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:25:07.496003: lr: 0.00013
2022-05-28 09:25:07.536707: saving checkpoint...
2022-05-28 09:25:08.594346: done, saving took 1.10 seconds
2022-05-28 09:25:08.664305: This epoch took 103.942864 s

2022-05-28 09:25:08.686345: 
epoch:  496
2022-05-28 09:26:42.541212: train loss : -0.8536
2022-05-28 09:26:51.724961: validation loss: -0.7845
2022-05-28 09:26:51.754176: Average global foreground Dice: [0.815]
2022-05-28 09:26:51.757864: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:26:52.334017: lr: 0.0001
2022-05-28 09:26:52.336385: This epoch took 103.624988 s

2022-05-28 09:26:52.338595: 
epoch:  497
2022-05-28 09:28:23.465344: train loss : -0.8567
2022-05-28 09:28:33.505551: validation loss: -0.7887
2022-05-28 09:28:33.520657: Average global foreground Dice: [0.8195]
2022-05-28 09:28:33.523568: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:28:34.239610: lr: 6.9e-05
2022-05-28 09:28:34.281439: This epoch took 101.940720 s

2022-05-28 09:28:34.303400: 
epoch:  498
2022-05-28 09:30:05.191931: train loss : -0.8482
2022-05-28 09:30:13.346687: validation loss: -0.8036
2022-05-28 09:30:13.350593: Average global foreground Dice: [0.8259]
2022-05-28 09:30:13.352655: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:30:13.824438: lr: 3.7e-05
2022-05-28 09:30:13.848361: This epoch took 99.522967 s

2022-05-28 09:30:13.857668: 
epoch:  499
2022-05-28 09:31:44.254838: train loss : -0.8626
2022-05-28 09:31:54.212741: validation loss: -0.7985
2022-05-28 09:31:54.216311: Average global foreground Dice: [0.8203]
2022-05-28 09:31:54.218724: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:31:54.702484: lr: 0.0
2022-05-28 09:31:54.704807: saving scheduled checkpoint file...
2022-05-28 09:31:54.738239: saving checkpoint...
2022-05-28 09:31:55.750674: done, saving took 1.04 seconds
2022-05-28 09:31:55.766857: done
2022-05-28 09:31:55.769113: This epoch took 101.909079 s

2022-05-28 09:31:55.799760: saving checkpoint...
2022-05-28 09:31:56.788840: done, saving took 1.02 seconds
panc_005 (2, 101, 363, 363)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 363, 363)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 86, 171], [0, 86, 171]]
number of tiles: 27
computing Gaussian
done
prediction done
panc_015 (2, 84, 290, 290)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 290, 290)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 49, 98], [0, 49, 98]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_021 (2, 90, 342, 342)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 75, 150], [0, 75, 150]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_032 (2, 86, 365, 365)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 365, 365)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 86, 173], [0, 86, 173]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_037 (2, 69, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 69, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 5], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_043 (2, 76, 295, 295)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 76, 295, 295)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 12], [0, 52, 103], [0, 52, 103]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_055 (2, 93, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_061 (2, 90, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_084 (2, 80, 288, 288)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 288, 288)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 96], [0, 96]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_094 (2, 82, 286, 286)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_096 (2, 105, 366, 366)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 105, 366, 366)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 41], [0, 87, 174], [0, 87, 174]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_102 (2, 89, 314, 314)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 314, 314)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 61, 122], [0, 61, 122]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_124 (2, 80, 376, 376)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 92, 184], [0, 92, 184]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_138 (2, 92, 371, 371)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 90, 179], [0, 90, 179]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_167 (2, 98, 301, 301)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_175 (2, 88, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 88, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_179 (2, 86, 311, 311)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 311, 311)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 60, 119], [0, 60, 119]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_183 (2, 74, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_196 (2, 89, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_198 (2, 108, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 108, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 44], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_203 (2, 103, 301, 301)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 103, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 39], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_222 (2, 75, 240, 240)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 240, 240)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 48], [0, 48]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_230 (2, 93, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_231 (2, 90, 313, 313)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 313, 313)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 60, 121], [0, 60, 121]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_239 (2, 89, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_244 (2, 100, 359, 359)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 359, 359)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 84, 167], [0, 84, 167]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_247 (2, 86, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_254 (2, 98, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_267 (2, 86, 269, 269)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 269, 269)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 77], [0, 77]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_270 (2, 84, 317, 317)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 317, 317)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 62, 125], [0, 62, 125]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_274 (2, 112, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 112, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 48], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_277 (2, 106, 376, 376)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 92, 184], [0, 92, 184]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_278 (2, 97, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_289 (2, 93, 272, 272)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 272, 272)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 80], [0, 80]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_290 (2, 94, 362, 362)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85, 170], [0, 85, 170]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_291 (2, 94, 362, 362)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85, 170], [0, 85, 170]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_297 (2, 98, 357, 357)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 357, 357)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 82, 165], [0, 82, 165]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_299 (2, 81, 270, 270)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 270, 270)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 78], [0, 78]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_303 (2, 110, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_320 (2, 88, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 88, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_328 (2, 92, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_331 (2, 98, 316, 316)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 62, 124], [0, 62, 124]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_339 (2, 102, 367, 367)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 88, 175], [0, 88, 175]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_344 (2, 109, 305, 305)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 109, 305, 305)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 45], [0, 56, 113], [0, 56, 113]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_355 (2, 167, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 167, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52, 77, 103], [0, 86], [0, 86]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_387 (2, 97, 309, 309)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 58, 117], [0, 58, 117]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_392 (2, 111, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 111, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 47], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_395 (2, 165, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 165, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50, 76, 101], [0, 58, 116], [0, 58, 116]]
number of tiles: 45
using precomputed Gaussian
prediction done
2022-05-28 09:39:52.287326: finished prediction
2022-05-28 09:39:52.291911: evaluation of raw predictions
2022-05-28 09:40:12.757340: determining postprocessing
Foreground vs background
before: 0.8282359726837804
after:  0.828235089574131
Only one class present, no need to do each class separately as this is covered in fg vs bg
done
for which classes:
[]
min_object_sizes
None
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
done
predicting segmentations for the next stage of the cascade
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
panc_005
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 363, 363)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 86, 171], [0, 86, 171]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_015
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 290, 290)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 49, 98], [0, 49, 98]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_021
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 75, 150], [0, 75, 150]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_032
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 365, 365)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 86, 173], [0, 86, 173]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_037
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 69, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 5], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_043
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 76, 295, 295)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 12], [0, 52, 103], [0, 52, 103]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_055
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_061
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_084
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 288, 288)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 96], [0, 96]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_094
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_096
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 105, 366, 366)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 41], [0, 87, 174], [0, 87, 174]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_102
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 314, 314)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 61, 122], [0, 61, 122]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_124
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 92, 184], [0, 92, 184]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_138
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 90, 179], [0, 90, 179]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_167
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_175
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 88, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_179
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 311, 311)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 60, 119], [0, 60, 119]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_183
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_196
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_198
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 108, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 44], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_203
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 103, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 39], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_222
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 240, 240)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 48], [0, 48]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_230
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_231
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 313, 313)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 60, 121], [0, 60, 121]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_239
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_244
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 359, 359)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 84, 167], [0, 84, 167]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_247
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_254
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_267
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 269, 269)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 77], [0, 77]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_270
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 317, 317)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 62, 125], [0, 62, 125]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_274
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 112, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 48], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_277
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 92, 184], [0, 92, 184]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_278
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_289
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 272, 272)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 80], [0, 80]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_290
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85, 170], [0, 85, 170]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_291
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85, 170], [0, 85, 170]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_297
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 357, 357)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 82, 165], [0, 82, 165]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_299
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 270, 270)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 78], [0, 78]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_303
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_320
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 88, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_328
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_331
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 62, 124], [0, 62, 124]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_339
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 88, 175], [0, 88, 175]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_344
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 109, 305, 305)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 45], [0, 56, 113], [0, 56, 113]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_355
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 167, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52, 77, 103], [0, 86], [0, 86]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_387
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 58, 117], [0, 58, 117]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_392
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 111, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 47], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_395
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 165, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50, 76, 101], [0, 58, 116], [0, 58, 116]]
number of tiles: 45
using precomputed Gaussian
prediction done


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_lowres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 93, 318, 318]), 'current_spacing': array([2.5757525 , 1.29418872, 1.29418872]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 40, 224, 224]), 'median_patient_size_in_voxels': array([ 96, 512, 512]), 'current_spacing': array([2.5       , 0.80273402, 0.80273402]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-05-28 09:49:54.751782: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/splits_final.pkl
2022-05-28 09:49:54.778425: The split file contains 5 splits.
2022-05-28 09:49:54.780877: Desired fold for training: 3
2022-05-28 09:49:54.782881: This split has 191 training and 48 validation cases.
unpacking dataset
done
Susy hier
Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-28 09:49:58.369940: lr: 0.01
using pin_memory on device 0
using pin_memory on device 0
2022-05-28 09:50:06.464756: Unable to plot network architecture:
2022-05-28 09:50:06.475711: No module named 'hiddenlayer'
2022-05-28 09:50:06.480376: 
printing the network instead:

2022-05-28 09:50:06.488510: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-28 09:50:06.495166: 

2022-05-28 09:50:06.497465: 
epoch:  0
2022-05-28 09:51:51.336783: train loss : -0.0499
2022-05-28 09:51:58.814326: validation loss: -0.2245
2022-05-28 09:51:58.818094: Average global foreground Dice: [0.3214]
2022-05-28 09:51:58.820546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:51:59.406926: lr: 0.009982
2022-05-28 09:51:59.412448: This epoch took 112.896020 s

2022-05-28 09:51:59.415657: 
epoch:  1
2022-05-28 09:53:31.280939: train loss : -0.2743
2022-05-28 09:53:39.668257: validation loss: -0.3091
2022-05-28 09:53:39.711763: Average global foreground Dice: [0.4041]
2022-05-28 09:53:39.740303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:53:40.601662: lr: 0.009964
2022-05-28 09:53:40.731571: saving checkpoint...
2022-05-28 09:53:41.984795: done, saving took 1.36 seconds
2022-05-28 09:53:41.999916: This epoch took 102.581865 s

2022-05-28 09:53:42.002461: 
epoch:  2
2022-05-28 09:55:14.406897: train loss : -0.3436
2022-05-28 09:55:22.154855: validation loss: -0.3640
2022-05-28 09:55:22.178910: Average global foreground Dice: [0.4611]
2022-05-28 09:55:22.196114: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:55:22.672234: lr: 0.009946
2022-05-28 09:55:22.732134: saving checkpoint...
2022-05-28 09:55:23.685014: done, saving took 1.00 seconds
2022-05-28 09:55:23.699776: This epoch took 101.694982 s

2022-05-28 09:55:23.701862: 
epoch:  3
2022-05-28 09:56:54.511680: train loss : -0.3790
2022-05-28 09:57:01.917058: validation loss: -0.3722
2022-05-28 09:57:01.920663: Average global foreground Dice: [0.4721]
2022-05-28 09:57:01.922804: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:57:02.361398: lr: 0.009928
2022-05-28 09:57:02.414435: saving checkpoint...
2022-05-28 09:57:03.482102: done, saving took 1.12 seconds
2022-05-28 09:57:03.495070: This epoch took 99.791285 s

2022-05-28 09:57:03.497317: 
epoch:  4
2022-05-28 09:58:35.147195: train loss : -0.4390
2022-05-28 09:58:42.490963: validation loss: -0.4699
2022-05-28 09:58:42.536831: Average global foreground Dice: [0.5675]
2022-05-28 09:58:42.546549: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 09:58:43.185169: lr: 0.00991
2022-05-28 09:58:43.316948: saving checkpoint...
2022-05-28 09:58:44.474935: done, saving took 1.26 seconds
2022-05-28 09:58:44.488578: This epoch took 100.989186 s

2022-05-28 09:58:44.490848: 
epoch:  5
2022-05-28 10:00:15.116744: train loss : -0.4892
2022-05-28 10:00:20.831650: validation loss: -0.4818
2022-05-28 10:00:20.835507: Average global foreground Dice: [0.5669]
2022-05-28 10:00:20.838667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:00:21.257581: lr: 0.009892
2022-05-28 10:00:21.308153: saving checkpoint...
2022-05-28 10:00:22.284994: done, saving took 1.02 seconds
2022-05-28 10:00:22.299582: This epoch took 97.806283 s

2022-05-28 10:00:22.301876: 
epoch:  6
2022-05-28 10:01:54.307768: train loss : -0.5189
2022-05-28 10:02:02.601744: validation loss: -0.4988
2022-05-28 10:02:02.634799: Average global foreground Dice: [0.5782]
2022-05-28 10:02:02.647327: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:02:03.263204: lr: 0.009874
2022-05-28 10:02:03.418318: saving checkpoint...
2022-05-28 10:02:04.618491: done, saving took 1.33 seconds
2022-05-28 10:02:04.673418: This epoch took 102.369299 s

2022-05-28 10:02:04.699585: 
epoch:  7
2022-05-28 10:03:36.804359: train loss : -0.5243
2022-05-28 10:03:45.204565: validation loss: -0.4759
2022-05-28 10:03:45.229183: Average global foreground Dice: [0.58]
2022-05-28 10:03:45.270315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:03:45.939899: lr: 0.009856
2022-05-28 10:03:46.018338: saving checkpoint...
2022-05-28 10:03:47.051046: done, saving took 1.08 seconds
2022-05-28 10:03:47.068675: This epoch took 102.356635 s

2022-05-28 10:03:47.070852: 
epoch:  8
2022-05-28 10:05:19.884981: train loss : -0.5104
2022-05-28 10:05:27.000302: validation loss: -0.4783
2022-05-28 10:05:27.027746: Average global foreground Dice: [0.5679]
2022-05-28 10:05:27.047292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:05:27.810848: lr: 0.009838
2022-05-28 10:05:27.869268: saving checkpoint...
2022-05-28 10:05:28.929897: done, saving took 1.10 seconds
2022-05-28 10:05:28.943270: This epoch took 101.870349 s

2022-05-28 10:05:28.946318: 
epoch:  9
2022-05-28 10:07:02.393842: train loss : -0.5389
2022-05-28 10:07:10.132071: validation loss: -0.4978
2022-05-28 10:07:10.159705: Average global foreground Dice: [0.5749]
2022-05-28 10:07:10.178483: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:07:11.385355: lr: 0.00982
2022-05-28 10:07:11.473703: saving checkpoint...
2022-05-28 10:07:13.127145: done, saving took 1.72 seconds
2022-05-28 10:07:13.143166: This epoch took 104.194996 s

2022-05-28 10:07:13.145797: 
epoch:  10
2022-05-28 10:08:44.721197: train loss : -0.5681
2022-05-28 10:08:51.337289: validation loss: -0.5503
2022-05-28 10:08:51.340687: Average global foreground Dice: [0.63]
2022-05-28 10:08:51.342976: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:08:51.775260: lr: 0.009802
2022-05-28 10:08:51.814688: saving checkpoint...
2022-05-28 10:08:52.790868: done, saving took 1.01 seconds
2022-05-28 10:08:52.804048: This epoch took 99.655948 s

2022-05-28 10:08:52.806019: 
epoch:  11
2022-05-28 10:10:25.164126: train loss : -0.5663
2022-05-28 10:10:32.379359: validation loss: -0.5587
2022-05-28 10:10:32.402148: Average global foreground Dice: [0.6262]
2022-05-28 10:10:32.418056: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:10:33.266622: lr: 0.009784
2022-05-28 10:10:33.304898: saving checkpoint...
2022-05-28 10:10:34.365915: done, saving took 1.10 seconds
2022-05-28 10:10:34.397370: This epoch took 101.589373 s

2022-05-28 10:10:34.399476: 
epoch:  12
2022-05-28 10:12:06.914570: train loss : -0.5954
2022-05-28 10:12:14.287363: validation loss: -0.5463
2022-05-28 10:12:14.290639: Average global foreground Dice: [0.6104]
2022-05-28 10:12:14.292787: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:12:14.734822: lr: 0.009766
2022-05-28 10:12:14.770463: saving checkpoint...
2022-05-28 10:12:15.706722: done, saving took 0.97 seconds
2022-05-28 10:12:15.732569: This epoch took 101.331069 s

2022-05-28 10:12:15.739080: 
epoch:  13
2022-05-28 10:13:45.877182: train loss : -0.5933
2022-05-28 10:13:52.584974: validation loss: -0.5722
2022-05-28 10:13:52.588140: Average global foreground Dice: [0.6485]
2022-05-28 10:13:52.590112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:13:53.207497: lr: 0.009748
2022-05-28 10:13:53.258406: saving checkpoint...
2022-05-28 10:13:54.269417: done, saving took 1.06 seconds
2022-05-28 10:13:54.284063: This epoch took 98.511094 s

2022-05-28 10:13:54.286930: 
epoch:  14
2022-05-28 10:15:25.925982: train loss : -0.6056
2022-05-28 10:15:32.627855: validation loss: -0.5840
2022-05-28 10:15:32.633365: Average global foreground Dice: [0.6539]
2022-05-28 10:15:32.635391: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:15:33.097049: lr: 0.00973
2022-05-28 10:15:33.160767: saving checkpoint...
2022-05-28 10:15:34.175861: done, saving took 1.07 seconds
2022-05-28 10:15:34.191216: This epoch took 99.902017 s

2022-05-28 10:15:34.193246: 
epoch:  15
2022-05-28 10:17:05.639647: train loss : -0.6102
2022-05-28 10:17:12.449814: validation loss: -0.5703
2022-05-28 10:17:12.461010: Average global foreground Dice: [0.6495]
2022-05-28 10:17:12.472064: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:17:12.915252: lr: 0.009712
2022-05-28 10:17:12.965061: saving checkpoint...
2022-05-28 10:17:14.044027: done, saving took 1.13 seconds
2022-05-28 10:17:14.059624: This epoch took 99.864346 s

2022-05-28 10:17:14.062105: 
epoch:  16
2022-05-28 10:18:45.269259: train loss : -0.6084
2022-05-28 10:18:51.293999: validation loss: -0.5963
2022-05-28 10:18:51.298149: Average global foreground Dice: [0.6655]
2022-05-28 10:18:51.300507: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:18:51.736797: lr: 0.009693
2022-05-28 10:18:51.782193: saving checkpoint...
2022-05-28 10:18:52.782498: done, saving took 1.04 seconds
2022-05-28 10:18:52.797623: This epoch took 98.733192 s

2022-05-28 10:18:52.799902: 
epoch:  17
2022-05-28 10:20:24.472662: train loss : -0.6198
2022-05-28 10:20:32.073967: validation loss: -0.6027
2022-05-28 10:20:32.097501: Average global foreground Dice: [0.6767]
2022-05-28 10:20:32.099916: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:20:32.737417: lr: 0.009675
2022-05-28 10:20:32.851594: saving checkpoint...
2022-05-28 10:20:34.067187: done, saving took 1.30 seconds
2022-05-28 10:20:34.083137: This epoch took 101.280817 s

2022-05-28 10:20:34.085370: 
epoch:  18
2022-05-28 10:22:06.172102: train loss : -0.6198
2022-05-28 10:22:12.897696: validation loss: -0.6327
2022-05-28 10:22:12.901003: Average global foreground Dice: [0.6848]
2022-05-28 10:22:12.902948: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:22:13.394408: lr: 0.009657
2022-05-28 10:22:13.456121: saving checkpoint...
2022-05-28 10:22:14.463991: done, saving took 1.06 seconds
2022-05-28 10:22:14.481296: This epoch took 100.394019 s

2022-05-28 10:22:14.483355: 
epoch:  19
2022-05-28 10:23:46.886626: train loss : -0.6104
2022-05-28 10:23:53.490853: validation loss: -0.6512
2022-05-28 10:23:53.494720: Average global foreground Dice: [0.7157]
2022-05-28 10:23:53.496864: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:23:53.960513: lr: 0.009639
2022-05-28 10:23:54.007937: saving checkpoint...
2022-05-28 10:23:55.002686: done, saving took 1.04 seconds
2022-05-28 10:23:55.017787: This epoch took 100.532280 s

2022-05-28 10:23:55.020068: 
epoch:  20
2022-05-28 10:25:27.863666: train loss : -0.6489
2022-05-28 10:25:35.892819: validation loss: -0.5814
2022-05-28 10:25:35.926902: Average global foreground Dice: [0.6854]
2022-05-28 10:25:35.949450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:25:36.886783: lr: 0.009621
2022-05-28 10:25:36.986221: saving checkpoint...
2022-05-28 10:25:38.214273: done, saving took 1.31 seconds
2022-05-28 10:25:38.230212: This epoch took 103.207962 s

2022-05-28 10:25:38.233776: 
epoch:  21
2022-05-28 10:27:09.898311: train loss : -0.6309
2022-05-28 10:27:16.576408: validation loss: -0.6104
2022-05-28 10:27:16.599127: Average global foreground Dice: [0.686]
2022-05-28 10:27:16.615612: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:27:17.263805: lr: 0.009603
2022-05-28 10:27:17.340621: saving checkpoint...
2022-05-28 10:27:18.511900: done, saving took 1.23 seconds
2022-05-28 10:27:18.525630: This epoch took 100.289303 s

2022-05-28 10:27:18.528325: 
epoch:  22
2022-05-28 10:28:50.072339: train loss : -0.6408
2022-05-28 10:28:57.036538: validation loss: -0.6073
2022-05-28 10:28:57.040575: Average global foreground Dice: [0.6913]
2022-05-28 10:28:57.042782: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:28:57.660486: lr: 0.009585
2022-05-28 10:28:57.712347: saving checkpoint...
2022-05-28 10:28:58.721473: done, saving took 1.05 seconds
2022-05-28 10:28:58.740554: This epoch took 100.210210 s

2022-05-28 10:28:58.742766: 
epoch:  23
2022-05-28 10:30:30.641609: train loss : -0.6367
2022-05-28 10:30:37.188665: validation loss: -0.6154
2022-05-28 10:30:37.192533: Average global foreground Dice: [0.6927]
2022-05-28 10:30:37.194843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:30:37.647948: lr: 0.009567
2022-05-28 10:30:37.684593: saving checkpoint...
2022-05-28 10:30:38.610364: done, saving took 0.96 seconds
2022-05-28 10:30:38.623935: This epoch took 99.879283 s

2022-05-28 10:30:38.626044: 
epoch:  24
2022-05-28 10:32:11.121224: train loss : -0.6484
2022-05-28 10:32:17.481882: validation loss: -0.6488
2022-05-28 10:32:17.486445: Average global foreground Dice: [0.7116]
2022-05-28 10:32:17.488786: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:32:17.928432: lr: 0.009549
2022-05-28 10:32:17.959049: saving checkpoint...
2022-05-28 10:32:18.898165: done, saving took 0.97 seconds
2022-05-28 10:32:18.913101: This epoch took 100.284988 s

2022-05-28 10:32:18.915684: 
epoch:  25
2022-05-28 10:33:49.619419: train loss : -0.6444
2022-05-28 10:33:57.025567: validation loss: -0.5582
2022-05-28 10:33:57.029484: Average global foreground Dice: [0.6593]
2022-05-28 10:33:57.031570: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:33:57.512307: lr: 0.009531
2022-05-28 10:33:57.567681: saving checkpoint...
2022-05-28 10:33:58.591343: done, saving took 1.08 seconds
2022-05-28 10:33:58.605851: This epoch took 99.687701 s

2022-05-28 10:33:58.608153: 
epoch:  26
2022-05-28 10:35:31.769082: train loss : -0.6574
2022-05-28 10:35:39.648167: validation loss: -0.6247
2022-05-28 10:35:39.686879: Average global foreground Dice: [0.7071]
2022-05-28 10:35:39.721289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:35:40.329385: lr: 0.009513
2022-05-28 10:35:40.389647: saving checkpoint...
2022-05-28 10:35:41.419346: done, saving took 1.09 seconds
2022-05-28 10:35:41.481307: This epoch took 102.870858 s

2022-05-28 10:35:41.505308: 
epoch:  27
2022-05-28 10:37:13.863588: train loss : -0.6703
2022-05-28 10:37:20.765413: validation loss: -0.6484
2022-05-28 10:37:20.769722: Average global foreground Dice: [0.7181]
2022-05-28 10:37:20.772029: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:37:21.222078: lr: 0.009495
2022-05-28 10:37:21.265632: saving checkpoint...
2022-05-28 10:37:22.254112: done, saving took 1.03 seconds
2022-05-28 10:37:22.272167: This epoch took 100.747181 s

2022-05-28 10:37:22.274302: 
epoch:  28
2022-05-28 10:38:54.608252: train loss : -0.6613
2022-05-28 10:39:01.175611: validation loss: -0.6177
2022-05-28 10:39:01.179567: Average global foreground Dice: [0.698]
2022-05-28 10:39:01.181619: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:39:01.665586: lr: 0.009476
2022-05-28 10:39:01.720106: saving checkpoint...
2022-05-28 10:39:02.808723: done, saving took 1.14 seconds
2022-05-28 10:39:02.823753: This epoch took 100.547496 s

2022-05-28 10:39:02.825763: 
epoch:  29
2022-05-28 10:40:35.015867: train loss : -0.6760
2022-05-28 10:40:41.516279: validation loss: -0.6534
2022-05-28 10:40:41.528015: Average global foreground Dice: [0.7112]
2022-05-28 10:40:41.539262: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:40:42.102029: lr: 0.009458
2022-05-28 10:40:42.148119: saving checkpoint...
2022-05-28 10:40:43.159850: done, saving took 1.05 seconds
2022-05-28 10:40:43.174456: This epoch took 100.346732 s

2022-05-28 10:40:43.176694: 
epoch:  30
2022-05-28 10:42:16.733832: train loss : -0.6844
2022-05-28 10:42:26.395444: validation loss: -0.6236
2022-05-28 10:42:26.434147: Average global foreground Dice: [0.7038]
2022-05-28 10:42:26.456347: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:42:27.078529: lr: 0.00944
2022-05-28 10:42:27.196646: saving checkpoint...
2022-05-28 10:42:28.366570: done, saving took 1.26 seconds
2022-05-28 10:42:28.381840: This epoch took 105.203029 s

2022-05-28 10:42:28.383917: 
epoch:  31
2022-05-28 10:44:04.670995: train loss : -0.6771
2022-05-28 10:44:11.904713: validation loss: -0.6301
2022-05-28 10:44:11.936825: Average global foreground Dice: [0.6916]
2022-05-28 10:44:11.959285: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:44:12.802909: lr: 0.009422
2022-05-28 10:44:12.924727: saving checkpoint...
2022-05-28 10:44:14.024806: done, saving took 1.19 seconds
2022-05-28 10:44:14.040131: This epoch took 105.653626 s

2022-05-28 10:44:14.042266: 
epoch:  32
2022-05-28 10:45:45.994371: train loss : -0.6706
2022-05-28 10:45:54.529008: validation loss: -0.6195
2022-05-28 10:45:54.538365: Average global foreground Dice: [0.6924]
2022-05-28 10:45:54.542339: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:45:55.080754: lr: 0.009404
2022-05-28 10:45:55.134895: saving checkpoint...
2022-05-28 10:45:56.179240: done, saving took 1.10 seconds
2022-05-28 10:45:56.196265: This epoch took 102.152044 s

2022-05-28 10:45:56.198697: 
epoch:  33
2022-05-28 10:47:27.843349: train loss : -0.6898
2022-05-28 10:47:34.464095: validation loss: -0.6539
2022-05-28 10:47:34.484895: Average global foreground Dice: [0.7098]
2022-05-28 10:47:34.515238: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:47:35.078036: lr: 0.009386
2022-05-28 10:47:35.204767: saving checkpoint...
2022-05-28 10:47:36.433714: done, saving took 1.34 seconds
2022-05-28 10:47:36.511307: This epoch took 100.310409 s

2022-05-28 10:47:36.545323: 
epoch:  34
2022-05-28 10:49:10.374870: train loss : -0.6900
2022-05-28 10:49:16.651211: validation loss: -0.6729
2022-05-28 10:49:16.687816: Average global foreground Dice: [0.7395]
2022-05-28 10:49:16.710484: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:49:17.230278: lr: 0.009368
2022-05-28 10:49:17.309059: saving checkpoint...
2022-05-28 10:49:18.536872: done, saving took 1.30 seconds
2022-05-28 10:49:18.553127: This epoch took 101.998522 s

2022-05-28 10:49:18.555353: 
epoch:  35
2022-05-28 10:50:50.480632: train loss : -0.6992
2022-05-28 10:50:56.837825: validation loss: -0.6167
2022-05-28 10:50:56.841711: Average global foreground Dice: [0.7091]
2022-05-28 10:50:56.843904: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:50:57.293722: lr: 0.00935
2022-05-28 10:50:57.343487: saving checkpoint...
2022-05-28 10:50:58.336478: done, saving took 1.04 seconds
2022-05-28 10:50:58.351621: This epoch took 99.794206 s

2022-05-28 10:50:58.353771: 
epoch:  36
2022-05-28 10:52:30.822526: train loss : -0.6874
2022-05-28 10:52:37.830585: validation loss: -0.6880
2022-05-28 10:52:37.860940: Average global foreground Dice: [0.7452]
2022-05-28 10:52:37.863367: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:52:38.334212: lr: 0.009331
2022-05-28 10:52:38.388896: saving checkpoint...
2022-05-28 10:52:39.440411: done, saving took 1.10 seconds
2022-05-28 10:52:39.455379: This epoch took 101.099418 s

2022-05-28 10:52:39.457457: 
epoch:  37
2022-05-28 10:54:12.561587: train loss : -0.6995
2022-05-28 10:54:19.675992: validation loss: -0.6185
2022-05-28 10:54:19.682839: Average global foreground Dice: [0.7007]
2022-05-28 10:54:19.685733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:54:20.156920: lr: 0.009313
2022-05-28 10:54:20.214766: saving checkpoint...
2022-05-28 10:54:21.155099: done, saving took 1.00 seconds
2022-05-28 10:54:21.172263: This epoch took 101.712755 s

2022-05-28 10:54:21.174748: 
epoch:  38
2022-05-28 10:55:52.913832: train loss : -0.6823
2022-05-28 10:56:00.226896: validation loss: -0.6706
2022-05-28 10:56:00.230665: Average global foreground Dice: [0.7227]
2022-05-28 10:56:00.234237: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:56:00.689779: lr: 0.009295
2022-05-28 10:56:00.740811: saving checkpoint...
2022-05-28 10:56:01.752573: done, saving took 1.06 seconds
2022-05-28 10:56:01.767609: This epoch took 100.590797 s

2022-05-28 10:56:01.770035: 
epoch:  39
2022-05-28 10:57:34.138490: train loss : -0.6942
2022-05-28 10:57:44.119707: validation loss: -0.6418
2022-05-28 10:57:44.146673: Average global foreground Dice: [0.7009]
2022-05-28 10:57:44.153113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:57:44.987889: lr: 0.009277
2022-05-28 10:57:45.160470: saving checkpoint...
2022-05-28 10:57:46.197929: done, saving took 1.19 seconds
2022-05-28 10:57:46.214653: This epoch took 104.442317 s

2022-05-28 10:57:46.216955: 
epoch:  40
2022-05-28 10:59:23.312377: train loss : -0.6802
2022-05-28 10:59:30.938639: validation loss: -0.6106
2022-05-28 10:59:30.942489: Average global foreground Dice: [0.696]
2022-05-28 10:59:30.945144: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 10:59:31.400990: lr: 0.009259
2022-05-28 10:59:31.454913: saving checkpoint...
2022-05-28 10:59:32.487685: done, saving took 1.08 seconds
2022-05-28 10:59:32.502884: This epoch took 106.284009 s

2022-05-28 10:59:32.505132: 
epoch:  41
2022-05-28 11:01:05.084938: train loss : -0.6984
2022-05-28 11:01:11.906128: validation loss: -0.6483
2022-05-28 11:01:11.939809: Average global foreground Dice: [0.7272]
2022-05-28 11:01:11.959990: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:01:12.483387: lr: 0.009241
2022-05-28 11:01:12.542191: saving checkpoint...
2022-05-28 11:01:13.703403: done, saving took 1.22 seconds
2022-05-28 11:01:13.719745: This epoch took 101.212569 s

2022-05-28 11:01:13.721675: 
epoch:  42
2022-05-28 11:02:47.707474: train loss : -0.6914
2022-05-28 11:02:55.343879: validation loss: -0.6258
2022-05-28 11:02:55.347417: Average global foreground Dice: [0.6961]
2022-05-28 11:02:55.352440: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:02:55.810983: lr: 0.009223
2022-05-28 11:02:55.833324: This epoch took 102.109566 s

2022-05-28 11:02:55.846420: 
epoch:  43
2022-05-28 11:04:28.223118: train loss : -0.7010
2022-05-28 11:04:34.716966: validation loss: -0.6648
2022-05-28 11:04:34.736996: Average global foreground Dice: [0.7279]
2022-05-28 11:04:34.752270: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:04:35.299297: lr: 0.009204
2022-05-28 11:04:35.355127: saving checkpoint...
2022-05-28 11:04:36.358571: done, saving took 1.06 seconds
2022-05-28 11:04:36.374809: This epoch took 100.525713 s

2022-05-28 11:04:36.377288: 
epoch:  44
2022-05-28 11:06:08.318486: train loss : -0.6884
2022-05-28 11:06:14.872452: validation loss: -0.6547
2022-05-28 11:06:14.920449: Average global foreground Dice: [0.7264]
2022-05-28 11:06:14.926804: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:06:15.393253: lr: 0.009186
2022-05-28 11:06:15.447959: saving checkpoint...
2022-05-28 11:06:16.450794: done, saving took 1.06 seconds
2022-05-28 11:06:16.466080: This epoch took 100.086347 s

2022-05-28 11:06:16.468119: 
epoch:  45
2022-05-28 11:07:50.349651: train loss : -0.7146
2022-05-28 11:07:58.919484: validation loss: -0.6783
2022-05-28 11:07:58.948783: Average global foreground Dice: [0.7434]
2022-05-28 11:07:58.964424: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:07:59.694914: lr: 0.009168
2022-05-28 11:07:59.801953: saving checkpoint...
2022-05-28 11:08:01.003334: done, saving took 1.29 seconds
2022-05-28 11:08:01.048347: This epoch took 104.578294 s

2022-05-28 11:08:01.057060: 
epoch:  46
2022-05-28 11:09:32.091768: train loss : -0.7111
2022-05-28 11:09:38.304257: validation loss: -0.6455
2022-05-28 11:09:38.309537: Average global foreground Dice: [0.7073]
2022-05-28 11:09:38.311736: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:09:38.743201: lr: 0.00915
2022-05-28 11:09:38.745521: This epoch took 97.686011 s

2022-05-28 11:09:38.747786: 
epoch:  47
2022-05-28 11:11:10.802397: train loss : -0.7206
2022-05-28 11:11:16.929576: validation loss: -0.6850
2022-05-28 11:11:16.933076: Average global foreground Dice: [0.7545]
2022-05-28 11:11:16.935799: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:11:17.385309: lr: 0.009132
2022-05-28 11:11:17.431785: saving checkpoint...
2022-05-28 11:11:18.411013: done, saving took 1.02 seconds
2022-05-28 11:11:18.426756: This epoch took 99.676737 s

2022-05-28 11:11:18.428845: 
epoch:  48
2022-05-28 11:12:53.415520: train loss : -0.7164
2022-05-28 11:13:01.661111: validation loss: -0.6466
2022-05-28 11:13:01.690126: Average global foreground Dice: [0.7087]
2022-05-28 11:13:01.712313: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:13:02.358993: lr: 0.009114
2022-05-28 11:13:02.381345: This epoch took 103.950237 s

2022-05-28 11:13:02.404309: 
epoch:  49
2022-05-28 11:14:41.079158: train loss : -0.7156
2022-05-28 11:14:48.705914: validation loss: -0.6430
2022-05-28 11:14:48.727698: Average global foreground Dice: [0.7363]
2022-05-28 11:14:48.748734: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:14:49.323385: lr: 0.009095
2022-05-28 11:14:49.325976: saving scheduled checkpoint file...
2022-05-28 11:14:49.360030: saving checkpoint...
2022-05-28 11:14:50.433359: done, saving took 1.11 seconds
2022-05-28 11:14:50.450024: done
2022-05-28 11:14:50.482427: saving checkpoint...
2022-05-28 11:14:51.532414: done, saving took 1.08 seconds
2022-05-28 11:14:51.548062: This epoch took 109.120770 s

2022-05-28 11:14:51.551314: 
epoch:  50
2022-05-28 11:16:22.162379: train loss : -0.7072
2022-05-28 11:16:28.295335: validation loss: -0.6698
2022-05-28 11:16:28.299007: Average global foreground Dice: [0.7279]
2022-05-28 11:16:28.301666: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:16:28.752406: lr: 0.009077
2022-05-28 11:16:28.793408: saving checkpoint...
2022-05-28 11:16:29.753885: done, saving took 1.00 seconds
2022-05-28 11:16:29.768167: This epoch took 98.213641 s

2022-05-28 11:16:29.770537: 
epoch:  51
2022-05-28 11:18:01.995441: train loss : -0.7088
2022-05-28 11:18:10.001009: validation loss: -0.7034
2022-05-28 11:18:10.024093: Average global foreground Dice: [0.7644]
2022-05-28 11:18:10.046964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:18:10.717151: lr: 0.009059
2022-05-28 11:18:10.807873: saving checkpoint...
2022-05-28 11:18:12.063025: done, saving took 1.32 seconds
2022-05-28 11:18:12.076352: This epoch took 102.303625 s

2022-05-28 11:18:12.078537: 
epoch:  52
2022-05-28 11:19:43.788104: train loss : -0.7188
2022-05-28 11:19:51.151783: validation loss: -0.6874
2022-05-28 11:19:51.165088: Average global foreground Dice: [0.7427]
2022-05-28 11:19:51.187324: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:19:51.896651: lr: 0.009041
2022-05-28 11:19:51.965344: saving checkpoint...
2022-05-28 11:19:53.075146: done, saving took 1.15 seconds
2022-05-28 11:19:53.127600: This epoch took 101.047065 s

2022-05-28 11:19:53.143479: 
epoch:  53
2022-05-28 11:21:25.080356: train loss : -0.7045
2022-05-28 11:21:32.747554: validation loss: -0.6752
2022-05-28 11:21:32.756769: Average global foreground Dice: [0.7583]
2022-05-28 11:21:32.759903: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:21:33.239792: lr: 0.009023
2022-05-28 11:21:33.298657: saving checkpoint...
2022-05-28 11:21:34.282947: done, saving took 1.02 seconds
2022-05-28 11:21:34.298624: This epoch took 101.121180 s

2022-05-28 11:21:34.300856: 
epoch:  54
2022-05-28 11:23:05.395916: train loss : -0.7130
2022-05-28 11:23:11.269117: validation loss: -0.6755
2022-05-28 11:23:11.273002: Average global foreground Dice: [0.7429]
2022-05-28 11:23:11.275204: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:23:11.725935: lr: 0.009004
2022-05-28 11:23:11.765106: saving checkpoint...
2022-05-28 11:23:12.707639: done, saving took 0.98 seconds
2022-05-28 11:23:12.723163: This epoch took 98.420133 s

2022-05-28 11:23:12.726592: 
epoch:  55
2022-05-28 11:24:43.336813: train loss : -0.7161
2022-05-28 11:24:49.083577: validation loss: -0.6615
2022-05-28 11:24:49.087974: Average global foreground Dice: [0.7401]
2022-05-28 11:24:49.090418: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:24:49.538711: lr: 0.008986
2022-05-28 11:24:49.584160: saving checkpoint...
2022-05-28 11:24:50.613127: done, saving took 1.07 seconds
2022-05-28 11:24:50.629474: This epoch took 97.900652 s

2022-05-28 11:24:50.631900: 
epoch:  56
2022-05-28 11:26:22.167765: train loss : -0.7162
2022-05-28 11:26:31.005121: validation loss: -0.6846
2022-05-28 11:26:31.029779: Average global foreground Dice: [0.747]
2022-05-28 11:26:31.051305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:26:31.617249: lr: 0.008968
2022-05-28 11:26:31.668623: saving checkpoint...
2022-05-28 11:26:32.707119: done, saving took 1.07 seconds
2022-05-28 11:26:32.720160: This epoch took 102.086039 s

2022-05-28 11:26:32.722363: 
epoch:  57
2022-05-28 11:28:04.436032: train loss : -0.7207
2022-05-28 11:28:11.939738: validation loss: -0.6893
2022-05-28 11:28:11.955452: Average global foreground Dice: [0.7472]
2022-05-28 11:28:11.958193: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:28:12.656748: lr: 0.00895
2022-05-28 11:28:12.700383: saving checkpoint...
2022-05-28 11:28:13.773082: done, saving took 1.11 seconds
2022-05-28 11:28:13.843379: This epoch took 101.118871 s

2022-05-28 11:28:13.850871: 
epoch:  58
2022-05-28 11:29:45.823739: train loss : -0.7087
2022-05-28 11:29:52.803422: validation loss: -0.6573
2022-05-28 11:29:52.825878: Average global foreground Dice: [0.7137]
2022-05-28 11:29:52.850304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:29:53.326169: lr: 0.008931
2022-05-28 11:29:53.328569: This epoch took 99.475619 s

2022-05-28 11:29:53.330611: 
epoch:  59
2022-05-28 11:31:29.608460: train loss : -0.7160
2022-05-28 11:31:35.643224: validation loss: -0.6746
2022-05-28 11:31:35.688866: Average global foreground Dice: [0.7267]
2022-05-28 11:31:35.715315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:31:36.485194: lr: 0.008913
2022-05-28 11:31:36.516011: This epoch took 103.183311 s

2022-05-28 11:31:36.548280: 
epoch:  60
2022-05-28 11:33:08.225481: train loss : -0.7082
2022-05-28 11:33:14.519647: validation loss: -0.6574
2022-05-28 11:33:14.523398: Average global foreground Dice: [0.7357]
2022-05-28 11:33:14.525546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:33:14.963070: lr: 0.008895
2022-05-28 11:33:14.965376: This epoch took 98.397100 s

2022-05-28 11:33:14.967566: 
epoch:  61
2022-05-28 11:34:48.331125: train loss : -0.7359
2022-05-28 11:34:54.625617: validation loss: -0.6600
2022-05-28 11:34:54.629131: Average global foreground Dice: [0.7374]
2022-05-28 11:34:54.631094: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:34:55.070759: lr: 0.008877
2022-05-28 11:34:55.073633: This epoch took 100.103923 s

2022-05-28 11:34:55.075475: 
epoch:  62
2022-05-28 11:36:29.162165: train loss : -0.7361
2022-05-28 11:36:38.045337: validation loss: -0.6511
2022-05-28 11:36:38.063771: Average global foreground Dice: [0.7232]
2022-05-28 11:36:38.088513: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:36:38.732696: lr: 0.008859
2022-05-28 11:36:38.738690: This epoch took 103.661319 s

2022-05-28 11:36:38.744995: 
epoch:  63
2022-05-28 11:38:10.438922: train loss : -0.7246
2022-05-28 11:38:16.274203: validation loss: -0.7063
2022-05-28 11:38:16.277253: Average global foreground Dice: [0.7508]
2022-05-28 11:38:16.279220: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:38:16.713418: lr: 0.00884
2022-05-28 11:38:16.757928: saving checkpoint...
2022-05-28 11:38:17.728484: done, saving took 1.01 seconds
2022-05-28 11:38:17.744114: This epoch took 98.982775 s

2022-05-28 11:38:17.746178: 
epoch:  64
2022-05-28 11:39:49.611168: train loss : -0.7182
2022-05-28 11:39:56.567105: validation loss: -0.6594
2022-05-28 11:39:56.571040: Average global foreground Dice: [0.7531]
2022-05-28 11:39:56.573371: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:39:57.175866: lr: 0.008822
2022-05-28 11:39:57.234387: saving checkpoint...
2022-05-28 11:39:58.321326: done, saving took 1.14 seconds
2022-05-28 11:39:58.336879: This epoch took 100.588845 s

2022-05-28 11:39:58.339097: 
epoch:  65
2022-05-28 11:41:30.400774: train loss : -0.7243
2022-05-28 11:41:38.315591: validation loss: -0.6992
2022-05-28 11:41:38.322759: Average global foreground Dice: [0.7562]
2022-05-28 11:41:38.326363: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:41:38.841891: lr: 0.008804
2022-05-28 11:41:38.927602: saving checkpoint...
2022-05-28 11:41:40.045024: done, saving took 1.17 seconds
2022-05-28 11:41:40.062775: This epoch took 101.721755 s

2022-05-28 11:41:40.064907: 
epoch:  66
2022-05-28 11:43:13.016443: train loss : -0.7227
2022-05-28 11:43:19.376444: validation loss: -0.6979
2022-05-28 11:43:19.407811: Average global foreground Dice: [0.7576]
2022-05-28 11:43:19.433284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:43:20.064677: lr: 0.008785
2022-05-28 11:43:20.216718: saving checkpoint...
2022-05-28 11:43:21.269699: done, saving took 1.18 seconds
2022-05-28 11:43:21.323302: This epoch took 101.255916 s

2022-05-28 11:43:21.334924: 
epoch:  67
2022-05-28 11:44:53.194396: train loss : -0.7218
2022-05-28 11:44:59.649956: validation loss: -0.6712
2022-05-28 11:44:59.654920: Average global foreground Dice: [0.7526]
2022-05-28 11:44:59.657131: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:45:00.095663: lr: 0.008767
2022-05-28 11:45:00.145882: saving checkpoint...
2022-05-28 11:45:01.155496: done, saving took 1.06 seconds
2022-05-28 11:45:01.169607: This epoch took 99.824314 s

2022-05-28 11:45:01.171984: 
epoch:  68
2022-05-28 11:46:34.994683: train loss : -0.7404
2022-05-28 11:46:43.613045: validation loss: -0.6761
2022-05-28 11:46:43.641842: Average global foreground Dice: [0.7382]
2022-05-28 11:46:43.677282: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:46:44.553466: lr: 0.008749
2022-05-28 11:46:44.574323: This epoch took 103.400080 s

2022-05-28 11:46:44.593373: 
epoch:  69
2022-05-28 11:48:17.240421: train loss : -0.7479
2022-05-28 11:48:24.983851: validation loss: -0.6910
2022-05-28 11:48:25.015879: Average global foreground Dice: [0.7508]
2022-05-28 11:48:25.038293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:48:25.638480: lr: 0.008731
2022-05-28 11:48:25.701715: saving checkpoint...
2022-05-28 11:48:26.959609: done, saving took 1.31 seconds
2022-05-28 11:48:26.975710: This epoch took 102.370405 s

2022-05-28 11:48:26.978045: 
epoch:  70
2022-05-28 11:49:59.095855: train loss : -0.7478
2022-05-28 11:50:06.710043: validation loss: -0.6737
2022-05-28 11:50:06.714235: Average global foreground Dice: [0.7458]
2022-05-28 11:50:06.716689: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:50:07.223815: lr: 0.008712
2022-05-28 11:50:07.266422: saving checkpoint...
2022-05-28 11:50:08.327437: done, saving took 1.10 seconds
2022-05-28 11:50:08.341985: This epoch took 101.361973 s

2022-05-28 11:50:08.344075: 
epoch:  71
2022-05-28 11:51:43.507678: train loss : -0.7383
2022-05-28 11:51:51.988898: validation loss: -0.7159
2022-05-28 11:51:52.000168: Average global foreground Dice: [0.7678]
2022-05-28 11:51:52.028610: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:51:52.517799: lr: 0.008694
2022-05-28 11:51:52.573895: saving checkpoint...
2022-05-28 11:51:53.527883: done, saving took 1.01 seconds
2022-05-28 11:51:53.544872: This epoch took 105.198428 s

2022-05-28 11:51:53.546806: 
epoch:  72
2022-05-28 11:53:24.351985: train loss : -0.7391
2022-05-28 11:53:30.908091: validation loss: -0.6617
2022-05-28 11:53:30.925372: Average global foreground Dice: [0.7376]
2022-05-28 11:53:30.930032: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:53:31.384597: lr: 0.008676
2022-05-28 11:53:31.386910: This epoch took 97.838115 s

2022-05-28 11:53:31.388886: 
epoch:  73
2022-05-28 11:55:02.981312: train loss : -0.7451
2022-05-28 11:55:09.109802: validation loss: -0.7203
2022-05-28 11:55:09.112933: Average global foreground Dice: [0.7822]
2022-05-28 11:55:09.115000: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:55:09.561990: lr: 0.008658
2022-05-28 11:55:09.615571: saving checkpoint...
2022-05-28 11:55:10.550740: done, saving took 0.99 seconds
2022-05-28 11:55:10.565884: This epoch took 99.175003 s

2022-05-28 11:55:10.568259: 
epoch:  74
2022-05-28 11:56:41.803794: train loss : -0.7475
2022-05-28 11:56:48.838544: validation loss: -0.6851
2022-05-28 11:56:48.856872: Average global foreground Dice: [0.7725]
2022-05-28 11:56:48.859589: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:56:49.372805: lr: 0.008639
2022-05-28 11:56:49.442864: saving checkpoint...
2022-05-28 11:56:50.567589: done, saving took 1.17 seconds
2022-05-28 11:56:50.583165: This epoch took 100.012909 s

2022-05-28 11:56:50.585233: 
epoch:  75
2022-05-28 11:58:22.867143: train loss : -0.7425
2022-05-28 11:58:30.118536: validation loss: -0.6878
2022-05-28 11:58:30.162839: Average global foreground Dice: [0.7568]
2022-05-28 11:58:30.199307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 11:58:30.856710: lr: 0.008621
2022-05-28 11:58:30.961573: saving checkpoint...
2022-05-28 11:58:32.194133: done, saving took 1.30 seconds
2022-05-28 11:58:32.210262: This epoch took 101.622985 s

2022-05-28 11:58:32.212284: 
epoch:  76
2022-05-28 12:00:03.242218: train loss : -0.7303
2022-05-28 12:00:09.481673: validation loss: -0.6851
2022-05-28 12:00:09.487673: Average global foreground Dice: [0.7708]
2022-05-28 12:00:09.494671: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:00:09.938802: lr: 0.008603
2022-05-28 12:00:09.998365: saving checkpoint...
2022-05-28 12:00:11.059908: done, saving took 1.11 seconds
2022-05-28 12:00:11.076106: This epoch took 98.861858 s

2022-05-28 12:00:11.078148: 
epoch:  77
2022-05-28 12:01:41.595811: train loss : -0.7407
2022-05-28 12:01:48.364481: validation loss: -0.6775
2022-05-28 12:01:48.368330: Average global foreground Dice: [0.7522]
2022-05-28 12:01:48.371024: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:01:48.893064: lr: 0.008584
2022-05-28 12:01:48.895496: This epoch took 97.815166 s

2022-05-28 12:01:48.897752: 
epoch:  78
2022-05-28 12:03:21.584515: train loss : -0.7404
2022-05-28 12:03:30.068491: validation loss: -0.7195
2022-05-28 12:03:30.094482: Average global foreground Dice: [0.7643]
2022-05-28 12:03:30.115375: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:03:30.946570: lr: 0.008566
2022-05-28 12:03:31.084510: saving checkpoint...
2022-05-28 12:03:32.363426: done, saving took 1.39 seconds
2022-05-28 12:03:32.423091: This epoch took 103.523128 s

2022-05-28 12:03:32.430602: 
epoch:  79
2022-05-28 12:05:11.443342: train loss : -0.7271
2022-05-28 12:05:18.889639: validation loss: -0.7296
2022-05-28 12:05:18.893280: Average global foreground Dice: [0.7787]
2022-05-28 12:05:18.895982: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:05:19.455444: lr: 0.008548
2022-05-28 12:05:19.535501: saving checkpoint...
2022-05-28 12:05:20.694492: done, saving took 1.22 seconds
2022-05-28 12:05:20.711012: This epoch took 108.278291 s

2022-05-28 12:05:20.713100: 
epoch:  80
2022-05-28 12:06:52.910990: train loss : -0.7391
2022-05-28 12:06:59.907962: validation loss: -0.6738
2022-05-28 12:06:59.911855: Average global foreground Dice: [0.7565]
2022-05-28 12:06:59.914068: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:07:00.389139: lr: 0.008529
2022-05-28 12:07:00.463300: saving checkpoint...
2022-05-28 12:07:01.477509: done, saving took 1.08 seconds
2022-05-28 12:07:01.494221: This epoch took 100.779280 s

2022-05-28 12:07:01.496539: 
epoch:  81
2022-05-28 12:08:33.827083: train loss : -0.7413
2022-05-28 12:08:40.246619: validation loss: -0.6691
2022-05-28 12:08:40.272785: Average global foreground Dice: [0.7372]
2022-05-28 12:08:40.288340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:08:40.775809: lr: 0.008511
2022-05-28 12:08:40.778696: This epoch took 99.279866 s

2022-05-28 12:08:40.781158: 
epoch:  82
2022-05-28 12:10:12.827779: train loss : -0.7330
2022-05-28 12:10:20.129114: validation loss: -0.6673
2022-05-28 12:10:20.168798: Average global foreground Dice: [0.7404]
2022-05-28 12:10:20.189204: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:10:20.656332: lr: 0.008493
2022-05-28 12:10:20.658956: This epoch took 99.874928 s

2022-05-28 12:10:20.660990: 
epoch:  83
2022-05-28 12:11:55.062733: train loss : -0.7289
2022-05-28 12:12:01.996590: validation loss: -0.6547
2022-05-28 12:12:01.999933: Average global foreground Dice: [0.729]
2022-05-28 12:12:02.002084: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:12:02.470518: lr: 0.008474
2022-05-28 12:12:02.473089: This epoch took 101.809970 s

2022-05-28 12:12:02.475333: 
epoch:  84
2022-05-28 12:13:36.343397: train loss : -0.7222
2022-05-28 12:13:43.338486: validation loss: -0.6668
2022-05-28 12:13:43.369718: Average global foreground Dice: [0.7368]
2022-05-28 12:13:43.410257: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:13:44.055894: lr: 0.008456
2022-05-28 12:13:44.083396: This epoch took 101.605971 s

2022-05-28 12:13:44.114295: 
epoch:  85
2022-05-28 12:15:18.485990: train loss : -0.7301
2022-05-28 12:15:27.915747: validation loss: -0.6552
2022-05-28 12:15:27.919804: Average global foreground Dice: [0.7316]
2022-05-28 12:15:27.922101: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:15:28.490639: lr: 0.008438
2022-05-28 12:15:28.497292: This epoch took 104.361007 s

2022-05-28 12:15:28.500459: 
epoch:  86
2022-05-28 12:17:01.588234: train loss : -0.7484
2022-05-28 12:17:10.602741: validation loss: -0.6694
2022-05-28 12:17:10.605952: Average global foreground Dice: [0.7488]
2022-05-28 12:17:10.607974: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:17:11.060956: lr: 0.008419
2022-05-28 12:17:11.063299: This epoch took 102.560123 s

2022-05-28 12:17:11.065206: 
epoch:  87
2022-05-28 12:18:43.279134: train loss : -0.7384
2022-05-28 12:18:49.979538: validation loss: -0.6725
2022-05-28 12:18:49.996380: Average global foreground Dice: [0.7489]
2022-05-28 12:18:49.999469: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:18:50.449646: lr: 0.008401
2022-05-28 12:18:50.452366: This epoch took 99.385157 s

2022-05-28 12:18:50.454551: 
epoch:  88
2022-05-28 12:20:23.276060: train loss : -0.7471
2022-05-28 12:20:31.685196: validation loss: -0.6899
2022-05-28 12:20:31.720050: Average global foreground Dice: [0.7567]
2022-05-28 12:20:31.734622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:20:32.380664: lr: 0.008383
2022-05-28 12:20:32.384043: This epoch took 101.927252 s

2022-05-28 12:20:32.386348: 
epoch:  89
2022-05-28 12:22:04.737828: train loss : -0.7334
2022-05-28 12:22:12.182068: validation loss: -0.6905
2022-05-28 12:22:12.214727: Average global foreground Dice: [0.7616]
2022-05-28 12:22:12.231301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:22:12.769322: lr: 0.008364
2022-05-28 12:22:12.775519: This epoch took 100.386991 s

2022-05-28 12:22:12.778943: 
epoch:  90
2022-05-28 12:23:45.446160: train loss : -0.7452
2022-05-28 12:23:51.925066: validation loss: -0.7016
2022-05-28 12:23:51.928742: Average global foreground Dice: [0.758]
2022-05-28 12:23:51.930774: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:23:52.386955: lr: 0.008346
2022-05-28 12:23:52.389384: This epoch took 99.607607 s

2022-05-28 12:23:52.391365: 
epoch:  91
2022-05-28 12:25:24.258116: train loss : -0.7209
2022-05-28 12:25:31.583121: validation loss: -0.6986
2022-05-28 12:25:31.598831: Average global foreground Dice: [0.7554]
2022-05-28 12:25:31.611280: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:25:32.419647: lr: 0.008328
2022-05-28 12:25:32.422382: This epoch took 100.029087 s

2022-05-28 12:25:32.426833: 
epoch:  92
2022-05-28 12:27:03.535984: train loss : -0.7260
2022-05-28 12:27:10.867328: validation loss: -0.6468
2022-05-28 12:27:10.870733: Average global foreground Dice: [0.7453]
2022-05-28 12:27:10.885075: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:27:11.409877: lr: 0.008309
2022-05-28 12:27:11.434169: This epoch took 99.003424 s

2022-05-28 12:27:11.454188: 
epoch:  93
2022-05-28 12:28:43.542151: train loss : -0.7264
2022-05-28 12:28:51.908540: validation loss: -0.7097
2022-05-28 12:28:51.936671: Average global foreground Dice: [0.7771]
2022-05-28 12:28:51.956307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:28:52.756499: lr: 0.008291
2022-05-28 12:28:52.781474: This epoch took 101.318980 s

2022-05-28 12:28:52.784211: 
epoch:  94
2022-05-28 12:30:24.333470: train loss : -0.7369
2022-05-28 12:30:31.334535: validation loss: -0.7067
2022-05-28 12:30:31.343390: Average global foreground Dice: [0.7657]
2022-05-28 12:30:31.362982: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:30:31.929241: lr: 0.008272
2022-05-28 12:30:31.943639: This epoch took 99.140054 s

2022-05-28 12:30:31.962310: 
epoch:  95
2022-05-28 12:32:02.466258: train loss : -0.7489
2022-05-28 12:32:08.521073: validation loss: -0.7104
2022-05-28 12:32:08.551871: Average global foreground Dice: [0.7622]
2022-05-28 12:32:08.557864: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:32:09.029021: lr: 0.008254
2022-05-28 12:32:09.031439: This epoch took 97.065329 s

2022-05-28 12:32:09.033610: 
epoch:  96
2022-05-28 12:33:40.472430: train loss : -0.7568
2022-05-28 12:33:46.876401: validation loss: -0.7227
2022-05-28 12:33:46.879989: Average global foreground Dice: [0.773]
2022-05-28 12:33:46.882332: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:33:47.328358: lr: 0.008236
2022-05-28 12:33:47.386475: saving checkpoint...
2022-05-28 12:33:48.437233: done, saving took 1.11 seconds
2022-05-28 12:33:48.462309: This epoch took 99.426730 s

2022-05-28 12:33:48.464526: 
epoch:  97
2022-05-28 12:35:21.523093: train loss : -0.7479
2022-05-28 12:35:29.270797: validation loss: -0.6874
2022-05-28 12:35:29.295222: Average global foreground Dice: [0.7644]
2022-05-28 12:35:29.297440: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:35:29.772075: lr: 0.008217
2022-05-28 12:35:29.830546: saving checkpoint...
2022-05-28 12:35:30.839575: done, saving took 1.07 seconds
2022-05-28 12:35:30.855603: This epoch took 102.389078 s

2022-05-28 12:35:30.857647: 
epoch:  98
2022-05-28 12:37:01.495181: train loss : -0.7560
2022-05-28 12:37:07.958886: validation loss: -0.6867
2022-05-28 12:37:07.963723: Average global foreground Dice: [0.7595]
2022-05-28 12:37:07.965841: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:37:08.416499: lr: 0.008199
2022-05-28 12:37:08.477071: saving checkpoint...
2022-05-28 12:37:09.473131: done, saving took 1.05 seconds
2022-05-28 12:37:09.487509: This epoch took 98.627981 s

2022-05-28 12:37:09.489669: 
epoch:  99
2022-05-28 12:38:42.064101: train loss : -0.7515
2022-05-28 12:38:48.356710: validation loss: -0.7002
2022-05-28 12:38:48.360019: Average global foreground Dice: [0.7714]
2022-05-28 12:38:48.362295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:38:48.802682: lr: 0.008181
2022-05-28 12:38:48.804797: saving scheduled checkpoint file...
2022-05-28 12:38:48.859045: saving checkpoint...
2022-05-28 12:38:49.885414: done, saving took 1.08 seconds
2022-05-28 12:38:49.903592: done
2022-05-28 12:38:49.942070: saving checkpoint...
2022-05-28 12:38:50.910894: done, saving took 1.01 seconds
2022-05-28 12:38:50.924386: This epoch took 101.432417 s

2022-05-28 12:38:50.926629: 
epoch:  100
2022-05-28 12:40:23.935126: train loss : -0.7402
2022-05-28 12:40:31.352085: validation loss: -0.7223
2022-05-28 12:40:31.356524: Average global foreground Dice: [0.7813]
2022-05-28 12:40:31.358845: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:40:31.813546: lr: 0.008162
2022-05-28 12:40:31.867087: saving checkpoint...
2022-05-28 12:40:32.875837: done, saving took 1.06 seconds
2022-05-28 12:40:32.893183: This epoch took 101.964324 s

2022-05-28 12:40:32.895328: 
epoch:  101
2022-05-28 12:42:04.065644: train loss : -0.7549
2022-05-28 12:42:12.096472: validation loss: -0.6417
2022-05-28 12:42:12.099682: Average global foreground Dice: [0.7272]
2022-05-28 12:42:12.102062: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:42:12.619205: lr: 0.008144
2022-05-28 12:42:12.624018: This epoch took 99.726425 s

2022-05-28 12:42:12.626690: 
epoch:  102
2022-05-28 12:43:49.417641: train loss : -0.7585
2022-05-28 12:43:56.485005: validation loss: -0.7089
2022-05-28 12:43:56.497284: Average global foreground Dice: [0.7678]
2022-05-28 12:43:56.499431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:43:56.950733: lr: 0.008125
2022-05-28 12:43:56.954764: This epoch took 104.325019 s

2022-05-28 12:43:56.956632: 
epoch:  103
2022-05-28 12:45:28.909381: train loss : -0.7538
2022-05-28 12:45:36.104496: validation loss: -0.7103
2022-05-28 12:45:36.113856: Average global foreground Dice: [0.774]
2022-05-28 12:45:36.131293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:45:36.670742: lr: 0.008107
2022-05-28 12:45:36.673554: This epoch took 99.715061 s

2022-05-28 12:45:36.676114: 
epoch:  104
2022-05-28 12:47:11.488005: train loss : -0.7564
2022-05-28 12:47:20.409951: validation loss: -0.6973
2022-05-28 12:47:20.422713: Average global foreground Dice: [0.7651]
2022-05-28 12:47:20.424833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:47:20.917908: lr: 0.008088
2022-05-28 12:47:20.938411: This epoch took 104.259533 s

2022-05-28 12:47:20.961298: 
epoch:  105
2022-05-28 12:48:52.766186: train loss : -0.7369
2022-05-28 12:49:00.705203: validation loss: -0.6844
2022-05-28 12:49:00.709373: Average global foreground Dice: [0.7677]
2022-05-28 12:49:00.711420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:49:01.160994: lr: 0.00807
2022-05-28 12:49:01.223585: saving checkpoint...
2022-05-28 12:49:02.217589: done, saving took 1.05 seconds
2022-05-28 12:49:02.231022: This epoch took 101.260489 s

2022-05-28 12:49:02.233203: 
epoch:  106
2022-05-28 12:50:37.619297: train loss : -0.7323
2022-05-28 12:50:45.903587: validation loss: -0.6859
2022-05-28 12:50:45.939610: Average global foreground Dice: [0.767]
2022-05-28 12:50:45.960884: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:50:46.593723: lr: 0.008052
2022-05-28 12:50:46.710809: saving checkpoint...
2022-05-28 12:50:47.913509: done, saving took 1.32 seconds
2022-05-28 12:50:47.929886: This epoch took 105.694577 s

2022-05-28 12:50:47.932003: 
epoch:  107
2022-05-28 12:52:19.367686: train loss : -0.7561
2022-05-28 12:52:25.201373: validation loss: -0.6957
2022-05-28 12:52:25.204717: Average global foreground Dice: [0.7657]
2022-05-28 12:52:25.206944: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:52:25.645634: lr: 0.008033
2022-05-28 12:52:25.696536: saving checkpoint...
2022-05-28 12:52:26.711721: done, saving took 1.06 seconds
2022-05-28 12:52:26.727510: This epoch took 98.793362 s

2022-05-28 12:52:26.729742: 
epoch:  108
2022-05-28 12:53:58.435241: train loss : -0.7542
2022-05-28 12:54:04.865217: validation loss: -0.6847
2022-05-28 12:54:04.869507: Average global foreground Dice: [0.7592]
2022-05-28 12:54:04.871847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:54:05.324047: lr: 0.008015
2022-05-28 12:54:05.337149: This epoch took 98.605313 s

2022-05-28 12:54:05.343565: 
epoch:  109
2022-05-28 12:55:37.287534: train loss : -0.7422
2022-05-28 12:55:46.014261: validation loss: -0.6527
2022-05-28 12:55:46.074826: Average global foreground Dice: [0.7297]
2022-05-28 12:55:46.093385: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:55:46.739256: lr: 0.007996
2022-05-28 12:55:46.742096: This epoch took 101.395693 s

2022-05-28 12:55:46.744638: 
epoch:  110
2022-05-28 12:57:18.770572: train loss : -0.7365
2022-05-28 12:57:25.292273: validation loss: -0.7156
2022-05-28 12:57:25.313864: Average global foreground Dice: [0.7788]
2022-05-28 12:57:25.316089: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:57:25.827416: lr: 0.007978
2022-05-28 12:57:25.829734: This epoch took 99.069536 s

2022-05-28 12:57:25.831942: 
epoch:  111
2022-05-28 12:59:00.670650: train loss : -0.7274
2022-05-28 12:59:07.672994: validation loss: -0.6793
2022-05-28 12:59:07.702842: Average global foreground Dice: [0.7603]
2022-05-28 12:59:07.744493: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 12:59:08.322897: lr: 0.007959
2022-05-28 12:59:08.342412: This epoch took 102.508382 s

2022-05-28 12:59:08.363314: 
epoch:  112
2022-05-28 13:00:46.355505: train loss : -0.7222
2022-05-28 13:00:54.813611: validation loss: -0.6309
2022-05-28 13:00:54.827690: Average global foreground Dice: [0.7244]
2022-05-28 13:00:54.830023: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:00:55.314392: lr: 0.007941
2022-05-28 13:00:55.316904: This epoch took 106.932606 s

2022-05-28 13:00:55.319232: 
epoch:  113
2022-05-28 13:02:27.594774: train loss : -0.7469
2022-05-28 13:02:35.071453: validation loss: -0.7080
2022-05-28 13:02:35.102889: Average global foreground Dice: [0.7728]
2022-05-28 13:02:35.127377: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:02:35.849082: lr: 0.007922
2022-05-28 13:02:35.874446: This epoch took 100.552849 s

2022-05-28 13:02:35.896324: 
epoch:  114
2022-05-28 13:04:07.322554: train loss : -0.7549
2022-05-28 13:04:13.654587: validation loss: -0.7258
2022-05-28 13:04:13.686867: Average global foreground Dice: [0.7858]
2022-05-28 13:04:13.708316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:04:14.418608: lr: 0.007904
2022-05-28 13:04:14.434016: This epoch took 98.517611 s

2022-05-28 13:04:14.452219: 
epoch:  115
2022-05-28 13:05:45.661523: train loss : -0.7566
2022-05-28 13:05:52.641505: validation loss: -0.7054
2022-05-28 13:05:52.644865: Average global foreground Dice: [0.7825]
2022-05-28 13:05:52.646933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:05:53.105166: lr: 0.007885
2022-05-28 13:05:53.157904: saving checkpoint...
2022-05-28 13:05:54.196793: done, saving took 1.09 seconds
2022-05-28 13:05:54.214774: This epoch took 99.759780 s

2022-05-28 13:05:54.217087: 
epoch:  116
2022-05-28 13:07:25.696275: train loss : -0.7501
2022-05-28 13:07:32.765544: validation loss: -0.7092
2022-05-28 13:07:32.772581: Average global foreground Dice: [0.777]
2022-05-28 13:07:32.774763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:07:33.397186: lr: 0.007867
2022-05-28 13:07:33.504790: saving checkpoint...
2022-05-28 13:07:34.501463: done, saving took 1.08 seconds
2022-05-28 13:07:34.517957: This epoch took 100.298758 s

2022-05-28 13:07:34.520108: 
epoch:  117
2022-05-28 13:09:05.799461: train loss : -0.7594
2022-05-28 13:09:14.263669: validation loss: -0.7053
2022-05-28 13:09:14.277074: Average global foreground Dice: [0.7631]
2022-05-28 13:09:14.279223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:09:14.767722: lr: 0.007848
2022-05-28 13:09:14.770061: This epoch took 100.247077 s

2022-05-28 13:09:14.772011: 
epoch:  118
2022-05-28 13:10:46.681204: train loss : -0.7412
2022-05-28 13:10:53.968005: validation loss: -0.6992
2022-05-28 13:10:53.996745: Average global foreground Dice: [0.7396]
2022-05-28 13:10:54.003503: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:10:54.520051: lr: 0.00783
2022-05-28 13:10:54.522307: This epoch took 99.748335 s

2022-05-28 13:10:54.524264: 
epoch:  119
2022-05-28 13:12:25.860796: train loss : -0.7521
2022-05-28 13:12:33.021390: validation loss: -0.6973
2022-05-28 13:12:33.051011: Average global foreground Dice: [0.7789]
2022-05-28 13:12:33.069286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:12:33.556490: lr: 0.007811
2022-05-28 13:12:33.558782: This epoch took 99.032554 s

2022-05-28 13:12:33.560660: 
epoch:  120
2022-05-28 13:14:05.128232: train loss : -0.7514
2022-05-28 13:14:14.355803: validation loss: -0.6885
2022-05-28 13:14:14.375829: Average global foreground Dice: [0.7498]
2022-05-28 13:14:14.396190: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:14:15.090874: lr: 0.007793
2022-05-28 13:14:15.093271: This epoch took 101.530835 s

2022-05-28 13:14:15.095151: 
epoch:  121
2022-05-28 13:15:46.139732: train loss : -0.7595
2022-05-28 13:15:52.857990: validation loss: -0.7151
2022-05-28 13:15:52.862110: Average global foreground Dice: [0.7654]
2022-05-28 13:15:52.864036: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:15:53.355170: lr: 0.007774
2022-05-28 13:15:53.357252: This epoch took 98.260009 s

2022-05-28 13:15:53.359165: 
epoch:  122
2022-05-28 13:17:23.682815: train loss : -0.7602
2022-05-28 13:17:30.267413: validation loss: -0.7441
2022-05-28 13:17:30.270557: Average global foreground Dice: [0.7844]
2022-05-28 13:17:30.272516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:17:30.722558: lr: 0.007756
2022-05-28 13:17:30.779530: saving checkpoint...
2022-05-28 13:17:31.871134: done, saving took 1.15 seconds
2022-05-28 13:17:31.886985: This epoch took 98.526018 s

2022-05-28 13:17:31.889229: 
epoch:  123
2022-05-28 13:19:04.237219: train loss : -0.7509
2022-05-28 13:19:11.056422: validation loss: -0.7019
2022-05-28 13:19:11.095701: Average global foreground Dice: [0.7705]
2022-05-28 13:19:11.118299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:19:11.677664: lr: 0.007737
2022-05-28 13:19:11.737936: saving checkpoint...
2022-05-28 13:19:12.690882: done, saving took 1.01 seconds
2022-05-28 13:19:12.708504: This epoch took 100.817005 s

2022-05-28 13:19:12.710731: 
epoch:  124
2022-05-28 13:20:44.805260: train loss : -0.7458
2022-05-28 13:20:53.409413: validation loss: -0.7047
2022-05-28 13:20:53.430721: Average global foreground Dice: [0.7757]
2022-05-28 13:20:53.450930: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:20:54.101955: lr: 0.007719
2022-05-28 13:20:54.174595: saving checkpoint...
2022-05-28 13:20:55.181147: done, saving took 1.06 seconds
2022-05-28 13:20:55.197963: This epoch took 102.485205 s

2022-05-28 13:20:55.200061: 
epoch:  125
2022-05-28 13:22:26.898026: train loss : -0.7430
2022-05-28 13:22:33.815829: validation loss: -0.6627
2022-05-28 13:22:33.819242: Average global foreground Dice: [0.7353]
2022-05-28 13:22:33.821588: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:22:34.282718: lr: 0.0077
2022-05-28 13:22:34.284936: This epoch took 99.082795 s

2022-05-28 13:22:34.286958: 
epoch:  126
2022-05-28 13:24:06.426399: train loss : -0.7223
2022-05-28 13:24:12.909877: validation loss: -0.6792
2022-05-28 13:24:12.913118: Average global foreground Dice: [0.7471]
2022-05-28 13:24:12.925697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:24:13.405191: lr: 0.007682
2022-05-28 13:24:13.407675: This epoch took 99.118690 s

2022-05-28 13:24:13.409907: 
epoch:  127
2022-05-28 13:25:48.136923: train loss : -0.7604
2022-05-28 13:25:56.729731: validation loss: -0.6842
2022-05-28 13:25:56.733464: Average global foreground Dice: [0.7726]
2022-05-28 13:25:56.735628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:25:57.205934: lr: 0.007663
2022-05-28 13:25:57.208336: This epoch took 103.796310 s

2022-05-28 13:25:57.210548: 
epoch:  128
2022-05-28 13:27:33.391581: train loss : -0.7319
2022-05-28 13:27:41.613786: validation loss: -0.6757
2022-05-28 13:27:41.619821: Average global foreground Dice: [0.7574]
2022-05-28 13:27:41.622010: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:27:42.119120: lr: 0.007645
2022-05-28 13:27:42.121326: This epoch took 104.908629 s

2022-05-28 13:27:42.123387: 
epoch:  129
2022-05-28 13:29:17.085657: train loss : -0.7460
2022-05-28 13:29:24.913992: validation loss: -0.7325
2022-05-28 13:29:24.941731: Average global foreground Dice: [0.7745]
2022-05-28 13:29:24.962298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:29:25.705488: lr: 0.007626
2022-05-28 13:29:25.736385: This epoch took 103.610937 s

2022-05-28 13:29:25.770224: 
epoch:  130
2022-05-28 13:30:57.527907: train loss : -0.7639
2022-05-28 13:31:05.780097: validation loss: -0.7108
2022-05-28 13:31:05.815517: Average global foreground Dice: [0.7762]
2022-05-28 13:31:05.835290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:31:06.432271: lr: 0.007608
2022-05-28 13:31:06.435029: This epoch took 100.662389 s

2022-05-28 13:31:06.437624: 
epoch:  131
2022-05-28 13:32:39.267640: train loss : -0.7646
2022-05-28 13:32:45.830105: validation loss: -0.7070
2022-05-28 13:32:45.835889: Average global foreground Dice: [0.7748]
2022-05-28 13:32:45.838138: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:32:46.321745: lr: 0.007589
2022-05-28 13:32:46.324488: This epoch took 99.884508 s

2022-05-28 13:32:46.328459: 
epoch:  132
2022-05-28 13:34:16.983037: train loss : -0.7733
2022-05-28 13:34:23.975127: validation loss: -0.6672
2022-05-28 13:34:23.978715: Average global foreground Dice: [0.7334]
2022-05-28 13:34:23.981100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:34:24.725960: lr: 0.007571
2022-05-28 13:34:24.728428: This epoch took 98.398013 s

2022-05-28 13:34:24.730384: 
epoch:  133
2022-05-28 13:35:58.808622: train loss : -0.7620
2022-05-28 13:36:07.574973: validation loss: -0.7153
2022-05-28 13:36:07.579311: Average global foreground Dice: [0.7683]
2022-05-28 13:36:07.581717: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:36:08.078277: lr: 0.007552
2022-05-28 13:36:08.099317: This epoch took 103.366890 s

2022-05-28 13:36:08.102729: 
epoch:  134
2022-05-28 13:37:39.181003: train loss : -0.7670
2022-05-28 13:37:46.057553: validation loss: -0.7008
2022-05-28 13:37:46.061002: Average global foreground Dice: [0.7736]
2022-05-28 13:37:46.063146: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:37:46.527693: lr: 0.007533
2022-05-28 13:37:46.536167: This epoch took 98.428934 s

2022-05-28 13:37:46.548827: 
epoch:  135
2022-05-28 13:39:16.775308: train loss : -0.7726
2022-05-28 13:39:22.653679: validation loss: -0.6897
2022-05-28 13:39:22.657748: Average global foreground Dice: [0.7599]
2022-05-28 13:39:22.659891: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:39:23.159398: lr: 0.007515
2022-05-28 13:39:23.161797: This epoch took 96.610939 s

2022-05-28 13:39:23.163800: 
epoch:  136
2022-05-28 13:40:54.552299: train loss : -0.7770
2022-05-28 13:41:03.775222: validation loss: -0.7261
2022-05-28 13:41:03.807897: Average global foreground Dice: [0.7717]
2022-05-28 13:41:03.831356: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:41:04.463604: lr: 0.007496
2022-05-28 13:41:04.481048: This epoch took 101.315338 s

2022-05-28 13:41:04.496289: 
epoch:  137
2022-05-28 13:42:36.631989: train loss : -0.7590
2022-05-28 13:42:42.755702: validation loss: -0.6350
2022-05-28 13:42:42.759846: Average global foreground Dice: [0.7216]
2022-05-28 13:42:42.761998: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:42:43.237054: lr: 0.007478
2022-05-28 13:42:43.239303: This epoch took 98.713991 s

2022-05-28 13:42:43.241450: 
epoch:  138
2022-05-28 13:44:17.963499: train loss : -0.7616
2022-05-28 13:44:24.213378: validation loss: -0.6968
2022-05-28 13:44:24.245806: Average global foreground Dice: [0.7633]
2022-05-28 13:44:24.265378: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:44:24.744987: lr: 0.007459
2022-05-28 13:44:24.747623: This epoch took 101.504187 s

2022-05-28 13:44:24.749923: 
epoch:  139
2022-05-28 13:45:55.175345: train loss : -0.7792
2022-05-28 13:46:04.132495: validation loss: -0.7212
2022-05-28 13:46:04.159025: Average global foreground Dice: [0.7674]
2022-05-28 13:46:04.171539: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:46:04.697131: lr: 0.00744
2022-05-28 13:46:04.709930: This epoch took 99.957725 s

2022-05-28 13:46:04.713280: 
epoch:  140
2022-05-28 13:47:35.886078: train loss : -0.7820
2022-05-28 13:47:43.813826: validation loss: -0.7358
2022-05-28 13:47:43.818089: Average global foreground Dice: [0.7738]
2022-05-28 13:47:43.820404: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:47:44.309670: lr: 0.007422
2022-05-28 13:47:44.316236: This epoch took 99.592097 s

2022-05-28 13:47:44.318313: 
epoch:  141
2022-05-28 13:49:20.198904: train loss : -0.7671
2022-05-28 13:49:29.547470: validation loss: -0.7010
2022-05-28 13:49:29.579807: Average global foreground Dice: [0.7735]
2022-05-28 13:49:29.582489: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:49:30.157489: lr: 0.007403
2022-05-28 13:49:30.159843: This epoch took 105.839302 s

2022-05-28 13:49:30.161987: 
epoch:  142
2022-05-28 13:51:01.422123: train loss : -0.7690
2022-05-28 13:51:08.220918: validation loss: -0.6744
2022-05-28 13:51:08.241448: Average global foreground Dice: [0.7321]
2022-05-28 13:51:08.244500: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:51:08.721985: lr: 0.007385
2022-05-28 13:51:08.726740: This epoch took 98.561927 s

2022-05-28 13:51:08.729483: 
epoch:  143
2022-05-28 13:52:42.969092: train loss : -0.7625
2022-05-28 13:52:51.435696: validation loss: -0.6905
2022-05-28 13:52:51.439206: Average global foreground Dice: [0.7552]
2022-05-28 13:52:51.441626: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:52:51.949473: lr: 0.007366
2022-05-28 13:52:51.952186: This epoch took 103.220724 s

2022-05-28 13:52:51.954195: 
epoch:  144
2022-05-28 13:54:22.751745: train loss : -0.7584
2022-05-28 13:54:30.132762: validation loss: -0.6881
2022-05-28 13:54:30.135672: Average global foreground Dice: [0.7524]
2022-05-28 13:54:30.137743: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:54:30.617088: lr: 0.007347
2022-05-28 13:54:30.619351: This epoch took 98.662972 s

2022-05-28 13:54:30.621565: 
epoch:  145
2022-05-28 13:56:02.837126: train loss : -0.7552
2022-05-28 13:56:10.624190: validation loss: -0.6993
2022-05-28 13:56:10.631805: Average global foreground Dice: [0.7569]
2022-05-28 13:56:10.648024: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:56:11.183500: lr: 0.007329
2022-05-28 13:56:11.185868: This epoch took 100.562260 s

2022-05-28 13:56:11.187767: 
epoch:  146
2022-05-28 13:57:42.191191: train loss : -0.7730
2022-05-28 13:57:49.802451: validation loss: -0.7089
2022-05-28 13:57:49.806767: Average global foreground Dice: [0.7888]
2022-05-28 13:57:49.808928: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:57:50.315492: lr: 0.00731
2022-05-28 13:57:50.345365: This epoch took 99.155623 s

2022-05-28 13:57:50.362284: 
epoch:  147
2022-05-28 13:59:21.760517: train loss : -0.7750
2022-05-28 13:59:29.583650: validation loss: -0.7199
2022-05-28 13:59:29.594764: Average global foreground Dice: [0.7705]
2022-05-28 13:59:29.604404: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 13:59:30.077070: lr: 0.007291
2022-05-28 13:59:30.079548: This epoch took 99.698255 s

2022-05-28 13:59:30.081738: 
epoch:  148
2022-05-28 14:01:05.413629: train loss : -0.7705
2022-05-28 14:01:13.042182: validation loss: -0.6444
2022-05-28 14:01:13.046144: Average global foreground Dice: [0.7561]
2022-05-28 14:01:13.048197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:01:13.518733: lr: 0.007273
2022-05-28 14:01:13.521353: This epoch took 103.437270 s

2022-05-28 14:01:13.523638: 
epoch:  149
2022-05-28 14:02:45.419668: train loss : -0.7775
2022-05-28 14:02:54.080976: validation loss: -0.7121
2022-05-28 14:02:54.084276: Average global foreground Dice: [0.7646]
2022-05-28 14:02:54.104753: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:02:54.798331: lr: 0.007254
2022-05-28 14:02:54.827381: saving scheduled checkpoint file...
2022-05-28 14:02:54.896372: saving checkpoint...
2022-05-28 14:02:55.854422: done, saving took 1.02 seconds
2022-05-28 14:02:55.870342: done
2022-05-28 14:02:55.872578: This epoch took 102.346542 s

2022-05-28 14:02:55.874754: 
epoch:  150
2022-05-28 14:04:27.864774: train loss : -0.7810
2022-05-28 14:04:34.790402: validation loss: -0.7162
2022-05-28 14:04:34.794464: Average global foreground Dice: [0.7791]
2022-05-28 14:04:34.796478: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:04:35.262569: lr: 0.007236
2022-05-28 14:04:35.265210: This epoch took 99.388438 s

2022-05-28 14:04:35.267318: 
epoch:  151
2022-05-28 14:06:06.662930: train loss : -0.7754
2022-05-28 14:06:13.124699: validation loss: -0.7592
2022-05-28 14:06:13.128498: Average global foreground Dice: [0.8018]
2022-05-28 14:06:13.130731: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:06:13.734023: lr: 0.007217
2022-05-28 14:06:13.783158: saving checkpoint...
2022-05-28 14:06:14.731338: done, saving took 0.99 seconds
2022-05-28 14:06:14.753077: This epoch took 99.483863 s

2022-05-28 14:06:14.755378: 
epoch:  152
2022-05-28 14:07:46.370743: train loss : -0.7906
2022-05-28 14:07:55.403654: validation loss: -0.7243
2022-05-28 14:07:55.421432: Average global foreground Dice: [0.7903]
2022-05-28 14:07:55.440440: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:07:55.965729: lr: 0.007198
2022-05-28 14:07:56.025429: saving checkpoint...
2022-05-28 14:07:56.989318: done, saving took 1.02 seconds
2022-05-28 14:07:57.006300: This epoch took 102.248654 s

2022-05-28 14:07:57.008683: 
epoch:  153
2022-05-28 14:09:29.984218: train loss : -0.7832
2022-05-28 14:09:39.440225: validation loss: -0.7403
2022-05-28 14:09:39.453725: Average global foreground Dice: [0.7842]
2022-05-28 14:09:39.467292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:09:40.240295: lr: 0.00718
2022-05-28 14:09:40.316726: saving checkpoint...
2022-05-28 14:09:41.498952: done, saving took 1.24 seconds
2022-05-28 14:09:41.524238: This epoch took 104.513126 s

2022-05-28 14:09:41.526750: 
epoch:  154
2022-05-28 14:11:17.654697: train loss : -0.7591
2022-05-28 14:11:26.339533: validation loss: -0.6876
2022-05-28 14:11:26.345147: Average global foreground Dice: [0.7616]
2022-05-28 14:11:26.354640: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:11:26.812629: lr: 0.007161
2022-05-28 14:11:26.814979: This epoch took 105.286073 s

2022-05-28 14:11:26.817667: 
epoch:  155
2022-05-28 14:12:59.733673: train loss : -0.7700
2022-05-28 14:13:09.202359: validation loss: -0.6815
2022-05-28 14:13:09.205692: Average global foreground Dice: [0.7724]
2022-05-28 14:13:09.207649: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:13:09.669323: lr: 0.007142
2022-05-28 14:13:09.671457: This epoch took 102.851235 s

2022-05-28 14:13:09.673459: 
epoch:  156
2022-05-28 14:14:41.958532: train loss : -0.7859
2022-05-28 14:14:50.888793: validation loss: -0.7329
2022-05-28 14:14:50.936829: Average global foreground Dice: [0.7774]
2022-05-28 14:14:50.957078: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:14:51.665218: lr: 0.007123
2022-05-28 14:14:51.686332: This epoch took 102.010631 s

2022-05-28 14:14:51.708361: 
epoch:  157
2022-05-28 14:16:23.490238: train loss : -0.7577
2022-05-28 14:16:31.354543: validation loss: -0.7025
2022-05-28 14:16:31.377727: Average global foreground Dice: [0.7637]
2022-05-28 14:16:31.399360: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:16:31.893087: lr: 0.007105
2022-05-28 14:16:31.895489: This epoch took 100.160182 s

2022-05-28 14:16:31.897656: 
epoch:  158
2022-05-28 14:18:02.885340: train loss : -0.7692
2022-05-28 14:18:09.590992: validation loss: -0.7008
2022-05-28 14:18:09.594687: Average global foreground Dice: [0.764]
2022-05-28 14:18:09.597269: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:18:10.210781: lr: 0.007086
2022-05-28 14:18:10.213308: This epoch took 98.314129 s

2022-05-28 14:18:10.215630: 
epoch:  159
2022-05-28 14:19:42.115876: train loss : -0.7700
2022-05-28 14:19:47.897934: validation loss: -0.7262
2022-05-28 14:19:47.902031: Average global foreground Dice: [0.7742]
2022-05-28 14:19:47.904757: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:19:48.360320: lr: 0.007067
2022-05-28 14:19:48.362793: This epoch took 98.144923 s

2022-05-28 14:19:48.365127: 
epoch:  160
2022-05-28 14:21:19.902986: train loss : -0.7900
2022-05-28 14:21:27.832160: validation loss: -0.7406
2022-05-28 14:21:27.871756: Average global foreground Dice: [0.7933]
2022-05-28 14:21:27.903352: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:21:28.725230: lr: 0.007049
2022-05-28 14:21:28.825259: saving checkpoint...
2022-05-28 14:21:30.090457: done, saving took 1.35 seconds
2022-05-28 14:21:30.154381: This epoch took 101.787292 s

2022-05-28 14:21:30.174305: 
epoch:  161
2022-05-28 14:23:03.090258: train loss : -0.7721
2022-05-28 14:23:11.326258: validation loss: -0.7292
2022-05-28 14:23:11.359972: Average global foreground Dice: [0.7905]
2022-05-28 14:23:11.367022: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:23:11.860800: lr: 0.00703
2022-05-28 14:23:11.928946: saving checkpoint...
2022-05-28 14:23:12.906439: done, saving took 1.04 seconds
2022-05-28 14:23:12.923700: This epoch took 102.731390 s

2022-05-28 14:23:12.926281: 
epoch:  162
2022-05-28 14:24:44.415350: train loss : -0.7631
2022-05-28 14:24:52.251893: validation loss: -0.6920
2022-05-28 14:24:52.255495: Average global foreground Dice: [0.7606]
2022-05-28 14:24:52.257812: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:24:52.891186: lr: 0.007011
2022-05-28 14:24:52.894487: This epoch took 99.966021 s

2022-05-28 14:24:52.899391: 
epoch:  163
2022-05-28 14:26:26.842966: train loss : -0.7729
2022-05-28 14:26:33.849682: validation loss: -0.6920
2022-05-28 14:26:33.861086: Average global foreground Dice: [0.7922]
2022-05-28 14:26:33.865006: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:26:34.390456: lr: 0.006992
2022-05-28 14:26:34.450911: saving checkpoint...
2022-05-28 14:26:35.469954: done, saving took 1.07 seconds
2022-05-28 14:26:35.488019: This epoch took 102.586372 s

2022-05-28 14:26:35.490418: 
epoch:  164
2022-05-28 14:28:05.612542: train loss : -0.7826
2022-05-28 14:28:13.254366: validation loss: -0.7160
2022-05-28 14:28:13.258487: Average global foreground Dice: [0.7706]
2022-05-28 14:28:13.261099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:28:13.729550: lr: 0.006974
2022-05-28 14:28:13.731923: This epoch took 98.239079 s

2022-05-28 14:28:13.733894: 
epoch:  165
2022-05-28 14:29:45.601850: train loss : -0.7717
2022-05-28 14:29:53.184538: validation loss: -0.7331
2022-05-28 14:29:53.190678: Average global foreground Dice: [0.7829]
2022-05-28 14:29:53.193752: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:29:53.760647: lr: 0.006955
2022-05-28 14:29:53.808093: saving checkpoint...
2022-05-28 14:29:54.828727: done, saving took 1.07 seconds
2022-05-28 14:29:54.843849: This epoch took 101.108020 s

2022-05-28 14:29:54.846460: 
epoch:  166
2022-05-28 14:31:28.239904: train loss : -0.7695
2022-05-28 14:31:34.755708: validation loss: -0.7156
2022-05-28 14:31:34.759695: Average global foreground Dice: [0.7733]
2022-05-28 14:31:34.761914: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:31:35.339101: lr: 0.006936
2022-05-28 14:31:35.341404: This epoch took 100.492752 s

2022-05-28 14:31:35.344369: 
epoch:  167
2022-05-28 14:33:07.939882: train loss : -0.7709
2022-05-28 14:33:15.351517: validation loss: -0.6989
2022-05-28 14:33:15.355827: Average global foreground Dice: [0.7785]
2022-05-28 14:33:15.358985: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:33:15.830227: lr: 0.006918
2022-05-28 14:33:15.889733: saving checkpoint...
2022-05-28 14:33:16.933251: done, saving took 1.10 seconds
2022-05-28 14:33:16.950707: This epoch took 101.603992 s

2022-05-28 14:33:16.952962: 
epoch:  168
2022-05-28 14:34:48.721031: train loss : -0.7851
2022-05-28 14:34:56.149500: validation loss: -0.7023
2022-05-28 14:34:56.177749: Average global foreground Dice: [0.7796]
2022-05-28 14:34:56.197981: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:34:56.854682: lr: 0.006899
2022-05-28 14:34:56.947299: saving checkpoint...
2022-05-28 14:34:58.154354: done, saving took 1.29 seconds
2022-05-28 14:34:58.187851: This epoch took 101.232665 s

2022-05-28 14:34:58.190058: 
epoch:  169
2022-05-28 14:36:29.113127: train loss : -0.7855
2022-05-28 14:36:35.452323: validation loss: -0.7108
2022-05-28 14:36:35.455792: Average global foreground Dice: [0.7838]
2022-05-28 14:36:35.458014: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:36:35.919028: lr: 0.00688
2022-05-28 14:36:35.983482: saving checkpoint...
2022-05-28 14:36:36.942629: done, saving took 1.02 seconds
2022-05-28 14:36:36.957263: This epoch took 98.765110 s

2022-05-28 14:36:36.959330: 
epoch:  170
2022-05-28 14:38:07.653334: train loss : -0.7720
2022-05-28 14:38:14.558526: validation loss: -0.7121
2022-05-28 14:38:14.578876: Average global foreground Dice: [0.7926]
2022-05-28 14:38:14.598606: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:38:15.262545: lr: 0.006861
2022-05-28 14:38:15.337320: saving checkpoint...
2022-05-28 14:38:16.439281: done, saving took 1.15 seconds
2022-05-28 14:38:16.455075: This epoch took 99.493871 s

2022-05-28 14:38:16.457427: 
epoch:  171
2022-05-28 14:39:47.669121: train loss : -0.7505
2022-05-28 14:39:55.037341: validation loss: -0.7152
2022-05-28 14:39:55.044237: Average global foreground Dice: [0.7725]
2022-05-28 14:39:55.060332: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:39:55.695206: lr: 0.006842
2022-05-28 14:39:55.701486: This epoch took 99.241828 s

2022-05-28 14:39:55.710907: 
epoch:  172
2022-05-28 14:41:28.368609: train loss : -0.7747
2022-05-28 14:41:36.553614: validation loss: -0.7013
2022-05-28 14:41:36.584843: Average global foreground Dice: [0.7842]
2022-05-28 14:41:36.607891: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:41:37.577054: lr: 0.006824
2022-05-28 14:41:37.654235: saving checkpoint...
2022-05-28 14:41:38.990530: done, saving took 1.39 seconds
2022-05-28 14:41:39.031309: This epoch took 103.313811 s

2022-05-28 14:41:39.033854: 
epoch:  173
2022-05-28 14:43:12.347021: train loss : -0.7918
2022-05-28 14:43:19.411478: validation loss: -0.7350
2022-05-28 14:43:19.422009: Average global foreground Dice: [0.778]
2022-05-28 14:43:19.424395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:43:19.904053: lr: 0.006805
2022-05-28 14:43:19.906731: This epoch took 100.856252 s

2022-05-28 14:43:19.909582: 
epoch:  174
2022-05-28 14:44:54.044590: train loss : -0.7832
2022-05-28 14:45:03.192505: validation loss: -0.6984
2022-05-28 14:45:03.272738: Average global foreground Dice: [0.7681]
2022-05-28 14:45:03.294910: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:45:04.106623: lr: 0.006786
2022-05-28 14:45:04.132695: This epoch took 104.220776 s

2022-05-28 14:45:04.166287: 
epoch:  175
2022-05-28 14:46:36.328922: train loss : -0.7866
2022-05-28 14:46:43.414990: validation loss: -0.7212
2022-05-28 14:46:43.421674: Average global foreground Dice: [0.783]
2022-05-28 14:46:43.459305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:46:44.132254: lr: 0.006767
2022-05-28 14:46:44.159457: This epoch took 99.971169 s

2022-05-28 14:46:44.171510: 
epoch:  176
2022-05-28 14:48:16.342502: train loss : -0.7832
2022-05-28 14:48:24.214398: validation loss: -0.7439
2022-05-28 14:48:24.218827: Average global foreground Dice: [0.7862]
2022-05-28 14:48:24.221292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:48:24.672497: lr: 0.006749
2022-05-28 14:48:24.725020: saving checkpoint...
2022-05-28 14:48:25.701058: done, saving took 1.03 seconds
2022-05-28 14:48:25.715452: This epoch took 101.533128 s

2022-05-28 14:48:25.717420: 
epoch:  177
2022-05-28 14:49:58.542915: train loss : -0.7791
2022-05-28 14:50:06.883276: validation loss: -0.6881
2022-05-28 14:50:06.897571: Average global foreground Dice: [0.7738]
2022-05-28 14:50:06.910236: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:50:07.508812: lr: 0.00673
2022-05-28 14:50:07.511083: This epoch took 101.791689 s

2022-05-28 14:50:07.513118: 
epoch:  178
2022-05-28 14:51:39.708913: train loss : -0.7751
2022-05-28 14:51:48.169896: validation loss: -0.7057
2022-05-28 14:51:48.175529: Average global foreground Dice: [0.7828]
2022-05-28 14:51:48.178402: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:51:48.696701: lr: 0.006711
2022-05-28 14:51:48.701363: This epoch took 101.186234 s

2022-05-28 14:51:48.705652: 
epoch:  179
2022-05-28 14:53:21.422515: train loss : -0.7634
2022-05-28 14:53:29.666558: validation loss: -0.7097
2022-05-28 14:53:29.697790: Average global foreground Dice: [0.7607]
2022-05-28 14:53:29.733314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:53:30.871640: lr: 0.006692
2022-05-28 14:53:30.892308: This epoch took 102.184464 s

2022-05-28 14:53:30.915287: 
epoch:  180
2022-05-28 14:55:10.333822: train loss : -0.7774
2022-05-28 14:55:16.937191: validation loss: -0.7035
2022-05-28 14:55:16.940955: Average global foreground Dice: [0.7754]
2022-05-28 14:55:16.942872: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:55:17.405408: lr: 0.006673
2022-05-28 14:55:17.407634: This epoch took 106.464140 s

2022-05-28 14:55:17.419088: 
epoch:  181
2022-05-28 14:56:48.520461: train loss : -0.7768
2022-05-28 14:56:56.600663: validation loss: -0.6968
2022-05-28 14:56:56.620451: Average global foreground Dice: [0.7686]
2022-05-28 14:56:56.641948: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:56:57.149737: lr: 0.006654
2022-05-28 14:56:57.159318: This epoch took 99.738187 s

2022-05-28 14:56:57.161287: 
epoch:  182
2022-05-28 14:58:33.965823: train loss : -0.7805
2022-05-28 14:58:42.405560: validation loss: -0.6908
2022-05-28 14:58:42.409621: Average global foreground Dice: [0.7712]
2022-05-28 14:58:42.412207: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 14:58:42.875069: lr: 0.006636
2022-05-28 14:58:42.877614: This epoch took 105.712420 s

2022-05-28 14:58:42.879586: 
epoch:  183
2022-05-28 15:00:16.789927: train loss : -0.7853
2022-05-28 15:00:24.426208: validation loss: -0.7321
2022-05-28 15:00:24.429653: Average global foreground Dice: [0.7912]
2022-05-28 15:00:24.435809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:00:24.993744: lr: 0.006617
2022-05-28 15:00:25.015324: This epoch took 102.133665 s

2022-05-28 15:00:25.037288: 
epoch:  184
2022-05-28 15:01:57.002660: train loss : -0.7894
2022-05-28 15:02:03.630791: validation loss: -0.7183
2022-05-28 15:02:03.634660: Average global foreground Dice: [0.7814]
2022-05-28 15:02:03.637475: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:02:04.156288: lr: 0.006598
2022-05-28 15:02:04.163086: This epoch took 99.092789 s

2022-05-28 15:02:04.166669: 
epoch:  185
2022-05-28 15:03:35.646781: train loss : -0.7824
2022-05-28 15:03:43.654223: validation loss: -0.7271
2022-05-28 15:03:43.657716: Average global foreground Dice: [0.782]
2022-05-28 15:03:43.660164: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:03:44.125782: lr: 0.006579
2022-05-28 15:03:44.128569: This epoch took 99.959107 s

2022-05-28 15:03:44.130903: 
epoch:  186
2022-05-28 15:05:15.274652: train loss : -0.7627
2022-05-28 15:05:21.241851: validation loss: -0.6739
2022-05-28 15:05:21.245821: Average global foreground Dice: [0.7569]
2022-05-28 15:05:21.248214: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:05:21.698912: lr: 0.00656
2022-05-28 15:05:21.701344: This epoch took 97.568534 s

2022-05-28 15:05:21.703271: 
epoch:  187
2022-05-28 15:06:55.855686: train loss : -0.7865
2022-05-28 15:07:01.846014: validation loss: -0.7021
2022-05-28 15:07:01.849727: Average global foreground Dice: [0.7814]
2022-05-28 15:07:01.851939: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:07:02.324446: lr: 0.006541
2022-05-28 15:07:02.327267: This epoch took 100.621956 s

2022-05-28 15:07:02.329324: 
epoch:  188
2022-05-28 15:08:34.388736: train loss : -0.7950
2022-05-28 15:08:42.376699: validation loss: -0.7026
2022-05-28 15:08:42.379961: Average global foreground Dice: [0.7677]
2022-05-28 15:08:42.381970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:08:42.880014: lr: 0.006522
2022-05-28 15:08:42.883054: This epoch took 100.551694 s

2022-05-28 15:08:42.891767: 
epoch:  189
2022-05-28 15:10:14.350347: train loss : -0.7836
2022-05-28 15:10:21.766831: validation loss: -0.7145
2022-05-28 15:10:21.771136: Average global foreground Dice: [0.7644]
2022-05-28 15:10:21.773558: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:10:22.244164: lr: 0.006504
2022-05-28 15:10:22.246684: This epoch took 99.351978 s

2022-05-28 15:10:22.248783: 
epoch:  190
2022-05-28 15:11:53.832109: train loss : -0.7943
2022-05-28 15:12:02.113385: validation loss: -0.7138
2022-05-28 15:12:02.156781: Average global foreground Dice: [0.767]
2022-05-28 15:12:02.177391: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:12:02.750672: lr: 0.006485
2022-05-28 15:12:02.773366: This epoch took 100.522019 s

2022-05-28 15:12:02.798371: 
epoch:  191
2022-05-28 15:13:34.961545: train loss : -0.7806
2022-05-28 15:13:44.266582: validation loss: -0.7437
2022-05-28 15:13:44.296806: Average global foreground Dice: [0.7913]
2022-05-28 15:13:44.315318: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:13:45.387671: lr: 0.006466
2022-05-28 15:13:45.409463: This epoch took 102.602375 s

2022-05-28 15:13:45.439289: 
epoch:  192
2022-05-28 15:15:16.301617: train loss : -0.7957
2022-05-28 15:15:22.334825: validation loss: -0.7135
2022-05-28 15:15:22.338837: Average global foreground Dice: [0.7728]
2022-05-28 15:15:22.340935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:15:22.823483: lr: 0.006447
2022-05-28 15:15:22.825724: This epoch took 97.364419 s

2022-05-28 15:15:22.827681: 
epoch:  193
2022-05-28 15:16:54.857253: train loss : -0.7753
2022-05-28 15:17:01.446712: validation loss: -0.7034
2022-05-28 15:17:01.450843: Average global foreground Dice: [0.7772]
2022-05-28 15:17:01.453010: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:17:01.907178: lr: 0.006428
2022-05-28 15:17:01.909529: This epoch took 99.079787 s

2022-05-28 15:17:01.911739: 
epoch:  194
2022-05-28 15:18:33.346279: train loss : -0.7907
2022-05-28 15:18:42.070588: validation loss: -0.6720
2022-05-28 15:18:42.091817: Average global foreground Dice: [0.7524]
2022-05-28 15:18:42.125317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:18:42.657713: lr: 0.006409
2022-05-28 15:18:42.690370: This epoch took 100.776168 s

2022-05-28 15:18:42.720411: 
epoch:  195
2022-05-28 15:20:14.394309: train loss : -0.7897
2022-05-28 15:20:22.322376: validation loss: -0.7134
2022-05-28 15:20:22.326981: Average global foreground Dice: [0.7842]
2022-05-28 15:20:22.331597: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:20:22.805251: lr: 0.00639
2022-05-28 15:20:22.807845: This epoch took 100.065498 s

2022-05-28 15:20:22.810968: 
epoch:  196
2022-05-28 15:21:54.061700: train loss : -0.7735
2022-05-28 15:22:01.339534: validation loss: -0.7344
2022-05-28 15:22:01.342989: Average global foreground Dice: [0.791]
2022-05-28 15:22:01.344987: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:22:01.822459: lr: 0.006371
2022-05-28 15:22:01.825097: This epoch took 99.011271 s

2022-05-28 15:22:01.827129: 
epoch:  197
2022-05-28 15:23:33.655828: train loss : -0.7906
2022-05-28 15:23:43.387538: validation loss: -0.7011
2022-05-28 15:23:43.391437: Average global foreground Dice: [0.7624]
2022-05-28 15:23:43.393666: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:23:44.005168: lr: 0.006352
2022-05-28 15:23:44.026448: This epoch took 102.197124 s

2022-05-28 15:23:44.056303: 
epoch:  198
2022-05-28 15:25:15.622889: train loss : -0.7838
2022-05-28 15:25:23.258805: validation loss: -0.7316
2022-05-28 15:25:23.293809: Average global foreground Dice: [0.7921]
2022-05-28 15:25:23.335001: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:25:24.076458: lr: 0.006333
2022-05-28 15:25:24.078794: This epoch took 100.006640 s

2022-05-28 15:25:24.080642: 
epoch:  199
2022-05-28 15:26:56.170552: train loss : -0.7880
2022-05-28 15:27:02.483315: validation loss: -0.7356
2022-05-28 15:27:02.487632: Average global foreground Dice: [0.7865]
2022-05-28 15:27:02.490292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:27:03.016835: lr: 0.006314
2022-05-28 15:27:03.019266: saving scheduled checkpoint file...
2022-05-28 15:27:03.075269: saving checkpoint...
2022-05-28 15:27:04.092420: done, saving took 1.07 seconds
2022-05-28 15:27:04.114256: done
2022-05-28 15:27:04.116366: This epoch took 100.033797 s

2022-05-28 15:27:04.118342: 
epoch:  200
2022-05-28 15:28:36.392657: train loss : -0.7858
2022-05-28 15:28:44.951337: validation loss: -0.6841
2022-05-28 15:28:44.971683: Average global foreground Dice: [0.7476]
2022-05-28 15:28:44.983309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:28:45.597267: lr: 0.006296
2022-05-28 15:28:45.599803: This epoch took 101.479549 s

2022-05-28 15:28:45.602174: 
epoch:  201
2022-05-28 15:30:18.556495: train loss : -0.7648
2022-05-28 15:30:26.565876: validation loss: -0.7143
2022-05-28 15:30:26.569251: Average global foreground Dice: [0.7785]
2022-05-28 15:30:26.571467: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:30:27.066084: lr: 0.006277
2022-05-28 15:30:27.068292: This epoch took 101.464091 s

2022-05-28 15:30:27.070333: 
epoch:  202
2022-05-28 15:31:58.945253: train loss : -0.7716
2022-05-28 15:32:07.953560: validation loss: -0.7045
2022-05-28 15:32:07.977893: Average global foreground Dice: [0.7532]
2022-05-28 15:32:07.997347: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:32:08.651112: lr: 0.006258
2022-05-28 15:32:08.671495: This epoch took 101.599273 s

2022-05-28 15:32:08.695326: 
epoch:  203
2022-05-28 15:33:40.491740: train loss : -0.7814
2022-05-28 15:33:48.529514: validation loss: -0.6962
2022-05-28 15:33:48.533513: Average global foreground Dice: [0.7732]
2022-05-28 15:33:48.535608: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:33:49.013674: lr: 0.006239
2022-05-28 15:33:49.015854: This epoch took 100.302537 s

2022-05-28 15:33:49.018653: 
epoch:  204
2022-05-28 15:35:20.263173: train loss : -0.7770
2022-05-28 15:35:27.760733: validation loss: -0.7376
2022-05-28 15:35:27.765136: Average global foreground Dice: [0.7934]
2022-05-28 15:35:27.767308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:35:28.249449: lr: 0.00622
2022-05-28 15:35:28.251966: This epoch took 99.228427 s

2022-05-28 15:35:28.254206: 
epoch:  205
2022-05-28 15:36:59.791018: train loss : -0.7794
2022-05-28 15:37:08.228928: validation loss: -0.7112
2022-05-28 15:37:08.233327: Average global foreground Dice: [0.7696]
2022-05-28 15:37:08.235362: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:37:08.710117: lr: 0.006201
2022-05-28 15:37:08.712708: This epoch took 100.456368 s

2022-05-28 15:37:08.714647: 
epoch:  206
2022-05-28 15:38:42.948671: train loss : -0.7772
2022-05-28 15:38:52.192374: validation loss: -0.7126
2022-05-28 15:38:52.201311: Average global foreground Dice: [0.7741]
2022-05-28 15:38:52.227063: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:38:52.831315: lr: 0.006182
2022-05-28 15:38:52.854350: This epoch took 104.135246 s

2022-05-28 15:38:52.868427: 
epoch:  207
2022-05-28 15:40:26.462989: train loss : -0.7887
2022-05-28 15:40:35.725138: validation loss: -0.7371
2022-05-28 15:40:35.729866: Average global foreground Dice: [0.8097]
2022-05-28 15:40:35.732475: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:40:36.249874: lr: 0.006163
2022-05-28 15:40:36.282375: This epoch took 103.406458 s

2022-05-28 15:40:36.305285: 
epoch:  208
2022-05-28 15:42:08.004089: train loss : -0.7823
2022-05-28 15:42:15.726294: validation loss: -0.7069
2022-05-28 15:42:15.756996: Average global foreground Dice: [0.7812]
2022-05-28 15:42:15.776369: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:42:16.317623: lr: 0.006144
2022-05-28 15:42:16.320513: This epoch took 100.000231 s

2022-05-28 15:42:16.323043: 
epoch:  209
2022-05-28 15:43:47.291630: train loss : -0.7821
2022-05-28 15:43:53.210802: validation loss: -0.7378
2022-05-28 15:43:53.214185: Average global foreground Dice: [0.7915]
2022-05-28 15:43:53.216140: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:43:53.660425: lr: 0.006125
2022-05-28 15:43:53.719158: saving checkpoint...
2022-05-28 15:43:54.684992: done, saving took 1.02 seconds
2022-05-28 15:43:54.700723: This epoch took 98.375253 s

2022-05-28 15:43:54.703108: 
epoch:  210
2022-05-28 15:45:26.673640: train loss : -0.7695
2022-05-28 15:45:34.564161: validation loss: -0.7066
2022-05-28 15:45:34.576514: Average global foreground Dice: [0.7595]
2022-05-28 15:45:34.578931: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:45:35.075010: lr: 0.006106
2022-05-28 15:45:35.106532: This epoch took 100.400129 s

2022-05-28 15:45:35.123296: 
epoch:  211
2022-05-28 15:47:06.482852: train loss : -0.7689
2022-05-28 15:47:14.984766: validation loss: -0.7392
2022-05-28 15:47:14.987899: Average global foreground Dice: [0.7892]
2022-05-28 15:47:14.989944: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:47:15.658868: lr: 0.006087
2022-05-28 15:47:15.661490: This epoch took 100.516200 s

2022-05-28 15:47:15.663824: 
epoch:  212
2022-05-28 15:48:47.024122: train loss : -0.7685
2022-05-28 15:48:56.309832: validation loss: -0.7057
2022-05-28 15:48:56.320764: Average global foreground Dice: [0.7691]
2022-05-28 15:48:56.325405: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:48:56.830878: lr: 0.006068
2022-05-28 15:48:56.840119: This epoch took 101.173905 s

2022-05-28 15:48:56.842399: 
epoch:  213
2022-05-28 15:50:27.029468: train loss : -0.7858
2022-05-28 15:50:34.127800: validation loss: -0.7011
2022-05-28 15:50:34.131631: Average global foreground Dice: [0.7939]
2022-05-28 15:50:34.134015: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:50:34.587600: lr: 0.006049
2022-05-28 15:50:34.590044: This epoch took 97.745637 s

2022-05-28 15:50:34.591991: 
epoch:  214
2022-05-28 15:52:08.901219: train loss : -0.7781
2022-05-28 15:52:15.357812: validation loss: -0.7300
2022-05-28 15:52:15.366830: Average global foreground Dice: [0.79]
2022-05-28 15:52:15.368885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:52:15.839230: lr: 0.00603
2022-05-28 15:52:15.892297: saving checkpoint...
2022-05-28 15:52:16.857955: done, saving took 1.02 seconds
2022-05-28 15:52:16.873288: This epoch took 102.279158 s

2022-05-28 15:52:16.875288: 
epoch:  215
2022-05-28 15:53:47.527086: train loss : -0.7997
2022-05-28 15:53:53.621547: validation loss: -0.6784
2022-05-28 15:53:53.625732: Average global foreground Dice: [0.7773]
2022-05-28 15:53:53.627927: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:53:54.094100: lr: 0.006011
2022-05-28 15:53:54.096298: This epoch took 97.218991 s

2022-05-28 15:53:54.098484: 
epoch:  216
2022-05-28 15:55:25.782815: train loss : -0.7914
2022-05-28 15:55:33.296414: validation loss: -0.7022
2022-05-28 15:55:33.300287: Average global foreground Dice: [0.7557]
2022-05-28 15:55:33.302667: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:55:33.782505: lr: 0.005991
2022-05-28 15:55:33.784728: This epoch took 99.684337 s

2022-05-28 15:55:33.787024: 
epoch:  217
2022-05-28 15:57:05.383116: train loss : -0.7898
2022-05-28 15:57:12.844136: validation loss: -0.7389
2022-05-28 15:57:12.847767: Average global foreground Dice: [0.7945]
2022-05-28 15:57:12.849941: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:57:13.333771: lr: 0.005972
2022-05-28 15:57:13.335963: This epoch took 99.546872 s

2022-05-28 15:57:13.337917: 
epoch:  218
2022-05-28 15:58:46.468825: train loss : -0.7794
2022-05-28 15:58:54.668066: validation loss: -0.6800
2022-05-28 15:58:54.689920: Average global foreground Dice: [0.7432]
2022-05-28 15:58:54.692805: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 15:58:55.257315: lr: 0.005953
2022-05-28 15:58:55.259521: This epoch took 101.919830 s

2022-05-28 15:58:55.261517: 
epoch:  219
2022-05-28 16:00:26.776740: train loss : -0.7814
2022-05-28 16:00:35.193419: validation loss: -0.7010
2022-05-28 16:00:35.196886: Average global foreground Dice: [0.7685]
2022-05-28 16:00:35.199185: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:00:35.740251: lr: 0.005934
2022-05-28 16:00:35.742771: This epoch took 100.479430 s

2022-05-28 16:00:35.746669: 
epoch:  220
2022-05-28 16:02:07.876225: train loss : -0.7828
2022-05-28 16:02:17.516383: validation loss: -0.6747
2022-05-28 16:02:17.543886: Average global foreground Dice: [0.7519]
2022-05-28 16:02:17.566299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:02:18.211125: lr: 0.005915
2022-05-28 16:02:18.222945: This epoch took 102.472941 s

2022-05-28 16:02:18.225358: 
epoch:  221
2022-05-28 16:03:52.103155: train loss : -0.7954
2022-05-28 16:04:00.929898: validation loss: -0.7018
2022-05-28 16:04:00.950754: Average global foreground Dice: [0.7898]
2022-05-28 16:04:00.953070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:04:01.659667: lr: 0.005896
2022-05-28 16:04:01.668072: This epoch took 103.439546 s

2022-05-28 16:04:01.680674: 
epoch:  222
2022-05-28 16:05:33.580919: train loss : -0.7958
2022-05-28 16:05:42.337021: validation loss: -0.6693
2022-05-28 16:05:42.339969: Average global foreground Dice: [0.7753]
2022-05-28 16:05:42.341925: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:05:42.832569: lr: 0.005877
2022-05-28 16:05:42.834963: This epoch took 101.143384 s

2022-05-28 16:05:42.837534: 
epoch:  223
2022-05-28 16:07:20.881102: train loss : -0.7895
2022-05-28 16:07:30.821906: validation loss: -0.7093
2022-05-28 16:07:30.827653: Average global foreground Dice: [0.7819]
2022-05-28 16:07:30.830154: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:07:31.347434: lr: 0.005858
2022-05-28 16:07:31.350389: This epoch took 108.510835 s

2022-05-28 16:07:31.355371: 
epoch:  224
2022-05-28 16:09:02.353434: train loss : -0.8074
2022-05-28 16:09:09.145175: validation loss: -0.7212
2022-05-28 16:09:09.149785: Average global foreground Dice: [0.7663]
2022-05-28 16:09:09.152151: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:09:09.629105: lr: 0.005839
2022-05-28 16:09:09.631927: This epoch took 98.274501 s

2022-05-28 16:09:09.634219: 
epoch:  225
2022-05-28 16:10:40.829386: train loss : -0.7814
2022-05-28 16:10:47.701527: validation loss: -0.6762
2022-05-28 16:10:47.708155: Average global foreground Dice: [0.7705]
2022-05-28 16:10:47.710121: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:10:48.187228: lr: 0.00582
2022-05-28 16:10:48.189393: This epoch took 98.550653 s

2022-05-28 16:10:48.191397: 
epoch:  226
2022-05-28 16:12:18.788713: train loss : -0.7872
2022-05-28 16:12:24.561090: validation loss: -0.7236
2022-05-28 16:12:24.565392: Average global foreground Dice: [0.7775]
2022-05-28 16:12:24.567729: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:12:25.028881: lr: 0.005801
2022-05-28 16:12:25.031557: This epoch took 96.838216 s

2022-05-28 16:12:25.033822: 
epoch:  227
2022-05-28 16:13:59.472981: train loss : -0.8056
2022-05-28 16:14:08.860940: validation loss: -0.7438
2022-05-28 16:14:08.901569: Average global foreground Dice: [0.8004]
2022-05-28 16:14:08.943290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:14:09.703821: lr: 0.005781
2022-05-28 16:14:09.714739: This epoch took 104.678791 s

2022-05-28 16:14:09.720664: 
epoch:  228
2022-05-28 16:15:41.100799: train loss : -0.8021
2022-05-28 16:15:49.118029: validation loss: -0.6752
2022-05-28 16:15:49.122158: Average global foreground Dice: [0.7568]
2022-05-28 16:15:49.124102: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:15:49.570458: lr: 0.005762
2022-05-28 16:15:49.572745: This epoch took 99.849476 s

2022-05-28 16:15:49.574901: 
epoch:  229
2022-05-28 16:17:20.920948: train loss : -0.7949
2022-05-28 16:17:29.363491: validation loss: -0.7366
2022-05-28 16:17:29.368202: Average global foreground Dice: [0.791]
2022-05-28 16:17:29.370351: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:17:29.835939: lr: 0.005743
2022-05-28 16:17:29.838088: This epoch took 100.261339 s

2022-05-28 16:17:29.840138: 
epoch:  230
2022-05-28 16:19:01.533215: train loss : -0.7998
2022-05-28 16:19:10.048880: validation loss: -0.7086
2022-05-28 16:19:10.060849: Average global foreground Dice: [0.7698]
2022-05-28 16:19:10.082293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:19:10.855597: lr: 0.005724
2022-05-28 16:19:10.867968: This epoch took 101.025831 s

2022-05-28 16:19:10.889519: 
epoch:  231
2022-05-28 16:20:47.252725: train loss : -0.7794
2022-05-28 16:20:56.581467: validation loss: -0.6819
2022-05-28 16:20:56.587193: Average global foreground Dice: [0.7497]
2022-05-28 16:20:56.590132: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:20:57.065862: lr: 0.005705
2022-05-28 16:20:57.069065: This epoch took 106.164755 s

2022-05-28 16:20:57.072103: 
epoch:  232
2022-05-28 16:22:36.612799: train loss : -0.7996
2022-05-28 16:22:44.261721: validation loss: -0.7292
2022-05-28 16:22:44.265691: Average global foreground Dice: [0.7915]
2022-05-28 16:22:44.268030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:22:44.834218: lr: 0.005686
2022-05-28 16:22:44.836551: This epoch took 107.761006 s

2022-05-28 16:22:44.838631: 
epoch:  233
2022-05-28 16:24:17.013463: train loss : -0.7750
2022-05-28 16:24:25.864901: validation loss: -0.6952
2022-05-28 16:24:25.869787: Average global foreground Dice: [0.7868]
2022-05-28 16:24:25.872890: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:24:26.371764: lr: 0.005667
2022-05-28 16:24:26.374487: This epoch took 101.533813 s

2022-05-28 16:24:26.377834: 
epoch:  234
2022-05-28 16:25:58.622789: train loss : -0.7871
2022-05-28 16:26:05.770311: validation loss: -0.7331
2022-05-28 16:26:05.799781: Average global foreground Dice: [0.7701]
2022-05-28 16:26:05.802180: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:26:06.336636: lr: 0.005647
2022-05-28 16:26:06.352271: This epoch took 99.960798 s

2022-05-28 16:26:06.361290: 
epoch:  235
2022-05-28 16:27:38.190871: train loss : -0.7971
2022-05-28 16:27:48.940256: validation loss: -0.7011
2022-05-28 16:27:48.943808: Average global foreground Dice: [0.7737]
2022-05-28 16:27:48.946327: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:27:49.497586: lr: 0.005628
2022-05-28 16:27:49.502442: This epoch took 103.117157 s

2022-05-28 16:27:49.511154: 
epoch:  236
2022-05-28 16:29:19.911585: train loss : -0.8089
2022-05-28 16:29:25.714696: validation loss: -0.7171
2022-05-28 16:29:25.718036: Average global foreground Dice: [0.7848]
2022-05-28 16:29:25.720064: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:29:26.187258: lr: 0.005609
2022-05-28 16:29:26.189877: This epoch took 96.676701 s

2022-05-28 16:29:26.192067: 
epoch:  237
2022-05-28 16:30:57.639980: train loss : -0.7863
2022-05-28 16:31:05.990303: validation loss: -0.6904
2022-05-28 16:31:05.993796: Average global foreground Dice: [0.7659]
2022-05-28 16:31:05.995695: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:31:06.456010: lr: 0.00559
2022-05-28 16:31:06.458563: This epoch took 100.264238 s

2022-05-28 16:31:06.460706: 
epoch:  238
2022-05-28 16:32:37.419901: train loss : -0.7966
2022-05-28 16:32:47.848355: validation loss: -0.7341
2022-05-28 16:32:47.897921: Average global foreground Dice: [0.795]
2022-05-28 16:32:47.905129: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:32:48.702060: lr: 0.005571
2022-05-28 16:32:48.707855: This epoch took 102.245044 s

2022-05-28 16:32:48.717402: 
epoch:  239
2022-05-28 16:34:19.907288: train loss : -0.8023
2022-05-28 16:34:26.121905: validation loss: -0.7128
2022-05-28 16:34:26.151117: Average global foreground Dice: [0.7876]
2022-05-28 16:34:26.161592: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:34:26.692085: lr: 0.005551
2022-05-28 16:34:26.694710: This epoch took 97.955421 s

2022-05-28 16:34:26.697273: 
epoch:  240
2022-05-28 16:35:57.866477: train loss : -0.7945
2022-05-28 16:36:07.909428: validation loss: -0.6989
2022-05-28 16:36:07.926689: Average global foreground Dice: [0.7693]
2022-05-28 16:36:07.930417: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:36:08.435073: lr: 0.005532
2022-05-28 16:36:08.437834: This epoch took 101.737802 s

2022-05-28 16:36:08.440064: 
epoch:  241
2022-05-28 16:37:41.425184: train loss : -0.7984
2022-05-28 16:37:49.250710: validation loss: -0.6952
2022-05-28 16:37:49.284015: Average global foreground Dice: [0.776]
2022-05-28 16:37:49.303280: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:37:49.940021: lr: 0.005513
2022-05-28 16:37:49.960498: This epoch took 101.518235 s

2022-05-28 16:37:49.985299: 
epoch:  242
2022-05-28 16:39:22.493296: train loss : -0.7956
2022-05-28 16:39:32.921317: validation loss: -0.7476
2022-05-28 16:39:32.924334: Average global foreground Dice: [0.8064]
2022-05-28 16:39:32.926442: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:39:33.471888: lr: 0.005494
2022-05-28 16:39:33.474556: This epoch took 103.454265 s

2022-05-28 16:39:33.486343: 
epoch:  243
2022-05-28 16:41:05.001950: train loss : -0.7983
2022-05-28 16:41:13.823884: validation loss: -0.7463
2022-05-28 16:41:13.828314: Average global foreground Dice: [0.7965]
2022-05-28 16:41:13.830984: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:41:14.357588: lr: 0.005474
2022-05-28 16:41:14.428334: saving checkpoint...
2022-05-28 16:41:15.541821: done, saving took 1.17 seconds
2022-05-28 16:41:15.556423: This epoch took 102.067661 s

2022-05-28 16:41:15.558851: 
epoch:  244
2022-05-28 16:42:46.361676: train loss : -0.7990
2022-05-28 16:42:54.703330: validation loss: -0.7051
2022-05-28 16:42:54.720801: Average global foreground Dice: [0.7667]
2022-05-28 16:42:54.723727: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:42:55.486009: lr: 0.005455
2022-05-28 16:42:55.497823: This epoch took 99.936669 s

2022-05-28 16:42:55.499928: 
epoch:  245
2022-05-28 16:44:28.064014: train loss : -0.8097
2022-05-28 16:44:38.165326: validation loss: -0.7309
2022-05-28 16:44:38.180544: Average global foreground Dice: [0.7965]
2022-05-28 16:44:38.197519: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:44:39.036725: lr: 0.005436
2022-05-28 16:44:39.082668: saving checkpoint...
2022-05-28 16:44:40.097880: done, saving took 1.06 seconds
2022-05-28 16:44:40.112049: This epoch took 104.610103 s

2022-05-28 16:44:40.113910: 
epoch:  246
2022-05-28 16:46:13.727593: train loss : -0.7930
2022-05-28 16:46:23.313208: validation loss: -0.7047
2022-05-28 16:46:23.347517: Average global foreground Dice: [0.7855]
2022-05-28 16:46:23.356659: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:46:24.004658: lr: 0.005417
2022-05-28 16:46:24.057031: saving checkpoint...
2022-05-28 16:46:25.026892: done, saving took 1.02 seconds
2022-05-28 16:46:25.041660: This epoch took 104.925718 s

2022-05-28 16:46:25.044030: 
epoch:  247
2022-05-28 16:47:56.474595: train loss : -0.8002
2022-05-28 16:48:04.993960: validation loss: -0.7468
2022-05-28 16:48:05.015946: Average global foreground Dice: [0.8046]
2022-05-28 16:48:05.034418: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:48:06.087180: lr: 0.005397
2022-05-28 16:48:06.191180: saving checkpoint...
2022-05-28 16:48:07.417526: done, saving took 1.32 seconds
2022-05-28 16:48:07.494315: This epoch took 102.447369 s

2022-05-28 16:48:07.528280: 
epoch:  248
2022-05-28 16:49:38.579088: train loss : -0.8067
2022-05-28 16:49:46.532727: validation loss: -0.7322
2022-05-28 16:49:46.537023: Average global foreground Dice: [0.799]
2022-05-28 16:49:46.539358: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:49:47.004562: lr: 0.005378
2022-05-28 16:49:47.056224: saving checkpoint...
2022-05-28 16:49:48.031119: done, saving took 1.02 seconds
2022-05-28 16:49:48.047976: This epoch took 100.493022 s

2022-05-28 16:49:48.049937: 
epoch:  249
2022-05-28 16:51:18.494751: train loss : -0.8082
2022-05-28 16:51:25.076714: validation loss: -0.7184
2022-05-28 16:51:25.083588: Average global foreground Dice: [0.7912]
2022-05-28 16:51:25.086313: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:51:25.582796: lr: 0.005359
2022-05-28 16:51:25.585754: saving scheduled checkpoint file...
2022-05-28 16:51:25.633628: saving checkpoint...
2022-05-28 16:51:26.571192: done, saving took 0.98 seconds
2022-05-28 16:51:26.589334: done
2022-05-28 16:51:26.636453: saving checkpoint...
2022-05-28 16:51:27.555887: done, saving took 0.96 seconds
2022-05-28 16:51:27.571725: This epoch took 99.519557 s

2022-05-28 16:51:27.573974: 
epoch:  250
2022-05-28 16:52:58.498634: train loss : -0.7990
2022-05-28 16:53:07.824996: validation loss: -0.7040
2022-05-28 16:53:07.844429: Average global foreground Dice: [0.773]
2022-05-28 16:53:07.854790: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:53:08.451602: lr: 0.00534
2022-05-28 16:53:08.458946: This epoch took 100.882952 s

2022-05-28 16:53:08.465281: 
epoch:  251
2022-05-28 16:54:41.119150: train loss : -0.7780
2022-05-28 16:54:50.402713: validation loss: -0.7175
2022-05-28 16:54:50.410712: Average global foreground Dice: [0.7931]
2022-05-28 16:54:50.413348: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:54:50.919863: lr: 0.00532
2022-05-28 16:54:50.924331: This epoch took 102.449323 s

2022-05-28 16:54:50.932617: 
epoch:  252
2022-05-28 16:56:24.286454: train loss : -0.7852
2022-05-28 16:56:33.098415: validation loss: -0.7229
2022-05-28 16:56:33.125986: Average global foreground Dice: [0.7719]
2022-05-28 16:56:33.128142: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:56:33.771046: lr: 0.005301
2022-05-28 16:56:33.789387: This epoch took 102.827089 s

2022-05-28 16:56:33.800213: 
epoch:  253
2022-05-28 16:58:07.145008: train loss : -0.7800
2022-05-28 16:58:15.847510: validation loss: -0.7109
2022-05-28 16:58:15.854338: Average global foreground Dice: [0.7753]
2022-05-28 16:58:15.857233: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:58:16.331308: lr: 0.005282
2022-05-28 16:58:16.333748: This epoch took 102.500445 s

2022-05-28 16:58:16.336553: 
epoch:  254
2022-05-28 16:59:48.293035: train loss : -0.7998
2022-05-28 16:59:59.151559: validation loss: -0.7065
2022-05-28 16:59:59.179377: Average global foreground Dice: [0.7894]
2022-05-28 16:59:59.181926: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 16:59:59.840378: lr: 0.005262
2022-05-28 16:59:59.872329: This epoch took 103.532275 s

2022-05-28 16:59:59.886764: 
epoch:  255
2022-05-28 17:01:33.674284: train loss : -0.7819
2022-05-28 17:01:44.425260: validation loss: -0.6969
2022-05-28 17:01:44.429614: Average global foreground Dice: [0.7538]
2022-05-28 17:01:44.432173: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:01:44.949914: lr: 0.005243
2022-05-28 17:01:44.952185: This epoch took 105.045884 s

2022-05-28 17:01:44.954188: 
epoch:  256
2022-05-28 17:03:16.634447: train loss : -0.7818
2022-05-28 17:03:27.352834: validation loss: -0.7043
2022-05-28 17:03:27.374976: Average global foreground Dice: [0.7684]
2022-05-28 17:03:27.392141: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:03:28.128695: lr: 0.005224
2022-05-28 17:03:28.131432: This epoch took 103.174881 s

2022-05-28 17:03:28.134123: 
epoch:  257
2022-05-28 17:04:59.056656: train loss : -0.8075
2022-05-28 17:05:05.805231: validation loss: -0.7585
2022-05-28 17:05:05.811784: Average global foreground Dice: [0.8039]
2022-05-28 17:05:05.813992: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:05:06.300411: lr: 0.005204
2022-05-28 17:05:06.302842: This epoch took 98.166036 s

2022-05-28 17:05:06.304997: 
epoch:  258
2022-05-28 17:06:37.130712: train loss : -0.8087
2022-05-28 17:06:46.046839: validation loss: -0.7045
2022-05-28 17:06:46.051620: Average global foreground Dice: [0.7811]
2022-05-28 17:06:46.055336: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:06:46.735293: lr: 0.005185
2022-05-28 17:06:46.737394: This epoch took 100.430404 s

2022-05-28 17:06:46.738708: 
epoch:  259
2022-05-28 17:08:19.562997: train loss : -0.7871
2022-05-28 17:08:25.848703: validation loss: -0.7206
2022-05-28 17:08:25.870700: Average global foreground Dice: [0.7837]
2022-05-28 17:08:25.892311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:08:26.942917: lr: 0.005166
2022-05-28 17:08:26.981380: This epoch took 100.215084 s

2022-05-28 17:08:27.007307: 
epoch:  260
2022-05-28 17:09:58.462602: train loss : -0.8008
2022-05-28 17:10:07.367278: validation loss: -0.7207
2022-05-28 17:10:07.370795: Average global foreground Dice: [0.7869]
2022-05-28 17:10:07.372883: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:10:07.865663: lr: 0.005146
2022-05-28 17:10:07.870017: This epoch took 100.845675 s

2022-05-28 17:10:07.872221: 
epoch:  261
2022-05-28 17:11:41.719466: train loss : -0.8012
2022-05-28 17:11:50.046978: validation loss: -0.7199
2022-05-28 17:11:50.051033: Average global foreground Dice: [0.796]
2022-05-28 17:11:50.053183: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:11:50.550111: lr: 0.005127
2022-05-28 17:11:50.552117: This epoch took 102.667038 s

2022-05-28 17:11:50.554215: 
epoch:  262
2022-05-28 17:13:25.880411: train loss : -0.7957
2022-05-28 17:13:33.445407: validation loss: -0.7184
2022-05-28 17:13:33.448631: Average global foreground Dice: [0.792]
2022-05-28 17:13:33.450672: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:13:33.947536: lr: 0.005107
2022-05-28 17:13:33.950260: This epoch took 103.393789 s

2022-05-28 17:13:33.952586: 
epoch:  263
2022-05-28 17:15:05.134229: train loss : -0.7971
2022-05-28 17:15:14.999729: validation loss: -0.7244
2022-05-28 17:15:15.027196: Average global foreground Dice: [0.7949]
2022-05-28 17:15:15.048305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:15:15.671700: lr: 0.005088
2022-05-28 17:15:15.693322: This epoch took 101.738467 s

2022-05-28 17:15:15.710291: 
epoch:  264
2022-05-28 17:16:50.276703: train loss : -0.8007
2022-05-28 17:16:58.755008: validation loss: -0.7350
2022-05-28 17:16:58.764265: Average global foreground Dice: [0.7875]
2022-05-28 17:16:58.766461: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:16:59.342191: lr: 0.005069
2022-05-28 17:16:59.344636: This epoch took 103.617540 s

2022-05-28 17:16:59.346716: 
epoch:  265
2022-05-28 17:18:30.433182: train loss : -0.8003
2022-05-28 17:18:39.406053: validation loss: -0.7271
2022-05-28 17:18:39.409887: Average global foreground Dice: [0.7977]
2022-05-28 17:18:39.411878: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:18:39.886637: lr: 0.005049
2022-05-28 17:18:39.949947: saving checkpoint...
2022-05-28 17:18:41.098782: done, saving took 1.21 seconds
2022-05-28 17:18:41.113678: This epoch took 101.764975 s

2022-05-28 17:18:41.115974: 
epoch:  266
2022-05-28 17:20:12.075274: train loss : -0.7996
2022-05-28 17:20:21.498899: validation loss: -0.7474
2022-05-28 17:20:21.502441: Average global foreground Dice: [0.7926]
2022-05-28 17:20:21.504910: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:20:22.002989: lr: 0.00503
2022-05-28 17:20:22.124504: saving checkpoint...
2022-05-28 17:20:23.230472: done, saving took 1.21 seconds
2022-05-28 17:20:23.244805: This epoch took 102.126840 s

2022-05-28 17:20:23.247174: 
epoch:  267
2022-05-28 17:21:56.315578: train loss : -0.7961
2022-05-28 17:22:06.014542: validation loss: -0.7263
2022-05-28 17:22:06.017845: Average global foreground Dice: [0.7723]
2022-05-28 17:22:06.019923: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:22:06.495255: lr: 0.00501
2022-05-28 17:22:06.497945: This epoch took 103.248276 s

2022-05-28 17:22:06.510567: 
epoch:  268
2022-05-28 17:23:41.967359: train loss : -0.8106
2022-05-28 17:23:51.419019: validation loss: -0.7131
2022-05-28 17:23:51.441493: Average global foreground Dice: [0.7785]
2022-05-28 17:23:51.444794: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:23:52.032249: lr: 0.004991
2022-05-28 17:23:52.070359: This epoch took 105.554239 s

2022-05-28 17:23:52.078588: 
epoch:  269
2022-05-28 17:25:23.763698: train loss : -0.8053
2022-05-28 17:25:31.505235: validation loss: -0.7262
2022-05-28 17:25:31.536374: Average global foreground Dice: [0.7899]
2022-05-28 17:25:31.540340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:25:32.069509: lr: 0.004971
2022-05-28 17:25:32.071942: This epoch took 99.990277 s

2022-05-28 17:25:32.077970: 
epoch:  270
2022-05-28 17:27:07.676995: train loss : -0.8081
2022-05-28 17:27:15.923373: validation loss: -0.7125
2022-05-28 17:27:15.926824: Average global foreground Dice: [0.7669]
2022-05-28 17:27:15.929104: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:27:16.419757: lr: 0.004952
2022-05-28 17:27:16.422150: This epoch took 104.341904 s

2022-05-28 17:27:16.424480: 
epoch:  271
2022-05-28 17:28:52.679605: train loss : -0.8006
2022-05-28 17:29:01.309358: validation loss: -0.7381
2022-05-28 17:29:01.312546: Average global foreground Dice: [0.7958]
2022-05-28 17:29:01.315181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:29:01.808143: lr: 0.004933
2022-05-28 17:29:01.834408: This epoch took 105.407202 s

2022-05-28 17:29:01.836706: 
epoch:  272
2022-05-28 17:30:33.103421: train loss : -0.8141
2022-05-28 17:30:42.221332: validation loss: -0.7238
2022-05-28 17:30:42.225610: Average global foreground Dice: [0.7897]
2022-05-28 17:30:42.230935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:30:42.729003: lr: 0.004913
2022-05-28 17:30:42.731354: This epoch took 100.892235 s

2022-05-28 17:30:42.733289: 
epoch:  273
2022-05-28 17:32:20.475280: train loss : -0.8075
2022-05-28 17:32:29.602857: validation loss: -0.7200
2022-05-28 17:32:29.606781: Average global foreground Dice: [0.7837]
2022-05-28 17:32:29.608808: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:32:30.144401: lr: 0.004894
2022-05-28 17:32:30.146600: This epoch took 107.411327 s

2022-05-28 17:32:30.148538: 
epoch:  274
2022-05-28 17:34:02.024786: train loss : -0.7981
2022-05-28 17:34:12.331196: validation loss: -0.7236
2022-05-28 17:34:12.334138: Average global foreground Dice: [0.7828]
2022-05-28 17:34:12.336258: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:34:12.882538: lr: 0.004874
2022-05-28 17:34:12.885073: This epoch took 102.734719 s

2022-05-28 17:34:12.889306: 
epoch:  275
2022-05-28 17:35:48.517073: train loss : -0.7967
2022-05-28 17:35:59.815764: validation loss: -0.7526
2022-05-28 17:35:59.861869: Average global foreground Dice: [0.7994]
2022-05-28 17:35:59.875902: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:36:00.443423: lr: 0.004855
2022-05-28 17:36:00.465339: This epoch took 107.565604 s

2022-05-28 17:36:00.495325: 
epoch:  276
2022-05-28 17:37:32.952960: train loss : -0.8057
2022-05-28 17:37:40.602028: validation loss: -0.7185
2022-05-28 17:37:40.606403: Average global foreground Dice: [0.7719]
2022-05-28 17:37:40.608779: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:37:41.096276: lr: 0.004835
2022-05-28 17:37:41.099064: This epoch took 100.570766 s

2022-05-28 17:37:41.101110: 
epoch:  277
2022-05-28 17:39:14.020892: train loss : -0.8069
2022-05-28 17:39:23.258792: validation loss: -0.7167
2022-05-28 17:39:23.279576: Average global foreground Dice: [0.7842]
2022-05-28 17:39:23.302292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:39:24.146725: lr: 0.004816
2022-05-28 17:39:24.154540: This epoch took 103.051388 s

2022-05-28 17:39:24.157624: 
epoch:  278
2022-05-28 17:40:56.450485: train loss : -0.8046
2022-05-28 17:41:06.819735: validation loss: -0.7403
2022-05-28 17:41:06.860905: Average global foreground Dice: [0.802]
2022-05-28 17:41:06.872958: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:41:07.721665: lr: 0.004796
2022-05-28 17:41:07.742342: This epoch took 103.579734 s

2022-05-28 17:41:07.762118: 
epoch:  279
2022-05-28 17:42:44.254214: train loss : -0.8089
2022-05-28 17:42:54.038621: validation loss: -0.7456
2022-05-28 17:42:54.052175: Average global foreground Dice: [0.8034]
2022-05-28 17:42:54.054499: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:42:54.644216: lr: 0.004776
2022-05-28 17:42:54.773814: saving checkpoint...
2022-05-28 17:42:55.981354: done, saving took 1.31 seconds
2022-05-28 17:42:55.997949: This epoch took 108.221382 s

2022-05-28 17:42:56.000169: 
epoch:  280
2022-05-28 17:44:28.570733: train loss : -0.8168
2022-05-28 17:44:36.761515: validation loss: -0.7144
2022-05-28 17:44:36.766861: Average global foreground Dice: [0.8096]
2022-05-28 17:44:36.769754: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:44:37.393305: lr: 0.004757
2022-05-28 17:44:37.438004: saving checkpoint...
2022-05-28 17:44:38.484775: done, saving took 1.09 seconds
2022-05-28 17:44:38.498359: This epoch took 102.496033 s

2022-05-28 17:44:38.500569: 
epoch:  281
2022-05-28 17:46:11.164949: train loss : -0.8135
2022-05-28 17:46:18.640651: validation loss: -0.7311
2022-05-28 17:46:18.661726: Average global foreground Dice: [0.7845]
2022-05-28 17:46:18.678641: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:46:19.257456: lr: 0.004737
2022-05-28 17:46:19.279327: This epoch took 100.776706 s

2022-05-28 17:46:19.288133: 
epoch:  282
2022-05-28 17:47:49.943576: train loss : -0.8167
2022-05-28 17:47:56.889576: validation loss: -0.7285
2022-05-28 17:47:56.893883: Average global foreground Dice: [0.7994]
2022-05-28 17:47:56.896431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:47:57.361326: lr: 0.004718
2022-05-28 17:47:57.408339: saving checkpoint...
2022-05-28 17:47:58.398417: done, saving took 1.03 seconds
2022-05-28 17:47:58.412674: This epoch took 99.105552 s

2022-05-28 17:47:58.414793: 
epoch:  283
2022-05-28 17:49:31.693020: train loss : -0.8096
2022-05-28 17:49:42.168492: validation loss: -0.7250
2022-05-28 17:49:42.211989: Average global foreground Dice: [0.7621]
2022-05-28 17:49:42.232303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:49:42.794592: lr: 0.004698
2022-05-28 17:49:42.797104: This epoch took 104.379955 s

2022-05-28 17:49:42.799092: 
epoch:  284
2022-05-28 17:51:14.409519: train loss : -0.8104
2022-05-28 17:51:24.677545: validation loss: -0.6907
2022-05-28 17:51:24.681884: Average global foreground Dice: [0.7731]
2022-05-28 17:51:24.684033: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:51:25.168358: lr: 0.004679
2022-05-28 17:51:25.170453: This epoch took 102.369156 s

2022-05-28 17:51:25.172550: 
epoch:  285
2022-05-28 17:52:59.392423: train loss : -0.8166
2022-05-28 17:53:08.527395: validation loss: -0.7355
2022-05-28 17:53:08.560685: Average global foreground Dice: [0.7979]
2022-05-28 17:53:08.582310: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:53:09.153381: lr: 0.004659
2022-05-28 17:53:09.155561: This epoch took 103.981012 s

2022-05-28 17:53:09.157754: 
epoch:  286
2022-05-28 17:54:39.829417: train loss : -0.8154
2022-05-28 17:54:46.578426: validation loss: -0.7422
2022-05-28 17:54:46.581637: Average global foreground Dice: [0.7843]
2022-05-28 17:54:46.583766: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:54:47.093267: lr: 0.004639
2022-05-28 17:54:47.095695: This epoch took 97.935997 s

2022-05-28 17:54:47.097580: 
epoch:  287
2022-05-28 17:56:18.722433: train loss : -0.8260
2022-05-28 17:56:26.320495: validation loss: -0.7347
2022-05-28 17:56:26.357873: Average global foreground Dice: [0.8027]
2022-05-28 17:56:26.377901: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:56:26.849796: lr: 0.00462
2022-05-28 17:56:26.852101: This epoch took 99.752502 s

2022-05-28 17:56:26.853933: 
epoch:  288
2022-05-28 17:58:00.240544: train loss : -0.8132
2022-05-28 17:58:08.899836: validation loss: -0.7450
2022-05-28 17:58:08.903439: Average global foreground Dice: [0.7901]
2022-05-28 17:58:08.908665: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:58:09.483346: lr: 0.0046
2022-05-28 17:58:09.492211: This epoch took 102.626166 s

2022-05-28 17:58:09.494591: 
epoch:  289
2022-05-28 17:59:45.586686: train loss : -0.7964
2022-05-28 17:59:54.582276: validation loss: -0.7269
2022-05-28 17:59:54.585860: Average global foreground Dice: [0.7834]
2022-05-28 17:59:54.588021: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 17:59:55.062808: lr: 0.004581
2022-05-28 17:59:55.065120: This epoch took 105.568126 s

2022-05-28 17:59:55.067185: 
epoch:  290
2022-05-28 18:01:31.679697: train loss : -0.8120
2022-05-28 18:01:39.455968: validation loss: -0.6983
2022-05-28 18:01:39.477746: Average global foreground Dice: [0.7782]
2022-05-28 18:01:39.498077: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:01:40.143734: lr: 0.004561
2022-05-28 18:01:40.147796: This epoch took 105.077997 s

2022-05-28 18:01:40.150817: 
epoch:  291
2022-05-28 18:03:15.219713: train loss : -0.8163
2022-05-28 18:03:24.385078: validation loss: -0.7332
2022-05-28 18:03:24.395697: Average global foreground Dice: [0.7923]
2022-05-28 18:03:24.403713: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:03:25.035064: lr: 0.004541
2022-05-28 18:03:25.047055: This epoch took 104.893468 s

2022-05-28 18:03:25.055641: 
epoch:  292
2022-05-28 18:04:56.996219: train loss : -0.8203
2022-05-28 18:05:04.392473: validation loss: -0.7134
2022-05-28 18:05:04.418567: Average global foreground Dice: [0.7864]
2022-05-28 18:05:04.451454: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:05:04.991763: lr: 0.004522
2022-05-28 18:05:05.006074: This epoch took 99.935882 s

2022-05-28 18:05:05.008761: 
epoch:  293
2022-05-28 18:06:36.828810: train loss : -0.8053
2022-05-28 18:06:45.074390: validation loss: -0.7499
2022-05-28 18:06:45.124930: Average global foreground Dice: [0.804]
2022-05-28 18:06:45.149291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:06:45.921033: lr: 0.004502
2022-05-28 18:06:45.923451: This epoch took 100.895995 s

2022-05-28 18:06:45.940133: 
epoch:  294
2022-05-28 18:08:17.644948: train loss : -0.8152
2022-05-28 18:08:25.465776: validation loss: -0.7162
2022-05-28 18:08:25.471036: Average global foreground Dice: [0.7919]
2022-05-28 18:08:25.473248: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:08:25.947792: lr: 0.004482
2022-05-28 18:08:25.950031: This epoch took 99.966733 s

2022-05-28 18:08:25.951957: 
epoch:  295
2022-05-28 18:10:00.359518: train loss : -0.8133
2022-05-28 18:10:09.025071: validation loss: -0.6956
2022-05-28 18:10:09.030869: Average global foreground Dice: [0.7696]
2022-05-28 18:10:09.033581: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:10:09.681601: lr: 0.004463
2022-05-28 18:10:09.685677: This epoch took 103.731868 s

2022-05-28 18:10:09.691423: 
epoch:  296
2022-05-28 18:11:41.440143: train loss : -0.8077
2022-05-28 18:11:50.065478: validation loss: -0.7188
2022-05-28 18:11:50.085120: Average global foreground Dice: [0.7864]
2022-05-28 18:11:50.104604: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:11:50.758892: lr: 0.004443
2022-05-28 18:11:50.771007: This epoch took 101.077487 s

2022-05-28 18:11:50.791711: 
epoch:  297
2022-05-28 18:13:23.346356: train loss : -0.8237
2022-05-28 18:13:33.075132: validation loss: -0.7506
2022-05-28 18:13:33.107360: Average global foreground Dice: [0.802]
2022-05-28 18:13:33.125516: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:13:33.778877: lr: 0.004423
2022-05-28 18:13:33.811325: This epoch took 103.017112 s

2022-05-28 18:13:33.834294: 
epoch:  298
2022-05-28 18:15:04.906132: train loss : -0.8233
2022-05-28 18:15:12.262415: validation loss: -0.7616
2022-05-28 18:15:12.282736: Average global foreground Dice: [0.8054]
2022-05-28 18:15:12.309315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:15:13.020630: lr: 0.004404
2022-05-28 18:15:13.023852: This epoch took 99.167537 s

2022-05-28 18:15:13.053295: 
epoch:  299
2022-05-28 18:16:45.229161: train loss : -0.8114
2022-05-28 18:16:53.421122: validation loss: -0.7364
2022-05-28 18:16:53.424872: Average global foreground Dice: [0.8083]
2022-05-28 18:16:53.427406: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:16:53.898749: lr: 0.004384
2022-05-28 18:16:53.900984: saving scheduled checkpoint file...
2022-05-28 18:16:53.937240: saving checkpoint...
2022-05-28 18:16:54.913987: done, saving took 1.01 seconds
2022-05-28 18:16:54.929763: done
2022-05-28 18:16:54.965415: saving checkpoint...
2022-05-28 18:16:55.872155: done, saving took 0.94 seconds
2022-05-28 18:16:55.886055: This epoch took 102.821001 s

2022-05-28 18:16:55.888178: 
epoch:  300
2022-05-28 18:18:26.659734: train loss : -0.8143
2022-05-28 18:18:32.937766: validation loss: -0.7106
2022-05-28 18:18:32.942503: Average global foreground Dice: [0.791]
2022-05-28 18:18:32.944754: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:18:33.414530: lr: 0.004364
2022-05-28 18:18:33.416738: This epoch took 97.526414 s

2022-05-28 18:18:33.418684: 
epoch:  301
2022-05-28 18:20:12.928007: train loss : -0.8162
2022-05-28 18:20:22.287428: validation loss: -0.7384
2022-05-28 18:20:22.291452: Average global foreground Dice: [0.7829]
2022-05-28 18:20:22.294074: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:20:22.761311: lr: 0.004344
2022-05-28 18:20:22.780535: This epoch took 109.359990 s

2022-05-28 18:20:22.797293: 
epoch:  302
2022-05-28 18:21:57.556199: train loss : -0.7993
2022-05-28 18:22:06.069134: validation loss: -0.7318
2022-05-28 18:22:06.072826: Average global foreground Dice: [0.791]
2022-05-28 18:22:06.075163: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:22:06.566749: lr: 0.004325
2022-05-28 18:22:06.569297: This epoch took 103.752653 s

2022-05-28 18:22:06.571303: 
epoch:  303
2022-05-28 18:23:40.065825: train loss : -0.8050
2022-05-28 18:23:48.806508: validation loss: -0.7589
2022-05-28 18:23:48.834739: Average global foreground Dice: [0.8112]
2022-05-28 18:23:48.858296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:23:49.392458: lr: 0.004305
2022-05-28 18:23:49.460248: saving checkpoint...
2022-05-28 18:23:50.520868: done, saving took 1.11 seconds
2022-05-28 18:23:50.537360: This epoch took 103.963805 s

2022-05-28 18:23:50.539757: 
epoch:  304
2022-05-28 18:25:21.351844: train loss : -0.8119
2022-05-28 18:25:28.796346: validation loss: -0.7211
2022-05-28 18:25:28.808820: Average global foreground Dice: [0.7678]
2022-05-28 18:25:28.812059: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:25:29.307078: lr: 0.004285
2022-05-28 18:25:29.330418: This epoch took 98.788298 s

2022-05-28 18:25:29.352442: 
epoch:  305
2022-05-28 18:27:00.263902: train loss : -0.8066
2022-05-28 18:27:08.731642: validation loss: -0.7337
2022-05-28 18:27:08.758994: Average global foreground Dice: [0.7957]
2022-05-28 18:27:08.780474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:27:09.279004: lr: 0.004265
2022-05-28 18:27:09.281362: This epoch took 99.906907 s

2022-05-28 18:27:09.283343: 
epoch:  306
2022-05-28 18:28:40.157498: train loss : -0.8136
2022-05-28 18:28:49.801941: validation loss: -0.7525
2022-05-28 18:28:49.808404: Average global foreground Dice: [0.7978]
2022-05-28 18:28:49.813582: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:28:50.463346: lr: 0.004245
2022-05-28 18:28:50.483312: This epoch took 101.197973 s

2022-05-28 18:28:50.488627: 
epoch:  307
2022-05-28 18:30:22.121013: train loss : -0.8189
2022-05-28 18:30:30.748631: validation loss: -0.7287
2022-05-28 18:30:30.766521: Average global foreground Dice: [0.7853]
2022-05-28 18:30:30.774821: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:30:31.265450: lr: 0.004226
2022-05-28 18:30:31.267931: This epoch took 100.776585 s

2022-05-28 18:30:31.270060: 
epoch:  308
2022-05-28 18:32:03.405251: train loss : -0.8177
2022-05-28 18:32:14.763117: validation loss: -0.7173
2022-05-28 18:32:14.770714: Average global foreground Dice: [0.7864]
2022-05-28 18:32:14.774176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:32:15.268159: lr: 0.004206
2022-05-28 18:32:15.276560: This epoch took 104.004610 s

2022-05-28 18:32:15.282093: 
epoch:  309
2022-05-28 18:33:47.065424: train loss : -0.8077
2022-05-28 18:33:54.731151: validation loss: -0.7143
2022-05-28 18:33:54.735636: Average global foreground Dice: [0.8003]
2022-05-28 18:33:54.738338: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:33:55.215001: lr: 0.004186
2022-05-28 18:33:55.217654: This epoch took 99.917799 s

2022-05-28 18:33:55.219854: 
epoch:  310
2022-05-28 18:35:26.622175: train loss : -0.8255
2022-05-28 18:35:32.961859: validation loss: -0.7313
2022-05-28 18:35:32.966956: Average global foreground Dice: [0.793]
2022-05-28 18:35:32.969622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:35:33.443811: lr: 0.004166
2022-05-28 18:35:33.446026: This epoch took 98.224126 s

2022-05-28 18:35:33.448117: 
epoch:  311
2022-05-28 18:37:07.420354: train loss : -0.8046
2022-05-28 18:37:16.214829: validation loss: -0.7326
2022-05-28 18:37:16.248900: Average global foreground Dice: [0.7826]
2022-05-28 18:37:16.251358: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:37:16.795326: lr: 0.004146
2022-05-28 18:37:16.797965: This epoch took 103.347436 s

2022-05-28 18:37:16.800331: 
epoch:  312
2022-05-28 18:38:51.243940: train loss : -0.7934
2022-05-28 18:38:57.857707: validation loss: -0.7118
2022-05-28 18:38:57.860933: Average global foreground Dice: [0.7935]
2022-05-28 18:38:57.863084: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:38:58.434206: lr: 0.004127
2022-05-28 18:38:58.436573: This epoch took 101.633678 s

2022-05-28 18:38:58.438929: 
epoch:  313
2022-05-28 18:40:29.139821: train loss : -0.8107
2022-05-28 18:40:36.438887: validation loss: -0.7311
2022-05-28 18:40:36.447752: Average global foreground Dice: [0.7907]
2022-05-28 18:40:36.450387: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:40:36.931098: lr: 0.004107
2022-05-28 18:40:36.934287: This epoch took 98.492298 s

2022-05-28 18:40:36.936518: 
epoch:  314
2022-05-28 18:42:09.668282: train loss : -0.8161
2022-05-28 18:42:17.033700: validation loss: -0.7364
2022-05-28 18:42:17.038084: Average global foreground Dice: [0.7926]
2022-05-28 18:42:17.040652: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:42:17.548876: lr: 0.004087
2022-05-28 18:42:17.551237: This epoch took 100.612606 s

2022-05-28 18:42:17.553221: 
epoch:  315
2022-05-28 18:43:50.643058: train loss : -0.8109
2022-05-28 18:43:58.985082: validation loss: -0.6999
2022-05-28 18:43:59.030892: Average global foreground Dice: [0.7887]
2022-05-28 18:43:59.058308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:43:59.685863: lr: 0.004067
2022-05-28 18:43:59.690609: This epoch took 102.135527 s

2022-05-28 18:43:59.694138: 
epoch:  316
2022-05-28 18:45:35.210231: train loss : -0.8126
2022-05-28 18:45:42.094931: validation loss: -0.7246
2022-05-28 18:45:42.137860: Average global foreground Dice: [0.788]
2022-05-28 18:45:42.165733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:45:43.006750: lr: 0.004047
2022-05-28 18:45:43.033341: This epoch took 103.336995 s

2022-05-28 18:45:43.057806: 
epoch:  317
2022-05-28 18:47:15.157831: train loss : -0.8137
2022-05-28 18:47:23.758158: validation loss: -0.7268
2022-05-28 18:47:23.791626: Average global foreground Dice: [0.7859]
2022-05-28 18:47:23.819299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:47:24.615832: lr: 0.004027
2022-05-28 18:47:24.620400: This epoch took 101.537965 s

2022-05-28 18:47:24.622613: 
epoch:  318
2022-05-28 18:48:56.197633: train loss : -0.8167
2022-05-28 18:49:03.811146: validation loss: -0.7216
2022-05-28 18:49:03.823936: Average global foreground Dice: [0.7851]
2022-05-28 18:49:03.826678: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:49:04.320756: lr: 0.004007
2022-05-28 18:49:04.323193: This epoch took 99.698579 s

2022-05-28 18:49:04.325212: 
epoch:  319
2022-05-28 18:50:35.812274: train loss : -0.8180
2022-05-28 18:50:43.071193: validation loss: -0.6504
2022-05-28 18:50:43.075198: Average global foreground Dice: [0.7502]
2022-05-28 18:50:43.077309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:50:43.573662: lr: 0.003987
2022-05-28 18:50:43.576071: This epoch took 99.248745 s

2022-05-28 18:50:43.578472: 
epoch:  320
2022-05-28 18:52:15.780661: train loss : -0.8205
2022-05-28 18:52:23.975420: validation loss: -0.7640
2022-05-28 18:52:23.978925: Average global foreground Dice: [0.7993]
2022-05-28 18:52:23.980935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:52:24.492943: lr: 0.003967
2022-05-28 18:52:24.495275: This epoch took 100.914743 s

2022-05-28 18:52:24.497387: 
epoch:  321
2022-05-28 18:53:55.669879: train loss : -0.8217
2022-05-28 18:54:01.792732: validation loss: -0.7237
2022-05-28 18:54:01.797417: Average global foreground Dice: [0.8043]
2022-05-28 18:54:01.802457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:54:02.291377: lr: 0.003947
2022-05-28 18:54:02.293659: This epoch took 97.794364 s

2022-05-28 18:54:02.295580: 
epoch:  322
2022-05-28 18:55:33.838524: train loss : -0.8197
2022-05-28 18:55:41.828629: validation loss: -0.7329
2022-05-28 18:55:41.862056: Average global foreground Dice: [0.7932]
2022-05-28 18:55:41.891320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:55:42.567558: lr: 0.003927
2022-05-28 18:55:42.569684: This epoch took 100.272086 s

2022-05-28 18:55:42.589586: 
epoch:  323
2022-05-28 18:57:13.427018: train loss : -0.8260
2022-05-28 18:57:22.047518: validation loss: -0.7204
2022-05-28 18:57:22.051298: Average global foreground Dice: [0.7968]
2022-05-28 18:57:22.053817: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:57:22.517378: lr: 0.003907
2022-05-28 18:57:22.519708: This epoch took 99.900419 s

2022-05-28 18:57:22.521857: 
epoch:  324
2022-05-28 18:58:54.571146: train loss : -0.8320
2022-05-28 18:59:04.943798: validation loss: -0.7163
2022-05-28 18:59:04.962787: Average global foreground Dice: [0.7878]
2022-05-28 18:59:04.966395: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 18:59:05.455228: lr: 0.003887
2022-05-28 18:59:05.458042: This epoch took 102.934008 s

2022-05-28 18:59:05.460454: 
epoch:  325
2022-05-28 19:00:39.156874: train loss : -0.8256
2022-05-28 19:00:47.266136: validation loss: -0.7068
2022-05-28 19:00:47.269442: Average global foreground Dice: [0.7802]
2022-05-28 19:00:47.272344: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:00:47.773611: lr: 0.003867
2022-05-28 19:00:47.788313: This epoch took 102.325466 s

2022-05-28 19:00:47.810028: 
epoch:  326
2022-05-28 19:02:24.897805: train loss : -0.8123
2022-05-28 19:02:33.052664: validation loss: -0.7355
2022-05-28 19:02:33.056036: Average global foreground Dice: [0.7819]
2022-05-28 19:02:33.058019: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:02:33.549001: lr: 0.003847
2022-05-28 19:02:33.551455: This epoch took 105.734850 s

2022-05-28 19:02:33.553621: 
epoch:  327
2022-05-28 19:04:06.625949: train loss : -0.8024
2022-05-28 19:04:16.262986: validation loss: -0.7219
2022-05-28 19:04:16.266353: Average global foreground Dice: [0.7787]
2022-05-28 19:04:16.268453: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:04:16.763294: lr: 0.003827
2022-05-28 19:04:16.765768: This epoch took 103.210118 s

2022-05-28 19:04:16.768543: 
epoch:  328
2022-05-28 19:05:48.017913: train loss : -0.8224
2022-05-28 19:05:55.953882: validation loss: -0.7106
2022-05-28 19:05:55.961711: Average global foreground Dice: [0.7786]
2022-05-28 19:05:55.964000: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:05:56.445587: lr: 0.003807
2022-05-28 19:05:56.463782: This epoch took 99.691620 s

2022-05-28 19:05:56.467287: 
epoch:  329
2022-05-28 19:07:27.784946: train loss : -0.8133
2022-05-28 19:07:36.466344: validation loss: -0.7226
2022-05-28 19:07:36.499126: Average global foreground Dice: [0.7932]
2022-05-28 19:07:36.502878: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:07:37.169050: lr: 0.003787
2022-05-28 19:07:37.194602: This epoch took 100.722522 s

2022-05-28 19:07:37.200903: 
epoch:  330
2022-05-28 19:09:07.743103: train loss : -0.8252
2022-05-28 19:09:15.759044: validation loss: -0.7398
2022-05-28 19:09:15.762977: Average global foreground Dice: [0.7986]
2022-05-28 19:09:15.765012: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:09:16.231397: lr: 0.003767
2022-05-28 19:09:16.241515: This epoch took 99.025244 s

2022-05-28 19:09:16.245703: 
epoch:  331
2022-05-28 19:10:50.064697: train loss : -0.8137
2022-05-28 19:11:01.108689: validation loss: -0.7085
2022-05-28 19:11:01.152193: Average global foreground Dice: [0.7633]
2022-05-28 19:11:01.159431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:11:01.698834: lr: 0.003747
2022-05-28 19:11:01.716455: This epoch took 105.468198 s

2022-05-28 19:11:01.726354: 
epoch:  332
2022-05-28 19:12:33.418158: train loss : -0.8295
2022-05-28 19:12:43.441481: validation loss: -0.7241
2022-05-28 19:12:43.464722: Average global foreground Dice: [0.7818]
2022-05-28 19:12:43.490620: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:12:44.064711: lr: 0.003727
2022-05-28 19:12:44.100374: This epoch took 102.362087 s

2022-05-28 19:12:44.107942: 
epoch:  333
2022-05-28 19:14:22.041351: train loss : -0.8099
2022-05-28 19:14:29.538560: validation loss: -0.7421
2022-05-28 19:14:29.565940: Average global foreground Dice: [0.7935]
2022-05-28 19:14:29.587306: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:14:30.219179: lr: 0.003707
2022-05-28 19:14:30.222255: This epoch took 106.104976 s

2022-05-28 19:14:30.225680: 
epoch:  334
2022-05-28 19:16:01.476574: train loss : -0.8180
2022-05-28 19:16:11.077721: validation loss: -0.7175
2022-05-28 19:16:11.081284: Average global foreground Dice: [0.7889]
2022-05-28 19:16:11.083832: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:16:11.612674: lr: 0.003687
2022-05-28 19:16:11.644395: This epoch took 101.415895 s

2022-05-28 19:16:11.677381: 
epoch:  335
2022-05-28 19:17:43.658677: train loss : -0.8179
2022-05-28 19:17:52.540559: validation loss: -0.7459
2022-05-28 19:17:52.551821: Average global foreground Dice: [0.7981]
2022-05-28 19:17:52.554127: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:17:53.052736: lr: 0.003667
2022-05-28 19:17:53.055095: This epoch took 101.360967 s

2022-05-28 19:17:53.057400: 
epoch:  336
2022-05-28 19:19:26.188961: train loss : -0.8048
2022-05-28 19:19:34.766272: validation loss: -0.7217
2022-05-28 19:19:34.770510: Average global foreground Dice: [0.7911]
2022-05-28 19:19:34.773042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:19:35.266266: lr: 0.003647
2022-05-28 19:19:35.269083: This epoch took 102.209461 s

2022-05-28 19:19:35.271053: 
epoch:  337
2022-05-28 19:21:06.804506: train loss : -0.8243
2022-05-28 19:21:13.571573: validation loss: -0.7063
2022-05-28 19:21:13.576205: Average global foreground Dice: [0.7773]
2022-05-28 19:21:13.580438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:21:14.066056: lr: 0.003627
2022-05-28 19:21:14.073959: This epoch took 98.800899 s

2022-05-28 19:21:14.076016: 
epoch:  338
2022-05-28 19:22:45.903727: train loss : -0.8316
2022-05-28 19:22:53.419477: validation loss: -0.7341
2022-05-28 19:22:53.423788: Average global foreground Dice: [0.79]
2022-05-28 19:22:53.426478: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:22:53.938511: lr: 0.003606
2022-05-28 19:22:53.940727: This epoch took 99.859870 s

2022-05-28 19:22:53.942780: 
epoch:  339
2022-05-28 19:24:25.205641: train loss : -0.8199
2022-05-28 19:24:33.040870: validation loss: -0.7486
2022-05-28 19:24:33.045325: Average global foreground Dice: [0.7922]
2022-05-28 19:24:33.074925: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:24:33.593897: lr: 0.003586
2022-05-28 19:24:33.596522: This epoch took 99.652253 s

2022-05-28 19:24:33.598488: 
epoch:  340
2022-05-28 19:26:09.628638: train loss : -0.8226
2022-05-28 19:26:17.439724: validation loss: -0.7403
2022-05-28 19:26:17.443376: Average global foreground Dice: [0.8053]
2022-05-28 19:26:17.445438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:26:17.934978: lr: 0.003566
2022-05-28 19:26:17.957329: This epoch took 104.356966 s

2022-05-28 19:26:17.979306: 
epoch:  341
2022-05-28 19:27:50.776210: train loss : -0.8217
2022-05-28 19:27:58.161118: validation loss: -0.7614
2022-05-28 19:27:58.164888: Average global foreground Dice: [0.8108]
2022-05-28 19:27:58.167188: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:27:58.623867: lr: 0.003546
2022-05-28 19:27:58.626033: This epoch took 100.623736 s

2022-05-28 19:27:58.627929: 
epoch:  342
2022-05-28 19:29:30.474337: train loss : -0.8077
2022-05-28 19:29:39.414593: validation loss: -0.7087
2022-05-28 19:29:39.418669: Average global foreground Dice: [0.7771]
2022-05-28 19:29:39.440882: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:29:40.004948: lr: 0.003526
2022-05-28 19:29:40.025385: This epoch took 101.395483 s

2022-05-28 19:29:40.048352: 
epoch:  343
2022-05-28 19:31:14.084094: train loss : -0.8226
2022-05-28 19:31:22.709533: validation loss: -0.7185
2022-05-28 19:31:22.716751: Average global foreground Dice: [0.773]
2022-05-28 19:31:22.719038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:31:23.291099: lr: 0.003505
2022-05-28 19:31:23.313399: This epoch took 103.239700 s

2022-05-28 19:31:23.333599: 
epoch:  344
2022-05-28 19:32:55.158139: train loss : -0.7985
2022-05-28 19:33:04.076337: validation loss: -0.7218
2022-05-28 19:33:04.105766: Average global foreground Dice: [0.7849]
2022-05-28 19:33:04.128298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:33:04.764171: lr: 0.003485
2022-05-28 19:33:04.771508: This epoch took 101.417825 s

2022-05-28 19:33:04.773673: 
epoch:  345
2022-05-28 19:34:36.217468: train loss : -0.8218
2022-05-28 19:34:43.008370: validation loss: -0.7240
2022-05-28 19:34:43.013329: Average global foreground Dice: [0.7775]
2022-05-28 19:34:43.015680: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:34:43.514168: lr: 0.003465
2022-05-28 19:34:43.516471: This epoch took 98.730117 s

2022-05-28 19:34:43.518484: 
epoch:  346
2022-05-28 19:36:16.213707: train loss : -0.8179
2022-05-28 19:36:25.638041: validation loss: -0.7176
2022-05-28 19:36:25.643046: Average global foreground Dice: [0.799]
2022-05-28 19:36:25.648977: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:36:26.150968: lr: 0.003445
2022-05-28 19:36:26.170098: This epoch took 102.649483 s

2022-05-28 19:36:26.176358: 
epoch:  347
2022-05-28 19:37:56.936188: train loss : -0.8333
2022-05-28 19:38:06.516368: validation loss: -0.7539
2022-05-28 19:38:06.543797: Average global foreground Dice: [0.7944]
2022-05-28 19:38:06.555786: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:38:07.271471: lr: 0.003424
2022-05-28 19:38:07.273741: This epoch took 101.089831 s

2022-05-28 19:38:07.281609: 
epoch:  348
2022-05-28 19:39:39.854252: train loss : -0.8224
2022-05-28 19:39:48.115296: validation loss: -0.7171
2022-05-28 19:39:48.171756: Average global foreground Dice: [0.7945]
2022-05-28 19:39:48.193317: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:39:48.949307: lr: 0.003404
2022-05-28 19:39:48.963162: This epoch took 101.678060 s

2022-05-28 19:39:48.992220: 
epoch:  349
2022-05-28 19:41:21.404940: train loss : -0.8340
2022-05-28 19:41:30.980746: validation loss: -0.7106
2022-05-28 19:41:30.999806: Average global foreground Dice: [0.8045]
2022-05-28 19:41:31.019899: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:41:31.572589: lr: 0.003384
2022-05-28 19:41:31.605351: saving scheduled checkpoint file...
2022-05-28 19:41:31.708748: saving checkpoint...
2022-05-28 19:41:32.846477: done, saving took 1.22 seconds
2022-05-28 19:41:32.864168: done
2022-05-28 19:41:32.866695: This epoch took 103.863396 s

2022-05-28 19:41:32.868734: 
epoch:  350
2022-05-28 19:43:03.510377: train loss : -0.8194
2022-05-28 19:43:11.835709: validation loss: -0.7399
2022-05-28 19:43:11.865405: Average global foreground Dice: [0.7952]
2022-05-28 19:43:11.884893: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:43:12.542186: lr: 0.003364
2022-05-28 19:43:12.569780: This epoch took 99.698914 s

2022-05-28 19:43:12.586869: 
epoch:  351
2022-05-28 19:44:45.792197: train loss : -0.8059
2022-05-28 19:44:56.450104: validation loss: -0.7541
2022-05-28 19:44:56.454435: Average global foreground Dice: [0.8068]
2022-05-28 19:44:56.457125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:44:57.144645: lr: 0.003343
2022-05-28 19:44:57.147452: This epoch took 104.543179 s

2022-05-28 19:44:57.150872: 
epoch:  352
2022-05-28 19:46:29.275917: train loss : -0.8137
2022-05-28 19:46:36.963920: validation loss: -0.7503
2022-05-28 19:46:36.967000: Average global foreground Dice: [0.8049]
2022-05-28 19:46:36.969255: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:46:37.449750: lr: 0.003323
2022-05-28 19:46:37.504652: saving checkpoint...
2022-05-28 19:46:38.533580: done, saving took 1.08 seconds
2022-05-28 19:46:38.557861: This epoch took 101.404366 s

2022-05-28 19:46:38.577307: 
epoch:  353
2022-05-28 19:48:10.668795: train loss : -0.8141
2022-05-28 19:48:22.505787: validation loss: -0.7318
2022-05-28 19:48:22.531479: Average global foreground Dice: [0.7986]
2022-05-28 19:48:22.545286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:48:23.301333: lr: 0.003303
2022-05-28 19:48:23.394051: saving checkpoint...
2022-05-28 19:48:24.481621: done, saving took 1.15 seconds
2022-05-28 19:48:24.501091: This epoch took 105.908158 s

2022-05-28 19:48:24.503297: 
epoch:  354
2022-05-28 19:49:55.647026: train loss : -0.8172
2022-05-28 19:50:03.091670: validation loss: -0.7099
2022-05-28 19:50:03.096257: Average global foreground Dice: [0.7782]
2022-05-28 19:50:03.098446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:50:03.586892: lr: 0.003282
2022-05-28 19:50:03.591662: This epoch took 99.086214 s

2022-05-28 19:50:03.595724: 
epoch:  355
2022-05-28 19:51:35.041946: train loss : -0.8145
2022-05-28 19:51:42.889380: validation loss: -0.7473
2022-05-28 19:51:42.893028: Average global foreground Dice: [0.7862]
2022-05-28 19:51:42.895294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:51:43.399382: lr: 0.003262
2022-05-28 19:51:43.401768: This epoch took 99.803609 s

2022-05-28 19:51:43.403831: 
epoch:  356
2022-05-28 19:53:21.139573: train loss : -0.8264
2022-05-28 19:53:29.612279: validation loss: -0.7213
2022-05-28 19:53:29.615815: Average global foreground Dice: [0.7944]
2022-05-28 19:53:29.619009: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:53:30.160658: lr: 0.003241
2022-05-28 19:53:30.162940: This epoch took 106.757245 s

2022-05-28 19:53:30.164803: 
epoch:  357
2022-05-28 19:55:01.247601: train loss : -0.8214
2022-05-28 19:55:10.956180: validation loss: -0.7358
2022-05-28 19:55:11.005090: Average global foreground Dice: [0.8079]
2022-05-28 19:55:11.028412: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:55:12.080227: lr: 0.003221
2022-05-28 19:55:12.124790: This epoch took 101.957979 s

2022-05-28 19:55:12.135312: 
epoch:  358
2022-05-28 19:56:44.760221: train loss : -0.8157
2022-05-28 19:56:53.472832: validation loss: -0.7330
2022-05-28 19:56:53.505725: Average global foreground Dice: [0.7874]
2022-05-28 19:56:53.530297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:56:54.308949: lr: 0.003201
2022-05-28 19:56:54.355544: This epoch took 102.201262 s

2022-05-28 19:56:54.370667: 
epoch:  359
2022-05-28 19:58:31.201325: train loss : -0.8044
2022-05-28 19:58:39.126212: validation loss: -0.7274
2022-05-28 19:58:39.157705: Average global foreground Dice: [0.7932]
2022-05-28 19:58:39.177294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 19:58:39.769809: lr: 0.00318
2022-05-28 19:58:39.791375: This epoch took 105.410441 s

2022-05-28 19:58:39.813310: 
epoch:  360
2022-05-28 20:00:12.318323: train loss : -0.8091
2022-05-28 20:00:20.577094: validation loss: -0.7204
2022-05-28 20:00:20.595881: Average global foreground Dice: [0.7805]
2022-05-28 20:00:20.606276: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:00:21.184846: lr: 0.00316
2022-05-28 20:00:21.224016: This epoch took 101.388694 s

2022-05-28 20:00:21.243779: 
epoch:  361
2022-05-28 20:01:56.372492: train loss : -0.8241
2022-05-28 20:02:03.807254: validation loss: -0.7303
2022-05-28 20:02:03.811788: Average global foreground Dice: [0.8072]
2022-05-28 20:02:03.814177: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:02:04.276673: lr: 0.003139
2022-05-28 20:02:04.279174: This epoch took 103.010964 s

2022-05-28 20:02:04.281199: 
epoch:  362
2022-05-28 20:03:35.926628: train loss : -0.8319
2022-05-28 20:03:42.716051: validation loss: -0.7618
2022-05-28 20:03:42.720213: Average global foreground Dice: [0.8026]
2022-05-28 20:03:42.722294: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:03:43.269497: lr: 0.003119
2022-05-28 20:03:43.288355: This epoch took 99.005172 s

2022-05-28 20:03:43.290754: 
epoch:  363
2022-05-28 20:05:20.226062: train loss : -0.8283
2022-05-28 20:05:28.169929: validation loss: -0.7421
2022-05-28 20:05:28.174352: Average global foreground Dice: [0.8146]
2022-05-28 20:05:28.176550: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:05:28.642123: lr: 0.003098
2022-05-28 20:05:28.699738: saving checkpoint...
2022-05-28 20:05:29.756598: done, saving took 1.11 seconds
2022-05-28 20:05:29.773881: This epoch took 106.477419 s

2022-05-28 20:05:29.776000: 
epoch:  364
2022-05-28 20:07:01.709982: train loss : -0.8282
2022-05-28 20:07:10.536395: validation loss: -0.7208
2022-05-28 20:07:10.549305: Average global foreground Dice: [0.7899]
2022-05-28 20:07:10.552365: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:07:11.063728: lr: 0.003078
2022-05-28 20:07:11.065970: This epoch took 101.287994 s

2022-05-28 20:07:11.067816: 
epoch:  365
2022-05-28 20:08:42.556778: train loss : -0.8349
2022-05-28 20:08:51.092220: validation loss: -0.7144
2022-05-28 20:08:51.095948: Average global foreground Dice: [0.7852]
2022-05-28 20:08:51.109642: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:08:51.761812: lr: 0.003057
2022-05-28 20:08:51.764185: This epoch took 100.694498 s

2022-05-28 20:08:51.779287: 
epoch:  366
2022-05-28 20:10:28.506739: train loss : -0.8210
2022-05-28 20:10:37.351426: validation loss: -0.7305
2022-05-28 20:10:37.358837: Average global foreground Dice: [0.7894]
2022-05-28 20:10:37.360987: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:10:37.913188: lr: 0.003037
2022-05-28 20:10:37.917983: This epoch took 106.132390 s

2022-05-28 20:10:37.921035: 
epoch:  367
2022-05-28 20:12:15.875702: train loss : -0.8116
2022-05-28 20:12:25.328955: validation loss: -0.7455
2022-05-28 20:12:25.332739: Average global foreground Dice: [0.8062]
2022-05-28 20:12:25.334888: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:12:25.812748: lr: 0.003016
2022-05-28 20:12:25.817483: This epoch took 107.892369 s

2022-05-28 20:12:25.822219: 
epoch:  368
2022-05-28 20:13:57.284828: train loss : -0.8277
2022-05-28 20:14:04.249952: validation loss: -0.7333
2022-05-28 20:14:04.253731: Average global foreground Dice: [0.7949]
2022-05-28 20:14:04.255982: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:14:04.763233: lr: 0.002996
2022-05-28 20:14:04.765567: This epoch took 98.941029 s

2022-05-28 20:14:04.768111: 
epoch:  369
2022-05-28 20:15:37.135997: train loss : -0.8293
2022-05-28 20:15:44.648976: validation loss: -0.7422
2022-05-28 20:15:44.670019: Average global foreground Dice: [0.7915]
2022-05-28 20:15:44.680736: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:15:45.245939: lr: 0.002975
2022-05-28 20:15:45.258536: This epoch took 100.487263 s

2022-05-28 20:15:45.280423: 
epoch:  370
2022-05-28 20:17:16.302123: train loss : -0.8293
2022-05-28 20:17:23.800870: validation loss: -0.7191
2022-05-28 20:17:23.814872: Average global foreground Dice: [0.7926]
2022-05-28 20:17:23.842299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:17:24.562044: lr: 0.002954
2022-05-28 20:17:24.564926: This epoch took 99.264300 s

2022-05-28 20:17:24.567051: 
epoch:  371
2022-05-28 20:18:55.207974: train loss : -0.8423
2022-05-28 20:19:01.153001: validation loss: -0.7231
2022-05-28 20:19:01.156992: Average global foreground Dice: [0.7839]
2022-05-28 20:19:01.159175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:19:01.814819: lr: 0.002934
2022-05-28 20:19:01.816963: This epoch took 97.247561 s

2022-05-28 20:19:01.818790: 
epoch:  372
2022-05-28 20:20:34.202424: train loss : -0.8284
2022-05-28 20:20:42.494567: validation loss: -0.7254
2022-05-28 20:20:42.500888: Average global foreground Dice: [0.7951]
2022-05-28 20:20:42.502814: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:20:43.002851: lr: 0.002913
2022-05-28 20:20:43.005337: This epoch took 101.184724 s

2022-05-28 20:20:43.007435: 
epoch:  373
2022-05-28 20:22:13.147052: train loss : -0.8274
2022-05-28 20:22:21.411330: validation loss: -0.7592
2022-05-28 20:22:21.443073: Average global foreground Dice: [0.8008]
2022-05-28 20:22:21.463160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:22:22.158904: lr: 0.002892
2022-05-28 20:22:22.161912: This epoch took 99.152433 s

2022-05-28 20:22:22.164512: 
epoch:  374
2022-05-28 20:23:53.765687: train loss : -0.8208
2022-05-28 20:24:02.444732: validation loss: -0.7130
2022-05-28 20:24:02.469672: Average global foreground Dice: [0.7835]
2022-05-28 20:24:02.488315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:24:03.146784: lr: 0.002872
2022-05-28 20:24:03.149701: This epoch took 100.982656 s

2022-05-28 20:24:03.151863: 
epoch:  375
2022-05-28 20:25:34.263846: train loss : -0.8249
2022-05-28 20:25:42.801161: validation loss: -0.7480
2022-05-28 20:25:42.804965: Average global foreground Dice: [0.7994]
2022-05-28 20:25:42.807030: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:25:43.289720: lr: 0.002851
2022-05-28 20:25:43.292187: This epoch took 100.138165 s

2022-05-28 20:25:43.294095: 
epoch:  376
2022-05-28 20:27:17.802167: train loss : -0.8277
2022-05-28 20:27:26.220439: validation loss: -0.7269
2022-05-28 20:27:26.250993: Average global foreground Dice: [0.8011]
2022-05-28 20:27:26.270298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:27:27.086372: lr: 0.00283
2022-05-28 20:27:27.115751: This epoch took 103.819532 s

2022-05-28 20:27:27.146955: 
epoch:  377
2022-05-28 20:29:02.884240: train loss : -0.8241
2022-05-28 20:29:11.427912: validation loss: -0.6996
2022-05-28 20:29:11.438745: Average global foreground Dice: [0.7628]
2022-05-28 20:29:11.450151: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:29:12.066824: lr: 0.00281
2022-05-28 20:29:12.070979: This epoch took 104.909680 s

2022-05-28 20:29:12.073431: 
epoch:  378
2022-05-28 20:30:42.092203: train loss : -0.8182
2022-05-28 20:30:49.688111: validation loss: -0.7164
2022-05-28 20:30:49.692508: Average global foreground Dice: [0.7797]
2022-05-28 20:30:49.694856: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:30:50.203408: lr: 0.002789
2022-05-28 20:30:50.205737: This epoch took 98.129949 s

2022-05-28 20:30:50.207755: 
epoch:  379
2022-05-28 20:32:21.304179: train loss : -0.8330
2022-05-28 20:32:27.915659: validation loss: -0.7161
2022-05-28 20:32:27.919877: Average global foreground Dice: [0.7742]
2022-05-28 20:32:27.922081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:32:28.393786: lr: 0.002768
2022-05-28 20:32:28.396611: This epoch took 98.186958 s

2022-05-28 20:32:28.399720: 
epoch:  380
2022-05-28 20:33:59.332017: train loss : -0.8291
2022-05-28 20:34:06.286315: validation loss: -0.7215
2022-05-28 20:34:06.290910: Average global foreground Dice: [0.7885]
2022-05-28 20:34:06.293088: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:34:06.813151: lr: 0.002747
2022-05-28 20:34:06.816134: This epoch took 98.413084 s

2022-05-28 20:34:06.819746: 
epoch:  381
2022-05-28 20:35:39.981487: train loss : -0.8203
2022-05-28 20:35:50.760519: validation loss: -0.7040
2022-05-28 20:35:50.793331: Average global foreground Dice: [0.7786]
2022-05-28 20:35:50.801489: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:35:51.486892: lr: 0.002727
2022-05-28 20:35:51.501589: This epoch took 104.676344 s

2022-05-28 20:35:51.522156: 
epoch:  382
2022-05-28 20:37:22.924140: train loss : -0.8240
2022-05-28 20:37:31.364036: validation loss: -0.7200
2022-05-28 20:37:31.378780: Average global foreground Dice: [0.7796]
2022-05-28 20:37:31.381075: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:37:31.932429: lr: 0.002706
2022-05-28 20:37:31.935127: This epoch took 100.388649 s

2022-05-28 20:37:31.937038: 
epoch:  383
2022-05-28 20:39:03.078804: train loss : -0.8312
2022-05-28 20:39:10.610811: validation loss: -0.7435
2022-05-28 20:39:10.614305: Average global foreground Dice: [0.8016]
2022-05-28 20:39:10.616448: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:39:11.096174: lr: 0.002685
2022-05-28 20:39:11.098880: This epoch took 99.160047 s

2022-05-28 20:39:11.100960: 
epoch:  384
2022-05-28 20:40:47.810318: train loss : -0.8224
2022-05-28 20:40:57.602848: validation loss: -0.7274
2022-05-28 20:40:57.606338: Average global foreground Dice: [0.774]
2022-05-28 20:40:57.608590: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:40:58.085528: lr: 0.002664
2022-05-28 20:40:58.088036: This epoch took 106.984933 s

2022-05-28 20:40:58.090039: 
epoch:  385
2022-05-28 20:42:29.819116: train loss : -0.8331
2022-05-28 20:42:36.719488: validation loss: -0.7115
2022-05-28 20:42:36.723677: Average global foreground Dice: [0.7882]
2022-05-28 20:42:36.725620: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:42:37.299982: lr: 0.002643
2022-05-28 20:42:37.302301: This epoch took 99.208971 s

2022-05-28 20:42:37.304573: 
epoch:  386
2022-05-28 20:44:09.189641: train loss : -0.8393
2022-05-28 20:44:18.246487: validation loss: -0.7103
2022-05-28 20:44:18.250416: Average global foreground Dice: [0.7637]
2022-05-28 20:44:18.263444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:44:18.770852: lr: 0.002622
2022-05-28 20:44:18.792355: This epoch took 101.485715 s

2022-05-28 20:44:18.815319: 
epoch:  387
2022-05-28 20:45:53.203357: train loss : -0.8172
2022-05-28 20:46:03.766316: validation loss: -0.7164
2022-05-28 20:46:03.791661: Average global foreground Dice: [0.7749]
2022-05-28 20:46:03.793798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:46:04.513905: lr: 0.002601
2022-05-28 20:46:04.536543: This epoch took 105.699244 s

2022-05-28 20:46:04.564290: 
epoch:  388
2022-05-28 20:47:35.898199: train loss : -0.8289
2022-05-28 20:47:45.568679: validation loss: -0.7273
2022-05-28 20:47:45.572879: Average global foreground Dice: [0.7709]
2022-05-28 20:47:45.575416: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:47:46.065554: lr: 0.002581
2022-05-28 20:47:46.068458: This epoch took 101.471153 s

2022-05-28 20:47:46.070490: 
epoch:  389
2022-05-28 20:49:17.585688: train loss : -0.8338
2022-05-28 20:49:26.745516: validation loss: -0.7274
2022-05-28 20:49:26.768916: Average global foreground Dice: [0.8039]
2022-05-28 20:49:26.790462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:49:27.589892: lr: 0.00256
2022-05-28 20:49:27.611117: This epoch took 101.538691 s

2022-05-28 20:49:27.631326: 
epoch:  390
2022-05-28 20:51:00.488553: train loss : -0.8431
2022-05-28 20:51:07.767411: validation loss: -0.7317
2022-05-28 20:51:07.787900: Average global foreground Dice: [0.7861]
2022-05-28 20:51:07.822304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:51:08.354035: lr: 0.002539
2022-05-28 20:51:08.382980: This epoch took 100.746782 s

2022-05-28 20:51:08.388920: 
epoch:  391
2022-05-28 20:52:42.356284: train loss : -0.8241
2022-05-28 20:52:52.136026: validation loss: -0.7336
2022-05-28 20:52:52.166635: Average global foreground Dice: [0.7939]
2022-05-28 20:52:52.179127: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:52:52.671278: lr: 0.002518
2022-05-28 20:52:52.682440: This epoch took 104.283745 s

2022-05-28 20:52:52.702430: 
epoch:  392
2022-05-28 20:54:23.327501: train loss : -0.8178
2022-05-28 20:54:32.038476: validation loss: -0.7182
2022-05-28 20:54:32.052682: Average global foreground Dice: [0.7918]
2022-05-28 20:54:32.054843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:54:32.772537: lr: 0.002497
2022-05-28 20:54:32.793111: This epoch took 100.068811 s

2022-05-28 20:54:32.803322: 
epoch:  393
2022-05-28 20:56:03.005212: train loss : -0.8319
2022-05-28 20:56:11.599798: validation loss: -0.7462
2022-05-28 20:56:11.631311: Average global foreground Dice: [0.7856]
2022-05-28 20:56:11.650289: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:56:12.244342: lr: 0.002476
2022-05-28 20:56:12.249078: This epoch took 99.427462 s

2022-05-28 20:56:12.251449: 
epoch:  394
2022-05-28 20:57:42.532881: train loss : -0.8302
2022-05-28 20:57:50.921927: validation loss: -0.7192
2022-05-28 20:57:50.925420: Average global foreground Dice: [0.791]
2022-05-28 20:57:50.927910: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:57:51.415539: lr: 0.002455
2022-05-28 20:57:51.417855: This epoch took 99.164268 s

2022-05-28 20:57:51.420014: 
epoch:  395
2022-05-28 20:59:22.418769: train loss : -0.8300
2022-05-28 20:59:31.079431: validation loss: -0.7523
2022-05-28 20:59:31.109935: Average global foreground Dice: [0.7904]
2022-05-28 20:59:31.130324: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 20:59:31.658847: lr: 0.002434
2022-05-28 20:59:31.661075: This epoch took 100.238980 s

2022-05-28 20:59:31.662934: 
epoch:  396
2022-05-28 21:01:04.656154: train loss : -0.8437
2022-05-28 21:01:13.799096: validation loss: -0.7270
2022-05-28 21:01:13.802974: Average global foreground Dice: [0.777]
2022-05-28 21:01:13.805141: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:01:14.430229: lr: 0.002413
2022-05-28 21:01:14.432706: This epoch took 102.767997 s

2022-05-28 21:01:14.434828: 
epoch:  397
2022-05-28 21:02:47.698100: train loss : -0.8344
2022-05-28 21:02:57.066721: validation loss: -0.7378
2022-05-28 21:02:57.101033: Average global foreground Dice: [0.7946]
2022-05-28 21:02:57.129814: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:02:58.109549: lr: 0.002391
2022-05-28 21:02:58.112344: This epoch took 103.675682 s

2022-05-28 21:02:58.114751: 
epoch:  398
2022-05-28 21:04:30.474966: train loss : -0.8426
2022-05-28 21:04:40.766419: validation loss: -0.6961
2022-05-28 21:04:40.794316: Average global foreground Dice: [0.7895]
2022-05-28 21:04:40.814322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:04:41.477069: lr: 0.00237
2022-05-28 21:04:41.480115: This epoch took 103.349188 s

2022-05-28 21:04:41.482378: 
epoch:  399
2022-05-28 21:06:12.371317: train loss : -0.8444
2022-05-28 21:06:20.705443: validation loss: -0.7163
2022-05-28 21:06:20.709883: Average global foreground Dice: [0.7954]
2022-05-28 21:06:20.712249: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:06:21.192001: lr: 0.002349
2022-05-28 21:06:21.194284: saving scheduled checkpoint file...
2022-05-28 21:06:21.233868: saving checkpoint...
2022-05-28 21:06:22.318044: done, saving took 1.12 seconds
2022-05-28 21:06:22.337767: done
2022-05-28 21:06:22.339893: This epoch took 100.855333 s

2022-05-28 21:06:22.342017: 
epoch:  400
2022-05-28 21:07:52.984508: train loss : -0.8230
2022-05-28 21:08:01.657005: validation loss: -0.7171
2022-05-28 21:08:01.660827: Average global foreground Dice: [0.784]
2022-05-28 21:08:01.662836: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:08:02.177807: lr: 0.002328
2022-05-28 21:08:02.180219: This epoch took 99.836294 s

2022-05-28 21:08:02.182341: 
epoch:  401
2022-05-28 21:09:35.064442: train loss : -0.8362
2022-05-28 21:09:43.123036: validation loss: -0.6949
2022-05-28 21:09:43.130409: Average global foreground Dice: [0.783]
2022-05-28 21:09:43.132572: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:09:43.621614: lr: 0.002307
2022-05-28 21:09:43.623973: This epoch took 101.438796 s

2022-05-28 21:09:43.626057: 
epoch:  402
2022-05-28 21:11:15.266232: train loss : -0.8412
2022-05-28 21:11:24.212183: validation loss: -0.7010
2022-05-28 21:11:24.231838: Average global foreground Dice: [0.8011]
2022-05-28 21:11:24.249376: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:11:25.035989: lr: 0.002286
2022-05-28 21:11:25.043944: This epoch took 101.415451 s

2022-05-28 21:11:25.074284: 
epoch:  403
2022-05-28 21:12:58.414735: train loss : -0.8464
2022-05-28 21:13:07.109738: validation loss: -0.7415
2022-05-28 21:13:07.130299: Average global foreground Dice: [0.7839]
2022-05-28 21:13:07.132552: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:13:07.799662: lr: 0.002264
2022-05-28 21:13:07.804733: This epoch took 102.701355 s

2022-05-28 21:13:07.806880: 
epoch:  404
2022-05-28 21:14:39.372679: train loss : -0.8300
2022-05-28 21:14:47.704865: validation loss: -0.7270
2022-05-28 21:14:47.719392: Average global foreground Dice: [0.7825]
2022-05-28 21:14:47.723592: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:14:48.299504: lr: 0.002243
2022-05-28 21:14:48.301901: This epoch took 100.492989 s

2022-05-28 21:14:48.304130: 
epoch:  405
2022-05-28 21:16:20.442203: train loss : -0.8314
2022-05-28 21:16:29.454234: validation loss: -0.7221
2022-05-28 21:16:29.460385: Average global foreground Dice: [0.7839]
2022-05-28 21:16:29.493784: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:16:30.101683: lr: 0.002222
2022-05-28 21:16:30.105403: This epoch took 101.799326 s

2022-05-28 21:16:30.107663: 
epoch:  406
2022-05-28 21:18:01.804748: train loss : -0.8341
2022-05-28 21:18:11.536940: validation loss: -0.6989
2022-05-28 21:18:11.541376: Average global foreground Dice: [0.7599]
2022-05-28 21:18:11.544070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:18:12.044764: lr: 0.002201
2022-05-28 21:18:12.049006: This epoch took 101.939219 s

2022-05-28 21:18:12.058064: 
epoch:  407
2022-05-28 21:19:43.304897: train loss : -0.8414
2022-05-28 21:19:50.568860: validation loss: -0.7097
2022-05-28 21:19:50.572335: Average global foreground Dice: [0.7706]
2022-05-28 21:19:50.575048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:19:51.068867: lr: 0.002179
2022-05-28 21:19:51.071554: This epoch took 99.011168 s

2022-05-28 21:19:51.073684: 
epoch:  408
2022-05-28 21:21:23.175664: train loss : -0.8414
2022-05-28 21:21:31.845738: validation loss: -0.7172
2022-05-28 21:21:31.862092: Average global foreground Dice: [0.7952]
2022-05-28 21:21:31.898192: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:21:32.766654: lr: 0.002158
2022-05-28 21:21:32.793416: This epoch took 101.717470 s

2022-05-28 21:21:32.809291: 
epoch:  409
2022-05-28 21:23:08.122701: train loss : -0.8414
2022-05-28 21:23:15.408808: validation loss: -0.7314
2022-05-28 21:23:15.412196: Average global foreground Dice: [0.7896]
2022-05-28 21:23:15.418874: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:23:16.087322: lr: 0.002137
2022-05-28 21:23:16.089710: This epoch took 103.247429 s

2022-05-28 21:23:16.091866: 
epoch:  410
2022-05-28 21:24:46.494000: train loss : -0.8355
2022-05-28 21:24:54.993189: validation loss: -0.7208
2022-05-28 21:24:54.997507: Average global foreground Dice: [0.7792]
2022-05-28 21:24:54.999504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:24:55.483701: lr: 0.002115
2022-05-28 21:24:55.486329: This epoch took 99.392052 s

2022-05-28 21:24:55.488162: 
epoch:  411
2022-05-28 21:26:29.575549: train loss : -0.8465
2022-05-28 21:26:37.207864: validation loss: -0.7210
2022-05-28 21:26:37.211289: Average global foreground Dice: [0.7867]
2022-05-28 21:26:37.213446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:26:37.679818: lr: 0.002094
2022-05-28 21:26:37.684225: This epoch took 102.192937 s

2022-05-28 21:26:37.686427: 
epoch:  412
2022-05-28 21:28:12.343006: train loss : -0.8357
2022-05-28 21:28:20.258830: validation loss: -0.7053
2022-05-28 21:28:20.262044: Average global foreground Dice: [0.7861]
2022-05-28 21:28:20.264625: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:28:20.730641: lr: 0.002072
2022-05-28 21:28:20.733116: This epoch took 103.044028 s

2022-05-28 21:28:20.735370: 
epoch:  413
2022-05-28 21:29:57.664471: train loss : -0.8366
2022-05-28 21:30:07.083558: validation loss: -0.7270
2022-05-28 21:30:07.104290: Average global foreground Dice: [0.7848]
2022-05-28 21:30:07.128703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:30:07.631319: lr: 0.002051
2022-05-28 21:30:07.633605: This epoch took 106.896196 s

2022-05-28 21:30:07.635526: 
epoch:  414
2022-05-28 21:31:38.830679: train loss : -0.8383
2022-05-28 21:31:49.105220: validation loss: -0.7360
2022-05-28 21:31:49.112965: Average global foreground Dice: [0.7968]
2022-05-28 21:31:49.130752: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:31:49.632885: lr: 0.00203
2022-05-28 21:31:49.635540: This epoch took 101.998093 s

2022-05-28 21:31:49.637787: 
epoch:  415
2022-05-28 21:33:22.898510: train loss : -0.8369
2022-05-28 21:33:31.267379: validation loss: -0.7438
2022-05-28 21:33:31.300673: Average global foreground Dice: [0.7933]
2022-05-28 21:33:31.323280: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:33:31.967860: lr: 0.002008
2022-05-28 21:33:31.970391: This epoch took 102.330296 s

2022-05-28 21:33:31.972598: 
epoch:  416
2022-05-28 21:35:06.275399: train loss : -0.8376
2022-05-28 21:35:15.197073: validation loss: -0.7380
2022-05-28 21:35:15.223171: Average global foreground Dice: [0.7842]
2022-05-28 21:35:15.226556: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:35:15.767929: lr: 0.001987
2022-05-28 21:35:15.770533: This epoch took 103.795574 s

2022-05-28 21:35:15.772845: 
epoch:  417
2022-05-28 21:36:47.481561: train loss : -0.8302
2022-05-28 21:36:57.289563: validation loss: -0.7392
2022-05-28 21:36:57.318681: Average global foreground Dice: [0.7986]
2022-05-28 21:36:57.338287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:36:58.096832: lr: 0.001965
2022-05-28 21:36:58.119411: This epoch took 102.344214 s

2022-05-28 21:36:58.137885: 
epoch:  418
2022-05-28 21:38:29.764045: train loss : -0.8403
2022-05-28 21:38:38.736307: validation loss: -0.7379
2022-05-28 21:38:38.749998: Average global foreground Dice: [0.7874]
2022-05-28 21:38:38.772312: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:38:39.377182: lr: 0.001943
2022-05-28 21:38:39.379685: This epoch took 101.224643 s

2022-05-28 21:38:39.381699: 
epoch:  419
2022-05-28 21:40:12.823553: train loss : -0.8368
2022-05-28 21:40:20.592450: validation loss: -0.7089
2022-05-28 21:40:20.605437: Average global foreground Dice: [0.7564]
2022-05-28 21:40:20.617338: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:40:21.071764: lr: 0.001922
2022-05-28 21:40:21.074262: This epoch took 101.690636 s

2022-05-28 21:40:21.086487: 
epoch:  420
2022-05-28 21:41:52.412710: train loss : -0.8200
2022-05-28 21:42:02.959803: validation loss: -0.7246
2022-05-28 21:42:02.982711: Average global foreground Dice: [0.7849]
2022-05-28 21:42:02.999419: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:42:03.556588: lr: 0.0019
2022-05-28 21:42:03.558938: This epoch took 102.469301 s

2022-05-28 21:42:03.561230: 
epoch:  421
2022-05-28 21:43:35.350728: train loss : -0.8352
2022-05-28 21:43:44.077483: validation loss: -0.7167
2022-05-28 21:43:44.081256: Average global foreground Dice: [0.7839]
2022-05-28 21:43:44.083488: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:43:44.544461: lr: 0.001879
2022-05-28 21:43:44.547267: This epoch took 100.983996 s

2022-05-28 21:43:44.549213: 
epoch:  422
2022-05-28 21:45:17.241509: train loss : -0.8276
2022-05-28 21:45:25.553962: validation loss: -0.7134
2022-05-28 21:45:25.564325: Average global foreground Dice: [0.7958]
2022-05-28 21:45:25.566346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:45:26.061430: lr: 0.001857
2022-05-28 21:45:26.064091: This epoch took 101.505065 s

2022-05-28 21:45:26.066493: 
epoch:  423
2022-05-28 21:47:00.326553: train loss : -0.8416
2022-05-28 21:47:10.923730: validation loss: -0.7489
2022-05-28 21:47:10.927886: Average global foreground Dice: [0.7936]
2022-05-28 21:47:10.931384: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:47:11.413816: lr: 0.001835
2022-05-28 21:47:11.416106: This epoch took 105.347213 s

2022-05-28 21:47:11.418147: 
epoch:  424
2022-05-28 21:48:42.759795: train loss : -0.8372
2022-05-28 21:48:48.884178: validation loss: -0.7255
2022-05-28 21:48:48.915718: Average global foreground Dice: [0.7848]
2022-05-28 21:48:48.929297: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:48:49.441160: lr: 0.001813
2022-05-28 21:48:49.443455: This epoch took 98.022994 s

2022-05-28 21:48:49.445426: 
epoch:  425
2022-05-28 21:50:23.399296: train loss : -0.8328
2022-05-28 21:50:32.864078: validation loss: -0.7090
2022-05-28 21:50:32.867319: Average global foreground Dice: [0.7764]
2022-05-28 21:50:32.869504: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:50:33.379253: lr: 0.001792
2022-05-28 21:50:33.391309: This epoch took 103.943613 s

2022-05-28 21:50:33.420519: 
epoch:  426
2022-05-28 21:52:05.893316: train loss : -0.8436
2022-05-28 21:52:15.916871: validation loss: -0.7284
2022-05-28 21:52:15.941329: Average global foreground Dice: [0.7977]
2022-05-28 21:52:15.964229: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:52:16.501774: lr: 0.00177
2022-05-28 21:52:16.520453: This epoch took 103.076139 s

2022-05-28 21:52:16.543381: 
epoch:  427
2022-05-28 21:53:47.394174: train loss : -0.8407
2022-05-28 21:53:54.366474: validation loss: -0.7072
2022-05-28 21:53:54.369663: Average global foreground Dice: [0.7685]
2022-05-28 21:53:54.371528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:53:54.843583: lr: 0.001748
2022-05-28 21:53:54.846177: This epoch took 98.279735 s

2022-05-28 21:53:54.848703: 
epoch:  428
2022-05-28 21:55:24.796574: train loss : -0.8416
2022-05-28 21:55:30.736217: validation loss: -0.7306
2022-05-28 21:55:30.743258: Average global foreground Dice: [0.8043]
2022-05-28 21:55:30.752047: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:55:31.267479: lr: 0.001726
2022-05-28 21:55:31.273655: This epoch took 96.422582 s

2022-05-28 21:55:31.276173: 
epoch:  429
2022-05-28 21:57:02.313250: train loss : -0.8320
2022-05-28 21:57:10.062289: validation loss: -0.7556
2022-05-28 21:57:10.065860: Average global foreground Dice: [0.8041]
2022-05-28 21:57:10.081302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:57:10.551804: lr: 0.001704
2022-05-28 21:57:10.554808: This epoch took 99.276315 s

2022-05-28 21:57:10.557105: 
epoch:  430
2022-05-28 21:58:46.173853: train loss : -0.8463
2022-05-28 21:58:56.109470: validation loss: -0.7288
2022-05-28 21:58:56.114354: Average global foreground Dice: [0.7934]
2022-05-28 21:58:56.117733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 21:58:56.710557: lr: 0.001682
2022-05-28 21:58:56.733445: This epoch took 106.173896 s

2022-05-28 21:58:56.754315: 
epoch:  431
2022-05-28 22:00:28.159377: train loss : -0.8386
2022-05-28 22:00:34.949227: validation loss: -0.6980
2022-05-28 22:00:34.956745: Average global foreground Dice: [0.7611]
2022-05-28 22:00:34.959396: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:00:35.466010: lr: 0.00166
2022-05-28 22:00:35.468392: This epoch took 98.710445 s

2022-05-28 22:00:35.470419: 
epoch:  432
2022-05-28 22:02:06.400219: train loss : -0.8488
2022-05-28 22:02:13.397327: validation loss: -0.7212
2022-05-28 22:02:13.401098: Average global foreground Dice: [0.7737]
2022-05-28 22:02:13.403510: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:02:13.874876: lr: 0.001638
2022-05-28 22:02:13.877566: This epoch took 98.405000 s

2022-05-28 22:02:13.879995: 
epoch:  433
2022-05-28 22:03:48.042045: train loss : -0.8405
2022-05-28 22:03:56.564410: validation loss: -0.7198
2022-05-28 22:03:56.576273: Average global foreground Dice: [0.7902]
2022-05-28 22:03:56.586738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:03:57.157354: lr: 0.001616
2022-05-28 22:03:57.195525: This epoch took 103.313508 s

2022-05-28 22:03:57.215653: 
epoch:  434
2022-05-28 22:05:29.493740: train loss : -0.8384
2022-05-28 22:05:38.512228: validation loss: -0.7148
2022-05-28 22:05:38.515690: Average global foreground Dice: [0.7908]
2022-05-28 22:05:38.517952: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:05:39.164894: lr: 0.001594
2022-05-28 22:05:39.188172: This epoch took 101.954968 s

2022-05-28 22:05:39.196747: 
epoch:  435
2022-05-28 22:07:10.129932: train loss : -0.8480
2022-05-28 22:07:18.540130: validation loss: -0.7323
2022-05-28 22:07:18.543472: Average global foreground Dice: [0.7852]
2022-05-28 22:07:18.545627: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:07:19.030387: lr: 0.001572
2022-05-28 22:07:19.033430: This epoch took 99.834344 s

2022-05-28 22:07:19.035694: 
epoch:  436
2022-05-28 22:08:52.474060: train loss : -0.8410
2022-05-28 22:09:01.706911: validation loss: -0.7250
2022-05-28 22:09:01.710600: Average global foreground Dice: [0.7945]
2022-05-28 22:09:01.713166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:09:02.220257: lr: 0.00155
2022-05-28 22:09:02.223059: This epoch took 103.185051 s

2022-05-28 22:09:02.225125: 
epoch:  437
2022-05-28 22:10:33.604596: train loss : -0.8479
2022-05-28 22:10:41.929086: validation loss: -0.7073
2022-05-28 22:10:41.935678: Average global foreground Dice: [0.8015]
2022-05-28 22:10:41.942231: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:10:42.446159: lr: 0.001528
2022-05-28 22:10:42.449073: This epoch took 100.221793 s

2022-05-28 22:10:42.451255: 
epoch:  438
2022-05-28 22:12:16.806208: train loss : -0.8537
2022-05-28 22:12:26.707181: validation loss: -0.7291
2022-05-28 22:12:26.711226: Average global foreground Dice: [0.8035]
2022-05-28 22:12:26.713738: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:12:27.239133: lr: 0.001506
2022-05-28 22:12:27.276583: This epoch took 104.823327 s

2022-05-28 22:12:27.298359: 
epoch:  439
2022-05-28 22:13:58.319494: train loss : -0.8489
2022-05-28 22:14:04.567527: validation loss: -0.7241
2022-05-28 22:14:04.572757: Average global foreground Dice: [0.7763]
2022-05-28 22:14:04.575189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:14:05.096248: lr: 0.001483
2022-05-28 22:14:05.098598: This epoch took 97.781877 s

2022-05-28 22:14:05.100665: 
epoch:  440
2022-05-28 22:15:37.211634: train loss : -0.8482
2022-05-28 22:15:47.559816: validation loss: -0.7405
2022-05-28 22:15:47.563598: Average global foreground Dice: [0.7833]
2022-05-28 22:15:47.565986: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:15:48.086891: lr: 0.001461
2022-05-28 22:15:48.089434: This epoch took 102.986617 s

2022-05-28 22:15:48.091628: 
epoch:  441
2022-05-28 22:17:25.391411: train loss : -0.8464
2022-05-28 22:17:38.491036: validation loss: -0.7421
2022-05-28 22:17:38.513941: Average global foreground Dice: [0.792]
2022-05-28 22:17:38.516499: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:17:39.122289: lr: 0.001439
2022-05-28 22:17:39.125222: This epoch took 111.031251 s

2022-05-28 22:17:39.127240: 
epoch:  442
2022-05-28 22:19:13.945632: train loss : -0.8442
2022-05-28 22:19:23.626330: validation loss: -0.7521
2022-05-28 22:19:23.645500: Average global foreground Dice: [0.8064]
2022-05-28 22:19:23.648956: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:19:24.161599: lr: 0.001416
2022-05-28 22:19:24.164215: This epoch took 105.034921 s

2022-05-28 22:19:24.166260: 
epoch:  443
2022-05-28 22:21:02.353626: train loss : -0.8498
2022-05-28 22:21:09.754490: validation loss: -0.7363
2022-05-28 22:21:09.759167: Average global foreground Dice: [0.7923]
2022-05-28 22:21:09.762093: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:21:10.225120: lr: 0.001394
2022-05-28 22:21:10.227771: This epoch took 106.059237 s

2022-05-28 22:21:10.230126: 
epoch:  444
2022-05-28 22:22:40.827832: train loss : -0.8530
2022-05-28 22:22:48.196537: validation loss: -0.7392
2022-05-28 22:22:48.212778: Average global foreground Dice: [0.7926]
2022-05-28 22:22:48.236319: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:22:48.828556: lr: 0.001372
2022-05-28 22:22:48.838068: This epoch took 98.605729 s

2022-05-28 22:22:48.843640: 
epoch:  445
2022-05-28 22:24:21.440047: train loss : -0.8517
2022-05-28 22:24:29.902391: validation loss: -0.7475
2022-05-28 22:24:29.906451: Average global foreground Dice: [0.7944]
2022-05-28 22:24:29.926279: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:24:30.470384: lr: 0.001349
2022-05-28 22:24:30.473060: This epoch took 101.627245 s

2022-05-28 22:24:30.475188: 
epoch:  446
2022-05-28 22:26:04.247676: train loss : -0.8475
2022-05-28 22:26:14.496152: validation loss: -0.7396
2022-05-28 22:26:14.499564: Average global foreground Dice: [0.801]
2022-05-28 22:26:14.502187: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:26:15.055995: lr: 0.001327
2022-05-28 22:26:15.058527: This epoch took 104.581183 s

2022-05-28 22:26:15.060772: 
epoch:  447
2022-05-28 22:27:46.855997: train loss : -0.8406
2022-05-28 22:27:55.189943: validation loss: -0.7491
2022-05-28 22:27:55.193311: Average global foreground Dice: [0.8006]
2022-05-28 22:27:55.195682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:27:55.669409: lr: 0.001304
2022-05-28 22:27:55.672585: This epoch took 100.609528 s

2022-05-28 22:27:55.675218: 
epoch:  448
2022-05-28 22:29:31.391180: train loss : -0.8528
2022-05-28 22:29:42.036302: validation loss: -0.7298
2022-05-28 22:29:42.039489: Average global foreground Dice: [0.8033]
2022-05-28 22:29:42.041901: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:29:42.541785: lr: 0.001282
2022-05-28 22:29:42.544468: This epoch took 106.866671 s

2022-05-28 22:29:42.547033: 
epoch:  449
2022-05-28 22:31:13.477474: train loss : -0.8567
2022-05-28 22:31:23.327773: validation loss: -0.7571
2022-05-28 22:31:23.331317: Average global foreground Dice: [0.8172]
2022-05-28 22:31:23.334589: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:31:23.802957: lr: 0.001259
2022-05-28 22:31:23.805543: saving scheduled checkpoint file...
2022-05-28 22:31:23.857051: saving checkpoint...
2022-05-28 22:31:24.890439: done, saving took 1.08 seconds
2022-05-28 22:31:24.909052: done
2022-05-28 22:31:24.911510: This epoch took 102.362194 s

2022-05-28 22:31:24.914126: 
epoch:  450
2022-05-28 22:32:59.125238: train loss : -0.8537
2022-05-28 22:33:11.020692: validation loss: -0.7500
2022-05-28 22:33:11.024352: Average global foreground Dice: [0.813]
2022-05-28 22:33:11.027666: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:33:11.514323: lr: 0.001236
2022-05-28 22:33:11.569901: saving checkpoint...
2022-05-28 22:33:12.703983: done, saving took 1.19 seconds
2022-05-28 22:33:12.724284: This epoch took 107.807769 s

2022-05-28 22:33:12.726361: 
epoch:  451
2022-05-28 22:34:42.451823: train loss : -0.8555
2022-05-28 22:34:48.189892: validation loss: -0.7238
2022-05-28 22:34:48.193357: Average global foreground Dice: [0.7881]
2022-05-28 22:34:48.195565: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:34:48.660061: lr: 0.001214
2022-05-28 22:34:48.662758: This epoch took 95.933928 s

2022-05-28 22:34:48.664827: 
epoch:  452
2022-05-28 22:36:19.811532: train loss : -0.8555
2022-05-28 22:36:30.576147: validation loss: -0.7534
2022-05-28 22:36:30.579717: Average global foreground Dice: [0.7957]
2022-05-28 22:36:30.581897: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:36:31.044505: lr: 0.001191
2022-05-28 22:36:31.046945: This epoch took 102.379879 s

2022-05-28 22:36:31.049370: 
epoch:  453
2022-05-28 22:38:07.242366: train loss : -0.8498
2022-05-28 22:38:17.465288: validation loss: -0.7102
2022-05-28 22:38:17.469675: Average global foreground Dice: [0.774]
2022-05-28 22:38:17.472064: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:38:18.107632: lr: 0.001168
2022-05-28 22:38:18.138803: This epoch took 107.087179 s

2022-05-28 22:38:18.158933: 
epoch:  454
2022-05-28 22:39:50.467297: train loss : -0.8481
2022-05-28 22:39:59.493576: validation loss: -0.7246
2022-05-28 22:39:59.509605: Average global foreground Dice: [0.7866]
2022-05-28 22:39:59.512286: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:39:59.982629: lr: 0.001145
2022-05-28 22:39:59.985420: This epoch took 101.806295 s

2022-05-28 22:39:59.988057: 
epoch:  455
2022-05-28 22:41:40.007582: train loss : -0.8511
2022-05-28 22:41:49.839665: validation loss: -0.7590
2022-05-28 22:41:49.843593: Average global foreground Dice: [0.7953]
2022-05-28 22:41:49.846082: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:41:50.309802: lr: 0.001122
2022-05-28 22:41:50.312174: This epoch took 110.321439 s

2022-05-28 22:41:50.314292: 
epoch:  456
2022-05-28 22:43:22.078184: train loss : -0.8583
2022-05-28 22:43:31.531961: validation loss: -0.7254
2022-05-28 22:43:31.552862: Average global foreground Dice: [0.8001]
2022-05-28 22:43:31.572429: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:43:32.184767: lr: 0.001099
2022-05-28 22:43:32.206411: This epoch took 101.889979 s

2022-05-28 22:43:32.213974: 
epoch:  457
2022-05-28 22:45:09.710189: train loss : -0.8458
2022-05-28 22:45:19.275489: validation loss: -0.7734
2022-05-28 22:45:19.310160: Average global foreground Dice: [0.8207]
2022-05-28 22:45:19.332951: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:45:19.981985: lr: 0.001076
2022-05-28 22:45:19.997390: This epoch took 107.740016 s

2022-05-28 22:45:20.016299: 
epoch:  458
2022-05-28 22:46:52.511760: train loss : -0.8514
2022-05-28 22:47:00.807271: validation loss: -0.7313
2022-05-28 22:47:00.827125: Average global foreground Dice: [0.787]
2022-05-28 22:47:00.829545: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:47:01.434016: lr: 0.001053
2022-05-28 22:47:01.437495: This epoch took 101.404186 s

2022-05-28 22:47:01.444056: 
epoch:  459
2022-05-28 22:48:32.534482: train loss : -0.8353
2022-05-28 22:48:42.026765: validation loss: -0.7278
2022-05-28 22:48:42.068207: Average global foreground Dice: [0.7768]
2022-05-28 22:48:42.087769: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:48:42.778472: lr: 0.00103
2022-05-28 22:48:42.781189: This epoch took 101.335050 s

2022-05-28 22:48:42.783470: 
epoch:  460
2022-05-28 22:50:14.379165: train loss : -0.8423
2022-05-28 22:50:25.974911: validation loss: -0.7581
2022-05-28 22:50:25.978914: Average global foreground Dice: [0.8058]
2022-05-28 22:50:25.981272: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:50:26.454486: lr: 0.001007
2022-05-28 22:50:26.456874: This epoch took 103.670987 s

2022-05-28 22:50:26.459285: 
epoch:  461
2022-05-28 22:51:59.881761: train loss : -0.8473
2022-05-28 22:52:09.858958: validation loss: -0.7023
2022-05-28 22:52:09.880750: Average global foreground Dice: [0.7892]
2022-05-28 22:52:09.903311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:52:10.397870: lr: 0.000983
2022-05-28 22:52:10.400692: This epoch took 103.939326 s

2022-05-28 22:52:10.403147: 
epoch:  462
2022-05-28 22:53:42.699493: train loss : -0.8524
2022-05-28 22:53:50.499678: validation loss: -0.7519
2022-05-28 22:53:50.503247: Average global foreground Dice: [0.7945]
2022-05-28 22:53:50.505710: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:53:51.010886: lr: 0.00096
2022-05-28 22:53:51.013302: This epoch took 100.607643 s

2022-05-28 22:53:51.015335: 
epoch:  463
2022-05-28 22:55:24.061569: train loss : -0.8564
2022-05-28 22:55:31.594340: validation loss: -0.7545
2022-05-28 22:55:31.597429: Average global foreground Dice: [0.7935]
2022-05-28 22:55:31.599642: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:55:32.081183: lr: 0.000937
2022-05-28 22:55:32.083741: This epoch took 101.066258 s

2022-05-28 22:55:32.085779: 
epoch:  464
2022-05-28 22:57:05.969751: train loss : -0.8524
2022-05-28 22:57:13.276094: validation loss: -0.7433
2022-05-28 22:57:13.293071: Average global foreground Dice: [0.8062]
2022-05-28 22:57:13.312999: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:57:13.926346: lr: 0.000913
2022-05-28 22:57:13.945485: This epoch took 101.857566 s

2022-05-28 22:57:13.965580: 
epoch:  465
2022-05-28 22:58:46.716149: train loss : -0.8504
2022-05-28 22:58:56.877433: validation loss: -0.7340
2022-05-28 22:58:56.912714: Average global foreground Dice: [0.787]
2022-05-28 22:58:56.915639: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 22:58:57.588567: lr: 0.00089
2022-05-28 22:58:57.594286: This epoch took 103.608491 s

2022-05-28 22:58:57.596420: 
epoch:  466
2022-05-28 23:00:29.008619: train loss : -0.8519
2022-05-28 23:00:36.337122: validation loss: -0.7488
2022-05-28 23:00:36.340663: Average global foreground Dice: [0.815]
2022-05-28 23:00:36.342952: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:00:36.803133: lr: 0.000866
2022-05-28 23:00:36.805681: This epoch took 99.207112 s

2022-05-28 23:00:36.808421: 
epoch:  467
2022-05-28 23:02:08.114201: train loss : -0.8406
2022-05-28 23:02:16.229349: validation loss: -0.7211
2022-05-28 23:02:16.233537: Average global foreground Dice: [0.7819]
2022-05-28 23:02:16.236250: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:02:16.698518: lr: 0.000842
2022-05-28 23:02:16.700830: This epoch took 99.888869 s

2022-05-28 23:02:16.702915: 
epoch:  468
2022-05-28 23:03:53.833613: train loss : -0.8458
2022-05-28 23:04:03.835926: validation loss: -0.7157
2022-05-28 23:04:03.839442: Average global foreground Dice: [0.7731]
2022-05-28 23:04:03.842081: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:04:04.311763: lr: 0.000819
2022-05-28 23:04:04.314123: This epoch took 107.609083 s

2022-05-28 23:04:04.316142: 
epoch:  469
2022-05-28 23:05:36.014290: train loss : -0.8500
2022-05-28 23:05:44.495592: validation loss: -0.7376
2022-05-28 23:05:44.499124: Average global foreground Dice: [0.7872]
2022-05-28 23:05:44.501562: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:05:44.959645: lr: 0.000795
2022-05-28 23:05:44.962166: This epoch took 100.643991 s

2022-05-28 23:05:44.964458: 
epoch:  470
2022-05-28 23:07:16.583889: train loss : -0.8539
2022-05-28 23:07:25.828397: validation loss: -0.7303
2022-05-28 23:07:25.832738: Average global foreground Dice: [0.7942]
2022-05-28 23:07:25.835299: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:07:26.334424: lr: 0.000771
2022-05-28 23:07:26.336848: This epoch took 101.370358 s

2022-05-28 23:07:26.339063: 
epoch:  471
2022-05-28 23:09:02.202086: train loss : -0.8514
2022-05-28 23:09:13.871307: validation loss: -0.7168
2022-05-28 23:09:13.890190: Average global foreground Dice: [0.792]
2022-05-28 23:09:13.897295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:09:14.600184: lr: 0.000747
2022-05-28 23:09:14.608953: This epoch took 108.267808 s

2022-05-28 23:09:14.611254: 
epoch:  472
2022-05-28 23:10:46.022552: train loss : -0.8430
2022-05-28 23:10:55.847198: validation loss: -0.7375
2022-05-28 23:10:55.851081: Average global foreground Dice: [0.7875]
2022-05-28 23:10:55.853453: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:10:56.389526: lr: 0.000723
2022-05-28 23:10:56.393403: This epoch took 101.780016 s

2022-05-28 23:10:56.398735: 
epoch:  473
2022-05-28 23:12:29.829884: train loss : -0.8621
2022-05-28 23:12:41.782799: validation loss: -0.6961
2022-05-28 23:12:41.786273: Average global foreground Dice: [0.7752]
2022-05-28 23:12:41.788563: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:12:42.306957: lr: 0.000699
2022-05-28 23:12:42.309517: This epoch took 105.907992 s

2022-05-28 23:12:42.311676: 
epoch:  474
2022-05-28 23:14:18.859129: train loss : -0.8583
2022-05-28 23:14:25.355279: validation loss: -0.7248
2022-05-28 23:14:25.378831: Average global foreground Dice: [0.7917]
2022-05-28 23:14:25.404305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:14:26.100398: lr: 0.000675
2022-05-28 23:14:26.120322: This epoch took 103.806466 s

2022-05-28 23:14:26.139282: 
epoch:  475
2022-05-28 23:15:58.559879: train loss : -0.8546
2022-05-28 23:16:07.946260: validation loss: -0.7060
2022-05-28 23:16:07.956702: Average global foreground Dice: [0.7844]
2022-05-28 23:16:07.959021: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:16:08.458147: lr: 0.00065
2022-05-28 23:16:08.460634: This epoch took 102.302360 s

2022-05-28 23:16:08.462805: 
epoch:  476
2022-05-28 23:17:39.617439: train loss : -0.8631
2022-05-28 23:17:47.676956: validation loss: -0.7195
2022-05-28 23:17:47.680945: Average global foreground Dice: [0.7902]
2022-05-28 23:17:47.683745: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:17:48.178852: lr: 0.000626
2022-05-28 23:17:48.181086: This epoch took 99.716176 s

2022-05-28 23:17:48.183013: 
epoch:  477
2022-05-28 23:19:20.351213: train loss : -0.8593
2022-05-28 23:19:28.771449: validation loss: -0.7331
2022-05-28 23:19:28.792621: Average global foreground Dice: [0.7916]
2022-05-28 23:19:28.798759: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:19:29.311731: lr: 0.000601
2022-05-28 23:19:29.326873: This epoch took 101.141871 s

2022-05-28 23:19:29.347027: 
epoch:  478
2022-05-28 23:21:03.564011: train loss : -0.8391
2022-05-28 23:21:12.396449: validation loss: -0.7465
2022-05-28 23:21:12.436999: Average global foreground Dice: [0.793]
2022-05-28 23:21:12.463591: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:21:13.031388: lr: 0.000577
2022-05-28 23:21:13.034145: This epoch took 103.673463 s

2022-05-28 23:21:13.037268: 
epoch:  479
2022-05-28 23:22:46.897329: train loss : -0.8564
2022-05-28 23:22:57.370225: validation loss: -0.7332
2022-05-28 23:22:57.378928: Average global foreground Dice: [0.7955]
2022-05-28 23:22:57.386885: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:22:57.906305: lr: 0.000552
2022-05-28 23:22:57.934098: This epoch took 104.894592 s

2022-05-28 23:22:57.948321: 
epoch:  480
2022-05-28 23:24:28.510655: train loss : -0.8569
2022-05-28 23:24:36.738202: validation loss: -0.7284
2022-05-28 23:24:36.742273: Average global foreground Dice: [0.7828]
2022-05-28 23:24:36.744939: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:24:37.228163: lr: 0.000527
2022-05-28 23:24:37.231951: This epoch took 99.262668 s

2022-05-28 23:24:37.234369: 
epoch:  481
2022-05-28 23:26:07.293094: train loss : -0.8572
2022-05-28 23:26:14.592426: validation loss: -0.7068
2022-05-28 23:26:14.597328: Average global foreground Dice: [0.7758]
2022-05-28 23:26:14.599438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:26:15.089257: lr: 0.000502
2022-05-28 23:26:15.092134: This epoch took 97.855722 s

2022-05-28 23:26:15.094501: 
epoch:  482
2022-05-28 23:27:48.062793: train loss : -0.8585
2022-05-28 23:27:58.268404: validation loss: -0.7093
2022-05-28 23:27:58.272571: Average global foreground Dice: [0.7949]
2022-05-28 23:27:58.275975: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:27:58.763291: lr: 0.000477
2022-05-28 23:27:58.766351: This epoch took 103.669397 s

2022-05-28 23:27:58.769858: 
epoch:  483
2022-05-28 23:29:30.416959: train loss : -0.8613
2022-05-28 23:29:40.026543: validation loss: -0.7562
2022-05-28 23:29:40.030679: Average global foreground Dice: [0.8009]
2022-05-28 23:29:40.032933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:29:40.562817: lr: 0.000451
2022-05-28 23:29:40.590363: This epoch took 101.818200 s

2022-05-28 23:29:40.617295: 
epoch:  484
2022-05-28 23:31:11.017336: train loss : -0.8638
2022-05-28 23:31:19.044871: validation loss: -0.7276
2022-05-28 23:31:19.049011: Average global foreground Dice: [0.7917]
2022-05-28 23:31:19.051146: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:31:19.529821: lr: 0.000426
2022-05-28 23:31:19.532712: This epoch took 98.903384 s

2022-05-28 23:31:19.534946: 
epoch:  485
2022-05-28 23:32:50.712451: train loss : -0.8640
2022-05-28 23:33:00.736316: validation loss: -0.7398
2022-05-28 23:33:00.747757: Average global foreground Dice: [0.803]
2022-05-28 23:33:00.768421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:33:01.258401: lr: 0.0004
2022-05-28 23:33:01.287143: This epoch took 101.750080 s

2022-05-28 23:33:01.294567: 
epoch:  486
2022-05-28 23:34:32.356249: train loss : -0.8548
2022-05-28 23:34:41.504667: validation loss: -0.7372
2022-05-28 23:34:41.514158: Average global foreground Dice: [0.7866]
2022-05-28 23:34:41.520085: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:34:42.018927: lr: 0.000375
2022-05-28 23:34:42.021587: This epoch took 100.686849 s

2022-05-28 23:34:42.023736: 
epoch:  487
2022-05-28 23:36:15.458182: train loss : -0.8605
2022-05-28 23:36:25.309835: validation loss: -0.7374
2022-05-28 23:36:25.313596: Average global foreground Dice: [0.7954]
2022-05-28 23:36:25.316140: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:36:25.884811: lr: 0.000348
2022-05-28 23:36:25.887302: This epoch took 103.861362 s

2022-05-28 23:36:25.889527: 
epoch:  488
2022-05-28 23:37:57.191815: train loss : -0.8652
2022-05-28 23:38:06.781816: validation loss: -0.7358
2022-05-28 23:38:06.785954: Average global foreground Dice: [0.8034]
2022-05-28 23:38:06.788453: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:38:07.282863: lr: 0.000322
2022-05-28 23:38:07.285416: This epoch took 101.393645 s

2022-05-28 23:38:07.287854: 
epoch:  489
2022-05-28 23:39:38.235831: train loss : -0.8486
2022-05-28 23:39:45.352902: validation loss: -0.7462
2022-05-28 23:39:45.383698: Average global foreground Dice: [0.7949]
2022-05-28 23:39:45.409261: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:39:46.099877: lr: 0.000296
2022-05-28 23:39:46.102466: This epoch took 98.812540 s

2022-05-28 23:39:46.104824: 
epoch:  490
2022-05-28 23:41:21.211916: train loss : -0.8632
2022-05-28 23:41:30.513021: validation loss: -0.7540
2022-05-28 23:41:30.516343: Average global foreground Dice: [0.7968]
2022-05-28 23:41:30.521438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:41:31.118864: lr: 0.000269
2022-05-28 23:41:31.121552: This epoch took 105.014243 s

2022-05-28 23:41:31.124011: 
epoch:  491
2022-05-28 23:43:02.294227: train loss : -0.8588
2022-05-28 23:43:10.163578: validation loss: -0.7115
2022-05-28 23:43:10.182112: Average global foreground Dice: [0.79]
2022-05-28 23:43:10.196342: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:43:10.766088: lr: 0.000242
2022-05-28 23:43:10.771437: This epoch took 99.645229 s

2022-05-28 23:43:10.774113: 
epoch:  492
2022-05-28 23:44:43.396752: train loss : -0.8505
2022-05-28 23:44:53.294566: validation loss: -0.6995
2022-05-28 23:44:53.298763: Average global foreground Dice: [0.7818]
2022-05-28 23:44:53.300966: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:44:53.877934: lr: 0.000215
2022-05-28 23:44:53.900316: This epoch took 103.123338 s

2022-05-28 23:44:53.922376: 
epoch:  493
2022-05-28 23:46:25.916766: train loss : -0.8571
2022-05-28 23:46:35.605717: validation loss: -0.7397
2022-05-28 23:46:35.609076: Average global foreground Dice: [0.7875]
2022-05-28 23:46:35.611162: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:46:36.223878: lr: 0.000187
2022-05-28 23:46:36.228143: This epoch took 102.301162 s

2022-05-28 23:46:36.231642: 
epoch:  494
2022-05-28 23:48:15.497514: train loss : -0.8580
2022-05-28 23:48:24.646108: validation loss: -0.7252
2022-05-28 23:48:24.649433: Average global foreground Dice: [0.7728]
2022-05-28 23:48:24.651824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:48:25.239028: lr: 0.000158
2022-05-28 23:48:25.242732: This epoch took 109.008657 s

2022-05-28 23:48:25.245180: 
epoch:  495
2022-05-28 23:49:57.445788: train loss : -0.8501
2022-05-28 23:50:05.295009: validation loss: -0.6657
2022-05-28 23:50:05.319004: Average global foreground Dice: [0.789]
2022-05-28 23:50:05.333708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:50:05.852834: lr: 0.00013
2022-05-28 23:50:05.855616: This epoch took 100.608339 s

2022-05-28 23:50:05.857872: 
epoch:  496
2022-05-28 23:51:39.316380: train loss : -0.8564
2022-05-28 23:51:49.132935: validation loss: -0.7531
2022-05-28 23:51:49.136807: Average global foreground Dice: [0.8029]
2022-05-28 23:51:49.156472: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:51:49.637801: lr: 0.0001
2022-05-28 23:51:49.640171: This epoch took 103.779971 s

2022-05-28 23:51:49.642304: 
epoch:  497
2022-05-28 23:53:20.479656: train loss : -0.8590
2022-05-28 23:53:28.083548: validation loss: -0.7396
2022-05-28 23:53:28.087540: Average global foreground Dice: [0.8095]
2022-05-28 23:53:28.090249: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:53:28.575847: lr: 6.9e-05
2022-05-28 23:53:28.579005: This epoch took 98.934625 s

2022-05-28 23:53:28.582890: 
epoch:  498
2022-05-28 23:54:59.270405: train loss : -0.8605
2022-05-28 23:55:06.928107: validation loss: -0.7272
2022-05-28 23:55:06.931645: Average global foreground Dice: [0.8085]
2022-05-28 23:55:06.933967: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:55:07.438879: lr: 3.7e-05
2022-05-28 23:55:07.441491: This epoch took 98.856481 s

2022-05-28 23:55:07.443973: 
epoch:  499
2022-05-28 23:56:40.707279: train loss : -0.8637
2022-05-28 23:56:50.807588: validation loss: -0.7504
2022-05-28 23:56:50.810946: Average global foreground Dice: [0.8037]
2022-05-28 23:56:50.814331: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-28 23:56:51.298150: lr: 0.0
2022-05-28 23:56:51.300406: saving scheduled checkpoint file...
2022-05-28 23:56:51.341447: saving checkpoint...
2022-05-28 23:56:52.388909: done, saving took 1.09 seconds
2022-05-28 23:56:52.404987: done
2022-05-28 23:56:52.407047: This epoch took 104.960466 s

2022-05-28 23:56:52.444041: saving checkpoint...
2022-05-28 23:56:53.428820: done, saving took 1.02 seconds
panc_001 (2, 107, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 63], [0, 63]]
number of tiles: 12
computing Gaussian
done
prediction done
panc_010 (2, 101, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_016 (2, 83, 306, 306)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 306, 306)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 57, 114], [0, 57, 114]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_018 (2, 84, 267, 267)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_029 (2, 96, 309, 309)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_049 (2, 84, 319, 319)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 319, 319)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 64, 127], [0, 64, 127]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_050 (2, 83, 286, 286)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_070 (2, 103, 345, 345)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 103, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 39], [0, 76, 153], [0, 76, 153]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_081 (2, 91, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 91, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_083 (2, 81, 304, 304)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_087 (2, 149, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 149, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 57, 85], [0, 63], [0, 63]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_098 (2, 143, 367, 367)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 143, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53, 79], [0, 88, 175], [0, 88, 175]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_110 (2, 95, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_120 (2, 162, 270, 270)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 162, 270, 270)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49, 74, 98], [0, 78], [0, 78]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_126 (2, 71, 291, 291)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_127 (2, 122, 344, 344)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 122, 344, 344)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58], [0, 76, 152], [0, 76, 152]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_130 (2, 151, 260, 260)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 151, 260, 260)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58, 87], [0, 68], [0, 68]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_149 (2, 75, 303, 303)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_158 (2, 128, 376, 376)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 128, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 64], [0, 92, 184], [0, 92, 184]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_160 (2, 73, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_169 (2, 84, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_172 (2, 92, 293, 293)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 293, 293)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 50, 101], [0, 50, 101]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_173 (2, 79, 274, 274)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 274, 274)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82], [0, 82]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_181 (2, 84, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_212 (2, 94, 345, 345)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 76, 153], [0, 76, 153]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_214 (2, 106, 336, 336)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 336, 336)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 72, 144], [0, 72, 144]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_229 (2, 84, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_242 (2, 98, 345, 345)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 76, 153], [0, 76, 153]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_279 (2, 78, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 78, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 14], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_284 (2, 83, 298, 298)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 298, 298)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 53, 106], [0, 53, 106]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_292 (2, 90, 331, 331)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 331, 331)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 70, 139], [0, 70, 139]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_309 (2, 92, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_316 (2, 86, 287, 287)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 95], [0, 95]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_326 (2, 86, 376, 376)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 92, 184], [0, 92, 184]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_327 (2, 96, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_330 (2, 86, 321, 321)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_347 (2, 86, 292, 292)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 292, 292)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 50, 100], [0, 50, 100]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_348 (2, 86, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_350 (2, 86, 287, 287)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 95], [0, 95]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_356 (2, 163, 268, 268)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 163, 268, 268)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50, 74, 99], [0, 76], [0, 76]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_357 (2, 85, 250, 250)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 250, 250)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 58], [0, 58]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_372 (2, 90, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_376 (2, 106, 340, 340)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 74, 148], [0, 74, 148]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_379 (2, 186, 275, 275)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 275, 275)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 83], [0, 83]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_382 (2, 108, 323, 323)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 108, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 44], [0, 66, 131], [0, 66, 131]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_385 (2, 95, 332, 332)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_401 (2, 175, 286, 286)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 175, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 83, 111], [0, 94], [0, 94]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_409 (2, 204, 311, 311)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 204, 311, 311)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 84, 112, 140], [0, 60, 119], [0, 60, 119]]
number of tiles: 54
using precomputed Gaussian
prediction done
2022-05-29 00:05:16.336480: finished prediction
2022-05-29 00:05:16.340587: evaluation of raw predictions
2022-05-29 00:05:34.421559: determining postprocessing
Foreground vs background
before: 0.7963720075763613
after:  0.7923568521376224
Only one class present, no need to do each class separately as this is covered in fg vs bg
done
for which classes:
[]
min_object_sizes
None
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
done
predicting segmentations for the next stage of the cascade
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
panc_001
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 63], [0, 63]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_010
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_016
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 306, 306)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 57, 114], [0, 57, 114]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_018
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_029
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_049
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 319, 319)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 64, 127], [0, 64, 127]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_050
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_070
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 103, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 39], [0, 76, 153], [0, 76, 153]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_081
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 91, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_083
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_087
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 149, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 57, 85], [0, 63], [0, 63]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_098
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 143, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53, 79], [0, 88, 175], [0, 88, 175]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_110
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_120
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 162, 270, 270)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49, 74, 98], [0, 78], [0, 78]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_126
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_127
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 122, 344, 344)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58], [0, 76, 152], [0, 76, 152]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_130
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 151, 260, 260)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58, 87], [0, 68], [0, 68]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_149
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_158
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 128, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 64], [0, 92, 184], [0, 92, 184]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_160
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_169
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_172
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 293, 293)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 50, 101], [0, 50, 101]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_173
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 274, 274)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82], [0, 82]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_181
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_212
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 76, 153], [0, 76, 153]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_214
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 336, 336)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 72, 144], [0, 72, 144]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_229
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_242
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 76, 153], [0, 76, 153]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_279
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 78, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 14], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_284
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 298, 298)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 53, 106], [0, 53, 106]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_292
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 331, 331)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 70, 139], [0, 70, 139]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_309
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_316
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 95], [0, 95]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_326
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 92, 184], [0, 92, 184]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_327
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_330
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_347
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 292, 292)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 50, 100], [0, 50, 100]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_348
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_350
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 95], [0, 95]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_356
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 163, 268, 268)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50, 74, 99], [0, 76], [0, 76]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_357
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 250, 250)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 58], [0, 58]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_372
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_376
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 74, 148], [0, 74, 148]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_379
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 275, 275)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 83], [0, 83]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_382
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 108, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 44], [0, 66, 131], [0, 66, 131]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_385
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_401
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 175, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 83, 111], [0, 94], [0, 94]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_409
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 204, 311, 311)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 84, 112, 140], [0, 60, 119], [0, 60, 119]]
number of tiles: 54
using precomputed Gaussian
prediction done


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_lowres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 93, 318, 318]), 'current_spacing': array([2.5757525 , 1.29418872, 1.29418872]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 40, 224, 224]), 'median_patient_size_in_voxels': array([ 96, 512, 512]), 'current_spacing': array([2.5       , 0.80273402, 0.80273402]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-05-29 00:15:32.393922: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/splits_final.pkl
2022-05-29 00:15:32.432580: The split file contains 5 splits.
2022-05-29 00:15:32.435266: Desired fold for training: 4
2022-05-29 00:15:32.437474: This split has 192 training and 47 validation cases.
unpacking dataset
done
Susy hier
Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 00:15:36.004980: lr: 0.01
using pin_memory on device 0
using pin_memory on device 0
2022-05-29 00:15:43.192693: Unable to plot network architecture:
2022-05-29 00:15:43.210156: No module named 'hiddenlayer'
2022-05-29 00:15:43.213725: 
printing the network instead:

2022-05-29 00:15:43.217234: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 00:15:43.224988: 

2022-05-29 00:15:43.228938: 
epoch:  0
2022-05-29 00:17:29.351835: train loss : -0.0549
2022-05-29 00:17:39.004611: validation loss: -0.2283
2022-05-29 00:17:39.008265: Average global foreground Dice: [0.3521]
2022-05-29 00:17:39.010414: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:17:39.586809: lr: 0.009982
2022-05-29 00:17:39.590348: This epoch took 116.357464 s

2022-05-29 00:17:39.592869: 
epoch:  1
2022-05-29 00:19:14.084847: train loss : -0.2403
2022-05-29 00:19:23.044089: validation loss: -0.3137
2022-05-29 00:19:23.070864: Average global foreground Dice: [0.4018]
2022-05-29 00:19:23.086296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:19:23.697589: lr: 0.009964
2022-05-29 00:19:23.814212: saving checkpoint...
2022-05-29 00:19:25.245429: done, saving took 1.53 seconds
2022-05-29 00:19:25.320724: This epoch took 105.725741 s

2022-05-29 00:19:25.337440: 
epoch:  2
2022-05-29 00:20:57.242259: train loss : -0.3366
2022-05-29 00:21:04.729392: validation loss: -0.3949
2022-05-29 00:21:04.732818: Average global foreground Dice: [0.4883]
2022-05-29 00:21:04.735785: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:21:05.190725: lr: 0.009946
2022-05-29 00:21:05.246136: saving checkpoint...
2022-05-29 00:21:06.237614: done, saving took 1.04 seconds
2022-05-29 00:21:06.255734: This epoch took 100.904502 s

2022-05-29 00:21:06.258095: 
epoch:  3
2022-05-29 00:22:38.950360: train loss : -0.3937
2022-05-29 00:22:47.442411: validation loss: -0.4524
2022-05-29 00:22:47.445469: Average global foreground Dice: [0.5328]
2022-05-29 00:22:47.447528: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:22:47.925729: lr: 0.009928
2022-05-29 00:22:48.001247: saving checkpoint...
2022-05-29 00:22:49.120904: done, saving took 1.17 seconds
2022-05-29 00:22:49.134341: This epoch took 102.873915 s

2022-05-29 00:22:49.136309: 
epoch:  4
2022-05-29 00:24:20.370573: train loss : -0.4591
2022-05-29 00:24:29.146458: validation loss: -0.4424
2022-05-29 00:24:29.169110: Average global foreground Dice: [0.5139]
2022-05-29 00:24:29.173290: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:24:29.841090: lr: 0.00991
2022-05-29 00:24:29.877738: saving checkpoint...
2022-05-29 00:24:30.916717: done, saving took 1.07 seconds
2022-05-29 00:24:30.932719: This epoch took 101.794553 s

2022-05-29 00:24:30.934996: 
epoch:  5
2022-05-29 00:26:03.188058: train loss : -0.4656
2022-05-29 00:26:12.456221: validation loss: -0.4952
2022-05-29 00:26:12.483159: Average global foreground Dice: [0.5784]
2022-05-29 00:26:12.498333: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:26:12.944997: lr: 0.009892
2022-05-29 00:26:12.993993: saving checkpoint...
2022-05-29 00:26:13.974778: done, saving took 1.03 seconds
2022-05-29 00:26:13.988949: This epoch took 103.051605 s

2022-05-29 00:26:13.991072: 
epoch:  6
2022-05-29 00:27:44.981163: train loss : -0.5035
2022-05-29 00:27:54.474886: validation loss: -0.5609
2022-05-29 00:27:54.478792: Average global foreground Dice: [0.6292]
2022-05-29 00:27:54.481322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:27:54.928259: lr: 0.009874
2022-05-29 00:27:54.996157: saving checkpoint...
2022-05-29 00:27:56.045458: done, saving took 1.11 seconds
2022-05-29 00:27:56.062845: This epoch took 102.069360 s

2022-05-29 00:27:56.065060: 
epoch:  7
2022-05-29 00:29:32.146020: train loss : -0.4928
2022-05-29 00:29:38.433342: validation loss: -0.5476
2022-05-29 00:29:38.437570: Average global foreground Dice: [0.6185]
2022-05-29 00:29:38.441375: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:29:38.882684: lr: 0.009856
2022-05-29 00:29:38.935723: saving checkpoint...
2022-05-29 00:29:40.070563: done, saving took 1.19 seconds
2022-05-29 00:29:40.086498: This epoch took 104.019223 s

2022-05-29 00:29:40.088847: 
epoch:  8
2022-05-29 00:31:16.301366: train loss : -0.5309
2022-05-29 00:31:22.970759: validation loss: -0.5494
2022-05-29 00:31:22.984793: Average global foreground Dice: [0.628]
2022-05-29 00:31:22.987670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:31:23.427453: lr: 0.009838
2022-05-29 00:31:23.462463: saving checkpoint...
2022-05-29 00:31:24.539335: done, saving took 1.11 seconds
2022-05-29 00:31:24.553715: This epoch took 104.462548 s

2022-05-29 00:31:24.555889: 
epoch:  9
2022-05-29 00:32:54.725337: train loss : -0.5477
2022-05-29 00:33:01.276386: validation loss: -0.5417
2022-05-29 00:33:01.280656: Average global foreground Dice: [0.6038]
2022-05-29 00:33:01.283292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:33:01.709429: lr: 0.00982
2022-05-29 00:33:01.745516: saving checkpoint...
2022-05-29 00:33:02.717700: done, saving took 1.01 seconds
2022-05-29 00:33:02.731227: This epoch took 98.173114 s

2022-05-29 00:33:02.733655: 
epoch:  10
2022-05-29 00:34:34.369536: train loss : -0.5334
2022-05-29 00:34:41.762410: validation loss: -0.5423
2022-05-29 00:34:41.772516: Average global foreground Dice: [0.6214]
2022-05-29 00:34:41.787256: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:34:42.345179: lr: 0.009802
2022-05-29 00:34:42.383627: saving checkpoint...
2022-05-29 00:34:43.412204: done, saving took 1.06 seconds
2022-05-29 00:34:43.425002: This epoch took 100.689136 s

2022-05-29 00:34:43.427311: 
epoch:  11
2022-05-29 00:36:16.595781: train loss : -0.5562
2022-05-29 00:36:24.426020: validation loss: -0.6145
2022-05-29 00:36:24.478280: Average global foreground Dice: [0.6847]
2022-05-29 00:36:24.481334: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:36:25.005568: lr: 0.009784
2022-05-29 00:36:25.054792: saving checkpoint...
2022-05-29 00:36:26.042489: done, saving took 1.03 seconds
2022-05-29 00:36:26.056877: This epoch took 102.627236 s

2022-05-29 00:36:26.059009: 
epoch:  12
2022-05-29 00:37:57.699943: train loss : -0.5946
2022-05-29 00:38:04.746967: validation loss: -0.5922
2022-05-29 00:38:04.764921: Average global foreground Dice: [0.6642]
2022-05-29 00:38:04.784586: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:38:05.562364: lr: 0.009766
2022-05-29 00:38:05.679516: saving checkpoint...
2022-05-29 00:38:06.787719: done, saving took 1.20 seconds
2022-05-29 00:38:06.803067: This epoch took 100.742016 s

2022-05-29 00:38:06.805108: 
epoch:  13
2022-05-29 00:39:41.517456: train loss : -0.5923
2022-05-29 00:39:48.498477: validation loss: -0.6295
2022-05-29 00:39:48.527716: Average global foreground Dice: [0.6929]
2022-05-29 00:39:48.554732: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:39:49.248928: lr: 0.009748
2022-05-29 00:39:49.306838: saving checkpoint...
2022-05-29 00:39:50.388543: done, saving took 1.13 seconds
2022-05-29 00:39:50.404063: This epoch took 103.596515 s

2022-05-29 00:39:50.406760: 
epoch:  14
2022-05-29 00:41:22.308602: train loss : -0.6101
2022-05-29 00:41:31.557627: validation loss: -0.6335
2022-05-29 00:41:31.603363: Average global foreground Dice: [0.7024]
2022-05-29 00:41:31.607075: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:41:32.195865: lr: 0.00973
2022-05-29 00:41:32.326498: saving checkpoint...
2022-05-29 00:41:33.740327: done, saving took 1.54 seconds
2022-05-29 00:41:33.755727: This epoch took 103.346889 s

2022-05-29 00:41:33.757895: 
epoch:  15
2022-05-29 00:43:05.565897: train loss : -0.5964
2022-05-29 00:43:13.063866: validation loss: -0.6267
2022-05-29 00:43:13.098660: Average global foreground Dice: [0.7011]
2022-05-29 00:43:13.120327: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:43:13.914667: lr: 0.009712
2022-05-29 00:43:13.967362: saving checkpoint...
2022-05-29 00:43:15.291474: done, saving took 1.36 seconds
2022-05-29 00:43:15.305634: This epoch took 101.545476 s

2022-05-29 00:43:15.307791: 
epoch:  16
2022-05-29 00:44:51.916623: train loss : -0.5965
2022-05-29 00:44:58.073234: validation loss: -0.5902
2022-05-29 00:44:58.102674: Average global foreground Dice: [0.6611]
2022-05-29 00:44:58.123296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:44:58.686408: lr: 0.009693
2022-05-29 00:44:58.731797: saving checkpoint...
2022-05-29 00:45:00.015030: done, saving took 1.31 seconds
2022-05-29 00:45:00.070309: This epoch took 104.760339 s

2022-05-29 00:45:00.082320: 
epoch:  17
2022-05-29 00:46:37.321794: train loss : -0.6110
2022-05-29 00:46:45.740888: validation loss: -0.6216
2022-05-29 00:46:45.764969: Average global foreground Dice: [0.6878]
2022-05-29 00:46:45.785414: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:46:46.503346: lr: 0.009675
2022-05-29 00:46:46.569729: saving checkpoint...
2022-05-29 00:46:47.630350: done, saving took 1.09 seconds
2022-05-29 00:46:47.644273: This epoch took 107.538980 s

2022-05-29 00:46:47.646596: 
epoch:  18
2022-05-29 00:48:19.373477: train loss : -0.6021
2022-05-29 00:48:27.360739: validation loss: -0.5773
2022-05-29 00:48:27.409677: Average global foreground Dice: [0.653]
2022-05-29 00:48:27.420285: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:48:28.000815: lr: 0.009657
2022-05-29 00:48:28.035565: saving checkpoint...
2022-05-29 00:48:29.033528: done, saving took 1.03 seconds
2022-05-29 00:48:29.093305: This epoch took 101.444432 s

2022-05-29 00:48:29.116292: 
epoch:  19
2022-05-29 00:50:01.241040: train loss : -0.6167
2022-05-29 00:50:07.603677: validation loss: -0.6435
2022-05-29 00:50:07.616396: Average global foreground Dice: [0.703]
2022-05-29 00:50:07.629291: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:50:08.069631: lr: 0.009639
2022-05-29 00:50:08.139732: saving checkpoint...
2022-05-29 00:50:09.242327: done, saving took 1.15 seconds
2022-05-29 00:50:09.257236: This epoch took 100.119947 s

2022-05-29 00:50:09.259906: 
epoch:  20
2022-05-29 00:51:40.068473: train loss : -0.6312
2022-05-29 00:51:46.387313: validation loss: -0.6325
2022-05-29 00:51:46.390735: Average global foreground Dice: [0.7027]
2022-05-29 00:51:46.393058: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:51:46.837376: lr: 0.009621
2022-05-29 00:51:46.902793: saving checkpoint...
2022-05-29 00:51:48.087172: done, saving took 1.25 seconds
2022-05-29 00:51:48.105002: This epoch took 98.842813 s

2022-05-29 00:51:48.107326: 
epoch:  21
2022-05-29 00:53:18.879912: train loss : -0.6367
2022-05-29 00:53:24.904935: validation loss: -0.6479
2022-05-29 00:53:24.908636: Average global foreground Dice: [0.7125]
2022-05-29 00:53:24.910721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:53:25.350039: lr: 0.009603
2022-05-29 00:53:25.387372: saving checkpoint...
2022-05-29 00:53:26.331006: done, saving took 0.98 seconds
2022-05-29 00:53:26.344927: This epoch took 98.235360 s

2022-05-29 00:53:26.347248: 
epoch:  22
2022-05-29 00:54:58.094278: train loss : -0.6509
2022-05-29 00:55:04.321054: validation loss: -0.6853
2022-05-29 00:55:04.324379: Average global foreground Dice: [0.7338]
2022-05-29 00:55:04.326581: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:55:04.784482: lr: 0.009585
2022-05-29 00:55:04.818568: saving checkpoint...
2022-05-29 00:55:05.815286: done, saving took 1.03 seconds
2022-05-29 00:55:05.830652: This epoch took 99.481335 s

2022-05-29 00:55:05.833004: 
epoch:  23
2022-05-29 00:56:37.820924: train loss : -0.6410
2022-05-29 00:56:45.964055: validation loss: -0.6544
2022-05-29 00:56:45.984837: Average global foreground Dice: [0.7164]
2022-05-29 00:56:46.002285: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:56:47.012397: lr: 0.009567
2022-05-29 00:56:47.130715: saving checkpoint...
2022-05-29 00:56:48.236491: done, saving took 1.20 seconds
2022-05-29 00:56:48.253128: This epoch took 102.417798 s

2022-05-29 00:56:48.256448: 
epoch:  24
2022-05-29 00:58:18.935805: train loss : -0.6478
2022-05-29 00:58:24.847195: validation loss: -0.6359
2022-05-29 00:58:24.851544: Average global foreground Dice: [0.7048]
2022-05-29 00:58:24.854463: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 00:58:25.294401: lr: 0.009549
2022-05-29 00:58:25.338652: saving checkpoint...
2022-05-29 00:58:26.332980: done, saving took 1.04 seconds
2022-05-29 00:58:26.348839: This epoch took 98.090212 s

2022-05-29 00:58:26.351384: 
epoch:  25
2022-05-29 01:00:00.324375: train loss : -0.6535
2022-05-29 01:00:07.929518: validation loss: -0.6687
2022-05-29 01:00:07.933293: Average global foreground Dice: [0.7398]
2022-05-29 01:00:07.936239: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:00:08.458627: lr: 0.009531
2022-05-29 01:00:08.505577: saving checkpoint...
2022-05-29 01:00:09.585526: done, saving took 1.12 seconds
2022-05-29 01:00:09.600614: This epoch took 103.246991 s

2022-05-29 01:00:09.603653: 
epoch:  26
2022-05-29 01:01:43.296510: train loss : -0.6686
2022-05-29 01:01:51.377767: validation loss: -0.7048
2022-05-29 01:01:51.381290: Average global foreground Dice: [0.7457]
2022-05-29 01:01:51.384124: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:01:51.856546: lr: 0.009513
2022-05-29 01:01:51.911721: saving checkpoint...
2022-05-29 01:01:53.343387: done, saving took 1.48 seconds
2022-05-29 01:01:53.406397: This epoch took 103.800196 s

2022-05-29 01:01:53.429280: 
epoch:  27
2022-05-29 01:03:28.638336: train loss : -0.6562
2022-05-29 01:03:37.072576: validation loss: -0.6786
2022-05-29 01:03:37.097713: Average global foreground Dice: [0.7497]
2022-05-29 01:03:37.117420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:03:37.823157: lr: 0.009495
2022-05-29 01:03:37.896610: saving checkpoint...
2022-05-29 01:03:39.003471: done, saving took 1.16 seconds
2022-05-29 01:03:39.022867: This epoch took 105.575570 s

2022-05-29 01:03:39.025830: 
epoch:  28
2022-05-29 01:05:10.314758: train loss : -0.6676
2022-05-29 01:05:17.985549: validation loss: -0.7034
2022-05-29 01:05:18.008942: Average global foreground Dice: [0.7539]
2022-05-29 01:05:18.040769: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:05:18.587056: lr: 0.009476
2022-05-29 01:05:18.619852: saving checkpoint...
2022-05-29 01:05:19.624137: done, saving took 1.03 seconds
2022-05-29 01:05:19.638168: This epoch took 100.609938 s

2022-05-29 01:05:19.641073: 
epoch:  29
2022-05-29 01:06:52.046197: train loss : -0.6734
2022-05-29 01:07:00.291346: validation loss: -0.6907
2022-05-29 01:07:00.339893: Average global foreground Dice: [0.7413]
2022-05-29 01:07:00.361508: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:07:00.931670: lr: 0.009458
2022-05-29 01:07:00.994445: saving checkpoint...
2022-05-29 01:07:02.042369: done, saving took 1.08 seconds
2022-05-29 01:07:02.109300: This epoch took 102.466040 s

2022-05-29 01:07:02.140320: 
epoch:  30
2022-05-29 01:08:34.249436: train loss : -0.6717
2022-05-29 01:08:40.375191: validation loss: -0.6578
2022-05-29 01:08:40.378290: Average global foreground Dice: [0.7167]
2022-05-29 01:08:40.380537: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:08:40.869770: lr: 0.00944
2022-05-29 01:08:40.906679: saving checkpoint...
2022-05-29 01:08:41.908499: done, saving took 1.04 seconds
2022-05-29 01:08:41.922332: This epoch took 99.766031 s

2022-05-29 01:08:41.924469: 
epoch:  31
2022-05-29 01:10:14.622092: train loss : -0.6746
2022-05-29 01:10:22.945179: validation loss: -0.6779
2022-05-29 01:10:22.960020: Average global foreground Dice: [0.7242]
2022-05-29 01:10:22.966403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:10:23.575376: lr: 0.009422
2022-05-29 01:10:23.634054: saving checkpoint...
2022-05-29 01:10:24.780178: done, saving took 1.20 seconds
2022-05-29 01:10:24.794994: This epoch took 102.868449 s

2022-05-29 01:10:24.798507: 
epoch:  32
2022-05-29 01:11:56.195488: train loss : -0.6982
2022-05-29 01:12:02.926475: validation loss: -0.7045
2022-05-29 01:12:02.930089: Average global foreground Dice: [0.7587]
2022-05-29 01:12:02.932704: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:12:03.379509: lr: 0.009404
2022-05-29 01:12:03.414850: saving checkpoint...
2022-05-29 01:12:04.609582: done, saving took 1.23 seconds
2022-05-29 01:12:04.671305: This epoch took 99.870173 s

2022-05-29 01:12:04.697474: 
epoch:  33
2022-05-29 01:13:35.756920: train loss : -0.6796
2022-05-29 01:13:42.716468: validation loss: -0.6729
2022-05-29 01:13:42.720002: Average global foreground Dice: [0.7417]
2022-05-29 01:13:42.722375: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:13:43.158711: lr: 0.009386
2022-05-29 01:13:43.194664: saving checkpoint...
2022-05-29 01:13:44.247446: done, saving took 1.09 seconds
2022-05-29 01:13:44.261919: This epoch took 99.532613 s

2022-05-29 01:13:44.264486: 
epoch:  34
2022-05-29 01:15:16.158956: train loss : -0.6752
2022-05-29 01:15:23.144394: validation loss: -0.7104
2022-05-29 01:15:23.171826: Average global foreground Dice: [0.7733]
2022-05-29 01:15:23.194298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:15:23.809701: lr: 0.009368
2022-05-29 01:15:23.889471: saving checkpoint...
2022-05-29 01:15:25.033335: done, saving took 1.20 seconds
2022-05-29 01:15:25.072991: This epoch took 100.805673 s

2022-05-29 01:15:25.077614: 
epoch:  35
2022-05-29 01:16:56.473479: train loss : -0.6926
2022-05-29 01:17:04.157633: validation loss: -0.7203
2022-05-29 01:17:04.168323: Average global foreground Dice: [0.7667]
2022-05-29 01:17:04.195287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:17:05.046518: lr: 0.00935
2022-05-29 01:17:05.128312: saving checkpoint...
2022-05-29 01:17:06.361115: done, saving took 1.28 seconds
2022-05-29 01:17:06.386476: This epoch took 101.306591 s

2022-05-29 01:17:06.388822: 
epoch:  36
2022-05-29 01:18:37.568424: train loss : -0.6948
2022-05-29 01:18:43.468373: validation loss: -0.7188
2022-05-29 01:18:43.472469: Average global foreground Dice: [0.7665]
2022-05-29 01:18:43.474881: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:18:43.903194: lr: 0.009331
2022-05-29 01:18:43.955492: saving checkpoint...
2022-05-29 01:18:44.982514: done, saving took 1.08 seconds
2022-05-29 01:18:44.997169: This epoch took 98.606238 s

2022-05-29 01:18:44.999453: 
epoch:  37
2022-05-29 01:20:17.052660: train loss : -0.6760
2022-05-29 01:20:23.988133: validation loss: -0.6643
2022-05-29 01:20:24.059185: Average global foreground Dice: [0.714]
2022-05-29 01:20:24.080288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:20:24.739745: lr: 0.009313
2022-05-29 01:20:24.761360: This epoch took 99.759899 s

2022-05-29 01:20:24.812717: 
epoch:  38
2022-05-29 01:21:58.297730: train loss : -0.6822
2022-05-29 01:22:04.509703: validation loss: -0.7100
2022-05-29 01:22:04.513167: Average global foreground Dice: [0.7672]
2022-05-29 01:22:04.515684: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:22:04.993641: lr: 0.009295
2022-05-29 01:22:05.037546: saving checkpoint...
2022-05-29 01:22:06.053158: done, saving took 1.06 seconds
2022-05-29 01:22:06.067713: This epoch took 101.225680 s

2022-05-29 01:22:06.069765: 
epoch:  39
2022-05-29 01:23:38.542453: train loss : -0.6884
2022-05-29 01:23:47.950846: validation loss: -0.6554
2022-05-29 01:23:47.974817: Average global foreground Dice: [0.7161]
2022-05-29 01:23:47.977329: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:23:48.534206: lr: 0.009277
2022-05-29 01:23:48.537103: This epoch took 102.464792 s

2022-05-29 01:23:48.539461: 
epoch:  40
2022-05-29 01:25:20.244848: train loss : -0.6788
2022-05-29 01:25:29.558006: validation loss: -0.7060
2022-05-29 01:25:29.583085: Average global foreground Dice: [0.7562]
2022-05-29 01:25:29.588230: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:25:30.298520: lr: 0.009259
2022-05-29 01:25:30.375724: saving checkpoint...
2022-05-29 01:25:31.583336: done, saving took 1.25 seconds
2022-05-29 01:25:31.662294: This epoch took 103.120348 s

2022-05-29 01:25:31.695284: 
epoch:  41
2022-05-29 01:27:06.841442: train loss : -0.6798
2022-05-29 01:27:15.080983: validation loss: -0.7114
2022-05-29 01:27:15.108687: Average global foreground Dice: [0.7656]
2022-05-29 01:27:15.135347: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:27:15.672018: lr: 0.009241
2022-05-29 01:27:15.747284: saving checkpoint...
2022-05-29 01:27:16.941896: done, saving took 1.24 seconds
2022-05-29 01:27:16.971322: This epoch took 105.254036 s

2022-05-29 01:27:16.995297: 
epoch:  42
2022-05-29 01:28:47.382823: train loss : -0.6970
2022-05-29 01:28:55.107715: validation loss: -0.6623
2022-05-29 01:28:55.121946: Average global foreground Dice: [0.726]
2022-05-29 01:28:55.139337: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:28:55.761929: lr: 0.009223
2022-05-29 01:28:55.764309: This epoch took 98.738016 s

2022-05-29 01:28:55.766591: 
epoch:  43
2022-05-29 01:30:27.067958: train loss : -0.6959
2022-05-29 01:30:33.432558: validation loss: -0.6754
2022-05-29 01:30:33.436714: Average global foreground Dice: [0.7272]
2022-05-29 01:30:33.439523: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:30:33.897988: lr: 0.009204
2022-05-29 01:30:33.900333: This epoch took 98.131546 s

2022-05-29 01:30:33.902474: 
epoch:  44
2022-05-29 01:32:05.229395: train loss : -0.6846
2022-05-29 01:32:11.230603: validation loss: -0.6867
2022-05-29 01:32:11.262722: Average global foreground Dice: [0.7585]
2022-05-29 01:32:11.278308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:32:11.922935: lr: 0.009186
2022-05-29 01:32:11.982978: saving checkpoint...
2022-05-29 01:32:13.045972: done, saving took 1.12 seconds
2022-05-29 01:32:13.062917: This epoch took 99.158097 s

2022-05-29 01:32:13.065078: 
epoch:  45
2022-05-29 01:33:45.021219: train loss : -0.6938
2022-05-29 01:33:51.254781: validation loss: -0.7067
2022-05-29 01:33:51.258634: Average global foreground Dice: [0.7577]
2022-05-29 01:33:51.261268: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:33:51.691779: lr: 0.009168
2022-05-29 01:33:51.743114: saving checkpoint...
2022-05-29 01:33:52.781189: done, saving took 1.09 seconds
2022-05-29 01:33:52.796494: This epoch took 99.729421 s

2022-05-29 01:33:52.798845: 
epoch:  46
2022-05-29 01:35:24.731812: train loss : -0.7144
2022-05-29 01:35:32.637537: validation loss: -0.7156
2022-05-29 01:35:32.653826: Average global foreground Dice: [0.7697]
2022-05-29 01:35:32.685292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:35:33.350580: lr: 0.00915
2022-05-29 01:35:33.439384: saving checkpoint...
2022-05-29 01:35:34.549185: done, saving took 1.16 seconds
2022-05-29 01:35:34.566158: This epoch took 101.765246 s

2022-05-29 01:35:34.568333: 
epoch:  47
2022-05-29 01:37:05.422829: train loss : -0.7101
2022-05-29 01:37:11.843174: validation loss: -0.7068
2022-05-29 01:37:11.846765: Average global foreground Dice: [0.7571]
2022-05-29 01:37:11.849144: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:37:12.291823: lr: 0.009132
2022-05-29 01:37:12.352729: saving checkpoint...
2022-05-29 01:37:13.506837: done, saving took 1.21 seconds
2022-05-29 01:37:13.523890: This epoch took 98.953590 s

2022-05-29 01:37:13.526322: 
epoch:  48
2022-05-29 01:38:46.125205: train loss : -0.7006
2022-05-29 01:38:55.519050: validation loss: -0.6852
2022-05-29 01:38:55.535707: Average global foreground Dice: [0.7435]
2022-05-29 01:38:55.538249: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:38:56.027286: lr: 0.009114
2022-05-29 01:38:56.061672: saving checkpoint...
2022-05-29 01:38:57.049865: done, saving took 1.02 seconds
2022-05-29 01:38:57.064095: This epoch took 103.535683 s

2022-05-29 01:38:57.066346: 
epoch:  49
2022-05-29 01:40:36.525628: train loss : -0.6970
2022-05-29 01:40:47.580739: validation loss: -0.6797
2022-05-29 01:40:47.584122: Average global foreground Dice: [0.7394]
2022-05-29 01:40:47.586750: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:40:48.163517: lr: 0.009095
2022-05-29 01:40:48.166400: saving scheduled checkpoint file...
2022-05-29 01:40:48.203172: saving checkpoint...
2022-05-29 01:40:49.202786: done, saving took 1.03 seconds
2022-05-29 01:40:49.217959: done
2022-05-29 01:40:49.221646: This epoch took 112.152740 s

2022-05-29 01:40:49.225023: 
epoch:  50
2022-05-29 01:42:19.350775: train loss : -0.7162
2022-05-29 01:42:25.985018: validation loss: -0.7029
2022-05-29 01:42:25.988636: Average global foreground Dice: [0.7586]
2022-05-29 01:42:25.991159: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:42:26.435061: lr: 0.009077
2022-05-29 01:42:26.469434: saving checkpoint...
2022-05-29 01:42:27.476581: done, saving took 1.04 seconds
2022-05-29 01:42:27.491360: This epoch took 98.263928 s

2022-05-29 01:42:27.493756: 
epoch:  51
2022-05-29 01:44:00.407604: train loss : -0.7100
2022-05-29 01:44:08.143665: validation loss: -0.7058
2022-05-29 01:44:08.158008: Average global foreground Dice: [0.7576]
2022-05-29 01:44:08.161625: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:44:08.658852: lr: 0.009059
2022-05-29 01:44:08.737230: saving checkpoint...
2022-05-29 01:44:09.825311: done, saving took 1.16 seconds
2022-05-29 01:44:09.841685: This epoch took 102.345893 s

2022-05-29 01:44:09.844388: 
epoch:  52
2022-05-29 01:45:41.351216: train loss : -0.7017
2022-05-29 01:45:47.108775: validation loss: -0.7083
2022-05-29 01:45:47.112274: Average global foreground Dice: [0.7624]
2022-05-29 01:45:47.114701: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:45:47.565367: lr: 0.009041
2022-05-29 01:45:47.611437: saving checkpoint...
2022-05-29 01:45:48.618935: done, saving took 1.05 seconds
2022-05-29 01:45:48.634247: This epoch took 98.787489 s

2022-05-29 01:45:48.636502: 
epoch:  53
2022-05-29 01:47:22.131278: train loss : -0.6992
2022-05-29 01:47:29.588442: validation loss: -0.6832
2022-05-29 01:47:29.592397: Average global foreground Dice: [0.7374]
2022-05-29 01:47:29.594752: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:47:30.083310: lr: 0.009023
2022-05-29 01:47:30.085926: This epoch took 101.447235 s

2022-05-29 01:47:30.087923: 
epoch:  54
2022-05-29 01:49:01.227851: train loss : -0.6941
2022-05-29 01:49:09.628768: validation loss: -0.6824
2022-05-29 01:49:09.635772: Average global foreground Dice: [0.7453]
2022-05-29 01:49:09.638021: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:49:10.153834: lr: 0.009004
2022-05-29 01:49:10.182438: This epoch took 100.092609 s

2022-05-29 01:49:10.193552: 
epoch:  55
2022-05-29 01:50:42.340563: train loss : -0.7102
2022-05-29 01:50:49.748766: validation loss: -0.6701
2022-05-29 01:50:49.774705: Average global foreground Dice: [0.7298]
2022-05-29 01:50:49.790241: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:50:50.435478: lr: 0.008986
2022-05-29 01:50:50.463312: This epoch took 100.264127 s

2022-05-29 01:50:50.474212: 
epoch:  56
2022-05-29 01:52:22.101697: train loss : -0.6986
2022-05-29 01:52:29.681620: validation loss: -0.6802
2022-05-29 01:52:29.685146: Average global foreground Dice: [0.7455]
2022-05-29 01:52:29.753978: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:52:30.262366: lr: 0.008968
2022-05-29 01:52:30.269970: This epoch took 99.789665 s

2022-05-29 01:52:30.276043: 
epoch:  57
2022-05-29 01:54:02.097305: train loss : -0.7048
2022-05-29 01:54:11.344000: validation loss: -0.7304
2022-05-29 01:54:11.353420: Average global foreground Dice: [0.7758]
2022-05-29 01:54:11.398259: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:54:12.360968: lr: 0.00895
2022-05-29 01:54:12.469910: saving checkpoint...
2022-05-29 01:54:13.791511: done, saving took 1.38 seconds
2022-05-29 01:54:13.872319: This epoch took 103.592435 s

2022-05-29 01:54:13.893277: 
epoch:  58
2022-05-29 01:55:45.907516: train loss : -0.7317
2022-05-29 01:55:54.315084: validation loss: -0.7051
2022-05-29 01:55:54.336781: Average global foreground Dice: [0.7646]
2022-05-29 01:55:54.359341: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:55:55.065133: lr: 0.008931
2022-05-29 01:55:55.142256: saving checkpoint...
2022-05-29 01:55:56.326362: done, saving took 1.25 seconds
2022-05-29 01:55:56.348678: This epoch took 102.443352 s

2022-05-29 01:55:56.350759: 
epoch:  59
2022-05-29 01:57:28.084346: train loss : -0.7032
2022-05-29 01:57:34.950383: validation loss: -0.7039
2022-05-29 01:57:34.977986: Average global foreground Dice: [0.7515]
2022-05-29 01:57:34.996326: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:57:35.485345: lr: 0.008913
2022-05-29 01:57:35.536324: saving checkpoint...
2022-05-29 01:57:36.690978: done, saving took 1.20 seconds
2022-05-29 01:57:36.706665: This epoch took 100.353788 s

2022-05-29 01:57:36.708844: 
epoch:  60
2022-05-29 01:59:08.471281: train loss : -0.7158
2022-05-29 01:59:15.838807: validation loss: -0.6982
2022-05-29 01:59:15.843080: Average global foreground Dice: [0.7483]
2022-05-29 01:59:15.847409: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 01:59:16.274504: lr: 0.008895
2022-05-29 01:59:16.276968: This epoch took 99.566077 s

2022-05-29 01:59:16.279028: 
epoch:  61
2022-05-29 02:00:46.682331: train loss : -0.7130
2022-05-29 02:00:53.269147: validation loss: -0.7001
2022-05-29 02:00:53.272765: Average global foreground Dice: [0.749]
2022-05-29 02:00:53.274984: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:00:53.708488: lr: 0.008877
2022-05-29 02:00:53.711215: This epoch took 97.430106 s

2022-05-29 02:00:53.713756: 
epoch:  62
2022-05-29 02:02:26.861280: train loss : -0.7073
2022-05-29 02:02:34.795927: validation loss: -0.7070
2022-05-29 02:02:34.799544: Average global foreground Dice: [0.7427]
2022-05-29 02:02:34.801952: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:02:35.275556: lr: 0.008859
2022-05-29 02:02:35.278929: This epoch took 101.563136 s

2022-05-29 02:02:35.281533: 
epoch:  63
2022-05-29 02:04:06.559949: train loss : -0.7061
2022-05-29 02:04:13.742792: validation loss: -0.7305
2022-05-29 02:04:13.746230: Average global foreground Dice: [0.7844]
2022-05-29 02:04:13.750038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:04:14.236619: lr: 0.00884
2022-05-29 02:04:14.271947: saving checkpoint...
2022-05-29 02:04:15.239397: done, saving took 1.00 seconds
2022-05-29 02:04:15.253455: This epoch took 99.969307 s

2022-05-29 02:04:15.255842: 
epoch:  64
2022-05-29 02:05:46.830519: train loss : -0.7280
2022-05-29 02:05:55.478880: validation loss: -0.6903
2022-05-29 02:05:55.482500: Average global foreground Dice: [0.7449]
2022-05-29 02:05:55.484575: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:05:55.943709: lr: 0.008822
2022-05-29 02:05:55.946072: This epoch took 100.687992 s

2022-05-29 02:05:55.948107: 
epoch:  65
2022-05-29 02:07:32.808923: train loss : -0.6983
2022-05-29 02:07:42.711581: validation loss: -0.7051
2022-05-29 02:07:42.743747: Average global foreground Dice: [0.7542]
2022-05-29 02:07:42.753346: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:07:43.529812: lr: 0.008804
2022-05-29 02:07:43.547260: This epoch took 107.596983 s

2022-05-29 02:07:43.572287: 
epoch:  66
2022-05-29 02:09:15.130349: train loss : -0.6994
2022-05-29 02:09:21.832421: validation loss: -0.6841
2022-05-29 02:09:21.848126: Average global foreground Dice: [0.7506]
2022-05-29 02:09:21.861195: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:09:22.336604: lr: 0.008785
2022-05-29 02:09:22.339767: This epoch took 98.746901 s

2022-05-29 02:09:22.343295: 
epoch:  67
2022-05-29 02:10:54.212193: train loss : -0.7098
2022-05-29 02:11:00.462629: validation loss: -0.7012
2022-05-29 02:11:00.466205: Average global foreground Dice: [0.7645]
2022-05-29 02:11:00.469072: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:11:00.920841: lr: 0.008767
2022-05-29 02:11:00.976895: saving checkpoint...
2022-05-29 02:11:01.974786: done, saving took 1.05 seconds
2022-05-29 02:11:01.990654: This epoch took 99.630444 s

2022-05-29 02:11:01.993044: 
epoch:  68
2022-05-29 02:12:33.810906: train loss : -0.7203
2022-05-29 02:12:42.447226: validation loss: -0.7026
2022-05-29 02:12:42.450801: Average global foreground Dice: [0.7732]
2022-05-29 02:12:42.452997: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:12:42.922165: lr: 0.008749
2022-05-29 02:12:42.972146: saving checkpoint...
2022-05-29 02:12:43.995731: done, saving took 1.07 seconds
2022-05-29 02:12:44.028029: This epoch took 102.032692 s

2022-05-29 02:12:44.030249: 
epoch:  69
2022-05-29 02:14:15.476377: train loss : -0.7149
2022-05-29 02:14:23.176081: validation loss: -0.7018
2022-05-29 02:14:23.179191: Average global foreground Dice: [0.7569]
2022-05-29 02:14:23.181664: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:14:23.618658: lr: 0.008731
2022-05-29 02:14:23.660692: saving checkpoint...
2022-05-29 02:14:24.659755: done, saving took 1.04 seconds
2022-05-29 02:14:24.675451: This epoch took 100.643106 s

2022-05-29 02:14:24.677969: 
epoch:  70
2022-05-29 02:15:55.406611: train loss : -0.7345
2022-05-29 02:16:01.481782: validation loss: -0.6884
2022-05-29 02:16:01.489774: Average global foreground Dice: [0.7473]
2022-05-29 02:16:01.492225: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:16:01.941462: lr: 0.008712
2022-05-29 02:16:01.944167: This epoch took 97.263946 s

2022-05-29 02:16:01.948790: 
epoch:  71
2022-05-29 02:17:33.559271: train loss : -0.7114
2022-05-29 02:17:40.417175: validation loss: -0.7164
2022-05-29 02:17:40.420687: Average global foreground Dice: [0.7719]
2022-05-29 02:17:40.423208: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:17:40.996535: lr: 0.008694
2022-05-29 02:17:41.063149: saving checkpoint...
2022-05-29 02:17:42.105890: done, saving took 1.09 seconds
2022-05-29 02:17:42.121328: This epoch took 100.170261 s

2022-05-29 02:17:42.124200: 
epoch:  72
2022-05-29 02:19:13.643375: train loss : -0.7211
2022-05-29 02:19:20.345959: validation loss: -0.7352
2022-05-29 02:19:20.360034: Average global foreground Dice: [0.7856]
2022-05-29 02:19:20.362278: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:19:20.802519: lr: 0.008676
2022-05-29 02:19:20.836518: saving checkpoint...
2022-05-29 02:19:21.837656: done, saving took 1.03 seconds
2022-05-29 02:19:21.851509: This epoch took 99.724756 s

2022-05-29 02:19:21.853657: 
epoch:  73
2022-05-29 02:20:53.682838: train loss : -0.7084
2022-05-29 02:21:01.700499: validation loss: -0.7113
2022-05-29 02:21:01.740838: Average global foreground Dice: [0.7646]
2022-05-29 02:21:01.776307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:21:02.393677: lr: 0.008658
2022-05-29 02:21:02.461746: saving checkpoint...
2022-05-29 02:21:03.642924: done, saving took 1.23 seconds
2022-05-29 02:21:03.659776: This epoch took 101.803966 s

2022-05-29 02:21:03.661963: 
epoch:  74
2022-05-29 02:22:38.067922: train loss : -0.7022
2022-05-29 02:22:45.788820: validation loss: -0.7293
2022-05-29 02:22:45.800756: Average global foreground Dice: [0.7849]
2022-05-29 02:22:45.803597: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:22:46.291933: lr: 0.008639
2022-05-29 02:22:46.340729: saving checkpoint...
2022-05-29 02:22:47.402030: done, saving took 1.11 seconds
2022-05-29 02:22:47.417338: This epoch took 103.753328 s

2022-05-29 02:22:47.419989: 
epoch:  75
2022-05-29 02:24:19.233697: train loss : -0.7335
2022-05-29 02:24:26.641353: validation loss: -0.7389
2022-05-29 02:24:26.645003: Average global foreground Dice: [0.7823]
2022-05-29 02:24:26.647843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:24:27.140598: lr: 0.008621
2022-05-29 02:24:27.214169: saving checkpoint...
2022-05-29 02:24:28.204451: done, saving took 1.04 seconds
2022-05-29 02:24:28.218814: This epoch took 100.796672 s

2022-05-29 02:24:28.222254: 
epoch:  76
2022-05-29 02:26:00.104440: train loss : -0.7281
2022-05-29 02:26:08.483345: validation loss: -0.7420
2022-05-29 02:26:08.495119: Average global foreground Dice: [0.7831]
2022-05-29 02:26:08.523498: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:26:09.067681: lr: 0.008603
2022-05-29 02:26:09.127881: saving checkpoint...
2022-05-29 02:26:10.410322: done, saving took 1.33 seconds
2022-05-29 02:26:10.423486: This epoch took 102.197929 s

2022-05-29 02:26:10.425708: 
epoch:  77
2022-05-29 02:27:41.606703: train loss : -0.7285
2022-05-29 02:27:48.644031: validation loss: -0.7164
2022-05-29 02:27:48.647336: Average global foreground Dice: [0.7636]
2022-05-29 02:27:48.649500: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:27:49.113436: lr: 0.008584
2022-05-29 02:27:49.115731: This epoch took 98.687984 s

2022-05-29 02:27:49.117798: 
epoch:  78
2022-05-29 02:29:20.534771: train loss : -0.7326
2022-05-29 02:29:26.532412: validation loss: -0.7226
2022-05-29 02:29:26.538625: Average global foreground Dice: [0.7868]
2022-05-29 02:29:26.549915: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:29:27.147975: lr: 0.008566
2022-05-29 02:29:27.201952: saving checkpoint...
2022-05-29 02:29:28.438139: done, saving took 1.27 seconds
2022-05-29 02:29:28.451594: This epoch took 99.331631 s

2022-05-29 02:29:28.453819: 
epoch:  79
2022-05-29 02:30:59.584146: train loss : -0.7355
2022-05-29 02:31:06.149314: validation loss: -0.7136
2022-05-29 02:31:06.159728: Average global foreground Dice: [0.7585]
2022-05-29 02:31:06.162048: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:31:06.669830: lr: 0.008548
2022-05-29 02:31:06.672622: This epoch took 98.216594 s

2022-05-29 02:31:06.675475: 
epoch:  80
2022-05-29 02:32:37.429523: train loss : -0.7234
2022-05-29 02:32:43.604926: validation loss: -0.7038
2022-05-29 02:32:43.609310: Average global foreground Dice: [0.77]
2022-05-29 02:32:43.611658: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:32:44.054646: lr: 0.008529
2022-05-29 02:32:44.057065: This epoch took 97.379474 s

2022-05-29 02:32:44.059094: 
epoch:  81
2022-05-29 02:34:20.755773: train loss : -0.7327
2022-05-29 02:34:28.920799: validation loss: -0.7219
2022-05-29 02:34:28.942762: Average global foreground Dice: [0.7797]
2022-05-29 02:34:28.964420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:34:29.559327: lr: 0.008511
2022-05-29 02:34:29.649766: saving checkpoint...
2022-05-29 02:34:30.784258: done, saving took 1.19 seconds
2022-05-29 02:34:30.800446: This epoch took 106.738694 s

2022-05-29 02:34:30.802715: 
epoch:  82
2022-05-29 02:36:03.665907: train loss : -0.7224
2022-05-29 02:36:12.760195: validation loss: -0.7104
2022-05-29 02:36:12.777768: Average global foreground Dice: [0.7777]
2022-05-29 02:36:12.780275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:36:13.244812: lr: 0.008493
2022-05-29 02:36:13.296930: saving checkpoint...
2022-05-29 02:36:14.364335: done, saving took 1.12 seconds
2022-05-29 02:36:14.380661: This epoch took 103.575871 s

2022-05-29 02:36:14.382975: 
epoch:  83
2022-05-29 02:37:44.614519: train loss : -0.7381
2022-05-29 02:37:51.918311: validation loss: -0.7147
2022-05-29 02:37:51.921418: Average global foreground Dice: [0.7627]
2022-05-29 02:37:51.923970: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:37:52.385059: lr: 0.008474
2022-05-29 02:37:52.387514: This epoch took 98.002041 s

2022-05-29 02:37:52.389618: 
epoch:  84
2022-05-29 02:39:28.201292: train loss : -0.7382
2022-05-29 02:39:35.787144: validation loss: -0.7243
2022-05-29 02:39:35.803324: Average global foreground Dice: [0.7763]
2022-05-29 02:39:35.823323: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:39:36.453270: lr: 0.008456
2022-05-29 02:39:36.560743: saving checkpoint...
2022-05-29 02:39:37.583031: done, saving took 1.11 seconds
2022-05-29 02:39:37.600600: This epoch took 105.208906 s

2022-05-29 02:39:37.602718: 
epoch:  85
2022-05-29 02:41:09.164724: train loss : -0.7282
2022-05-29 02:41:16.849811: validation loss: -0.7289
2022-05-29 02:41:16.853096: Average global foreground Dice: [0.7772]
2022-05-29 02:41:16.855367: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:41:17.296528: lr: 0.008438
2022-05-29 02:41:17.363273: saving checkpoint...
2022-05-29 02:41:18.465513: done, saving took 1.15 seconds
2022-05-29 02:41:18.480452: This epoch took 100.875031 s

2022-05-29 02:41:18.482878: 
epoch:  86
2022-05-29 02:42:53.062986: train loss : -0.7295
2022-05-29 02:43:02.524098: validation loss: -0.7316
2022-05-29 02:43:02.556722: Average global foreground Dice: [0.7786]
2022-05-29 02:43:02.589312: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:43:03.164926: lr: 0.008419
2022-05-29 02:43:03.218939: saving checkpoint...
2022-05-29 02:43:04.453441: done, saving took 1.27 seconds
2022-05-29 02:43:04.502401: This epoch took 106.017391 s

2022-05-29 02:43:04.525353: 
epoch:  87
2022-05-29 02:44:38.684772: train loss : -0.7260
2022-05-29 02:44:46.220191: validation loss: -0.7189
2022-05-29 02:44:46.227111: Average global foreground Dice: [0.7603]
2022-05-29 02:44:46.229753: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:44:46.673292: lr: 0.008401
2022-05-29 02:44:46.675774: This epoch took 102.119451 s

2022-05-29 02:44:46.677890: 
epoch:  88
2022-05-29 02:46:20.236235: train loss : -0.7355
2022-05-29 02:46:29.250337: validation loss: -0.7304
2022-05-29 02:46:29.281758: Average global foreground Dice: [0.7889]
2022-05-29 02:46:29.303070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:46:29.887858: lr: 0.008383
2022-05-29 02:46:29.950275: saving checkpoint...
2022-05-29 02:46:31.287096: done, saving took 1.38 seconds
2022-05-29 02:46:31.306018: This epoch took 104.625813 s

2022-05-29 02:46:31.308735: 
epoch:  89
2022-05-29 02:48:02.302288: train loss : -0.7243
2022-05-29 02:48:10.691974: validation loss: -0.7114
2022-05-29 02:48:10.723738: Average global foreground Dice: [0.7572]
2022-05-29 02:48:10.759340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:48:11.249211: lr: 0.008364
2022-05-29 02:48:11.288631: This epoch took 99.977491 s

2022-05-29 02:48:11.311293: 
epoch:  90
2022-05-29 02:49:46.323606: train loss : -0.7361
2022-05-29 02:49:53.987175: validation loss: -0.7198
2022-05-29 02:49:54.015555: Average global foreground Dice: [0.7873]
2022-05-29 02:49:54.035307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:49:54.593945: lr: 0.008346
2022-05-29 02:49:54.642901: saving checkpoint...
2022-05-29 02:49:55.673717: done, saving took 1.08 seconds
2022-05-29 02:49:55.690091: This epoch took 104.351715 s

2022-05-29 02:49:55.692467: 
epoch:  91
2022-05-29 02:51:29.365395: train loss : -0.7474
2022-05-29 02:51:36.631745: validation loss: -0.7404
2022-05-29 02:51:36.661803: Average global foreground Dice: [0.7866]
2022-05-29 02:51:36.678373: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:51:37.219811: lr: 0.008328
2022-05-29 02:51:37.274859: saving checkpoint...
2022-05-29 02:51:38.339919: done, saving took 1.11 seconds
2022-05-29 02:51:38.355580: This epoch took 102.660889 s

2022-05-29 02:51:38.358216: 
epoch:  92
2022-05-29 02:53:15.148715: train loss : -0.7399
2022-05-29 02:53:24.035093: validation loss: -0.7076
2022-05-29 02:53:24.040220: Average global foreground Dice: [0.7551]
2022-05-29 02:53:24.042385: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:53:24.531472: lr: 0.008309
2022-05-29 02:53:24.544237: This epoch took 106.183700 s

2022-05-29 02:53:24.547225: 
epoch:  93
2022-05-29 02:54:56.259999: train loss : -0.7378
2022-05-29 02:55:04.561868: validation loss: -0.7205
2022-05-29 02:55:04.568040: Average global foreground Dice: [0.7726]
2022-05-29 02:55:04.570484: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:55:05.150138: lr: 0.008291
2022-05-29 02:55:05.218611: This epoch took 100.667185 s

2022-05-29 02:55:05.223996: 
epoch:  94
2022-05-29 02:56:41.845737: train loss : -0.7455
2022-05-29 02:56:52.002598: validation loss: -0.7232
2022-05-29 02:56:52.006141: Average global foreground Dice: [0.7648]
2022-05-29 02:56:52.010330: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:56:52.643878: lr: 0.008272
2022-05-29 02:56:52.676323: This epoch took 107.448997 s

2022-05-29 02:56:52.713412: 
epoch:  95
2022-05-29 02:58:27.618610: train loss : -0.7383
2022-05-29 02:58:35.779948: validation loss: -0.7443
2022-05-29 02:58:35.793778: Average global foreground Dice: [0.788]
2022-05-29 02:58:35.795770: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 02:58:36.262835: lr: 0.008254
2022-05-29 02:58:36.265110: This epoch took 103.519629 s

2022-05-29 02:58:36.267313: 
epoch:  96
2022-05-29 03:00:10.693809: train loss : -0.7466
2022-05-29 03:00:17.985522: validation loss: -0.7415
2022-05-29 03:00:17.988836: Average global foreground Dice: [0.7796]
2022-05-29 03:00:17.990991: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:00:18.592576: lr: 0.008236
2022-05-29 03:00:18.614028: This epoch took 102.341467 s

2022-05-29 03:00:18.653428: 
epoch:  97
2022-05-29 03:01:52.443810: train loss : -0.7432
2022-05-29 03:02:01.294158: validation loss: -0.7381
2022-05-29 03:02:01.316281: Average global foreground Dice: [0.7955]
2022-05-29 03:02:01.334144: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:02:01.841010: lr: 0.008217
2022-05-29 03:02:01.982016: saving checkpoint...
2022-05-29 03:02:03.169335: done, saving took 1.30 seconds
2022-05-29 03:02:03.232071: This epoch took 104.559680 s

2022-05-29 03:02:03.237283: 
epoch:  98
2022-05-29 03:03:34.746823: train loss : -0.7514
2022-05-29 03:03:41.335014: validation loss: -0.7338
2022-05-29 03:03:41.342273: Average global foreground Dice: [0.783]
2022-05-29 03:03:41.346800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:03:41.795848: lr: 0.008199
2022-05-29 03:03:41.847650: saving checkpoint...
2022-05-29 03:03:42.876868: done, saving took 1.08 seconds
2022-05-29 03:03:42.893300: This epoch took 99.653437 s

2022-05-29 03:03:42.896640: 
epoch:  99
2022-05-29 03:05:15.336531: train loss : -0.7552
2022-05-29 03:05:23.723839: validation loss: -0.7435
2022-05-29 03:05:23.727307: Average global foreground Dice: [0.7863]
2022-05-29 03:05:23.729506: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:05:24.170882: lr: 0.008181
2022-05-29 03:05:24.173867: saving scheduled checkpoint file...
2022-05-29 03:05:24.224493: saving checkpoint...
2022-05-29 03:05:25.261889: done, saving took 1.09 seconds
2022-05-29 03:05:25.282687: done
2022-05-29 03:05:25.327787: saving checkpoint...
2022-05-29 03:05:26.315802: done, saving took 1.03 seconds
2022-05-29 03:05:26.330829: This epoch took 103.431900 s

2022-05-29 03:05:26.333252: 
epoch:  100
2022-05-29 03:06:56.538207: train loss : -0.7439
2022-05-29 03:07:03.966107: validation loss: -0.6891
2022-05-29 03:07:03.970102: Average global foreground Dice: [0.7629]
2022-05-29 03:07:03.975393: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:07:04.576826: lr: 0.008162
2022-05-29 03:07:04.581163: This epoch took 98.245577 s

2022-05-29 03:07:04.584176: 
epoch:  101
2022-05-29 03:08:36.416155: train loss : -0.7471
2022-05-29 03:08:44.370637: validation loss: -0.7316
2022-05-29 03:08:44.391978: Average global foreground Dice: [0.771]
2022-05-29 03:08:44.394431: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:08:45.004138: lr: 0.008144
2022-05-29 03:08:45.011797: This epoch took 100.424933 s

2022-05-29 03:08:45.026625: 
epoch:  102
2022-05-29 03:10:17.440213: train loss : -0.7449
2022-05-29 03:10:25.697850: validation loss: -0.6788
2022-05-29 03:10:25.701907: Average global foreground Dice: [0.731]
2022-05-29 03:10:25.704252: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:10:26.157984: lr: 0.008125
2022-05-29 03:10:26.160228: This epoch took 101.125650 s

2022-05-29 03:10:26.162495: 
epoch:  103
2022-05-29 03:11:57.909169: train loss : -0.7465
2022-05-29 03:12:07.209082: validation loss: -0.7384
2022-05-29 03:12:07.218167: Average global foreground Dice: [0.7944]
2022-05-29 03:12:07.243100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:12:07.828003: lr: 0.008107
2022-05-29 03:12:07.830802: This epoch took 101.666091 s

2022-05-29 03:12:07.833463: 
epoch:  104
2022-05-29 03:13:40.454936: train loss : -0.7481
2022-05-29 03:13:49.578017: validation loss: -0.7294
2022-05-29 03:13:49.584268: Average global foreground Dice: [0.7942]
2022-05-29 03:13:49.618332: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:13:50.110343: lr: 0.008088
2022-05-29 03:13:50.138499: This epoch took 102.302881 s

2022-05-29 03:13:50.149267: 
epoch:  105
2022-05-29 03:15:22.546343: train loss : -0.7642
2022-05-29 03:15:29.425303: validation loss: -0.7571
2022-05-29 03:15:29.434642: Average global foreground Dice: [0.7874]
2022-05-29 03:15:29.437444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:15:29.881355: lr: 0.00807
2022-05-29 03:15:29.883828: This epoch took 99.726755 s

2022-05-29 03:15:29.885831: 
epoch:  106
2022-05-29 03:17:02.945638: train loss : -0.7544
2022-05-29 03:17:12.895398: validation loss: -0.7216
2022-05-29 03:17:12.914607: Average global foreground Dice: [0.7598]
2022-05-29 03:17:12.939298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:17:13.566910: lr: 0.008052
2022-05-29 03:17:13.569253: This epoch took 103.679901 s

2022-05-29 03:17:13.587018: 
epoch:  107
2022-05-29 03:18:47.906601: train loss : -0.7440
2022-05-29 03:18:56.129947: validation loss: -0.7539
2022-05-29 03:18:56.167010: Average global foreground Dice: [0.7907]
2022-05-29 03:18:56.185398: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:18:56.712227: lr: 0.008033
2022-05-29 03:18:56.714719: This epoch took 103.125447 s

2022-05-29 03:18:56.718910: 
epoch:  108
2022-05-29 03:20:27.643190: train loss : -0.7394
2022-05-29 03:20:33.887514: validation loss: -0.7185
2022-05-29 03:20:33.891334: Average global foreground Dice: [0.7743]
2022-05-29 03:20:33.895650: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:20:34.369373: lr: 0.008015
2022-05-29 03:20:34.372013: This epoch took 97.626744 s

2022-05-29 03:20:34.374112: 
epoch:  109
2022-05-29 03:22:06.622580: train loss : -0.7570
2022-05-29 03:22:14.141812: validation loss: -0.7211
2022-05-29 03:22:14.158004: Average global foreground Dice: [0.7694]
2022-05-29 03:22:14.160959: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:22:14.671724: lr: 0.007996
2022-05-29 03:22:14.673946: This epoch took 100.297641 s

2022-05-29 03:22:14.676097: 
epoch:  110
2022-05-29 03:23:46.924369: train loss : -0.7645
2022-05-29 03:23:56.237656: validation loss: -0.7287
2022-05-29 03:23:56.241073: Average global foreground Dice: [0.7873]
2022-05-29 03:23:56.243873: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:23:56.822811: lr: 0.007978
2022-05-29 03:23:56.844076: This epoch took 102.166019 s

2022-05-29 03:23:56.846282: 
epoch:  111
2022-05-29 03:25:28.270269: train loss : -0.7484
2022-05-29 03:25:35.339692: validation loss: -0.7304
2022-05-29 03:25:35.343122: Average global foreground Dice: [0.7738]
2022-05-29 03:25:35.345882: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:25:35.808506: lr: 0.007959
2022-05-29 03:25:35.810866: This epoch took 98.952393 s

2022-05-29 03:25:35.812952: 
epoch:  112
2022-05-29 03:27:07.093715: train loss : -0.7520
2022-05-29 03:27:13.016634: validation loss: -0.7229
2022-05-29 03:27:13.020129: Average global foreground Dice: [0.7747]
2022-05-29 03:27:13.022697: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:27:13.459024: lr: 0.007941
2022-05-29 03:27:13.461384: This epoch took 97.646057 s

2022-05-29 03:27:13.465004: 
epoch:  113
2022-05-29 03:28:44.349005: train loss : -0.7666
2022-05-29 03:28:50.884860: validation loss: -0.7212
2022-05-29 03:28:50.888538: Average global foreground Dice: [0.7674]
2022-05-29 03:28:50.891105: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:28:51.349385: lr: 0.007922
2022-05-29 03:28:51.353133: This epoch took 97.885869 s

2022-05-29 03:28:51.355173: 
epoch:  114
2022-05-29 03:30:24.482919: train loss : -0.7598
2022-05-29 03:30:32.447217: validation loss: -0.7497
2022-05-29 03:30:32.452865: Average global foreground Dice: [0.793]
2022-05-29 03:30:32.455532: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:30:32.901169: lr: 0.007904
2022-05-29 03:30:32.903619: This epoch took 101.546149 s

2022-05-29 03:30:32.906022: 
epoch:  115
2022-05-29 03:32:07.613200: train loss : -0.7611
2022-05-29 03:32:16.237758: validation loss: -0.7185
2022-05-29 03:32:16.242425: Average global foreground Dice: [0.7732]
2022-05-29 03:32:16.244682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:32:16.739883: lr: 0.007885
2022-05-29 03:32:16.743029: This epoch took 103.834149 s

2022-05-29 03:32:16.745284: 
epoch:  116
2022-05-29 03:33:55.215911: train loss : -0.7621
2022-05-29 03:34:03.263142: validation loss: -0.7399
2022-05-29 03:34:03.310696: Average global foreground Dice: [0.7861]
2022-05-29 03:34:03.333305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:34:03.993559: lr: 0.007867
2022-05-29 03:34:04.129729: saving checkpoint...
2022-05-29 03:34:05.316367: done, saving took 1.30 seconds
2022-05-29 03:34:05.370296: This epoch took 108.622907 s

2022-05-29 03:34:05.389458: 
epoch:  117
2022-05-29 03:35:37.045013: train loss : -0.7688
2022-05-29 03:35:45.904845: validation loss: -0.7422
2022-05-29 03:35:45.911342: Average global foreground Dice: [0.7811]
2022-05-29 03:35:45.914389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:35:46.503218: lr: 0.007848
2022-05-29 03:35:46.543093: saving checkpoint...
2022-05-29 03:35:47.574084: done, saving took 1.07 seconds
2022-05-29 03:35:47.587478: This epoch took 102.186190 s

2022-05-29 03:35:47.589989: 
epoch:  118
2022-05-29 03:37:22.168555: train loss : -0.7609
2022-05-29 03:37:30.456512: validation loss: -0.7218
2022-05-29 03:37:30.477257: Average global foreground Dice: [0.7659]
2022-05-29 03:37:30.481574: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:37:31.110650: lr: 0.00783
2022-05-29 03:37:31.156348: This epoch took 103.564284 s

2022-05-29 03:37:31.179325: 
epoch:  119
2022-05-29 03:39:03.738840: train loss : -0.7428
2022-05-29 03:39:11.286192: validation loss: -0.7404
2022-05-29 03:39:11.302509: Average global foreground Dice: [0.792]
2022-05-29 03:39:11.312435: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:39:12.036463: lr: 0.007811
2022-05-29 03:39:12.100262: saving checkpoint...
2022-05-29 03:39:13.276987: done, saving took 1.23 seconds
2022-05-29 03:39:13.295075: This epoch took 102.100657 s

2022-05-29 03:39:13.297305: 
epoch:  120
2022-05-29 03:40:47.847845: train loss : -0.7656
2022-05-29 03:40:55.793288: validation loss: -0.7500
2022-05-29 03:40:55.803616: Average global foreground Dice: [0.8059]
2022-05-29 03:40:55.806161: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:40:56.328690: lr: 0.007793
2022-05-29 03:40:56.383461: saving checkpoint...
2022-05-29 03:40:57.447742: done, saving took 1.12 seconds
2022-05-29 03:40:57.463697: This epoch took 104.163783 s

2022-05-29 03:40:57.465979: 
epoch:  121
2022-05-29 03:42:29.309918: train loss : -0.7660
2022-05-29 03:42:37.786413: validation loss: -0.7358
2022-05-29 03:42:37.789880: Average global foreground Dice: [0.775]
2022-05-29 03:42:37.791924: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:42:38.292680: lr: 0.007774
2022-05-29 03:42:38.295345: This epoch took 100.827235 s

2022-05-29 03:42:38.297969: 
epoch:  122
2022-05-29 03:44:10.715651: train loss : -0.7612
2022-05-29 03:44:18.683933: validation loss: -0.7226
2022-05-29 03:44:18.690494: Average global foreground Dice: [0.7741]
2022-05-29 03:44:18.716972: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:44:19.369858: lr: 0.007756
2022-05-29 03:44:19.390382: This epoch took 101.089945 s

2022-05-29 03:44:19.401205: 
epoch:  123
2022-05-29 03:45:53.313821: train loss : -0.7621
2022-05-29 03:46:00.358576: validation loss: -0.7155
2022-05-29 03:46:00.364567: Average global foreground Dice: [0.7804]
2022-05-29 03:46:00.367910: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:46:00.836411: lr: 0.007737
2022-05-29 03:46:00.838939: This epoch took 101.426647 s

2022-05-29 03:46:00.841138: 
epoch:  124
2022-05-29 03:47:32.281441: train loss : -0.7502
2022-05-29 03:47:41.226848: validation loss: -0.7146
2022-05-29 03:47:41.230031: Average global foreground Dice: [0.7653]
2022-05-29 03:47:41.233494: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:47:41.738000: lr: 0.007719
2022-05-29 03:47:41.740951: This epoch took 100.897615 s

2022-05-29 03:47:41.743268: 
epoch:  125
2022-05-29 03:49:12.946583: train loss : -0.7403
2022-05-29 03:49:22.122922: validation loss: -0.7399
2022-05-29 03:49:22.126795: Average global foreground Dice: [0.7785]
2022-05-29 03:49:22.129544: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:49:22.587619: lr: 0.0077
2022-05-29 03:49:22.589869: This epoch took 100.840878 s

2022-05-29 03:49:22.591901: 
epoch:  126
2022-05-29 03:50:54.333390: train loss : -0.7436
2022-05-29 03:51:01.772589: validation loss: -0.7349
2022-05-29 03:51:01.776838: Average global foreground Dice: [0.7818]
2022-05-29 03:51:01.779351: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:51:02.223653: lr: 0.007682
2022-05-29 03:51:02.231264: This epoch took 99.637277 s

2022-05-29 03:51:02.235373: 
epoch:  127
2022-05-29 03:52:40.979812: train loss : -0.7526
2022-05-29 03:52:48.830059: validation loss: -0.7400
2022-05-29 03:52:48.833750: Average global foreground Dice: [0.7888]
2022-05-29 03:52:48.843980: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:52:49.303279: lr: 0.007663
2022-05-29 03:52:49.307101: This epoch took 107.066111 s

2022-05-29 03:52:49.320322: 
epoch:  128
2022-05-29 03:54:21.082531: train loss : -0.7581
2022-05-29 03:54:29.257267: validation loss: -0.7148
2022-05-29 03:54:29.265930: Average global foreground Dice: [0.7766]
2022-05-29 03:54:29.268046: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:54:29.739754: lr: 0.007645
2022-05-29 03:54:29.744029: This epoch took 100.406718 s

2022-05-29 03:54:29.759195: 
epoch:  129
2022-05-29 03:56:00.976073: train loss : -0.7367
2022-05-29 03:56:10.136698: validation loss: -0.7275
2022-05-29 03:56:10.140040: Average global foreground Dice: [0.7618]
2022-05-29 03:56:10.142283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:56:10.592669: lr: 0.007626
2022-05-29 03:56:10.595253: This epoch took 100.813852 s

2022-05-29 03:56:10.597806: 
epoch:  130
2022-05-29 03:57:41.003988: train loss : -0.7394
2022-05-29 03:57:47.881807: validation loss: -0.7048
2022-05-29 03:57:47.885620: Average global foreground Dice: [0.772]
2022-05-29 03:57:47.889371: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:57:48.349959: lr: 0.007608
2022-05-29 03:57:48.352196: This epoch took 97.750570 s

2022-05-29 03:57:48.354290: 
epoch:  131
2022-05-29 03:59:22.398617: train loss : -0.7541
2022-05-29 03:59:30.546707: validation loss: -0.7448
2022-05-29 03:59:30.576882: Average global foreground Dice: [0.788]
2022-05-29 03:59:30.596308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 03:59:31.370858: lr: 0.007589
2022-05-29 03:59:31.374121: This epoch took 103.017674 s

2022-05-29 03:59:31.376894: 
epoch:  132
2022-05-29 04:01:02.860116: train loss : -0.7584
2022-05-29 04:01:10.761091: validation loss: -0.7308
2022-05-29 04:01:10.781701: Average global foreground Dice: [0.7791]
2022-05-29 04:01:10.801284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:01:11.370134: lr: 0.007571
2022-05-29 04:01:11.372610: This epoch took 99.992898 s

2022-05-29 04:01:11.374839: 
epoch:  133
2022-05-29 04:02:43.217211: train loss : -0.7560
2022-05-29 04:02:52.211463: validation loss: -0.7251
2022-05-29 04:02:52.215080: Average global foreground Dice: [0.7901]
2022-05-29 04:02:52.217535: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:02:52.669840: lr: 0.007552
2022-05-29 04:02:52.672559: This epoch took 101.295550 s

2022-05-29 04:02:52.674880: 
epoch:  134
2022-05-29 04:04:25.611058: train loss : -0.7468
2022-05-29 04:04:32.777534: validation loss: -0.7188
2022-05-29 04:04:32.780954: Average global foreground Dice: [0.7742]
2022-05-29 04:04:32.789236: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:04:33.269265: lr: 0.007533
2022-05-29 04:04:33.271902: This epoch took 100.594617 s

2022-05-29 04:04:33.274179: 
epoch:  135
2022-05-29 04:06:03.922688: train loss : -0.7583
2022-05-29 04:06:09.783805: validation loss: -0.7308
2022-05-29 04:06:09.788783: Average global foreground Dice: [0.7733]
2022-05-29 04:06:09.790916: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:06:10.280222: lr: 0.007515
2022-05-29 04:06:10.282672: This epoch took 97.006048 s

2022-05-29 04:06:10.284961: 
epoch:  136
2022-05-29 04:07:41.809897: train loss : -0.7496
2022-05-29 04:07:48.070223: validation loss: -0.7197
2022-05-29 04:07:48.073995: Average global foreground Dice: [0.7783]
2022-05-29 04:07:48.076386: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:07:48.524663: lr: 0.007496
2022-05-29 04:07:48.527037: This epoch took 98.240051 s

2022-05-29 04:07:48.529273: 
epoch:  137
2022-05-29 04:09:18.957862: train loss : -0.7644
2022-05-29 04:09:27.149489: validation loss: -0.7316
2022-05-29 04:09:27.156080: Average global foreground Dice: [0.782]
2022-05-29 04:09:27.158831: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:09:27.650166: lr: 0.007478
2022-05-29 04:09:27.654105: This epoch took 99.122463 s

2022-05-29 04:09:27.656466: 
epoch:  138
2022-05-29 04:10:57.538850: train loss : -0.7680
2022-05-29 04:11:04.051168: validation loss: -0.7524
2022-05-29 04:11:04.054912: Average global foreground Dice: [0.8001]
2022-05-29 04:11:04.057106: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:11:04.513316: lr: 0.007459
2022-05-29 04:11:04.515791: This epoch took 96.857150 s

2022-05-29 04:11:04.518135: 
epoch:  139
2022-05-29 04:12:35.776618: train loss : -0.7479
2022-05-29 04:12:41.905879: validation loss: -0.7128
2022-05-29 04:12:41.909489: Average global foreground Dice: [0.7621]
2022-05-29 04:12:41.912060: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:12:42.359781: lr: 0.00744
2022-05-29 04:12:42.362060: This epoch took 97.841590 s

2022-05-29 04:12:42.364043: 
epoch:  140
2022-05-29 04:14:13.812181: train loss : -0.7744
2022-05-29 04:14:22.323097: validation loss: -0.7313
2022-05-29 04:14:22.329129: Average global foreground Dice: [0.7769]
2022-05-29 04:14:22.331223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:14:22.821382: lr: 0.007422
2022-05-29 04:14:22.823695: This epoch took 100.457619 s

2022-05-29 04:14:22.826098: 
epoch:  141
2022-05-29 04:15:55.150072: train loss : -0.7726
2022-05-29 04:16:03.454670: validation loss: -0.7463
2022-05-29 04:16:03.475959: Average global foreground Dice: [0.807]
2022-05-29 04:16:03.489303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:16:03.984562: lr: 0.007403
2022-05-29 04:16:04.073811: saving checkpoint...
2022-05-29 04:16:05.156653: done, saving took 1.17 seconds
2022-05-29 04:16:05.172494: This epoch took 102.342193 s

2022-05-29 04:16:05.174831: 
epoch:  142
2022-05-29 04:17:36.614489: train loss : -0.7538
2022-05-29 04:17:44.360845: validation loss: -0.7399
2022-05-29 04:17:44.365006: Average global foreground Dice: [0.7897]
2022-05-29 04:17:44.367794: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:17:44.814912: lr: 0.007385
2022-05-29 04:17:44.865495: saving checkpoint...
2022-05-29 04:17:45.928267: done, saving took 1.11 seconds
2022-05-29 04:17:45.944961: This epoch took 100.768001 s

2022-05-29 04:17:45.947010: 
epoch:  143
2022-05-29 04:19:17.534821: train loss : -0.7571
2022-05-29 04:19:26.817002: validation loss: -0.7145
2022-05-29 04:19:26.855870: Average global foreground Dice: [0.7759]
2022-05-29 04:19:26.881558: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:19:27.353906: lr: 0.007366
2022-05-29 04:19:27.356965: This epoch took 101.407932 s

2022-05-29 04:19:27.359762: 
epoch:  144
2022-05-29 04:20:59.386084: train loss : -0.7633
2022-05-29 04:21:07.345819: validation loss: -0.7445
2022-05-29 04:21:07.361734: Average global foreground Dice: [0.7988]
2022-05-29 04:21:07.384308: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:21:07.925602: lr: 0.007347
2022-05-29 04:21:07.986042: saving checkpoint...
2022-05-29 04:21:08.973216: done, saving took 1.04 seconds
2022-05-29 04:21:08.986582: This epoch took 101.623970 s

2022-05-29 04:21:08.988695: 
epoch:  145
2022-05-29 04:22:41.410336: train loss : -0.7876
2022-05-29 04:22:52.408728: validation loss: -0.7454
2022-05-29 04:22:52.411884: Average global foreground Dice: [0.803]
2022-05-29 04:22:52.414176: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:22:53.187785: lr: 0.007329
2022-05-29 04:22:53.251302: saving checkpoint...
2022-05-29 04:22:54.296983: done, saving took 1.08 seconds
2022-05-29 04:22:54.310421: This epoch took 105.319494 s

2022-05-29 04:22:54.312518: 
epoch:  146
2022-05-29 04:24:28.297340: train loss : -0.7788
2022-05-29 04:24:35.242931: validation loss: -0.7510
2022-05-29 04:24:35.279675: Average global foreground Dice: [0.8029]
2022-05-29 04:24:35.300287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:24:35.872597: lr: 0.00731
2022-05-29 04:24:35.995458: saving checkpoint...
2022-05-29 04:24:37.277476: done, saving took 1.40 seconds
2022-05-29 04:24:37.296829: This epoch took 102.982307 s

2022-05-29 04:24:37.299714: 
epoch:  147
2022-05-29 04:26:09.309540: train loss : -0.7613
2022-05-29 04:26:17.683756: validation loss: -0.7202
2022-05-29 04:26:17.687888: Average global foreground Dice: [0.7883]
2022-05-29 04:26:17.690157: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:26:18.146392: lr: 0.007291
2022-05-29 04:26:18.182036: saving checkpoint...
2022-05-29 04:26:19.211153: done, saving took 1.06 seconds
2022-05-29 04:26:19.226392: This epoch took 101.924413 s

2022-05-29 04:26:19.228751: 
epoch:  148
2022-05-29 04:27:49.718868: train loss : -0.7453
2022-05-29 04:27:57.341053: validation loss: -0.7366
2022-05-29 04:27:57.345165: Average global foreground Dice: [0.7835]
2022-05-29 04:27:57.347644: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:27:57.901909: lr: 0.007273
2022-05-29 04:27:57.910910: This epoch took 98.679849 s

2022-05-29 04:27:57.912824: 
epoch:  149
2022-05-29 04:29:28.790550: train loss : -0.7583
2022-05-29 04:29:36.732777: validation loss: -0.7419
2022-05-29 04:29:36.736510: Average global foreground Dice: [0.7843]
2022-05-29 04:29:36.739316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:29:37.203001: lr: 0.007254
2022-05-29 04:29:37.205579: saving scheduled checkpoint file...
2022-05-29 04:29:37.244857: saving checkpoint...
2022-05-29 04:29:38.279789: done, saving took 1.07 seconds
2022-05-29 04:29:38.295719: done
2022-05-29 04:29:38.298144: This epoch took 100.381982 s

2022-05-29 04:29:38.300464: 
epoch:  150
2022-05-29 04:31:09.574948: train loss : -0.7561
2022-05-29 04:31:17.444837: validation loss: -0.7354
2022-05-29 04:31:17.448647: Average global foreground Dice: [0.7826]
2022-05-29 04:31:17.451057: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:31:17.912910: lr: 0.007236
2022-05-29 04:31:17.915239: This epoch took 99.612645 s

2022-05-29 04:31:17.917482: 
epoch:  151
2022-05-29 04:32:52.286962: train loss : -0.7664
2022-05-29 04:33:02.989481: validation loss: -0.7507
2022-05-29 04:33:03.019050: Average global foreground Dice: [0.7897]
2022-05-29 04:33:03.038288: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:33:03.588565: lr: 0.007217
2022-05-29 04:33:03.591471: This epoch took 105.671837 s

2022-05-29 04:33:03.593710: 
epoch:  152
2022-05-29 04:34:38.880367: train loss : -0.7802
2022-05-29 04:34:46.800659: validation loss: -0.7317
2022-05-29 04:34:46.804066: Average global foreground Dice: [0.7773]
2022-05-29 04:34:46.806382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:34:47.424751: lr: 0.007198
2022-05-29 04:34:47.435725: This epoch took 103.839783 s

2022-05-29 04:34:47.477285: 
epoch:  153
2022-05-29 04:36:18.915374: train loss : -0.7754
2022-05-29 04:36:25.046444: validation loss: -0.7295
2022-05-29 04:36:25.052577: Average global foreground Dice: [0.79]
2022-05-29 04:36:25.054976: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:36:25.517313: lr: 0.00718
2022-05-29 04:36:25.519851: This epoch took 98.013552 s

2022-05-29 04:36:25.522101: 
epoch:  154
2022-05-29 04:37:56.705135: train loss : -0.7721
2022-05-29 04:38:03.550928: validation loss: -0.7370
2022-05-29 04:38:03.556086: Average global foreground Dice: [0.786]
2022-05-29 04:38:03.560210: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:38:04.028805: lr: 0.007161
2022-05-29 04:38:04.031233: This epoch took 98.506804 s

2022-05-29 04:38:04.037034: 
epoch:  155
2022-05-29 04:39:36.035436: train loss : -0.7765
2022-05-29 04:39:46.073323: validation loss: -0.7127
2022-05-29 04:39:46.077110: Average global foreground Dice: [0.7841]
2022-05-29 04:39:46.079800: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:39:46.593382: lr: 0.007142
2022-05-29 04:39:46.596114: This epoch took 102.555488 s

2022-05-29 04:39:46.598693: 
epoch:  156
2022-05-29 04:41:18.874083: train loss : -0.7666
2022-05-29 04:41:27.318886: validation loss: -0.7345
2022-05-29 04:41:27.323171: Average global foreground Dice: [0.7775]
2022-05-29 04:41:27.325628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:41:27.824311: lr: 0.007123
2022-05-29 04:41:27.826913: This epoch took 101.225851 s

2022-05-29 04:41:27.829540: 
epoch:  157
2022-05-29 04:43:02.143408: train loss : -0.7831
2022-05-29 04:43:09.620535: validation loss: -0.7652
2022-05-29 04:43:09.624895: Average global foreground Dice: [0.7997]
2022-05-29 04:43:09.627031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:43:10.160459: lr: 0.007105
2022-05-29 04:43:10.169849: This epoch took 102.338135 s

2022-05-29 04:43:10.196301: 
epoch:  158
2022-05-29 04:44:41.867862: train loss : -0.7766
2022-05-29 04:44:50.766834: validation loss: -0.7497
2022-05-29 04:44:50.800363: Average global foreground Dice: [0.7795]
2022-05-29 04:44:50.802678: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:44:51.303768: lr: 0.007086
2022-05-29 04:44:51.337334: This epoch took 101.119945 s

2022-05-29 04:44:51.346986: 
epoch:  159
2022-05-29 04:46:23.933869: train loss : -0.7735
2022-05-29 04:46:34.821017: validation loss: -0.7375
2022-05-29 04:46:34.845050: Average global foreground Dice: [0.8035]
2022-05-29 04:46:34.861218: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:46:35.619325: lr: 0.007067
2022-05-29 04:46:35.653723: saving checkpoint...
2022-05-29 04:46:36.830279: done, saving took 1.21 seconds
2022-05-29 04:46:36.848933: This epoch took 105.499180 s

2022-05-29 04:46:36.853039: 
epoch:  160
2022-05-29 04:48:09.504438: train loss : -0.7723
2022-05-29 04:48:20.305085: validation loss: -0.7481
2022-05-29 04:48:20.308665: Average global foreground Dice: [0.7892]
2022-05-29 04:48:20.310842: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:48:20.768464: lr: 0.007049
2022-05-29 04:48:20.802109: saving checkpoint...
2022-05-29 04:48:21.828714: done, saving took 1.06 seconds
2022-05-29 04:48:21.841968: This epoch took 104.985804 s

2022-05-29 04:48:21.844270: 
epoch:  161
2022-05-29 04:49:53.091061: train loss : -0.7672
2022-05-29 04:50:00.101079: validation loss: -0.7483
2022-05-29 04:50:00.104709: Average global foreground Dice: [0.7992]
2022-05-29 04:50:00.106937: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:50:00.594107: lr: 0.00703
2022-05-29 04:50:00.629082: saving checkpoint...
2022-05-29 04:50:01.700969: done, saving took 1.10 seconds
2022-05-29 04:50:01.714842: This epoch took 99.868388 s

2022-05-29 04:50:01.717062: 
epoch:  162
2022-05-29 04:51:33.439539: train loss : -0.7741
2022-05-29 04:51:41.434630: validation loss: -0.7235
2022-05-29 04:51:41.438037: Average global foreground Dice: [0.7653]
2022-05-29 04:51:41.440270: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:51:41.933945: lr: 0.007011
2022-05-29 04:51:41.936321: This epoch took 100.217113 s

2022-05-29 04:51:41.938651: 
epoch:  163
2022-05-29 04:53:25.443775: train loss : -0.7714
2022-05-29 04:53:33.245397: validation loss: -0.7327
2022-05-29 04:53:33.248676: Average global foreground Dice: [0.7896]
2022-05-29 04:53:33.250976: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:53:33.737325: lr: 0.006992
2022-05-29 04:53:33.740502: This epoch took 111.799427 s

2022-05-29 04:53:33.742613: 
epoch:  164
2022-05-29 04:55:05.494082: train loss : -0.7597
2022-05-29 04:55:15.111711: validation loss: -0.7202
2022-05-29 04:55:15.137535: Average global foreground Dice: [0.7752]
2022-05-29 04:55:15.161418: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:55:15.749774: lr: 0.006974
2022-05-29 04:55:15.771398: This epoch took 102.026608 s

2022-05-29 04:55:15.791414: 
epoch:  165
2022-05-29 04:56:49.491003: train loss : -0.7661
2022-05-29 04:56:57.776299: validation loss: -0.7625
2022-05-29 04:56:57.806686: Average global foreground Dice: [0.7989]
2022-05-29 04:56:57.846284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:56:58.348147: lr: 0.006955
2022-05-29 04:56:58.350679: This epoch took 102.554966 s

2022-05-29 04:56:58.352944: 
epoch:  166
2022-05-29 04:58:29.713131: train loss : -0.7673
2022-05-29 04:58:38.068376: validation loss: -0.7550
2022-05-29 04:58:38.081599: Average global foreground Dice: [0.7893]
2022-05-29 04:58:38.103801: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 04:58:38.600269: lr: 0.006936
2022-05-29 04:58:38.608016: This epoch took 100.252645 s

2022-05-29 04:58:38.629313: 
epoch:  167
2022-05-29 05:00:11.336493: train loss : -0.7593
2022-05-29 05:00:19.995615: validation loss: -0.7304
2022-05-29 05:00:20.007704: Average global foreground Dice: [0.7764]
2022-05-29 05:00:20.029285: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:00:20.595821: lr: 0.006918
2022-05-29 05:00:20.598209: This epoch took 101.945917 s

2022-05-29 05:00:20.600591: 
epoch:  168
2022-05-29 05:01:56.092137: train loss : -0.7711
2022-05-29 05:02:06.436870: validation loss: -0.7487
2022-05-29 05:02:06.442524: Average global foreground Dice: [0.7849]
2022-05-29 05:02:06.446704: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:02:06.925800: lr: 0.006899
2022-05-29 05:02:06.928203: This epoch took 106.324836 s

2022-05-29 05:02:06.930438: 
epoch:  169
2022-05-29 05:03:41.308211: train loss : -0.7732
2022-05-29 05:03:49.270682: validation loss: -0.7548
2022-05-29 05:03:49.274092: Average global foreground Dice: [0.7954]
2022-05-29 05:03:49.281031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:03:49.833879: lr: 0.00688
2022-05-29 05:03:49.836799: This epoch took 102.904179 s

2022-05-29 05:03:49.839912: 
epoch:  170
2022-05-29 05:05:21.345468: train loss : -0.7681
2022-05-29 05:05:29.818579: validation loss: -0.7441
2022-05-29 05:05:29.822192: Average global foreground Dice: [0.7807]
2022-05-29 05:05:29.827281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:05:30.303063: lr: 0.006861
2022-05-29 05:05:30.305918: This epoch took 100.462576 s

2022-05-29 05:05:30.309060: 
epoch:  171
2022-05-29 05:07:01.273602: train loss : -0.7649
2022-05-29 05:07:11.051057: validation loss: -0.7192
2022-05-29 05:07:11.076762: Average global foreground Dice: [0.7679]
2022-05-29 05:07:11.084682: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:07:11.615165: lr: 0.006842
2022-05-29 05:07:11.617860: This epoch took 101.306296 s

2022-05-29 05:07:11.620132: 
epoch:  172
2022-05-29 05:08:41.956820: train loss : -0.7622
2022-05-29 05:08:48.524427: validation loss: -0.7358
2022-05-29 05:08:48.527726: Average global foreground Dice: [0.7758]
2022-05-29 05:08:48.529840: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:08:49.004528: lr: 0.006824
2022-05-29 05:08:49.006943: This epoch took 97.384456 s

2022-05-29 05:08:49.009109: 
epoch:  173
2022-05-29 05:10:19.466512: train loss : -0.7800
2022-05-29 05:10:25.698136: validation loss: -0.7209
2022-05-29 05:10:25.701446: Average global foreground Dice: [0.7756]
2022-05-29 05:10:25.703856: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:10:26.146211: lr: 0.006805
2022-05-29 05:10:26.148571: This epoch took 97.137375 s

2022-05-29 05:10:26.150917: 
epoch:  174
2022-05-29 05:11:56.438036: train loss : -0.7691
2022-05-29 05:12:04.568419: validation loss: -0.7449
2022-05-29 05:12:04.573656: Average global foreground Dice: [0.7964]
2022-05-29 05:12:04.575788: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:12:05.101404: lr: 0.006786
2022-05-29 05:12:05.105334: This epoch took 98.952326 s

2022-05-29 05:12:05.109375: 
epoch:  175
2022-05-29 05:13:36.192606: train loss : -0.7576
2022-05-29 05:13:44.088923: validation loss: -0.7451
2022-05-29 05:13:44.092005: Average global foreground Dice: [0.7872]
2022-05-29 05:13:44.094013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:13:44.566238: lr: 0.006767
2022-05-29 05:13:44.569167: This epoch took 99.457123 s

2022-05-29 05:13:44.571884: 
epoch:  176
2022-05-29 05:15:15.546853: train loss : -0.7774
2022-05-29 05:15:21.758105: validation loss: -0.7288
2022-05-29 05:15:21.766212: Average global foreground Dice: [0.769]
2022-05-29 05:15:21.768026: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:15:22.243840: lr: 0.006749
2022-05-29 05:15:22.246169: This epoch took 97.671275 s

2022-05-29 05:15:22.248274: 
epoch:  177
2022-05-29 05:16:57.025381: train loss : -0.7727
2022-05-29 05:17:06.680481: validation loss: -0.7438
2022-05-29 05:17:06.709521: Average global foreground Dice: [0.7843]
2022-05-29 05:17:06.740364: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:17:07.292733: lr: 0.00673
2022-05-29 05:17:07.304313: This epoch took 105.053682 s

2022-05-29 05:17:07.308008: 
epoch:  178
2022-05-29 05:18:44.854789: train loss : -0.7650
2022-05-29 05:18:53.907284: validation loss: -0.7498
2022-05-29 05:18:53.910231: Average global foreground Dice: [0.7878]
2022-05-29 05:18:53.913043: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:18:54.368573: lr: 0.006711
2022-05-29 05:18:54.370872: This epoch took 107.039582 s

2022-05-29 05:18:54.377709: 
epoch:  179
2022-05-29 05:20:27.962543: train loss : -0.7801
2022-05-29 05:20:36.843638: validation loss: -0.7403
2022-05-29 05:20:36.847459: Average global foreground Dice: [0.7884]
2022-05-29 05:20:36.849721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:20:37.315884: lr: 0.006692
2022-05-29 05:20:37.318764: This epoch took 102.938552 s

2022-05-29 05:20:37.321456: 
epoch:  180
2022-05-29 05:22:08.327969: train loss : -0.7795
2022-05-29 05:22:16.568209: validation loss: -0.7548
2022-05-29 05:22:16.572056: Average global foreground Dice: [0.7857]
2022-05-29 05:22:16.574917: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:22:17.039675: lr: 0.006673
2022-05-29 05:22:17.061345: This epoch took 99.737150 s

2022-05-29 05:22:17.064085: 
epoch:  181
2022-05-29 05:23:48.383172: train loss : -0.7750
2022-05-29 05:23:59.904128: validation loss: -0.7381
2022-05-29 05:23:59.907399: Average global foreground Dice: [0.7943]
2022-05-29 05:23:59.909634: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:24:00.406873: lr: 0.006654
2022-05-29 05:24:00.410306: This epoch took 103.343765 s

2022-05-29 05:24:00.412917: 
epoch:  182
2022-05-29 05:25:31.829424: train loss : -0.7725
2022-05-29 05:25:40.258708: validation loss: -0.7253
2022-05-29 05:25:40.295907: Average global foreground Dice: [0.7783]
2022-05-29 05:25:40.324633: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:25:40.934015: lr: 0.006636
2022-05-29 05:25:40.961334: This epoch took 100.537825 s

2022-05-29 05:25:40.993292: 
epoch:  183
2022-05-29 05:27:12.988164: train loss : -0.7633
2022-05-29 05:27:22.357544: validation loss: -0.7499
2022-05-29 05:27:22.388113: Average global foreground Dice: [0.7929]
2022-05-29 05:27:22.408315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:27:23.077717: lr: 0.006617
2022-05-29 05:27:23.103393: This epoch took 102.088105 s

2022-05-29 05:27:23.106292: 
epoch:  184
2022-05-29 05:28:59.156641: train loss : -0.7654
2022-05-29 05:29:08.699332: validation loss: -0.7537
2022-05-29 05:29:08.726477: Average global foreground Dice: [0.7962]
2022-05-29 05:29:08.748746: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:29:09.423849: lr: 0.006598
2022-05-29 05:29:09.426381: This epoch took 106.311569 s

2022-05-29 05:29:09.428664: 
epoch:  185
2022-05-29 05:30:42.614964: train loss : -0.7860
2022-05-29 05:30:51.431673: validation loss: -0.7237
2022-05-29 05:30:51.437443: Average global foreground Dice: [0.7701]
2022-05-29 05:30:51.439901: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:30:51.961407: lr: 0.006579
2022-05-29 05:30:51.964402: This epoch took 102.533397 s

2022-05-29 05:30:51.966777: 
epoch:  186
2022-05-29 05:32:23.681992: train loss : -0.7844
2022-05-29 05:32:33.111046: validation loss: -0.7523
2022-05-29 05:32:33.144885: Average global foreground Dice: [0.7956]
2022-05-29 05:32:33.155355: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:32:33.634291: lr: 0.00656
2022-05-29 05:32:33.636835: This epoch took 101.667828 s

2022-05-29 05:32:33.639481: 
epoch:  187
2022-05-29 05:34:07.581630: train loss : -0.7813
2022-05-29 05:34:16.538754: validation loss: -0.7414
2022-05-29 05:34:16.543904: Average global foreground Dice: [0.783]
2022-05-29 05:34:16.547064: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:34:17.210009: lr: 0.006541
2022-05-29 05:34:17.213109: This epoch took 103.571356 s

2022-05-29 05:34:17.215492: 
epoch:  188
2022-05-29 05:35:55.901542: train loss : -0.7803
2022-05-29 05:36:04.657325: validation loss: -0.7376
2022-05-29 05:36:04.661444: Average global foreground Dice: [0.7863]
2022-05-29 05:36:04.663873: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:36:05.177016: lr: 0.006522
2022-05-29 05:36:05.181327: This epoch took 107.963635 s

2022-05-29 05:36:05.189709: 
epoch:  189
2022-05-29 05:37:39.545813: train loss : -0.7823
2022-05-29 05:37:48.948566: validation loss: -0.7687
2022-05-29 05:37:48.953157: Average global foreground Dice: [0.804]
2022-05-29 05:37:48.955613: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:37:49.425373: lr: 0.006504
2022-05-29 05:37:49.427855: This epoch took 104.234775 s

2022-05-29 05:37:49.429838: 
epoch:  190
2022-05-29 05:39:20.939219: train loss : -0.7726
2022-05-29 05:39:29.509603: validation loss: -0.7118
2022-05-29 05:39:29.513249: Average global foreground Dice: [0.7666]
2022-05-29 05:39:29.515728: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:39:29.979562: lr: 0.006485
2022-05-29 05:39:29.982332: This epoch took 100.549232 s

2022-05-29 05:39:29.984677: 
epoch:  191
2022-05-29 05:41:01.567045: train loss : -0.7739
2022-05-29 05:41:12.426694: validation loss: -0.7331
2022-05-29 05:41:12.434308: Average global foreground Dice: [0.7892]
2022-05-29 05:41:12.441372: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:41:12.945552: lr: 0.006466
2022-05-29 05:41:12.948249: This epoch took 102.961405 s

2022-05-29 05:41:12.950531: 
epoch:  192
2022-05-29 05:42:43.984220: train loss : -0.7887
2022-05-29 05:42:50.893210: validation loss: -0.7340
2022-05-29 05:42:50.896672: Average global foreground Dice: [0.7993]
2022-05-29 05:42:50.898908: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:42:51.369292: lr: 0.006447
2022-05-29 05:42:51.371738: This epoch took 98.419034 s

2022-05-29 05:42:51.374041: 
epoch:  193
2022-05-29 05:44:22.709517: train loss : -0.7699
2022-05-29 05:44:32.066797: validation loss: -0.7608
2022-05-29 05:44:32.070979: Average global foreground Dice: [0.8032]
2022-05-29 05:44:32.081071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:44:32.551616: lr: 0.006428
2022-05-29 05:44:32.554138: This epoch took 101.174855 s

2022-05-29 05:44:32.556688: 
epoch:  194
2022-05-29 05:46:03.018950: train loss : -0.7826
2022-05-29 05:46:10.822712: validation loss: -0.7382
2022-05-29 05:46:10.826287: Average global foreground Dice: [0.7908]
2022-05-29 05:46:10.829019: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:46:11.451908: lr: 0.006409
2022-05-29 05:46:11.495218: saving checkpoint...
2022-05-29 05:46:12.567685: done, saving took 1.11 seconds
2022-05-29 05:46:12.583672: This epoch took 100.024720 s

2022-05-29 05:46:12.585916: 
epoch:  195
2022-05-29 05:47:49.598628: train loss : -0.7849
2022-05-29 05:47:57.547736: validation loss: -0.7214
2022-05-29 05:47:57.556152: Average global foreground Dice: [0.7843]
2022-05-29 05:47:57.561411: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:47:58.025207: lr: 0.00639
2022-05-29 05:47:58.027751: This epoch took 105.439861 s

2022-05-29 05:47:58.030170: 
epoch:  196
2022-05-29 05:49:30.345668: train loss : -0.7625
2022-05-29 05:49:40.547756: validation loss: -0.7306
2022-05-29 05:49:40.579820: Average global foreground Dice: [0.7881]
2022-05-29 05:49:40.606401: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:49:41.262875: lr: 0.006371
2022-05-29 05:49:41.278316: This epoch took 103.245986 s

2022-05-29 05:49:41.301302: 
epoch:  197
2022-05-29 05:51:12.617517: train loss : -0.7823
2022-05-29 05:51:21.566184: validation loss: -0.7332
2022-05-29 05:51:21.569398: Average global foreground Dice: [0.7785]
2022-05-29 05:51:21.571956: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:51:22.082908: lr: 0.006352
2022-05-29 05:51:22.085344: This epoch took 100.757832 s

2022-05-29 05:51:22.087386: 
epoch:  198
2022-05-29 05:52:52.349899: train loss : -0.7849
2022-05-29 05:53:00.918929: validation loss: -0.7473
2022-05-29 05:53:00.922602: Average global foreground Dice: [0.7954]
2022-05-29 05:53:00.924985: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:53:01.426775: lr: 0.006333
2022-05-29 05:53:01.429442: This epoch took 99.338885 s

2022-05-29 05:53:01.431490: 
epoch:  199
2022-05-29 05:54:33.767270: train loss : -0.7754
2022-05-29 05:54:44.546186: validation loss: -0.7431
2022-05-29 05:54:44.569997: Average global foreground Dice: [0.7926]
2022-05-29 05:54:44.577354: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:54:45.081688: lr: 0.006314
2022-05-29 05:54:45.084282: saving scheduled checkpoint file...
2022-05-29 05:54:45.126843: saving checkpoint...
2022-05-29 05:54:46.326806: done, saving took 1.24 seconds
2022-05-29 05:54:46.344767: done
2022-05-29 05:54:46.347506: This epoch took 104.913933 s

2022-05-29 05:54:46.349679: 
epoch:  200
2022-05-29 05:56:16.998178: train loss : -0.7718
2022-05-29 05:56:25.422275: validation loss: -0.7413
2022-05-29 05:56:25.427564: Average global foreground Dice: [0.799]
2022-05-29 05:56:25.430221: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:56:25.968811: lr: 0.006296
2022-05-29 05:56:26.022297: saving checkpoint...
2022-05-29 05:56:27.011432: done, saving took 1.04 seconds
2022-05-29 05:56:27.027132: This epoch took 100.674939 s

2022-05-29 05:56:27.029603: 
epoch:  201
2022-05-29 05:57:57.922944: train loss : -0.7742
2022-05-29 05:58:08.795925: validation loss: -0.7460
2022-05-29 05:58:08.799713: Average global foreground Dice: [0.7847]
2022-05-29 05:58:08.803366: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:58:09.355528: lr: 0.006277
2022-05-29 05:58:09.358218: This epoch took 102.326389 s

2022-05-29 05:58:09.360629: 
epoch:  202
2022-05-29 05:59:42.090268: train loss : -0.7734
2022-05-29 05:59:50.064857: validation loss: -0.7361
2022-05-29 05:59:50.068950: Average global foreground Dice: [0.7984]
2022-05-29 05:59:50.071473: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 05:59:50.530914: lr: 0.006258
2022-05-29 05:59:50.564359: saving checkpoint...
2022-05-29 05:59:51.707321: done, saving took 1.17 seconds
2022-05-29 05:59:51.721559: This epoch took 102.358393 s

2022-05-29 05:59:51.724271: 
epoch:  203
2022-05-29 06:01:23.216964: train loss : -0.7764
2022-05-29 06:01:29.950376: validation loss: -0.7165
2022-05-29 06:01:29.953972: Average global foreground Dice: [0.7795]
2022-05-29 06:01:29.956402: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:01:30.411484: lr: 0.006239
2022-05-29 06:01:30.414192: This epoch took 98.687601 s

2022-05-29 06:01:30.416728: 
epoch:  204
2022-05-29 06:03:05.774712: train loss : -0.7745
2022-05-29 06:03:15.423699: validation loss: -0.7344
2022-05-29 06:03:15.426686: Average global foreground Dice: [0.7785]
2022-05-29 06:03:15.428733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:03:15.917770: lr: 0.00622
2022-05-29 06:03:15.920668: This epoch took 105.501760 s

2022-05-29 06:03:15.923560: 
epoch:  205
2022-05-29 06:04:47.175704: train loss : -0.7797
2022-05-29 06:04:58.102981: validation loss: -0.7427
2022-05-29 06:04:58.106651: Average global foreground Dice: [0.7861]
2022-05-29 06:04:58.109628: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:04:58.579209: lr: 0.006201
2022-05-29 06:04:58.581485: This epoch took 102.655400 s

2022-05-29 06:04:58.583431: 
epoch:  206
2022-05-29 06:06:33.791532: train loss : -0.7798
2022-05-29 06:06:43.220057: validation loss: -0.7564
2022-05-29 06:06:43.223680: Average global foreground Dice: [0.7973]
2022-05-29 06:06:43.226472: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:06:43.763798: lr: 0.006182
2022-05-29 06:06:43.766341: This epoch took 105.180885 s

2022-05-29 06:06:43.768811: 
epoch:  207
2022-05-29 06:08:15.004828: train loss : -0.7794
2022-05-29 06:08:22.611211: validation loss: -0.7134
2022-05-29 06:08:22.614582: Average global foreground Dice: [0.7568]
2022-05-29 06:08:22.616674: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:08:23.073306: lr: 0.006163
2022-05-29 06:08:23.081313: This epoch took 99.309992 s

2022-05-29 06:08:23.104278: 
epoch:  208
2022-05-29 06:09:56.651559: train loss : -0.7750
2022-05-29 06:10:07.609530: validation loss: -0.7582
2022-05-29 06:10:07.612884: Average global foreground Dice: [0.8008]
2022-05-29 06:10:07.615436: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:10:08.130956: lr: 0.006144
2022-05-29 06:10:08.133372: This epoch took 105.007061 s

2022-05-29 06:10:08.135610: 
epoch:  209
2022-05-29 06:11:38.427084: train loss : -0.7730
2022-05-29 06:11:45.402986: validation loss: -0.7441
2022-05-29 06:11:45.406371: Average global foreground Dice: [0.7924]
2022-05-29 06:11:45.408611: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:11:45.965504: lr: 0.006125
2022-05-29 06:11:45.967802: This epoch took 97.830030 s

2022-05-29 06:11:45.969784: 
epoch:  210
2022-05-29 06:13:22.361508: train loss : -0.7773
2022-05-29 06:13:31.219560: validation loss: -0.6982
2022-05-29 06:13:31.223134: Average global foreground Dice: [0.7601]
2022-05-29 06:13:31.226781: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:13:31.671682: lr: 0.006106
2022-05-29 06:13:31.674056: This epoch took 105.702201 s

2022-05-29 06:13:31.676100: 
epoch:  211
2022-05-29 06:15:07.721621: train loss : -0.7830
2022-05-29 06:15:16.958516: validation loss: -0.7085
2022-05-29 06:15:16.993889: Average global foreground Dice: [0.7846]
2022-05-29 06:15:17.013336: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:15:17.979525: lr: 0.006087
2022-05-29 06:15:18.010346: This epoch took 106.332292 s

2022-05-29 06:15:18.043296: 
epoch:  212
2022-05-29 06:16:49.437450: train loss : -0.7802
2022-05-29 06:16:56.212376: validation loss: -0.7368
2022-05-29 06:16:56.215794: Average global foreground Dice: [0.778]
2022-05-29 06:16:56.218161: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:16:56.673613: lr: 0.006068
2022-05-29 06:16:56.675874: This epoch took 98.615592 s

2022-05-29 06:16:56.677900: 
epoch:  213
2022-05-29 06:18:27.427044: train loss : -0.7989
2022-05-29 06:18:35.405687: validation loss: -0.7429
2022-05-29 06:18:35.409353: Average global foreground Dice: [0.7885]
2022-05-29 06:18:35.411759: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:18:35.888060: lr: 0.006049
2022-05-29 06:18:35.890592: This epoch took 99.210118 s

2022-05-29 06:18:35.895012: 
epoch:  214
2022-05-29 06:20:06.600884: train loss : -0.7796
2022-05-29 06:20:13.202689: validation loss: -0.7216
2022-05-29 06:20:13.205939: Average global foreground Dice: [0.7752]
2022-05-29 06:20:13.209751: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:20:13.672929: lr: 0.00603
2022-05-29 06:20:13.675205: This epoch took 97.777003 s

2022-05-29 06:20:13.677247: 
epoch:  215
2022-05-29 06:21:45.269628: train loss : -0.7868
2022-05-29 06:21:53.380110: validation loss: -0.7621
2022-05-29 06:21:53.383922: Average global foreground Dice: [0.8008]
2022-05-29 06:21:53.386588: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:21:53.853395: lr: 0.006011
2022-05-29 06:21:53.873133: This epoch took 100.193891 s

2022-05-29 06:21:53.876666: 
epoch:  216
2022-05-29 06:23:26.760073: train loss : -0.7905
2022-05-29 06:23:35.784955: validation loss: -0.7715
2022-05-29 06:23:35.795836: Average global foreground Dice: [0.8057]
2022-05-29 06:23:35.798188: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:23:36.308954: lr: 0.005991
2022-05-29 06:23:36.312250: This epoch took 102.427445 s

2022-05-29 06:23:36.317828: 
epoch:  217
2022-05-29 06:25:10.035216: train loss : -0.7921
2022-05-29 06:25:20.820778: validation loss: -0.6991
2022-05-29 06:25:20.835356: Average global foreground Dice: [0.7754]
2022-05-29 06:25:20.838085: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:25:21.312375: lr: 0.005972
2022-05-29 06:25:21.315447: This epoch took 104.991290 s

2022-05-29 06:25:21.320446: 
epoch:  218
2022-05-29 06:26:53.342955: train loss : -0.7951
2022-05-29 06:27:00.463501: validation loss: -0.7441
2022-05-29 06:27:00.467642: Average global foreground Dice: [0.7863]
2022-05-29 06:27:00.469935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:27:00.956235: lr: 0.005953
2022-05-29 06:27:00.959809: This epoch took 99.627529 s

2022-05-29 06:27:00.962261: 
epoch:  219
2022-05-29 06:28:35.592294: train loss : -0.7719
2022-05-29 06:28:45.759019: validation loss: -0.7180
2022-05-29 06:28:45.762540: Average global foreground Dice: [0.7862]
2022-05-29 06:28:45.764908: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:28:46.242480: lr: 0.005934
2022-05-29 06:28:46.245816: This epoch took 105.281482 s

2022-05-29 06:28:46.251635: 
epoch:  220
2022-05-29 06:30:17.633152: train loss : -0.7754
2022-05-29 06:30:24.372124: validation loss: -0.7383
2022-05-29 06:30:24.386144: Average global foreground Dice: [0.7876]
2022-05-29 06:30:24.388458: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:30:24.934259: lr: 0.005915
2022-05-29 06:30:24.954666: This epoch took 98.700892 s

2022-05-29 06:30:24.963495: 
epoch:  221
2022-05-29 06:31:57.804934: train loss : -0.7552
2022-05-29 06:32:09.093301: validation loss: -0.7526
2022-05-29 06:32:09.097324: Average global foreground Dice: [0.7978]
2022-05-29 06:32:09.099998: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:32:09.604755: lr: 0.005896
2022-05-29 06:32:09.608687: This epoch took 104.628732 s

2022-05-29 06:32:09.620572: 
epoch:  222
2022-05-29 06:33:40.793855: train loss : -0.7833
2022-05-29 06:33:47.939925: validation loss: -0.7333
2022-05-29 06:33:47.943424: Average global foreground Dice: [0.7834]
2022-05-29 06:33:47.945559: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:33:48.391672: lr: 0.005877
2022-05-29 06:33:48.394126: This epoch took 98.771384 s

2022-05-29 06:33:48.396286: 
epoch:  223
2022-05-29 06:35:19.704864: train loss : -0.7711
2022-05-29 06:35:30.025620: validation loss: -0.7356
2022-05-29 06:35:30.029086: Average global foreground Dice: [0.7849]
2022-05-29 06:35:30.031486: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:35:30.484204: lr: 0.005858
2022-05-29 06:35:30.487354: This epoch took 102.088753 s

2022-05-29 06:35:30.489527: 
epoch:  224
2022-05-29 06:37:04.902391: train loss : -0.7763
2022-05-29 06:37:14.929685: validation loss: -0.7430
2022-05-29 06:37:14.942671: Average global foreground Dice: [0.7968]
2022-05-29 06:37:14.954903: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:37:15.432691: lr: 0.005839
2022-05-29 06:37:15.446584: This epoch took 104.954695 s

2022-05-29 06:37:15.455963: 
epoch:  225
2022-05-29 06:38:45.969769: train loss : -0.7754
2022-05-29 06:38:52.880231: validation loss: -0.7435
2022-05-29 06:38:52.883523: Average global foreground Dice: [0.7846]
2022-05-29 06:38:52.885603: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:38:53.355811: lr: 0.00582
2022-05-29 06:38:53.358461: This epoch took 97.888465 s

2022-05-29 06:38:53.360509: 
epoch:  226
2022-05-29 06:40:29.621010: train loss : -0.7806
2022-05-29 06:40:37.184384: validation loss: -0.7510
2022-05-29 06:40:37.187411: Average global foreground Dice: [0.7901]
2022-05-29 06:40:37.189543: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:40:37.636144: lr: 0.005801
2022-05-29 06:40:37.638486: This epoch took 104.275857 s

2022-05-29 06:40:37.640466: 
epoch:  227
2022-05-29 06:42:08.872857: train loss : -0.7876
2022-05-29 06:42:17.226743: validation loss: -0.7379
2022-05-29 06:42:17.230497: Average global foreground Dice: [0.795]
2022-05-29 06:42:17.233295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:42:17.688927: lr: 0.005781
2022-05-29 06:42:17.691205: This epoch took 100.048664 s

2022-05-29 06:42:17.694438: 
epoch:  228
2022-05-29 06:43:49.983255: train loss : -0.7864
2022-05-29 06:43:57.566658: validation loss: -0.7384
2022-05-29 06:43:57.570376: Average global foreground Dice: [0.7959]
2022-05-29 06:43:57.572809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:43:58.053698: lr: 0.005762
2022-05-29 06:43:58.055899: This epoch took 100.358502 s

2022-05-29 06:43:58.057864: 
epoch:  229
2022-05-29 06:45:29.686803: train loss : -0.7830
2022-05-29 06:45:38.901257: validation loss: -0.7331
2022-05-29 06:45:38.905289: Average global foreground Dice: [0.7948]
2022-05-29 06:45:38.907942: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:45:39.380893: lr: 0.005743
2022-05-29 06:45:39.383199: This epoch took 101.323323 s

2022-05-29 06:45:39.385153: 
epoch:  230
2022-05-29 06:47:15.885109: train loss : -0.7856
2022-05-29 06:47:24.750172: validation loss: -0.7261
2022-05-29 06:47:24.753469: Average global foreground Dice: [0.7659]
2022-05-29 06:47:24.756311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:47:25.251773: lr: 0.005724
2022-05-29 06:47:25.257251: This epoch took 105.870222 s

2022-05-29 06:47:25.260857: 
epoch:  231
2022-05-29 06:48:59.708151: train loss : -0.7735
2022-05-29 06:49:09.421576: validation loss: -0.7384
2022-05-29 06:49:09.433229: Average global foreground Dice: [0.7804]
2022-05-29 06:49:09.442323: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:49:09.951200: lr: 0.005705
2022-05-29 06:49:09.953351: This epoch took 104.681997 s

2022-05-29 06:49:09.957781: 
epoch:  232
2022-05-29 06:50:46.238012: train loss : -0.7691
2022-05-29 06:50:54.635003: validation loss: -0.7256
2022-05-29 06:50:54.638434: Average global foreground Dice: [0.7837]
2022-05-29 06:50:54.640681: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:50:55.109455: lr: 0.005686
2022-05-29 06:50:55.111746: This epoch took 105.151712 s

2022-05-29 06:50:55.113969: 
epoch:  233
2022-05-29 06:52:26.070544: train loss : -0.7758
2022-05-29 06:52:34.871266: validation loss: -0.7313
2022-05-29 06:52:34.875410: Average global foreground Dice: [0.7767]
2022-05-29 06:52:34.877633: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:52:35.369024: lr: 0.005667
2022-05-29 06:52:35.371955: This epoch took 100.255630 s

2022-05-29 06:52:35.374406: 
epoch:  234
2022-05-29 06:54:06.161627: train loss : -0.7845
2022-05-29 06:54:12.809692: validation loss: -0.7584
2022-05-29 06:54:12.814404: Average global foreground Dice: [0.7884]
2022-05-29 06:54:12.816827: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:54:13.301677: lr: 0.005647
2022-05-29 06:54:13.304116: This epoch took 97.927359 s

2022-05-29 06:54:13.306386: 
epoch:  235
2022-05-29 06:55:44.976810: train loss : -0.8017
2022-05-29 06:55:53.520617: validation loss: -0.7524
2022-05-29 06:55:53.524534: Average global foreground Dice: [0.7917]
2022-05-29 06:55:53.526918: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:55:53.980002: lr: 0.005628
2022-05-29 06:55:53.982598: This epoch took 100.674150 s

2022-05-29 06:55:53.984451: 
epoch:  236
2022-05-29 06:57:25.422635: train loss : -0.7988
2022-05-29 06:57:35.854847: validation loss: -0.7342
2022-05-29 06:57:35.883703: Average global foreground Dice: [0.7833]
2022-05-29 06:57:35.889449: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:57:36.415756: lr: 0.005609
2022-05-29 06:57:36.418360: This epoch took 102.431862 s

2022-05-29 06:57:36.419871: 
epoch:  237
2022-05-29 06:59:11.274185: train loss : -0.7984
2022-05-29 06:59:20.353812: validation loss: -0.7558
2022-05-29 06:59:20.374700: Average global foreground Dice: [0.7974]
2022-05-29 06:59:20.386311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 06:59:21.071856: lr: 0.00559
2022-05-29 06:59:21.102478: This epoch took 104.680174 s

2022-05-29 06:59:21.125807: 
epoch:  238
2022-05-29 07:00:52.382913: train loss : -0.7841
2022-05-29 07:01:00.703283: validation loss: -0.7573
2022-05-29 07:01:00.707270: Average global foreground Dice: [0.7954]
2022-05-29 07:01:00.709471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:01:01.158129: lr: 0.005571
2022-05-29 07:01:01.161534: This epoch took 100.008157 s

2022-05-29 07:01:01.177292: 
epoch:  239
2022-05-29 07:02:33.676914: train loss : -0.7904
2022-05-29 07:02:42.469587: validation loss: -0.7435
2022-05-29 07:02:42.472804: Average global foreground Dice: [0.7942]
2022-05-29 07:02:42.475125: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:02:42.924280: lr: 0.005551
2022-05-29 07:02:42.926407: This epoch took 101.746323 s

2022-05-29 07:02:42.928281: 
epoch:  240
2022-05-29 07:04:14.315441: train loss : -0.7996
2022-05-29 07:04:24.828268: validation loss: -0.7516
2022-05-29 07:04:24.834753: Average global foreground Dice: [0.79]
2022-05-29 07:04:24.845099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:04:25.549455: lr: 0.005532
2022-05-29 07:04:25.553340: This epoch took 102.622916 s

2022-05-29 07:04:25.561660: 
epoch:  241
2022-05-29 07:05:56.535823: train loss : -0.7819
2022-05-29 07:06:05.097806: validation loss: -0.7568
2022-05-29 07:06:05.103018: Average global foreground Dice: [0.8063]
2022-05-29 07:06:05.104889: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:06:05.572021: lr: 0.005513
2022-05-29 07:06:05.625195: saving checkpoint...
2022-05-29 07:06:06.600178: done, saving took 1.03 seconds
2022-05-29 07:06:06.623098: This epoch took 101.059325 s

2022-05-29 07:06:06.625258: 
epoch:  242
2022-05-29 07:07:37.516172: train loss : -0.7831
2022-05-29 07:07:47.047705: validation loss: -0.7342
2022-05-29 07:07:47.068547: Average global foreground Dice: [0.7917]
2022-05-29 07:07:47.088824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:07:47.695441: lr: 0.005494
2022-05-29 07:07:47.726561: saving checkpoint...
2022-05-29 07:07:48.708668: done, saving took 1.01 seconds
2022-05-29 07:07:48.721731: This epoch took 102.094146 s

2022-05-29 07:07:48.723915: 
epoch:  243
2022-05-29 07:09:19.549205: train loss : -0.7893
2022-05-29 07:09:28.473606: validation loss: -0.7512
2022-05-29 07:09:28.477177: Average global foreground Dice: [0.7928]
2022-05-29 07:09:28.479705: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:09:28.963270: lr: 0.005474
2022-05-29 07:09:28.998225: saving checkpoint...
2022-05-29 07:09:30.016014: done, saving took 1.05 seconds
2022-05-29 07:09:30.029739: This epoch took 101.303535 s

2022-05-29 07:09:30.031925: 
epoch:  244
2022-05-29 07:11:01.260556: train loss : -0.7974
2022-05-29 07:11:10.326733: validation loss: -0.7429
2022-05-29 07:11:10.330364: Average global foreground Dice: [0.7879]
2022-05-29 07:11:10.332735: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:11:10.790699: lr: 0.005455
2022-05-29 07:11:10.793142: This epoch took 100.759245 s

2022-05-29 07:11:10.795419: 
epoch:  245
2022-05-29 07:12:44.804458: train loss : -0.7942
2022-05-29 07:12:53.536018: validation loss: -0.7409
2022-05-29 07:12:53.540388: Average global foreground Dice: [0.787]
2022-05-29 07:12:53.543283: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:12:53.997982: lr: 0.005436
2022-05-29 07:12:54.000153: This epoch took 103.202632 s

2022-05-29 07:12:54.002224: 
epoch:  246
2022-05-29 07:14:25.525490: train loss : -0.8065
2022-05-29 07:14:35.880952: validation loss: -0.7517
2022-05-29 07:14:35.906260: Average global foreground Dice: [0.797]
2022-05-29 07:14:35.924373: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:14:36.654536: lr: 0.005417
2022-05-29 07:14:36.729694: saving checkpoint...
2022-05-29 07:14:37.875592: done, saving took 1.19 seconds
2022-05-29 07:14:37.964362: This epoch took 103.960254 s

2022-05-29 07:14:37.981969: 
epoch:  247
2022-05-29 07:16:09.131240: train loss : -0.8077
2022-05-29 07:16:17.278435: validation loss: -0.7535
2022-05-29 07:16:17.282008: Average global foreground Dice: [0.7879]
2022-05-29 07:16:17.285761: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:16:17.732417: lr: 0.005397
2022-05-29 07:16:17.734630: This epoch took 99.750607 s

2022-05-29 07:16:17.736589: 
epoch:  248
2022-05-29 07:17:50.075514: train loss : -0.7949
2022-05-29 07:17:59.633973: validation loss: -0.7330
2022-05-29 07:17:59.638534: Average global foreground Dice: [0.7844]
2022-05-29 07:17:59.641314: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:18:00.127092: lr: 0.005378
2022-05-29 07:18:00.129532: This epoch took 102.391033 s

2022-05-29 07:18:00.131746: 
epoch:  249
2022-05-29 07:19:31.302779: train loss : -0.8145
2022-05-29 07:19:40.401959: validation loss: -0.7674
2022-05-29 07:19:40.405799: Average global foreground Dice: [0.8033]
2022-05-29 07:19:40.407802: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:19:40.865175: lr: 0.005359
2022-05-29 07:19:40.867939: saving scheduled checkpoint file...
2022-05-29 07:19:40.909822: saving checkpoint...
2022-05-29 07:19:42.027561: done, saving took 1.16 seconds
2022-05-29 07:19:42.045612: done
2022-05-29 07:19:42.078969: saving checkpoint...
2022-05-29 07:19:43.052786: done, saving took 1.00 seconds
2022-05-29 07:19:43.066912: This epoch took 102.929981 s

2022-05-29 07:19:43.069036: 
epoch:  250
2022-05-29 07:21:17.163869: train loss : -0.7906
2022-05-29 07:21:25.169851: validation loss: -0.7389
2022-05-29 07:21:25.173273: Average global foreground Dice: [0.7883]
2022-05-29 07:21:25.175494: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:21:25.645020: lr: 0.00534
2022-05-29 07:21:25.647822: This epoch took 102.576848 s

2022-05-29 07:21:25.649869: 
epoch:  251
2022-05-29 07:22:56.544233: train loss : -0.8037
2022-05-29 07:23:04.116480: validation loss: -0.7590
2022-05-29 07:23:04.119999: Average global foreground Dice: [0.7948]
2022-05-29 07:23:04.122695: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:23:04.576594: lr: 0.00532
2022-05-29 07:23:04.614073: saving checkpoint...
2022-05-29 07:23:05.624175: done, saving took 1.05 seconds
2022-05-29 07:23:05.636887: This epoch took 99.984415 s

2022-05-29 07:23:05.638961: 
epoch:  252
2022-05-29 07:24:36.296605: train loss : -0.7906
2022-05-29 07:24:44.518282: validation loss: -0.7451
2022-05-29 07:24:44.524145: Average global foreground Dice: [0.7923]
2022-05-29 07:24:44.526860: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:24:45.002634: lr: 0.005301
2022-05-29 07:24:45.036674: saving checkpoint...
2022-05-29 07:24:46.023872: done, saving took 1.02 seconds
2022-05-29 07:24:46.038692: This epoch took 100.397866 s

2022-05-29 07:24:46.040801: 
epoch:  253
2022-05-29 07:26:17.850698: train loss : -0.7898
2022-05-29 07:26:27.139215: validation loss: -0.7460
2022-05-29 07:26:27.151922: Average global foreground Dice: [0.8]
2022-05-29 07:26:27.167278: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:26:27.774416: lr: 0.005282
2022-05-29 07:26:27.841857: saving checkpoint...
2022-05-29 07:26:28.949382: done, saving took 1.17 seconds
2022-05-29 07:26:29.017347: This epoch took 102.973552 s

2022-05-29 07:26:29.048290: 
epoch:  254
2022-05-29 07:28:01.349176: train loss : -0.8052
2022-05-29 07:28:11.006787: validation loss: -0.7467
2022-05-29 07:28:11.032758: Average global foreground Dice: [0.7903]
2022-05-29 07:28:11.057486: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:28:11.684844: lr: 0.005262
2022-05-29 07:28:11.717321: This epoch took 102.635011 s

2022-05-29 07:28:11.740288: 
epoch:  255
2022-05-29 07:29:42.376646: train loss : -0.8041
2022-05-29 07:29:50.963147: validation loss: -0.7487
2022-05-29 07:29:50.966192: Average global foreground Dice: [0.7833]
2022-05-29 07:29:50.968309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:29:51.438543: lr: 0.005243
2022-05-29 07:29:51.441108: This epoch took 99.697304 s

2022-05-29 07:29:51.443478: 
epoch:  256
2022-05-29 07:31:23.055933: train loss : -0.7989
2022-05-29 07:31:31.493488: validation loss: -0.7305
2022-05-29 07:31:31.522746: Average global foreground Dice: [0.7798]
2022-05-29 07:31:31.541292: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:31:32.118004: lr: 0.005224
2022-05-29 07:31:32.137422: This epoch took 100.692052 s

2022-05-29 07:31:32.147007: 
epoch:  257
2022-05-29 07:33:13.479876: train loss : -0.7969
2022-05-29 07:33:22.536062: validation loss: -0.7470
2022-05-29 07:33:22.539697: Average global foreground Dice: [0.7982]
2022-05-29 07:33:22.541946: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:33:23.139513: lr: 0.005204
2022-05-29 07:33:23.142341: This epoch took 110.993355 s

2022-05-29 07:33:23.144626: 
epoch:  258
2022-05-29 07:34:59.362902: train loss : -0.7975
2022-05-29 07:35:08.411715: validation loss: -0.7408
2022-05-29 07:35:08.415676: Average global foreground Dice: [0.7938]
2022-05-29 07:35:08.417637: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:35:08.876641: lr: 0.005185
2022-05-29 07:35:08.878851: This epoch took 105.731828 s

2022-05-29 07:35:08.880690: 
epoch:  259
2022-05-29 07:36:40.957922: train loss : -0.8002
2022-05-29 07:36:48.570717: validation loss: -0.7393
2022-05-29 07:36:48.577989: Average global foreground Dice: [0.7708]
2022-05-29 07:36:48.580217: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:36:49.092994: lr: 0.005166
2022-05-29 07:36:49.095572: This epoch took 100.213024 s

2022-05-29 07:36:49.097576: 
epoch:  260
2022-05-29 07:38:19.869071: train loss : -0.8045
2022-05-29 07:38:26.264465: validation loss: -0.7221
2022-05-29 07:38:26.268438: Average global foreground Dice: [0.7744]
2022-05-29 07:38:26.270894: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:38:26.713431: lr: 0.005146
2022-05-29 07:38:26.715719: This epoch took 97.616205 s

2022-05-29 07:38:26.717713: 
epoch:  261
2022-05-29 07:40:00.892237: train loss : -0.7969
2022-05-29 07:40:10.379452: validation loss: -0.7193
2022-05-29 07:40:10.404680: Average global foreground Dice: [0.7687]
2022-05-29 07:40:10.427284: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:40:11.001091: lr: 0.005127
2022-05-29 07:40:11.003316: This epoch took 104.283735 s

2022-05-29 07:40:11.005267: 
epoch:  262
2022-05-29 07:41:42.738338: train loss : -0.7876
2022-05-29 07:41:51.123778: validation loss: -0.7355
2022-05-29 07:41:51.148509: Average global foreground Dice: [0.7763]
2022-05-29 07:41:51.163424: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:41:51.823307: lr: 0.005107
2022-05-29 07:41:51.825867: This epoch took 100.818435 s

2022-05-29 07:41:51.828090: 
epoch:  263
2022-05-29 07:43:22.459084: train loss : -0.7942
2022-05-29 07:43:29.544304: validation loss: -0.7289
2022-05-29 07:43:29.548189: Average global foreground Dice: [0.7897]
2022-05-29 07:43:29.549908: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:43:29.999964: lr: 0.005088
2022-05-29 07:43:30.002131: This epoch took 98.171763 s

2022-05-29 07:43:30.004203: 
epoch:  264
2022-05-29 07:45:03.849040: train loss : -0.7942
2022-05-29 07:45:12.404308: validation loss: -0.7554
2022-05-29 07:45:12.429264: Average global foreground Dice: [0.8084]
2022-05-29 07:45:12.435387: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:45:12.916670: lr: 0.005069
2022-05-29 07:45:12.919006: This epoch took 102.912581 s

2022-05-29 07:45:12.920993: 
epoch:  265
2022-05-29 07:46:45.053427: train loss : -0.7948
2022-05-29 07:46:53.873991: validation loss: -0.7386
2022-05-29 07:46:53.878509: Average global foreground Dice: [0.7971]
2022-05-29 07:46:53.880599: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:46:54.350712: lr: 0.005049
2022-05-29 07:46:54.353348: This epoch took 101.430380 s

2022-05-29 07:46:54.355460: 
epoch:  266
2022-05-29 07:48:26.324041: train loss : -0.7758
2022-05-29 07:48:35.529222: validation loss: -0.7474
2022-05-29 07:48:35.532871: Average global foreground Dice: [0.791]
2022-05-29 07:48:35.535310: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:48:35.974129: lr: 0.00503
2022-05-29 07:48:35.976616: This epoch took 101.619221 s

2022-05-29 07:48:35.978626: 
epoch:  267
2022-05-29 07:50:08.339857: train loss : -0.7998
2022-05-29 07:50:16.829843: validation loss: -0.7228
2022-05-29 07:50:16.849731: Average global foreground Dice: [0.7893]
2022-05-29 07:50:16.873607: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:50:17.444930: lr: 0.00501
2022-05-29 07:50:17.447719: This epoch took 101.467265 s

2022-05-29 07:50:17.450527: 
epoch:  268
2022-05-29 07:51:53.812775: train loss : -0.8055
2022-05-29 07:52:03.112229: validation loss: -0.7366
2022-05-29 07:52:03.115494: Average global foreground Dice: [0.7872]
2022-05-29 07:52:03.117624: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:52:03.593401: lr: 0.004991
2022-05-29 07:52:03.595748: This epoch took 106.137176 s

2022-05-29 07:52:03.598007: 
epoch:  269
2022-05-29 07:53:35.471075: train loss : -0.8000
2022-05-29 07:53:42.421581: validation loss: -0.7367
2022-05-29 07:53:42.424901: Average global foreground Dice: [0.7737]
2022-05-29 07:53:42.427013: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:53:42.910140: lr: 0.004971
2022-05-29 07:53:42.912586: This epoch took 99.312624 s

2022-05-29 07:53:42.914971: 
epoch:  270
2022-05-29 07:55:13.839758: train loss : -0.8067
2022-05-29 07:55:20.011661: validation loss: -0.7452
2022-05-29 07:55:20.015107: Average global foreground Dice: [0.788]
2022-05-29 07:55:20.017303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:55:20.477198: lr: 0.004952
2022-05-29 07:55:20.479625: This epoch took 97.561587 s

2022-05-29 07:55:20.481708: 
epoch:  271
2022-05-29 07:56:54.427118: train loss : -0.8049
2022-05-29 07:57:03.834476: validation loss: -0.7386
2022-05-29 07:57:03.849734: Average global foreground Dice: [0.774]
2022-05-29 07:57:03.862373: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:57:04.366254: lr: 0.004933
2022-05-29 07:57:04.368944: This epoch took 103.884665 s

2022-05-29 07:57:04.376521: 
epoch:  272
2022-05-29 07:58:35.288411: train loss : -0.8032
2022-05-29 07:58:42.718732: validation loss: -0.7546
2022-05-29 07:58:42.722326: Average global foreground Dice: [0.8002]
2022-05-29 07:58:42.724660: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 07:58:43.183522: lr: 0.004913
2022-05-29 07:58:43.188614: This epoch took 98.809291 s

2022-05-29 07:58:43.193022: 
epoch:  273
2022-05-29 08:00:20.300746: train loss : -0.7918
2022-05-29 08:00:31.108562: validation loss: -0.7467
2022-05-29 08:00:31.112035: Average global foreground Dice: [0.7923]
2022-05-29 08:00:31.114221: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:00:31.667383: lr: 0.004894
2022-05-29 08:00:31.669542: This epoch took 108.471358 s

2022-05-29 08:00:31.671446: 
epoch:  274
2022-05-29 08:02:03.278028: train loss : -0.8071
2022-05-29 08:02:13.906041: validation loss: -0.7258
2022-05-29 08:02:13.909530: Average global foreground Dice: [0.7854]
2022-05-29 08:02:13.911964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:02:14.380291: lr: 0.004874
2022-05-29 08:02:14.382505: This epoch took 102.709039 s

2022-05-29 08:02:14.385067: 
epoch:  275
2022-05-29 08:03:47.122585: train loss : -0.7975
2022-05-29 08:03:57.937145: validation loss: -0.7516
2022-05-29 08:03:57.940878: Average global foreground Dice: [0.7957]
2022-05-29 08:03:57.943260: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:03:58.436852: lr: 0.004855
2022-05-29 08:03:58.467701: This epoch took 104.080470 s

2022-05-29 08:03:58.472624: 
epoch:  276
2022-05-29 08:05:36.512585: train loss : -0.8053
2022-05-29 08:05:47.396640: validation loss: -0.7635
2022-05-29 08:05:47.400807: Average global foreground Dice: [0.8025]
2022-05-29 08:05:47.403226: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:05:47.865840: lr: 0.004835
2022-05-29 08:05:47.868121: This epoch took 109.391750 s

2022-05-29 08:05:47.869992: 
epoch:  277
2022-05-29 08:07:18.934624: train loss : -0.7949
2022-05-29 08:07:29.095351: validation loss: -0.7368
2022-05-29 08:07:29.099152: Average global foreground Dice: [0.7738]
2022-05-29 08:07:29.101616: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:07:29.569878: lr: 0.004816
2022-05-29 08:07:29.574293: This epoch took 101.702290 s

2022-05-29 08:07:29.576727: 
epoch:  278
2022-05-29 08:09:06.856823: train loss : -0.8037
2022-05-29 08:09:16.834348: validation loss: -0.7325
2022-05-29 08:09:16.865744: Average global foreground Dice: [0.797]
2022-05-29 08:09:16.873690: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:09:17.346600: lr: 0.004796
2022-05-29 08:09:17.349250: This epoch took 107.770244 s

2022-05-29 08:09:17.351719: 
epoch:  279
2022-05-29 08:10:54.002715: train loss : -0.8026
2022-05-29 08:11:02.125516: validation loss: -0.7537
2022-05-29 08:11:02.128924: Average global foreground Dice: [0.7903]
2022-05-29 08:11:02.131899: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:11:02.665629: lr: 0.004776
2022-05-29 08:11:02.668972: This epoch took 105.314852 s

2022-05-29 08:11:02.671459: 
epoch:  280
2022-05-29 08:12:33.416764: train loss : -0.8056
2022-05-29 08:12:42.100171: validation loss: -0.6975
2022-05-29 08:12:42.103653: Average global foreground Dice: [0.7691]
2022-05-29 08:12:42.106163: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:12:42.555928: lr: 0.004757
2022-05-29 08:12:42.558669: This epoch took 99.884309 s

2022-05-29 08:12:42.561191: 
epoch:  281
2022-05-29 08:14:13.678812: train loss : -0.7937
2022-05-29 08:14:21.787424: validation loss: -0.7610
2022-05-29 08:14:21.795358: Average global foreground Dice: [0.7951]
2022-05-29 08:14:21.797661: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:14:22.318039: lr: 0.004737
2022-05-29 08:14:22.326201: This epoch took 99.762548 s

2022-05-29 08:14:22.346878: 
epoch:  282
2022-05-29 08:15:53.316846: train loss : -0.8147
2022-05-29 08:16:00.210951: validation loss: -0.7706
2022-05-29 08:16:00.214483: Average global foreground Dice: [0.8074]
2022-05-29 08:16:00.217843: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:16:00.744425: lr: 0.004718
2022-05-29 08:16:00.746957: This epoch took 98.394346 s

2022-05-29 08:16:00.748809: 
epoch:  283
2022-05-29 08:17:31.867295: train loss : -0.8062
2022-05-29 08:17:39.449832: validation loss: -0.7567
2022-05-29 08:17:39.454022: Average global foreground Dice: [0.8027]
2022-05-29 08:17:39.456137: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:17:39.934785: lr: 0.004698
2022-05-29 08:17:39.937397: This epoch took 99.179886 s

2022-05-29 08:17:39.939990: 
epoch:  284
2022-05-29 08:19:14.700839: train loss : -0.7969
2022-05-29 08:19:25.370378: validation loss: -0.7450
2022-05-29 08:19:25.397745: Average global foreground Dice: [0.7995]
2022-05-29 08:19:25.426315: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:19:26.040978: lr: 0.004679
2022-05-29 08:19:26.043369: This epoch took 106.100627 s

2022-05-29 08:19:26.045555: 
epoch:  285
2022-05-29 08:21:02.533460: train loss : -0.7880
2022-05-29 08:21:10.834774: validation loss: -0.7700
2022-05-29 08:21:10.838056: Average global foreground Dice: [0.7928]
2022-05-29 08:21:10.840546: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:21:11.376006: lr: 0.004659
2022-05-29 08:21:11.378453: This epoch took 105.318171 s

2022-05-29 08:21:11.380830: 
epoch:  286
2022-05-29 08:22:47.085398: train loss : -0.7821
2022-05-29 08:22:55.952707: validation loss: -0.7477
2022-05-29 08:22:55.956695: Average global foreground Dice: [0.799]
2022-05-29 08:22:55.959868: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:22:56.437592: lr: 0.004639
2022-05-29 08:22:56.509820: saving checkpoint...
2022-05-29 08:22:57.462300: done, saving took 1.02 seconds
2022-05-29 08:22:57.477454: This epoch took 106.094571 s

2022-05-29 08:22:57.479522: 
epoch:  287
2022-05-29 08:24:28.263682: train loss : -0.7938
2022-05-29 08:24:35.688786: validation loss: -0.7165
2022-05-29 08:24:35.692457: Average global foreground Dice: [0.7703]
2022-05-29 08:24:35.694736: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:24:36.157101: lr: 0.00462
2022-05-29 08:24:36.159227: This epoch took 98.677705 s

2022-05-29 08:24:36.161084: 
epoch:  288
2022-05-29 08:26:10.007377: train loss : -0.8065
2022-05-29 08:26:21.043314: validation loss: -0.7328
2022-05-29 08:26:21.046657: Average global foreground Dice: [0.7821]
2022-05-29 08:26:21.048873: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:26:21.647571: lr: 0.0046
2022-05-29 08:26:21.650441: This epoch took 105.487517 s

2022-05-29 08:26:21.653100: 
epoch:  289
2022-05-29 08:27:58.738840: train loss : -0.7966
2022-05-29 08:28:06.814131: validation loss: -0.7514
2022-05-29 08:28:06.817579: Average global foreground Dice: [0.7883]
2022-05-29 08:28:06.820210: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:28:07.270203: lr: 0.004581
2022-05-29 08:28:07.273649: This epoch took 105.618403 s

2022-05-29 08:28:07.277710: 
epoch:  290
2022-05-29 08:29:39.483801: train loss : -0.8022
2022-05-29 08:29:50.306264: validation loss: -0.7298
2022-05-29 08:29:50.314240: Average global foreground Dice: [0.7747]
2022-05-29 08:29:50.316489: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:29:50.791640: lr: 0.004561
2022-05-29 08:29:50.794115: This epoch took 103.512198 s

2022-05-29 08:29:50.800671: 
epoch:  291
2022-05-29 08:31:28.759215: train loss : -0.8045
2022-05-29 08:31:36.854032: validation loss: -0.7499
2022-05-29 08:31:36.857288: Average global foreground Dice: [0.7954]
2022-05-29 08:31:36.859303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:31:37.308946: lr: 0.004541
2022-05-29 08:31:37.311980: This epoch took 106.492952 s

2022-05-29 08:31:37.314321: 
epoch:  292
2022-05-29 08:33:11.413920: train loss : -0.8036
2022-05-29 08:33:21.080398: validation loss: -0.7566
2022-05-29 08:33:21.087552: Average global foreground Dice: [0.8009]
2022-05-29 08:33:21.090438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:33:21.625449: lr: 0.004522
2022-05-29 08:33:21.628120: This epoch took 104.311896 s

2022-05-29 08:33:21.630689: 
epoch:  293
2022-05-29 08:34:52.422858: train loss : -0.8081
2022-05-29 08:34:58.434095: validation loss: -0.7648
2022-05-29 08:34:58.441567: Average global foreground Dice: [0.7973]
2022-05-29 08:34:58.443769: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:34:58.908020: lr: 0.004502
2022-05-29 08:34:58.912866: This epoch took 97.255576 s

2022-05-29 08:34:58.914915: 
epoch:  294
2022-05-29 08:36:31.105722: train loss : -0.8133
2022-05-29 08:36:41.069587: validation loss: -0.7145
2022-05-29 08:36:41.083674: Average global foreground Dice: [0.784]
2022-05-29 08:36:41.091421: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:36:41.559097: lr: 0.004482
2022-05-29 08:36:41.561224: This epoch took 102.644345 s

2022-05-29 08:36:41.563116: 
epoch:  295
2022-05-29 08:38:13.584511: train loss : -0.8195
2022-05-29 08:38:23.812604: validation loss: -0.7330
2022-05-29 08:38:23.815611: Average global foreground Dice: [0.7782]
2022-05-29 08:38:23.817862: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:38:24.262652: lr: 0.004463
2022-05-29 08:38:24.265389: This epoch took 102.700335 s

2022-05-29 08:38:24.270434: 
epoch:  296
2022-05-29 08:39:55.930495: train loss : -0.8121
2022-05-29 08:40:03.835422: validation loss: -0.7486
2022-05-29 08:40:03.840591: Average global foreground Dice: [0.7939]
2022-05-29 08:40:03.842640: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:40:04.328795: lr: 0.004443
2022-05-29 08:40:04.331358: This epoch took 100.058718 s

2022-05-29 08:40:04.333448: 
epoch:  297
2022-05-29 08:41:35.611341: train loss : -0.8212
2022-05-29 08:41:44.458021: validation loss: -0.7513
2022-05-29 08:41:44.462512: Average global foreground Dice: [0.7984]
2022-05-29 08:41:44.465085: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:41:44.974498: lr: 0.004423
2022-05-29 08:41:44.976910: This epoch took 100.641214 s

2022-05-29 08:41:44.979417: 
epoch:  298
2022-05-29 08:43:23.725949: train loss : -0.8152
2022-05-29 08:43:32.524447: validation loss: -0.7337
2022-05-29 08:43:32.528224: Average global foreground Dice: [0.7867]
2022-05-29 08:43:32.530478: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:43:32.978629: lr: 0.004404
2022-05-29 08:43:32.981073: This epoch took 107.999396 s

2022-05-29 08:43:32.983137: 
epoch:  299
2022-05-29 08:45:03.963398: train loss : -0.8226
2022-05-29 08:45:09.799138: validation loss: -0.7520
2022-05-29 08:45:09.803853: Average global foreground Dice: [0.8005]
2022-05-29 08:45:09.808247: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:45:10.268760: lr: 0.004384
2022-05-29 08:45:10.271075: saving scheduled checkpoint file...
2022-05-29 08:45:10.324867: saving checkpoint...
2022-05-29 08:45:11.303342: done, saving took 1.03 seconds
2022-05-29 08:45:11.320760: done
2022-05-29 08:45:11.322978: This epoch took 98.337685 s

2022-05-29 08:45:11.325133: 
epoch:  300
2022-05-29 08:46:44.309766: train loss : -0.8122
2022-05-29 08:46:53.352433: validation loss: -0.7369
2022-05-29 08:46:53.391977: Average global foreground Dice: [0.7813]
2022-05-29 08:46:53.408359: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:46:54.016262: lr: 0.004364
2022-05-29 08:46:54.042464: This epoch took 102.715318 s

2022-05-29 08:46:54.051346: 
epoch:  301
2022-05-29 08:48:24.446019: train loss : -0.8155
2022-05-29 08:48:31.168418: validation loss: -0.7475
2022-05-29 08:48:31.171885: Average global foreground Dice: [0.7844]
2022-05-29 08:48:31.173814: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:48:31.651406: lr: 0.004344
2022-05-29 08:48:31.659371: This epoch took 97.586049 s

2022-05-29 08:48:31.662785: 
epoch:  302
2022-05-29 08:50:02.905169: train loss : -0.8024
2022-05-29 08:50:11.717865: validation loss: -0.7509
2022-05-29 08:50:11.727253: Average global foreground Dice: [0.7946]
2022-05-29 08:50:11.729656: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:50:12.233557: lr: 0.004325
2022-05-29 08:50:12.235822: This epoch took 100.570935 s

2022-05-29 08:50:12.237667: 
epoch:  303
2022-05-29 08:51:43.657279: train loss : -0.8063
2022-05-29 08:51:51.750021: validation loss: -0.7573
2022-05-29 08:51:51.754870: Average global foreground Dice: [0.8084]
2022-05-29 08:51:51.757696: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:51:52.253200: lr: 0.004305
2022-05-29 08:51:52.256104: This epoch took 100.016595 s

2022-05-29 08:51:52.258328: 
epoch:  304
2022-05-29 08:53:23.651843: train loss : -0.8115
2022-05-29 08:53:31.088548: validation loss: -0.7276
2022-05-29 08:53:31.092226: Average global foreground Dice: [0.7821]
2022-05-29 08:53:31.095319: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:53:31.592845: lr: 0.004285
2022-05-29 08:53:31.595781: This epoch took 99.335076 s

2022-05-29 08:53:31.598215: 
epoch:  305
2022-05-29 08:55:03.132594: train loss : -0.8090
2022-05-29 08:55:10.123691: validation loss: -0.7556
2022-05-29 08:55:10.127409: Average global foreground Dice: [0.7964]
2022-05-29 08:55:10.130096: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:55:10.607745: lr: 0.004265
2022-05-29 08:55:10.610270: This epoch took 99.000301 s

2022-05-29 08:55:10.612621: 
epoch:  306
2022-05-29 08:56:41.952214: train loss : -0.8133
2022-05-29 08:56:50.310020: validation loss: -0.7522
2022-05-29 08:56:50.313527: Average global foreground Dice: [0.7933]
2022-05-29 08:56:50.315862: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:56:50.770698: lr: 0.004245
2022-05-29 08:56:50.773769: This epoch took 100.158935 s

2022-05-29 08:56:50.776289: 
epoch:  307
2022-05-29 08:58:21.256205: train loss : -0.8198
2022-05-29 08:58:28.094278: validation loss: -0.7337
2022-05-29 08:58:28.098055: Average global foreground Dice: [0.7804]
2022-05-29 08:58:28.100287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 08:58:28.586852: lr: 0.004226
2022-05-29 08:58:28.590058: This epoch took 97.811299 s

2022-05-29 08:58:28.592351: 
epoch:  308
2022-05-29 09:00:00.396230: train loss : -0.8175
2022-05-29 09:00:09.270262: validation loss: -0.7283
2022-05-29 09:00:09.274716: Average global foreground Dice: [0.7762]
2022-05-29 09:00:09.278811: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:00:09.880844: lr: 0.004206
2022-05-29 09:00:09.883431: This epoch took 101.288817 s

2022-05-29 09:00:09.886370: 
epoch:  309
2022-05-29 09:01:44.022172: train loss : -0.8186
2022-05-29 09:01:54.693147: validation loss: -0.7594
2022-05-29 09:01:54.696238: Average global foreground Dice: [0.8071]
2022-05-29 09:01:54.698390: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:01:55.260219: lr: 0.004186
2022-05-29 09:01:55.262615: This epoch took 105.369866 s

2022-05-29 09:01:55.264741: 
epoch:  310
2022-05-29 09:03:26.453397: train loss : -0.8155
2022-05-29 09:03:34.570422: validation loss: -0.7477
2022-05-29 09:03:34.574472: Average global foreground Dice: [0.7929]
2022-05-29 09:03:34.577833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:03:35.054265: lr: 0.004166
2022-05-29 09:03:35.056708: This epoch took 99.789568 s

2022-05-29 09:03:35.059031: 
epoch:  311
2022-05-29 09:05:11.882482: train loss : -0.8212
2022-05-29 09:05:19.697523: validation loss: -0.7172
2022-05-29 09:05:19.700751: Average global foreground Dice: [0.7799]
2022-05-29 09:05:19.702994: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:05:20.155338: lr: 0.004146
2022-05-29 09:05:20.158003: This epoch took 105.096525 s

2022-05-29 09:05:20.160063: 
epoch:  312
2022-05-29 09:06:53.590020: train loss : -0.8049
2022-05-29 09:07:03.168458: validation loss: -0.7606
2022-05-29 09:07:03.194043: Average global foreground Dice: [0.793]
2022-05-29 09:07:03.212362: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:07:03.846028: lr: 0.004127
2022-05-29 09:07:03.871504: This epoch took 103.709468 s

2022-05-29 09:07:03.891721: 
epoch:  313
2022-05-29 09:08:35.242969: train loss : -0.8155
2022-05-29 09:08:44.479159: validation loss: -0.7347
2022-05-29 09:08:44.482829: Average global foreground Dice: [0.7986]
2022-05-29 09:08:44.486650: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:08:44.939990: lr: 0.004107
2022-05-29 09:08:44.942456: This epoch took 101.031066 s

2022-05-29 09:08:44.944649: 
epoch:  314
2022-05-29 09:10:16.045825: train loss : -0.8051
2022-05-29 09:10:25.470845: validation loss: -0.7396
2022-05-29 09:10:25.474285: Average global foreground Dice: [0.7844]
2022-05-29 09:10:25.476668: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:10:25.955724: lr: 0.004087
2022-05-29 09:10:25.961811: This epoch took 101.014838 s

2022-05-29 09:10:25.964157: 
epoch:  315
2022-05-29 09:11:59.259646: train loss : -0.7932
2022-05-29 09:12:07.346532: validation loss: -0.7530
2022-05-29 09:12:07.350507: Average global foreground Dice: [0.7997]
2022-05-29 09:12:07.352654: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:12:07.804060: lr: 0.004067
2022-05-29 09:12:07.806490: This epoch took 101.839987 s

2022-05-29 09:12:07.808336: 
epoch:  316
2022-05-29 09:13:39.145895: train loss : -0.8145
2022-05-29 09:13:45.979830: validation loss: -0.7410
2022-05-29 09:13:45.983311: Average global foreground Dice: [0.7972]
2022-05-29 09:13:45.985872: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:13:46.487640: lr: 0.004047
2022-05-29 09:13:46.490186: This epoch took 98.679735 s

2022-05-29 09:13:46.492470: 
epoch:  317
2022-05-29 09:15:17.757329: train loss : -0.8204
2022-05-29 09:15:24.254261: validation loss: -0.7282
2022-05-29 09:15:24.258894: Average global foreground Dice: [0.7833]
2022-05-29 09:15:24.261870: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:15:24.710069: lr: 0.004027
2022-05-29 09:15:24.712345: This epoch took 98.217598 s

2022-05-29 09:15:24.714438: 
epoch:  318
2022-05-29 09:16:58.309802: train loss : -0.8194
2022-05-29 09:17:07.517885: validation loss: -0.7533
2022-05-29 09:17:07.522179: Average global foreground Dice: [0.7972]
2022-05-29 09:17:07.530947: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:17:08.009195: lr: 0.004007
2022-05-29 09:17:08.012154: This epoch took 103.295463 s

2022-05-29 09:17:08.014074: 
epoch:  319
2022-05-29 09:18:41.649881: train loss : -0.8137
2022-05-29 09:18:50.434153: validation loss: -0.7395
2022-05-29 09:18:50.449918: Average global foreground Dice: [0.7883]
2022-05-29 09:18:50.452247: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:18:51.027757: lr: 0.003987
2022-05-29 09:18:51.030074: This epoch took 103.014130 s

2022-05-29 09:18:51.031932: 
epoch:  320
2022-05-29 09:20:22.456802: train loss : -0.8184
2022-05-29 09:20:32.296029: validation loss: -0.7247
2022-05-29 09:20:32.300127: Average global foreground Dice: [0.7864]
2022-05-29 09:20:32.303617: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:20:32.808890: lr: 0.003967
2022-05-29 09:20:32.835043: This epoch took 101.801124 s

2022-05-29 09:20:32.852376: 
epoch:  321
2022-05-29 09:22:04.513482: train loss : -0.8186
2022-05-29 09:22:11.832187: validation loss: -0.7496
2022-05-29 09:22:11.835721: Average global foreground Dice: [0.7796]
2022-05-29 09:22:11.837873: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:22:12.287732: lr: 0.003947
2022-05-29 09:22:12.290056: This epoch took 99.432929 s

2022-05-29 09:22:12.291819: 
epoch:  322
2022-05-29 09:23:43.153095: train loss : -0.8185
2022-05-29 09:23:51.787335: validation loss: -0.7311
2022-05-29 09:23:51.790515: Average global foreground Dice: [0.7944]
2022-05-29 09:23:51.794762: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:23:52.269398: lr: 0.003927
2022-05-29 09:23:52.271706: This epoch took 99.977986 s

2022-05-29 09:23:52.273640: 
epoch:  323
2022-05-29 09:25:24.594351: train loss : -0.8020
2022-05-29 09:25:34.152349: validation loss: -0.7507
2022-05-29 09:25:34.173403: Average global foreground Dice: [0.7894]
2022-05-29 09:25:34.176534: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:25:34.658084: lr: 0.003907
2022-05-29 09:25:34.670323: This epoch took 102.394806 s

2022-05-29 09:25:34.673423: 
epoch:  324
2022-05-29 09:27:06.179010: train loss : -0.8273
2022-05-29 09:27:14.990048: validation loss: -0.7647
2022-05-29 09:27:14.995107: Average global foreground Dice: [0.7995]
2022-05-29 09:27:14.997598: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:27:15.448118: lr: 0.003887
2022-05-29 09:27:15.450514: This epoch took 100.755209 s

2022-05-29 09:27:15.453061: 
epoch:  325
2022-05-29 09:28:46.206193: train loss : -0.8262
2022-05-29 09:28:55.503918: validation loss: -0.7530
2022-05-29 09:28:55.507376: Average global foreground Dice: [0.7845]
2022-05-29 09:28:55.509845: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:28:55.986951: lr: 0.003867
2022-05-29 09:28:55.989208: This epoch took 100.533936 s

2022-05-29 09:28:55.991198: 
epoch:  326
2022-05-29 09:30:30.844423: train loss : -0.8222
2022-05-29 09:30:42.010382: validation loss: -0.7376
2022-05-29 09:30:42.017869: Average global foreground Dice: [0.7816]
2022-05-29 09:30:42.023715: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:30:42.491233: lr: 0.003847
2022-05-29 09:30:42.493376: This epoch took 106.500252 s

2022-05-29 09:30:42.495358: 
epoch:  327
2022-05-29 09:32:13.445918: train loss : -0.8205
2022-05-29 09:32:21.180702: validation loss: -0.7451
2022-05-29 09:32:21.211743: Average global foreground Dice: [0.7965]
2022-05-29 09:32:21.244287: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:32:21.765129: lr: 0.003827
2022-05-29 09:32:21.767675: This epoch took 99.270267 s

2022-05-29 09:32:21.769932: 
epoch:  328
2022-05-29 09:33:53.522903: train loss : -0.8309
2022-05-29 09:34:01.704847: validation loss: -0.7175
2022-05-29 09:34:01.709058: Average global foreground Dice: [0.7857]
2022-05-29 09:34:01.712542: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:34:02.215536: lr: 0.003807
2022-05-29 09:34:02.217791: This epoch took 100.445858 s

2022-05-29 09:34:02.219900: 
epoch:  329
2022-05-29 09:35:33.198958: train loss : -0.8221
2022-05-29 09:35:40.604042: validation loss: -0.7657
2022-05-29 09:35:40.624670: Average global foreground Dice: [0.8023]
2022-05-29 09:35:40.627719: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:35:41.116409: lr: 0.003787
2022-05-29 09:35:41.121018: This epoch took 98.899080 s

2022-05-29 09:35:41.129638: 
epoch:  330
2022-05-29 09:37:12.242027: train loss : -0.8267
2022-05-29 09:37:21.029541: validation loss: -0.7542
2022-05-29 09:37:21.036874: Average global foreground Dice: [0.7952]
2022-05-29 09:37:21.038865: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:37:21.490256: lr: 0.003767
2022-05-29 09:37:21.492570: This epoch took 100.360759 s

2022-05-29 09:37:21.494408: 
epoch:  331
2022-05-29 09:38:53.180716: train loss : -0.8387
2022-05-29 09:39:00.702550: validation loss: -0.7541
2022-05-29 09:39:00.706933: Average global foreground Dice: [0.7919]
2022-05-29 09:39:00.710654: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:39:01.281293: lr: 0.003747
2022-05-29 09:39:01.283901: This epoch took 99.787511 s

2022-05-29 09:39:01.286865: 
epoch:  332
2022-05-29 09:40:32.240163: train loss : -0.8303
2022-05-29 09:40:39.508897: validation loss: -0.7530
2022-05-29 09:40:39.516075: Average global foreground Dice: [0.7886]
2022-05-29 09:40:39.525194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:40:39.999959: lr: 0.003727
2022-05-29 09:40:40.002376: This epoch took 98.711591 s

2022-05-29 09:40:40.004904: 
epoch:  333
2022-05-29 09:42:11.286738: train loss : -0.8199
2022-05-29 09:42:19.021388: validation loss: -0.7379
2022-05-29 09:42:19.024933: Average global foreground Dice: [0.7841]
2022-05-29 09:42:19.027080: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:42:19.534297: lr: 0.003707
2022-05-29 09:42:19.536450: This epoch took 99.527989 s

2022-05-29 09:42:19.538430: 
epoch:  334
2022-05-29 09:43:54.751834: train loss : -0.8048
2022-05-29 09:44:05.286809: validation loss: -0.7316
2022-05-29 09:44:05.290170: Average global foreground Dice: [0.7758]
2022-05-29 09:44:05.292533: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:44:05.884498: lr: 0.003687
2022-05-29 09:44:05.886786: This epoch took 106.346372 s

2022-05-29 09:44:05.888745: 
epoch:  335
2022-05-29 09:45:37.244972: train loss : -0.8022
2022-05-29 09:45:46.323126: validation loss: -0.7407
2022-05-29 09:45:46.328664: Average global foreground Dice: [0.7917]
2022-05-29 09:45:46.334133: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:45:46.834696: lr: 0.003667
2022-05-29 09:45:46.837503: This epoch took 100.946799 s

2022-05-29 09:45:46.840343: 
epoch:  336
2022-05-29 09:47:26.621130: train loss : -0.8095
2022-05-29 09:47:35.105462: validation loss: -0.7298
2022-05-29 09:47:35.108829: Average global foreground Dice: [0.8016]
2022-05-29 09:47:35.111105: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:47:35.592598: lr: 0.003647
2022-05-29 09:47:35.595285: This epoch took 108.752162 s

2022-05-29 09:47:35.597388: 
epoch:  337
2022-05-29 09:49:06.748741: train loss : -0.8218
2022-05-29 09:49:13.144655: validation loss: -0.7324
2022-05-29 09:49:13.147824: Average global foreground Dice: [0.7716]
2022-05-29 09:49:13.149773: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:49:13.625074: lr: 0.003627
2022-05-29 09:49:13.628088: This epoch took 98.028777 s

2022-05-29 09:49:13.640371: 
epoch:  338
2022-05-29 09:50:43.975286: train loss : -0.8124
2022-05-29 09:50:50.569922: validation loss: -0.7126
2022-05-29 09:50:50.574133: Average global foreground Dice: [0.7721]
2022-05-29 09:50:50.576397: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:50:51.033664: lr: 0.003606
2022-05-29 09:50:51.035891: This epoch took 97.384319 s

2022-05-29 09:50:51.037809: 
epoch:  339
2022-05-29 09:52:25.700709: train loss : -0.8092
2022-05-29 09:52:35.059465: validation loss: -0.7309
2022-05-29 09:52:35.062683: Average global foreground Dice: [0.7871]
2022-05-29 09:52:35.064778: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:52:35.598602: lr: 0.003586
2022-05-29 09:52:35.601007: This epoch took 104.560527 s

2022-05-29 09:52:35.603069: 
epoch:  340
2022-05-29 09:54:06.088901: train loss : -0.8040
2022-05-29 09:54:14.264529: validation loss: -0.7329
2022-05-29 09:54:14.268148: Average global foreground Dice: [0.7873]
2022-05-29 09:54:14.270255: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:54:14.719301: lr: 0.003566
2022-05-29 09:54:14.721720: This epoch took 99.116394 s

2022-05-29 09:54:14.723836: 
epoch:  341
2022-05-29 09:55:47.307780: train loss : -0.8176
2022-05-29 09:55:56.973835: validation loss: -0.7613
2022-05-29 09:55:56.977482: Average global foreground Dice: [0.7931]
2022-05-29 09:55:56.980296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:55:57.568919: lr: 0.003546
2022-05-29 09:55:57.571698: This epoch took 102.845366 s

2022-05-29 09:55:57.574246: 
epoch:  342
2022-05-29 09:57:29.268132: train loss : -0.8166
2022-05-29 09:57:37.318296: validation loss: -0.7416
2022-05-29 09:57:37.323470: Average global foreground Dice: [0.7979]
2022-05-29 09:57:37.325537: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:57:37.837276: lr: 0.003526
2022-05-29 09:57:37.839518: This epoch took 100.262670 s

2022-05-29 09:57:37.841651: 
epoch:  343
2022-05-29 09:59:08.765680: train loss : -0.8133
2022-05-29 09:59:17.512775: validation loss: -0.7539
2022-05-29 09:59:17.516384: Average global foreground Dice: [0.7992]
2022-05-29 09:59:17.528144: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 09:59:18.032581: lr: 0.003505
2022-05-29 09:59:18.035518: This epoch took 100.191827 s

2022-05-29 09:59:18.037994: 
epoch:  344
2022-05-29 10:00:48.923045: train loss : -0.8156
2022-05-29 10:00:56.864842: validation loss: -0.7342
2022-05-29 10:00:56.868470: Average global foreground Dice: [0.783]
2022-05-29 10:00:56.870538: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:00:57.350976: lr: 0.003485
2022-05-29 10:00:57.353337: This epoch took 99.310768 s

2022-05-29 10:00:57.355207: 
epoch:  345
2022-05-29 10:02:27.970410: train loss : -0.8211
2022-05-29 10:02:36.877434: validation loss: -0.7373
2022-05-29 10:02:36.881088: Average global foreground Dice: [0.7918]
2022-05-29 10:02:36.885645: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:02:37.358772: lr: 0.003465
2022-05-29 10:02:37.361404: This epoch took 100.004367 s

2022-05-29 10:02:37.363515: 
epoch:  346
2022-05-29 10:04:07.908423: train loss : -0.8267
2022-05-29 10:04:14.351240: validation loss: -0.7645
2022-05-29 10:04:14.384757: Average global foreground Dice: [0.7999]
2022-05-29 10:04:14.406332: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:04:14.932048: lr: 0.003445
2022-05-29 10:04:14.934482: This epoch took 97.568620 s

2022-05-29 10:04:14.940290: 
epoch:  347
2022-05-29 10:05:45.820273: train loss : -0.8293
2022-05-29 10:05:53.960946: validation loss: -0.7643
2022-05-29 10:05:53.967555: Average global foreground Dice: [0.801]
2022-05-29 10:05:53.971798: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:05:54.524402: lr: 0.003424
2022-05-29 10:05:54.526675: This epoch took 99.584004 s

2022-05-29 10:05:54.534544: 
epoch:  348
2022-05-29 10:07:25.465127: train loss : -0.8257
2022-05-29 10:07:33.622905: validation loss: -0.7358
2022-05-29 10:07:33.639208: Average global foreground Dice: [0.7957]
2022-05-29 10:07:33.641778: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:07:34.122796: lr: 0.003404
2022-05-29 10:07:34.144559: This epoch took 99.602288 s

2022-05-29 10:07:34.166296: 
epoch:  349
2022-05-29 10:09:06.269873: train loss : -0.8177
2022-05-29 10:09:15.539885: validation loss: -0.7282
2022-05-29 10:09:15.583719: Average global foreground Dice: [0.7769]
2022-05-29 10:09:15.614305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:09:16.242873: lr: 0.003384
2022-05-29 10:09:16.265306: saving scheduled checkpoint file...
2022-05-29 10:09:16.349677: saving checkpoint...
2022-05-29 10:09:17.333209: done, saving took 1.05 seconds
2022-05-29 10:09:17.347377: done
2022-05-29 10:09:17.349437: This epoch took 103.160917 s

2022-05-29 10:09:17.351439: 
epoch:  350
2022-05-29 10:10:54.293577: train loss : -0.8129
2022-05-29 10:11:05.636385: validation loss: -0.7486
2022-05-29 10:11:05.641141: Average global foreground Dice: [0.7873]
2022-05-29 10:11:05.643805: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:11:06.122771: lr: 0.003364
2022-05-29 10:11:06.124994: This epoch took 108.771649 s

2022-05-29 10:11:06.126850: 
epoch:  351
2022-05-29 10:12:37.076101: train loss : -0.8073
2022-05-29 10:12:45.079309: validation loss: -0.7324
2022-05-29 10:12:45.082910: Average global foreground Dice: [0.7831]
2022-05-29 10:12:45.085404: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:12:45.587454: lr: 0.003343
2022-05-29 10:12:45.593415: This epoch took 99.464755 s

2022-05-29 10:12:45.595885: 
epoch:  352
2022-05-29 10:14:17.582581: train loss : -0.8141
2022-05-29 10:14:27.902791: validation loss: -0.7520
2022-05-29 10:14:27.907662: Average global foreground Dice: [0.7999]
2022-05-29 10:14:27.910765: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:14:28.409935: lr: 0.003323
2022-05-29 10:14:28.412278: This epoch took 102.814023 s

2022-05-29 10:14:28.414284: 
epoch:  353
2022-05-29 10:16:00.785125: train loss : -0.8341
2022-05-29 10:16:10.524609: validation loss: -0.7332
2022-05-29 10:16:10.544705: Average global foreground Dice: [0.7841]
2022-05-29 10:16:10.571599: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:16:11.170880: lr: 0.003303
2022-05-29 10:16:11.173727: This epoch took 102.757561 s

2022-05-29 10:16:11.176187: 
epoch:  354
2022-05-29 10:17:42.726848: train loss : -0.8264
2022-05-29 10:17:51.388692: validation loss: -0.7564
2022-05-29 10:17:51.392451: Average global foreground Dice: [0.7972]
2022-05-29 10:17:51.395051: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:17:51.866075: lr: 0.003282
2022-05-29 10:17:51.868641: This epoch took 100.690358 s

2022-05-29 10:17:51.870874: 
epoch:  355
2022-05-29 10:19:23.190762: train loss : -0.8241
2022-05-29 10:19:30.498008: validation loss: -0.7420
2022-05-29 10:19:30.501708: Average global foreground Dice: [0.7953]
2022-05-29 10:19:30.503649: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:19:31.009610: lr: 0.003262
2022-05-29 10:19:31.011944: This epoch took 99.138975 s

2022-05-29 10:19:31.014757: 
epoch:  356
2022-05-29 10:21:02.867378: train loss : -0.8160
2022-05-29 10:21:11.537261: validation loss: -0.7681
2022-05-29 10:21:11.561290: Average global foreground Dice: [0.8051]
2022-05-29 10:21:11.582517: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:21:12.144578: lr: 0.003241
2022-05-29 10:21:12.171325: This epoch took 101.154221 s

2022-05-29 10:21:12.175086: 
epoch:  357
2022-05-29 10:22:44.327196: train loss : -0.8253
2022-05-29 10:22:51.188369: validation loss: -0.7595
2022-05-29 10:22:51.191742: Average global foreground Dice: [0.7942]
2022-05-29 10:22:51.193942: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:22:51.651138: lr: 0.003221
2022-05-29 10:22:51.654756: This epoch took 99.477221 s

2022-05-29 10:22:51.657438: 
epoch:  358
2022-05-29 10:24:23.187556: train loss : -0.8295
2022-05-29 10:24:32.664319: validation loss: -0.7634
2022-05-29 10:24:32.702945: Average global foreground Dice: [0.8118]
2022-05-29 10:24:32.726302: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:24:33.313689: lr: 0.003201
2022-05-29 10:24:33.358715: saving checkpoint...
2022-05-29 10:24:34.377843: done, saving took 1.06 seconds
2022-05-29 10:24:34.393158: This epoch took 102.733070 s

2022-05-29 10:24:34.395343: 
epoch:  359
2022-05-29 10:26:05.476660: train loss : -0.8174
2022-05-29 10:26:12.955263: validation loss: -0.7706
2022-05-29 10:26:13.007113: Average global foreground Dice: [0.8107]
2022-05-29 10:26:13.021580: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:26:13.543885: lr: 0.00318
2022-05-29 10:26:13.591957: saving checkpoint...
2022-05-29 10:26:14.638146: done, saving took 1.09 seconds
2022-05-29 10:26:14.650788: This epoch took 100.253437 s

2022-05-29 10:26:14.653086: 
epoch:  360
2022-05-29 10:27:45.396283: train loss : -0.8219
2022-05-29 10:27:54.289667: validation loss: -0.7406
2022-05-29 10:27:54.325728: Average global foreground Dice: [0.7891]
2022-05-29 10:27:54.354901: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:27:54.867337: lr: 0.00316
2022-05-29 10:27:54.888609: This epoch took 100.233587 s

2022-05-29 10:27:54.906407: 
epoch:  361
2022-05-29 10:29:30.212543: train loss : -0.8113
2022-05-29 10:29:37.758434: validation loss: -0.7300
2022-05-29 10:29:37.761658: Average global foreground Dice: [0.778]
2022-05-29 10:29:37.764039: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:29:38.246079: lr: 0.003139
2022-05-29 10:29:38.248914: This epoch took 103.315624 s

2022-05-29 10:29:38.251231: 
epoch:  362
2022-05-29 10:31:11.175047: train loss : -0.8146
2022-05-29 10:31:21.547218: validation loss: -0.7592
2022-05-29 10:31:21.550588: Average global foreground Dice: [0.7969]
2022-05-29 10:31:21.552769: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:31:22.021767: lr: 0.003119
2022-05-29 10:31:22.024567: This epoch took 103.770957 s

2022-05-29 10:31:22.027189: 
epoch:  363
2022-05-29 10:32:53.439208: train loss : -0.8105
2022-05-29 10:33:03.501457: validation loss: -0.7397
2022-05-29 10:33:03.519455: Average global foreground Dice: [0.8196]
2022-05-29 10:33:03.521652: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:33:04.114509: lr: 0.003098
2022-05-29 10:33:04.153079: saving checkpoint...
2022-05-29 10:33:05.159011: done, saving took 1.04 seconds
2022-05-29 10:33:05.172828: This epoch took 103.143064 s

2022-05-29 10:33:05.174606: 
epoch:  364
2022-05-29 10:34:38.390577: train loss : -0.8138
2022-05-29 10:34:46.575976: validation loss: -0.7382
2022-05-29 10:34:46.579751: Average global foreground Dice: [0.7741]
2022-05-29 10:34:46.581957: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:34:47.028505: lr: 0.003078
2022-05-29 10:34:47.031019: This epoch took 101.853421 s

2022-05-29 10:34:47.033196: 
epoch:  365
2022-05-29 10:36:18.529542: train loss : -0.8229
2022-05-29 10:36:24.650063: validation loss: -0.7613
2022-05-29 10:36:24.667912: Average global foreground Dice: [0.802]
2022-05-29 10:36:24.670160: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:36:25.186918: lr: 0.003057
2022-05-29 10:36:25.191308: This epoch took 98.156677 s

2022-05-29 10:36:25.202752: 
epoch:  366
2022-05-29 10:37:57.571829: train loss : -0.8189
2022-05-29 10:38:04.327141: validation loss: -0.7605
2022-05-29 10:38:04.331652: Average global foreground Dice: [0.8002]
2022-05-29 10:38:04.334298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:38:04.926819: lr: 0.003037
2022-05-29 10:38:04.931890: This epoch took 99.717669 s

2022-05-29 10:38:04.934137: 
epoch:  367
2022-05-29 10:39:36.915995: train loss : -0.8342
2022-05-29 10:39:44.056677: validation loss: -0.7274
2022-05-29 10:39:44.059918: Average global foreground Dice: [0.7872]
2022-05-29 10:39:44.061953: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:39:44.592199: lr: 0.003016
2022-05-29 10:39:44.595361: This epoch took 99.658411 s

2022-05-29 10:39:44.597278: 
epoch:  368
2022-05-29 10:41:19.629966: train loss : -0.8336
2022-05-29 10:41:29.174045: validation loss: -0.7614
2022-05-29 10:41:29.179136: Average global foreground Dice: [0.7858]
2022-05-29 10:41:29.181623: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:41:29.648891: lr: 0.002996
2022-05-29 10:41:29.651228: This epoch took 105.051949 s

2022-05-29 10:41:29.653076: 
epoch:  369
2022-05-29 10:43:00.953817: train loss : -0.8305
2022-05-29 10:43:10.387009: validation loss: -0.7543
2022-05-29 10:43:10.391115: Average global foreground Dice: [0.8084]
2022-05-29 10:43:10.393783: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:43:10.865871: lr: 0.002975
2022-05-29 10:43:10.868399: This epoch took 101.213531 s

2022-05-29 10:43:10.870811: 
epoch:  370
2022-05-29 10:44:45.296339: train loss : -0.8360
2022-05-29 10:44:55.191189: validation loss: -0.7704
2022-05-29 10:44:55.205551: Average global foreground Dice: [0.8053]
2022-05-29 10:44:55.222334: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:44:55.808060: lr: 0.002954
2022-05-29 10:44:55.810493: This epoch took 104.936699 s

2022-05-29 10:44:55.813434: 
epoch:  371
2022-05-29 10:46:27.528498: train loss : -0.8233
2022-05-29 10:46:35.082085: validation loss: -0.7226
2022-05-29 10:46:35.092586: Average global foreground Dice: [0.7804]
2022-05-29 10:46:35.095296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:46:35.799275: lr: 0.002934
2022-05-29 10:46:35.802143: This epoch took 99.986626 s

2022-05-29 10:46:35.804403: 
epoch:  372
2022-05-29 10:48:07.835825: train loss : -0.8358
2022-05-29 10:48:17.391624: validation loss: -0.7497
2022-05-29 10:48:17.398128: Average global foreground Dice: [0.7957]
2022-05-29 10:48:17.400466: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:48:17.854388: lr: 0.002913
2022-05-29 10:48:17.856527: This epoch took 102.049785 s

2022-05-29 10:48:17.858568: 
epoch:  373
2022-05-29 10:49:54.072999: train loss : -0.8124
2022-05-29 10:50:03.069929: validation loss: -0.7413
2022-05-29 10:50:03.073611: Average global foreground Dice: [0.7689]
2022-05-29 10:50:03.076124: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:50:03.524509: lr: 0.002892
2022-05-29 10:50:03.528394: This epoch took 105.667897 s

2022-05-29 10:50:03.531518: 
epoch:  374
2022-05-29 10:51:34.484723: train loss : -0.8177
2022-05-29 10:51:41.306929: validation loss: -0.7656
2022-05-29 10:51:41.310890: Average global foreground Dice: [0.8146]
2022-05-29 10:51:41.313275: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:51:41.817816: lr: 0.002872
2022-05-29 10:51:41.830423: This epoch took 98.296780 s

2022-05-29 10:51:41.837372: 
epoch:  375
2022-05-29 10:53:13.454547: train loss : -0.8233
2022-05-29 10:53:21.871278: validation loss: -0.7223
2022-05-29 10:53:21.877822: Average global foreground Dice: [0.7873]
2022-05-29 10:53:21.880088: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:53:22.381554: lr: 0.002851
2022-05-29 10:53:22.384053: This epoch took 100.531869 s

2022-05-29 10:53:22.387084: 
epoch:  376
2022-05-29 10:54:58.377727: train loss : -0.8307
2022-05-29 10:55:07.104039: validation loss: -0.7592
2022-05-29 10:55:07.131777: Average global foreground Dice: [0.8]
2022-05-29 10:55:07.154304: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:55:07.686232: lr: 0.00283
2022-05-29 10:55:07.688789: This epoch took 105.298469 s

2022-05-29 10:55:07.690857: 
epoch:  377
2022-05-29 10:56:39.710659: train loss : -0.8301
2022-05-29 10:56:48.600051: validation loss: -0.7479
2022-05-29 10:56:48.604500: Average global foreground Dice: [0.7893]
2022-05-29 10:56:48.606754: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:56:49.059458: lr: 0.00281
2022-05-29 10:56:49.061759: This epoch took 101.368886 s

2022-05-29 10:56:49.064313: 
epoch:  378
2022-05-29 10:58:20.628271: train loss : -0.8338
2022-05-29 10:58:29.317382: validation loss: -0.7654
2022-05-29 10:58:29.320634: Average global foreground Dice: [0.8094]
2022-05-29 10:58:29.323453: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 10:58:29.842748: lr: 0.002789
2022-05-29 10:58:29.845629: This epoch took 100.779015 s

2022-05-29 10:58:29.848146: 
epoch:  379
2022-05-29 11:00:00.591786: train loss : -0.8338
2022-05-29 11:00:06.320952: validation loss: -0.7432
2022-05-29 11:00:06.324785: Average global foreground Dice: [0.7872]
2022-05-29 11:00:06.327505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:00:06.808636: lr: 0.002768
2022-05-29 11:00:06.812066: This epoch took 96.961155 s

2022-05-29 11:00:06.814472: 
epoch:  380
2022-05-29 11:01:37.669850: train loss : -0.8333
2022-05-29 11:01:45.757010: validation loss: -0.7373
2022-05-29 11:01:45.777799: Average global foreground Dice: [0.7842]
2022-05-29 11:01:45.780096: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:01:46.462729: lr: 0.002747
2022-05-29 11:01:46.485338: This epoch took 99.668731 s

2022-05-29 11:01:46.508300: 
epoch:  381
2022-05-29 11:03:24.408230: train loss : -0.8350
2022-05-29 11:03:33.244529: validation loss: -0.7507
2022-05-29 11:03:33.248736: Average global foreground Dice: [0.7963]
2022-05-29 11:03:33.251179: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:03:33.713118: lr: 0.002727
2022-05-29 11:03:33.723011: This epoch took 107.192718 s

2022-05-29 11:03:33.729274: 
epoch:  382
2022-05-29 11:05:04.304043: train loss : -0.8315
2022-05-29 11:05:11.912117: validation loss: -0.7419
2022-05-29 11:05:11.915678: Average global foreground Dice: [0.7952]
2022-05-29 11:05:11.917943: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:05:12.372785: lr: 0.002706
2022-05-29 11:05:12.375200: This epoch took 98.643584 s

2022-05-29 11:05:12.377180: 
epoch:  383
2022-05-29 11:06:49.915720: train loss : -0.8407
2022-05-29 11:07:01.496223: validation loss: -0.7373
2022-05-29 11:07:01.503191: Average global foreground Dice: [0.7994]
2022-05-29 11:07:01.513307: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:07:02.020994: lr: 0.002685
2022-05-29 11:07:02.026798: This epoch took 109.647703 s

2022-05-29 11:07:02.028796: 
epoch:  384
2022-05-29 11:08:32.557057: train loss : -0.8132
2022-05-29 11:08:40.097705: validation loss: -0.7430
2022-05-29 11:08:40.101370: Average global foreground Dice: [0.7815]
2022-05-29 11:08:40.103580: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:08:40.568318: lr: 0.002664
2022-05-29 11:08:40.570749: This epoch took 98.539948 s

2022-05-29 11:08:40.573104: 
epoch:  385
2022-05-29 11:10:11.344429: train loss : -0.8371
2022-05-29 11:10:18.850552: validation loss: -0.7416
2022-05-29 11:10:18.854017: Average global foreground Dice: [0.7831]
2022-05-29 11:10:18.856262: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:10:19.321363: lr: 0.002643
2022-05-29 11:10:19.323619: This epoch took 98.748309 s

2022-05-29 11:10:19.325818: 
epoch:  386
2022-05-29 11:11:52.909678: train loss : -0.8316
2022-05-29 11:12:01.176078: validation loss: -0.7598
2022-05-29 11:12:01.183434: Average global foreground Dice: [0.7982]
2022-05-29 11:12:01.185840: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:12:01.642612: lr: 0.002622
2022-05-29 11:12:01.645099: This epoch took 102.317311 s

2022-05-29 11:12:01.647149: 
epoch:  387
2022-05-29 11:13:32.996755: train loss : -0.8344
2022-05-29 11:13:41.145673: validation loss: -0.7350
2022-05-29 11:13:41.178802: Average global foreground Dice: [0.7943]
2022-05-29 11:13:41.187847: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:13:41.668719: lr: 0.002601
2022-05-29 11:13:41.683326: This epoch took 100.033732 s

2022-05-29 11:13:41.686985: 
epoch:  388
2022-05-29 11:15:17.307165: train loss : -0.8382
2022-05-29 11:15:25.387365: validation loss: -0.7705
2022-05-29 11:15:25.391037: Average global foreground Dice: [0.8003]
2022-05-29 11:15:25.394305: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:15:25.894044: lr: 0.002581
2022-05-29 11:15:25.897828: This epoch took 104.208796 s

2022-05-29 11:15:25.909371: 
epoch:  389
2022-05-29 11:16:57.606756: train loss : -0.8192
2022-05-29 11:17:06.643136: validation loss: -0.7421
2022-05-29 11:17:06.647179: Average global foreground Dice: [0.7934]
2022-05-29 11:17:06.649350: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:17:07.112552: lr: 0.00256
2022-05-29 11:17:07.115930: This epoch took 101.179640 s

2022-05-29 11:17:07.118078: 
epoch:  390
2022-05-29 11:18:41.799917: train loss : -0.8278
2022-05-29 11:18:51.032164: validation loss: -0.7599
2022-05-29 11:18:51.049779: Average global foreground Dice: [0.795]
2022-05-29 11:18:51.071332: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:18:51.601504: lr: 0.002539
2022-05-29 11:18:51.603895: This epoch took 104.483589 s

2022-05-29 11:18:51.606063: 
epoch:  391
2022-05-29 11:20:22.575677: train loss : -0.8282
2022-05-29 11:20:31.325998: validation loss: -0.7587
2022-05-29 11:20:31.364661: Average global foreground Dice: [0.8068]
2022-05-29 11:20:31.368775: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:20:32.181729: lr: 0.002518
2022-05-29 11:20:32.187753: This epoch took 100.579591 s

2022-05-29 11:20:32.214317: 
epoch:  392
2022-05-29 11:22:03.213023: train loss : -0.8174
2022-05-29 11:22:10.748443: validation loss: -0.7166
2022-05-29 11:22:10.788789: Average global foreground Dice: [0.7862]
2022-05-29 11:22:10.806298: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:22:11.295886: lr: 0.002497
2022-05-29 11:22:11.302031: This epoch took 99.075663 s

2022-05-29 11:22:11.321248: 
epoch:  393
2022-05-29 11:23:42.728191: train loss : -0.8362
2022-05-29 11:23:53.204787: validation loss: -0.7745
2022-05-29 11:23:53.238695: Average global foreground Dice: [0.8062]
2022-05-29 11:23:53.271300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:23:53.803850: lr: 0.002476
2022-05-29 11:23:53.806511: This epoch took 102.481023 s

2022-05-29 11:23:53.808644: 
epoch:  394
2022-05-29 11:25:24.789440: train loss : -0.8243
2022-05-29 11:25:33.460104: validation loss: -0.7153
2022-05-29 11:25:33.464520: Average global foreground Dice: [0.7927]
2022-05-29 11:25:33.467194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:25:34.055213: lr: 0.002455
2022-05-29 11:25:34.057675: This epoch took 100.246604 s

2022-05-29 11:25:34.060228: 
epoch:  395
2022-05-29 11:27:06.689212: train loss : -0.8196
2022-05-29 11:27:17.307847: validation loss: -0.7554
2022-05-29 11:27:17.331704: Average global foreground Dice: [0.8001]
2022-05-29 11:27:17.348309: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:27:17.928753: lr: 0.002434
2022-05-29 11:27:17.930999: This epoch took 103.868682 s

2022-05-29 11:27:17.933147: 
epoch:  396
2022-05-29 11:28:48.497937: train loss : -0.8193
2022-05-29 11:28:55.341119: validation loss: -0.7543
2022-05-29 11:28:55.345032: Average global foreground Dice: [0.8022]
2022-05-29 11:28:55.346987: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:28:55.827923: lr: 0.002413
2022-05-29 11:28:55.838058: This epoch took 97.902872 s

2022-05-29 11:28:55.841191: 
epoch:  397
2022-05-29 11:30:29.510005: train loss : -0.8276
2022-05-29 11:30:37.863168: validation loss: -0.7317
2022-05-29 11:30:37.914901: Average global foreground Dice: [0.7896]
2022-05-29 11:30:37.935471: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:30:38.602549: lr: 0.002391
2022-05-29 11:30:38.604761: This epoch took 102.761441 s

2022-05-29 11:30:38.606715: 
epoch:  398
2022-05-29 11:32:10.114988: train loss : -0.8376
2022-05-29 11:32:17.452034: validation loss: -0.7530
2022-05-29 11:32:17.455172: Average global foreground Dice: [0.8006]
2022-05-29 11:32:17.457332: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:32:17.919745: lr: 0.00237
2022-05-29 11:32:17.922351: This epoch took 99.313768 s

2022-05-29 11:32:17.924355: 
epoch:  399
2022-05-29 11:33:49.195627: train loss : -0.8399
2022-05-29 11:34:01.166508: validation loss: -0.7331
2022-05-29 11:34:01.174639: Average global foreground Dice: [0.7979]
2022-05-29 11:34:01.177222: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:34:02.153990: lr: 0.002349
2022-05-29 11:34:02.173324: saving scheduled checkpoint file...
2022-05-29 11:34:02.267311: saving checkpoint...
2022-05-29 11:34:03.432670: done, saving took 1.22 seconds
2022-05-29 11:34:03.458349: done
2022-05-29 11:34:03.460653: This epoch took 105.534476 s

2022-05-29 11:34:03.463006: 
epoch:  400
2022-05-29 11:35:34.719008: train loss : -0.8430
2022-05-29 11:35:44.843074: validation loss: -0.7346
2022-05-29 11:35:44.849909: Average global foreground Dice: [0.7685]
2022-05-29 11:35:44.851935: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:35:45.359763: lr: 0.002328
2022-05-29 11:35:45.362240: This epoch took 101.896818 s

2022-05-29 11:35:45.365112: 
epoch:  401
2022-05-29 11:37:18.167146: train loss : -0.8344
2022-05-29 11:37:29.764359: validation loss: -0.7565
2022-05-29 11:37:29.775352: Average global foreground Dice: [0.8029]
2022-05-29 11:37:29.779441: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:37:30.406204: lr: 0.002307
2022-05-29 11:37:30.408556: This epoch took 105.040899 s

2022-05-29 11:37:30.434411: 
epoch:  402
2022-05-29 11:39:06.115194: train loss : -0.8352
2022-05-29 11:39:15.146718: validation loss: -0.7432
2022-05-29 11:39:15.179666: Average global foreground Dice: [0.7975]
2022-05-29 11:39:15.209293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:39:15.838892: lr: 0.002286
2022-05-29 11:39:15.841558: This epoch took 105.387166 s

2022-05-29 11:39:15.844223: 
epoch:  403
2022-05-29 11:40:48.480453: train loss : -0.8309
2022-05-29 11:40:57.594764: validation loss: -0.7465
2022-05-29 11:40:57.598832: Average global foreground Dice: [0.7834]
2022-05-29 11:40:57.601420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:40:58.135223: lr: 0.002264
2022-05-29 11:40:58.154404: This epoch took 102.307681 s

2022-05-29 11:40:58.156942: 
epoch:  404
2022-05-29 11:42:29.554583: train loss : -0.8254
2022-05-29 11:42:40.834088: validation loss: -0.7426
2022-05-29 11:42:40.837778: Average global foreground Dice: [0.7983]
2022-05-29 11:42:40.839705: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:42:41.307133: lr: 0.002243
2022-05-29 11:42:41.309768: This epoch took 103.150063 s

2022-05-29 11:42:41.312216: 
epoch:  405
2022-05-29 11:44:13.612711: train loss : -0.8144
2022-05-29 11:44:22.051850: validation loss: -0.7495
2022-05-29 11:44:22.067379: Average global foreground Dice: [0.7889]
2022-05-29 11:44:22.073824: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:44:22.580335: lr: 0.002222
2022-05-29 11:44:22.585879: This epoch took 101.271574 s

2022-05-29 11:44:22.588043: 
epoch:  406
2022-05-29 11:45:53.697975: train loss : -0.8287
2022-05-29 11:46:02.524749: validation loss: -0.7442
2022-05-29 11:46:02.528457: Average global foreground Dice: [0.7843]
2022-05-29 11:46:02.530616: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:46:02.990788: lr: 0.002201
2022-05-29 11:46:02.993374: This epoch took 100.402830 s

2022-05-29 11:46:02.995476: 
epoch:  407
2022-05-29 11:47:34.838443: train loss : -0.8139
2022-05-29 11:47:44.645559: validation loss: -0.7248
2022-05-29 11:47:44.651397: Average global foreground Dice: [0.783]
2022-05-29 11:47:44.653860: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:47:45.147792: lr: 0.002179
2022-05-29 11:47:45.149996: This epoch took 102.151950 s

2022-05-29 11:47:45.151945: 
epoch:  408
2022-05-29 11:49:16.554841: train loss : -0.8328
2022-05-29 11:49:25.456315: validation loss: -0.7411
2022-05-29 11:49:25.460735: Average global foreground Dice: [0.7947]
2022-05-29 11:49:25.462897: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:49:26.031810: lr: 0.002158
2022-05-29 11:49:26.038935: This epoch took 100.884963 s

2022-05-29 11:49:26.041263: 
epoch:  409
2022-05-29 11:50:56.304821: train loss : -0.8280
2022-05-29 11:51:03.909131: validation loss: -0.7510
2022-05-29 11:51:03.927724: Average global foreground Dice: [0.8021]
2022-05-29 11:51:03.940969: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:51:04.508548: lr: 0.002137
2022-05-29 11:51:04.526220: This epoch took 98.482584 s

2022-05-29 11:51:04.553294: 
epoch:  410
2022-05-29 11:52:39.393910: train loss : -0.8304
2022-05-29 11:52:47.845122: validation loss: -0.7690
2022-05-29 11:52:47.848365: Average global foreground Dice: [0.7975]
2022-05-29 11:52:47.850439: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:52:48.412436: lr: 0.002115
2022-05-29 11:52:48.414784: This epoch took 103.844477 s

2022-05-29 11:52:48.416940: 
epoch:  411
2022-05-29 11:54:18.990984: train loss : -0.8308
2022-05-29 11:54:27.075283: validation loss: -0.7321
2022-05-29 11:54:27.078917: Average global foreground Dice: [0.7779]
2022-05-29 11:54:27.081677: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:54:27.580435: lr: 0.002094
2022-05-29 11:54:27.592967: This epoch took 99.173816 s

2022-05-29 11:54:27.598858: 
epoch:  412
2022-05-29 11:55:57.631958: train loss : -0.8402
2022-05-29 11:56:04.073524: validation loss: -0.7596
2022-05-29 11:56:04.077542: Average global foreground Dice: [0.7959]
2022-05-29 11:56:04.080075: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:56:04.546546: lr: 0.002072
2022-05-29 11:56:04.549092: This epoch took 96.947341 s

2022-05-29 11:56:04.551167: 
epoch:  413
2022-05-29 11:57:36.482600: train loss : -0.8513
2022-05-29 11:57:44.898941: validation loss: -0.7457
2022-05-29 11:57:44.902841: Average global foreground Dice: [0.7862]
2022-05-29 11:57:44.905096: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:57:45.363150: lr: 0.002051
2022-05-29 11:57:45.365508: This epoch took 100.812217 s

2022-05-29 11:57:45.372931: 
epoch:  414
2022-05-29 11:59:17.092408: train loss : -0.8455
2022-05-29 11:59:25.570976: validation loss: -0.7388
2022-05-29 11:59:25.575320: Average global foreground Dice: [0.7985]
2022-05-29 11:59:25.577941: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 11:59:26.087882: lr: 0.00203
2022-05-29 11:59:26.090186: This epoch took 100.715301 s

2022-05-29 11:59:26.092013: 
epoch:  415
2022-05-29 12:00:57.461275: train loss : -0.8481
2022-05-29 12:01:04.644144: validation loss: -0.7364
2022-05-29 12:01:04.648164: Average global foreground Dice: [0.778]
2022-05-29 12:01:04.650761: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:01:05.146846: lr: 0.002008
2022-05-29 12:01:05.149461: This epoch took 99.055692 s

2022-05-29 12:01:05.151496: 
epoch:  416
2022-05-29 12:02:35.320238: train loss : -0.8373
2022-05-29 12:02:41.530726: validation loss: -0.7646
2022-05-29 12:02:41.541080: Average global foreground Dice: [0.8064]
2022-05-29 12:02:41.553920: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:02:42.086809: lr: 0.001987
2022-05-29 12:02:42.089286: This epoch took 96.935612 s

2022-05-29 12:02:42.091485: 
epoch:  417
2022-05-29 12:04:13.322511: train loss : -0.8352
2022-05-29 12:04:23.510264: validation loss: -0.7493
2022-05-29 12:04:23.521791: Average global foreground Dice: [0.7829]
2022-05-29 12:04:23.529933: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:04:24.065431: lr: 0.001965
2022-05-29 12:04:24.067649: This epoch took 101.973925 s

2022-05-29 12:04:24.069688: 
epoch:  418
2022-05-29 12:06:01.657448: train loss : -0.8319
2022-05-29 12:06:11.216606: validation loss: -0.7368
2022-05-29 12:06:11.237923: Average global foreground Dice: [0.796]
2022-05-29 12:06:11.257606: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:06:11.894093: lr: 0.001943
2022-05-29 12:06:11.926312: This epoch took 107.854200 s

2022-05-29 12:06:11.949274: 
epoch:  419
2022-05-29 12:07:45.612526: train loss : -0.8356
2022-05-29 12:07:56.064400: validation loss: -0.7532
2022-05-29 12:07:56.068637: Average global foreground Dice: [0.8015]
2022-05-29 12:07:56.071254: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:07:56.542104: lr: 0.001922
2022-05-29 12:07:56.544995: This epoch took 104.577688 s

2022-05-29 12:07:56.547436: 
epoch:  420
2022-05-29 12:09:31.915604: train loss : -0.8475
2022-05-29 12:09:40.042448: validation loss: -0.7438
2022-05-29 12:09:40.064804: Average global foreground Dice: [0.7905]
2022-05-29 12:09:40.086503: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:09:40.592450: lr: 0.0019
2022-05-29 12:09:40.614214: This epoch took 104.064342 s

2022-05-29 12:09:40.619259: 
epoch:  421
2022-05-29 12:11:11.659553: train loss : -0.8486
2022-05-29 12:11:19.202966: validation loss: -0.7644
2022-05-29 12:11:19.206115: Average global foreground Dice: [0.8117]
2022-05-29 12:11:19.208467: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:11:19.668872: lr: 0.001879
2022-05-29 12:11:19.671467: This epoch took 99.049882 s

2022-05-29 12:11:19.673450: 
epoch:  422
2022-05-29 12:12:50.259744: train loss : -0.8399
2022-05-29 12:12:57.773501: validation loss: -0.7471
2022-05-29 12:12:57.776678: Average global foreground Dice: [0.7891]
2022-05-29 12:12:57.778708: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:12:58.267326: lr: 0.001857
2022-05-29 12:12:58.269753: This epoch took 98.594319 s

2022-05-29 12:12:58.271860: 
epoch:  423
2022-05-29 12:14:29.333153: train loss : -0.8385
2022-05-29 12:14:37.935319: validation loss: -0.7481
2022-05-29 12:14:37.949655: Average global foreground Dice: [0.8036]
2022-05-29 12:14:37.967265: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:14:38.450850: lr: 0.001835
2022-05-29 12:14:38.453471: This epoch took 100.179459 s

2022-05-29 12:14:38.461013: 
epoch:  424
2022-05-29 12:16:12.419029: train loss : -0.8373
2022-05-29 12:16:20.695461: validation loss: -0.7711
2022-05-29 12:16:20.727845: Average global foreground Dice: [0.806]
2022-05-29 12:16:20.749296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:16:21.373972: lr: 0.001813
2022-05-29 12:16:21.378709: This epoch took 102.915492 s

2022-05-29 12:16:21.380929: 
epoch:  425
2022-05-29 12:17:53.246201: train loss : -0.8305
2022-05-29 12:18:01.542526: validation loss: -0.7262
2022-05-29 12:18:01.555473: Average global foreground Dice: [0.7962]
2022-05-29 12:18:01.589474: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:18:02.153478: lr: 0.001792
2022-05-29 12:18:02.155945: This epoch took 100.772704 s

2022-05-29 12:18:02.157980: 
epoch:  426
2022-05-29 12:19:34.677583: train loss : -0.8471
2022-05-29 12:19:44.290547: validation loss: -0.7664
2022-05-29 12:19:44.314860: Average global foreground Dice: [0.8082]
2022-05-29 12:19:44.338303: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:19:45.301756: lr: 0.00177
2022-05-29 12:19:45.377266: saving checkpoint...
2022-05-29 12:19:46.856327: done, saving took 1.53 seconds
2022-05-29 12:19:46.932285: This epoch took 104.771993 s

2022-05-29 12:19:46.950408: 
epoch:  427
2022-05-29 12:21:21.517204: train loss : -0.8380
2022-05-29 12:21:30.432609: validation loss: -0.7556
2022-05-29 12:21:30.439582: Average global foreground Dice: [0.7899]
2022-05-29 12:21:30.442074: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:21:30.903102: lr: 0.001748
2022-05-29 12:21:30.906871: This epoch took 103.953555 s

2022-05-29 12:21:30.908790: 
epoch:  428
2022-05-29 12:23:02.819705: train loss : -0.8344
2022-05-29 12:23:14.733902: validation loss: -0.7581
2022-05-29 12:23:14.756074: Average global foreground Dice: [0.8054]
2022-05-29 12:23:14.758836: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:23:15.231820: lr: 0.001726
2022-05-29 12:23:15.265501: saving checkpoint...
2022-05-29 12:23:16.350128: done, saving took 1.12 seconds
2022-05-29 12:23:16.363160: This epoch took 105.450785 s

2022-05-29 12:23:16.365198: 
epoch:  429
2022-05-29 12:24:48.762476: train loss : -0.8350
2022-05-29 12:24:58.071616: validation loss: -0.7383
2022-05-29 12:24:58.074932: Average global foreground Dice: [0.7802]
2022-05-29 12:24:58.078058: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:24:58.546550: lr: 0.001704
2022-05-29 12:24:58.549436: This epoch took 102.182234 s

2022-05-29 12:24:58.551814: 
epoch:  430
2022-05-29 12:26:31.103487: train loss : -0.8399
2022-05-29 12:26:42.027385: validation loss: -0.7513
2022-05-29 12:26:42.031119: Average global foreground Dice: [0.8058]
2022-05-29 12:26:42.033458: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:26:42.523527: lr: 0.001682
2022-05-29 12:26:42.526117: This epoch took 103.971599 s

2022-05-29 12:26:42.528164: 
epoch:  431
2022-05-29 12:28:12.882108: train loss : -0.8431
2022-05-29 12:28:19.776988: validation loss: -0.7601
2022-05-29 12:28:19.780614: Average global foreground Dice: [0.8034]
2022-05-29 12:28:19.782672: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:28:20.296440: lr: 0.00166
2022-05-29 12:28:20.298822: This epoch took 97.768689 s

2022-05-29 12:28:20.300728: 
epoch:  432
2022-05-29 12:29:51.828776: train loss : -0.8457
2022-05-29 12:30:01.376081: validation loss: -0.7574
2022-05-29 12:30:01.387924: Average global foreground Dice: [0.8015]
2022-05-29 12:30:01.410529: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:30:02.014462: lr: 0.001638
2022-05-29 12:30:02.056271: saving checkpoint...
2022-05-29 12:30:03.075473: done, saving took 1.06 seconds
2022-05-29 12:30:03.089365: This epoch took 102.786548 s

2022-05-29 12:30:03.091553: 
epoch:  433
2022-05-29 12:31:33.583428: train loss : -0.8513
2022-05-29 12:31:44.199335: validation loss: -0.7697
2022-05-29 12:31:44.210274: Average global foreground Dice: [0.8062]
2022-05-29 12:31:44.220146: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:31:44.712800: lr: 0.001616
2022-05-29 12:31:44.762666: saving checkpoint...
2022-05-29 12:31:45.803470: done, saving took 1.09 seconds
2022-05-29 12:31:45.818453: This epoch took 102.724800 s

2022-05-29 12:31:45.820579: 
epoch:  434
2022-05-29 12:33:23.157927: train loss : -0.8579
2022-05-29 12:33:32.512944: validation loss: -0.7458
2022-05-29 12:33:32.517461: Average global foreground Dice: [0.7862]
2022-05-29 12:33:32.519962: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:33:33.084536: lr: 0.001594
2022-05-29 12:33:33.087533: This epoch took 107.264606 s

2022-05-29 12:33:33.090864: 
epoch:  435
2022-05-29 12:35:06.681490: train loss : -0.8333
2022-05-29 12:35:16.418859: validation loss: -0.7421
2022-05-29 12:35:16.425115: Average global foreground Dice: [0.8002]
2022-05-29 12:35:16.457337: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:35:16.937876: lr: 0.001572
2022-05-29 12:35:16.939989: This epoch took 103.846587 s

2022-05-29 12:35:16.941852: 
epoch:  436
2022-05-29 12:36:50.001070: train loss : -0.8404
2022-05-29 12:36:56.891984: validation loss: -0.7560
2022-05-29 12:36:56.897918: Average global foreground Dice: [0.8112]
2022-05-29 12:36:56.904194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:36:57.403001: lr: 0.00155
2022-05-29 12:36:57.465527: saving checkpoint...
2022-05-29 12:36:58.460695: done, saving took 1.05 seconds
2022-05-29 12:36:58.474124: This epoch took 101.530215 s

2022-05-29 12:36:58.476423: 
epoch:  437
2022-05-29 12:38:31.550379: train loss : -0.8472
2022-05-29 12:38:40.616900: validation loss: -0.7537
2022-05-29 12:38:40.621594: Average global foreground Dice: [0.8022]
2022-05-29 12:38:40.624076: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:38:41.151551: lr: 0.001528
2022-05-29 12:38:41.179267: saving checkpoint...
2022-05-29 12:38:42.349385: done, saving took 1.20 seconds
2022-05-29 12:38:42.365166: This epoch took 103.886581 s

2022-05-29 12:38:42.367664: 
epoch:  438
2022-05-29 12:40:12.728907: train loss : -0.8485
2022-05-29 12:40:19.637009: validation loss: -0.7850
2022-05-29 12:40:19.640057: Average global foreground Dice: [0.8188]
2022-05-29 12:40:19.642033: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:40:20.109904: lr: 0.001506
2022-05-29 12:40:20.154012: saving checkpoint...
2022-05-29 12:40:21.107950: done, saving took 1.00 seconds
2022-05-29 12:40:21.123178: This epoch took 98.753050 s

2022-05-29 12:40:21.125792: 
epoch:  439
2022-05-29 12:41:51.985226: train loss : -0.8447
2022-05-29 12:42:01.312848: validation loss: -0.7240
2022-05-29 12:42:01.346052: Average global foreground Dice: [0.809]
2022-05-29 12:42:01.363511: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:42:02.251065: lr: 0.001483
2022-05-29 12:42:02.313604: saving checkpoint...
2022-05-29 12:42:03.710622: done, saving took 1.44 seconds
2022-05-29 12:42:03.761459: This epoch took 102.633212 s

2022-05-29 12:42:03.784365: 
epoch:  440
2022-05-29 12:43:37.722603: train loss : -0.8467
2022-05-29 12:43:46.895106: validation loss: -0.7372
2022-05-29 12:43:46.926171: Average global foreground Dice: [0.7862]
2022-05-29 12:43:46.939296: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:43:47.474740: lr: 0.001461
2022-05-29 12:43:47.479276: This epoch took 103.672995 s

2022-05-29 12:43:47.481329: 
epoch:  441
2022-05-29 12:45:19.464224: train loss : -0.8493
2022-05-29 12:45:30.513813: validation loss: -0.7348
2022-05-29 12:45:30.517005: Average global foreground Dice: [0.7855]
2022-05-29 12:45:30.519463: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:45:30.977364: lr: 0.001439
2022-05-29 12:45:30.980426: This epoch took 103.496910 s

2022-05-29 12:45:30.982648: 
epoch:  442
2022-05-29 12:47:02.034049: train loss : -0.8481
2022-05-29 12:47:11.295649: validation loss: -0.7431
2022-05-29 12:47:11.299707: Average global foreground Dice: [0.7923]
2022-05-29 12:47:11.302964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:47:11.780909: lr: 0.001416
2022-05-29 12:47:11.783442: This epoch took 100.798595 s

2022-05-29 12:47:11.785767: 
epoch:  443
2022-05-29 12:48:42.493432: train loss : -0.8417
2022-05-29 12:48:51.358116: validation loss: -0.7494
2022-05-29 12:48:51.361666: Average global foreground Dice: [0.8089]
2022-05-29 12:48:51.364038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:48:51.823029: lr: 0.001394
2022-05-29 12:48:51.825286: This epoch took 100.037527 s

2022-05-29 12:48:51.827864: 
epoch:  444
2022-05-29 12:50:22.927308: train loss : -0.8456
2022-05-29 12:50:32.784758: validation loss: -0.7653
2022-05-29 12:50:32.801288: Average global foreground Dice: [0.8093]
2022-05-29 12:50:32.813693: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:50:33.363412: lr: 0.001372
2022-05-29 12:50:33.392322: This epoch took 101.562307 s

2022-05-29 12:50:33.412401: 
epoch:  445
2022-05-29 12:52:07.369138: train loss : -0.8451
2022-05-29 12:52:17.573093: validation loss: -0.7564
2022-05-29 12:52:17.577594: Average global foreground Dice: [0.7967]
2022-05-29 12:52:17.580765: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:52:18.076370: lr: 0.001349
2022-05-29 12:52:18.082986: This epoch took 104.655676 s

2022-05-29 12:52:18.085338: 
epoch:  446
2022-05-29 12:53:49.281010: train loss : -0.8470
2022-05-29 12:53:58.002228: validation loss: -0.7572
2022-05-29 12:53:58.009144: Average global foreground Dice: [0.7908]
2022-05-29 12:53:58.011603: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:53:58.459817: lr: 0.001327
2022-05-29 12:53:58.462585: This epoch took 100.374835 s

2022-05-29 12:53:58.464452: 
epoch:  447
2022-05-29 12:55:28.794397: train loss : -0.8501
2022-05-29 12:55:34.826668: validation loss: -0.7558
2022-05-29 12:55:34.829829: Average global foreground Dice: [0.8045]
2022-05-29 12:55:34.831852: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:55:35.330404: lr: 0.001304
2022-05-29 12:55:35.332932: This epoch took 96.866597 s

2022-05-29 12:55:35.336004: 
epoch:  448
2022-05-29 12:57:05.560004: train loss : -0.8437
2022-05-29 12:57:11.554630: validation loss: -0.7505
2022-05-29 12:57:11.558928: Average global foreground Dice: [0.8009]
2022-05-29 12:57:11.560938: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:57:12.044089: lr: 0.001282
2022-05-29 12:57:12.047324: This epoch took 96.708372 s

2022-05-29 12:57:12.050602: 
epoch:  449
2022-05-29 12:58:43.211297: train loss : -0.8538
2022-05-29 12:58:52.142521: validation loss: -0.7723
2022-05-29 12:58:52.146448: Average global foreground Dice: [0.8025]
2022-05-29 12:58:52.149216: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 12:58:52.646392: lr: 0.001259
2022-05-29 12:58:52.658307: saving scheduled checkpoint file...
2022-05-29 12:58:52.712550: saving checkpoint...
2022-05-29 12:58:53.697291: done, saving took 1.04 seconds
2022-05-29 12:58:53.713805: done
2022-05-29 12:58:53.715793: This epoch took 101.663169 s

2022-05-29 12:58:53.717773: 
epoch:  450
2022-05-29 13:00:24.804019: train loss : -0.8440
2022-05-29 13:00:34.112384: validation loss: -0.7684
2022-05-29 13:00:34.116977: Average global foreground Dice: [0.7964]
2022-05-29 13:00:34.119419: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:00:34.670346: lr: 0.001236
2022-05-29 13:00:34.673159: This epoch took 100.953343 s

2022-05-29 13:00:34.686357: 
epoch:  451
2022-05-29 13:02:04.880679: train loss : -0.8501
2022-05-29 13:02:12.235050: validation loss: -0.7580
2022-05-29 13:02:12.238596: Average global foreground Dice: [0.804]
2022-05-29 13:02:12.240703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:02:12.788049: lr: 0.001214
2022-05-29 13:02:12.790526: This epoch took 98.099136 s

2022-05-29 13:02:12.792580: 
epoch:  452
2022-05-29 13:03:46.471567: train loss : -0.8475
2022-05-29 13:03:54.296756: validation loss: -0.7754
2022-05-29 13:03:54.303088: Average global foreground Dice: [0.813]
2022-05-29 13:03:54.319489: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:03:54.909235: lr: 0.001191
2022-05-29 13:03:54.911846: This epoch took 102.117303 s

2022-05-29 13:03:54.913985: 
epoch:  453
2022-05-29 13:05:30.035210: train loss : -0.8622
2022-05-29 13:05:38.817795: validation loss: -0.7588
2022-05-29 13:05:38.844133: Average global foreground Dice: [0.8004]
2022-05-29 13:05:38.846956: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:05:39.310404: lr: 0.001168
2022-05-29 13:05:39.322370: This epoch took 104.406322 s

2022-05-29 13:05:39.324753: 
epoch:  454
2022-05-29 13:07:10.676910: train loss : -0.8476
2022-05-29 13:07:20.022438: validation loss: -0.7409
2022-05-29 13:07:20.026573: Average global foreground Dice: [0.794]
2022-05-29 13:07:20.029008: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:07:20.545904: lr: 0.001145
2022-05-29 13:07:20.573356: This epoch took 101.246173 s

2022-05-29 13:07:20.595294: 
epoch:  455
2022-05-29 13:08:52.190443: train loss : -0.8587
2022-05-29 13:09:01.765000: validation loss: -0.7721
2022-05-29 13:09:01.768701: Average global foreground Dice: [0.81]
2022-05-29 13:09:01.771415: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:09:02.225885: lr: 0.001122
2022-05-29 13:09:02.228597: This epoch took 101.611308 s

2022-05-29 13:09:02.230934: 
epoch:  456
2022-05-29 13:10:34.006499: train loss : -0.8456
2022-05-29 13:10:42.905725: validation loss: -0.7690
2022-05-29 13:10:42.909545: Average global foreground Dice: [0.7982]
2022-05-29 13:10:42.912174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:10:43.395188: lr: 0.001099
2022-05-29 13:10:43.397398: This epoch took 101.164865 s

2022-05-29 13:10:43.399450: 
epoch:  457
2022-05-29 13:12:16.840064: train loss : -0.8547
2022-05-29 13:12:24.776452: validation loss: -0.7695
2022-05-29 13:12:24.821734: Average global foreground Dice: [0.8002]
2022-05-29 13:12:24.841454: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:12:25.638342: lr: 0.001076
2022-05-29 13:12:25.652519: This epoch took 102.251025 s

2022-05-29 13:12:25.663507: 
epoch:  458
2022-05-29 13:13:57.002033: train loss : -0.8471
2022-05-29 13:14:06.022793: validation loss: -0.7516
2022-05-29 13:14:06.026993: Average global foreground Dice: [0.8061]
2022-05-29 13:14:06.029386: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:14:06.564287: lr: 0.001053
2022-05-29 13:14:06.567021: This epoch took 100.875094 s

2022-05-29 13:14:06.569202: 
epoch:  459
2022-05-29 13:15:42.386217: train loss : -0.8474
2022-05-29 13:15:53.206162: validation loss: -0.7632
2022-05-29 13:15:53.210427: Average global foreground Dice: [0.8018]
2022-05-29 13:15:53.244625: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:15:53.945590: lr: 0.00103
2022-05-29 13:15:53.978158: This epoch took 107.402222 s

2022-05-29 13:15:53.995063: 
epoch:  460
2022-05-29 13:17:29.101264: train loss : -0.8425
2022-05-29 13:17:37.449861: validation loss: -0.7447
2022-05-29 13:17:37.454279: Average global foreground Dice: [0.7834]
2022-05-29 13:17:37.456846: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:17:37.927965: lr: 0.001007
2022-05-29 13:17:37.930058: This epoch took 103.913768 s

2022-05-29 13:17:37.931970: 
epoch:  461
2022-05-29 13:19:08.832664: train loss : -0.8474
2022-05-29 13:19:19.005693: validation loss: -0.7364
2022-05-29 13:19:19.009617: Average global foreground Dice: [0.7983]
2022-05-29 13:19:19.011703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:19:19.515306: lr: 0.000983
2022-05-29 13:19:19.517642: This epoch took 101.583723 s

2022-05-29 13:19:19.519661: 
epoch:  462
2022-05-29 13:20:51.704962: train loss : -0.8435
2022-05-29 13:21:01.698836: validation loss: -0.7603
2022-05-29 13:21:01.702354: Average global foreground Dice: [0.8003]
2022-05-29 13:21:01.704622: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:21:02.171790: lr: 0.00096
2022-05-29 13:21:02.174026: This epoch took 102.652445 s

2022-05-29 13:21:02.176313: 
epoch:  463
2022-05-29 13:22:32.907896: train loss : -0.8539
2022-05-29 13:22:41.231047: validation loss: -0.7518
2022-05-29 13:22:41.235553: Average global foreground Dice: [0.8158]
2022-05-29 13:22:41.238039: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:22:41.762846: lr: 0.000937
2022-05-29 13:22:41.765703: This epoch took 99.586961 s

2022-05-29 13:22:41.769011: 
epoch:  464
2022-05-29 13:24:14.845876: train loss : -0.8408
2022-05-29 13:24:23.070392: validation loss: -0.7696
2022-05-29 13:24:23.074175: Average global foreground Dice: [0.8137]
2022-05-29 13:24:23.076184: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:24:23.552758: lr: 0.000913
2022-05-29 13:24:23.590866: saving checkpoint...
2022-05-29 13:24:24.585426: done, saving took 1.03 seconds
2022-05-29 13:24:24.599841: This epoch took 102.828547 s

2022-05-29 13:24:24.601964: 
epoch:  465
2022-05-29 13:25:56.661984: train loss : -0.8645
2022-05-29 13:26:06.480549: validation loss: -0.7514
2022-05-29 13:26:06.494389: Average global foreground Dice: [0.8045]
2022-05-29 13:26:06.497320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:26:07.158010: lr: 0.00089
2022-05-29 13:26:07.230947: saving checkpoint...
2022-05-29 13:26:08.248456: done, saving took 1.06 seconds
2022-05-29 13:26:08.260888: This epoch took 103.656514 s

2022-05-29 13:26:08.262990: 
epoch:  466
2022-05-29 13:27:38.613492: train loss : -0.8522
2022-05-29 13:27:46.007831: validation loss: -0.7523
2022-05-29 13:27:46.011141: Average global foreground Dice: [0.7892]
2022-05-29 13:27:46.013417: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:27:46.467076: lr: 0.000866
2022-05-29 13:27:46.472686: This epoch took 98.207778 s

2022-05-29 13:27:46.474853: 
epoch:  467
2022-05-29 13:29:19.091258: train loss : -0.8533
2022-05-29 13:29:27.932882: validation loss: -0.7675
2022-05-29 13:29:27.967796: Average global foreground Dice: [0.804]
2022-05-29 13:29:27.983480: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:29:29.064631: lr: 0.000842
2022-05-29 13:29:29.092330: This epoch took 102.613513 s

2022-05-29 13:29:29.103838: 
epoch:  468
2022-05-29 13:30:59.622885: train loss : -0.8561
2022-05-29 13:31:07.864197: validation loss: -0.7605
2022-05-29 13:31:07.867620: Average global foreground Dice: [0.7993]
2022-05-29 13:31:07.869689: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:31:08.386512: lr: 0.000819
2022-05-29 13:31:08.389058: This epoch took 99.265116 s

2022-05-29 13:31:08.391130: 
epoch:  469
2022-05-29 13:32:42.865260: train loss : -0.8483
2022-05-29 13:32:51.703852: validation loss: -0.7619
2022-05-29 13:32:51.707831: Average global foreground Dice: [0.8063]
2022-05-29 13:32:51.710457: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:32:52.162750: lr: 0.000795
2022-05-29 13:32:52.165131: This epoch took 103.771951 s

2022-05-29 13:32:52.167168: 
epoch:  470
2022-05-29 13:34:25.729914: train loss : -0.8549
2022-05-29 13:34:35.179957: validation loss: -0.7426
2022-05-29 13:34:35.185573: Average global foreground Dice: [0.8106]
2022-05-29 13:34:35.187787: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:34:35.683845: lr: 0.000771
2022-05-29 13:34:35.726638: saving checkpoint...
2022-05-29 13:34:36.749816: done, saving took 1.06 seconds
2022-05-29 13:34:36.765403: This epoch took 104.596232 s

2022-05-29 13:34:36.767656: 
epoch:  471
2022-05-29 13:36:12.374259: train loss : -0.8596
2022-05-29 13:36:24.430786: validation loss: -0.7557
2022-05-29 13:36:24.462688: Average global foreground Dice: [0.8061]
2022-05-29 13:36:24.480316: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:36:25.075444: lr: 0.000747
2022-05-29 13:36:25.126796: saving checkpoint...
2022-05-29 13:36:26.147074: done, saving took 1.07 seconds
2022-05-29 13:36:26.163213: This epoch took 109.393326 s

2022-05-29 13:36:26.175091: 
epoch:  472
2022-05-29 13:37:58.498095: train loss : -0.8502
2022-05-29 13:38:06.074148: validation loss: -0.7378
2022-05-29 13:38:06.077323: Average global foreground Dice: [0.7906]
2022-05-29 13:38:06.079554: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:38:06.532926: lr: 0.000723
2022-05-29 13:38:06.535120: This epoch took 100.357061 s

2022-05-29 13:38:06.537369: 
epoch:  473
2022-05-29 13:39:38.228171: train loss : -0.8633
2022-05-29 13:39:45.579944: validation loss: -0.7563
2022-05-29 13:39:45.588260: Average global foreground Dice: [0.7882]
2022-05-29 13:39:45.597508: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:39:46.320503: lr: 0.000699
2022-05-29 13:39:46.341306: This epoch took 99.801826 s

2022-05-29 13:39:46.374290: 
epoch:  474
2022-05-29 13:41:22.693118: train loss : -0.8465
2022-05-29 13:41:30.405086: validation loss: -0.7731
2022-05-29 13:41:30.420687: Average global foreground Dice: [0.8062]
2022-05-29 13:41:30.438310: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:41:31.075223: lr: 0.000675
2022-05-29 13:41:31.076936: This epoch took 104.680649 s

2022-05-29 13:41:31.079462: 
epoch:  475
2022-05-29 13:43:01.811947: train loss : -0.8417
2022-05-29 13:43:10.521267: validation loss: -0.7515
2022-05-29 13:43:10.525258: Average global foreground Dice: [0.8053]
2022-05-29 13:43:10.527454: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:43:10.977383: lr: 0.00065
2022-05-29 13:43:10.979569: This epoch took 99.898032 s

2022-05-29 13:43:10.981740: 
epoch:  476
2022-05-29 13:44:41.501450: train loss : -0.8584
2022-05-29 13:44:49.825860: validation loss: -0.7557
2022-05-29 13:44:49.829118: Average global foreground Dice: [0.798]
2022-05-29 13:44:49.831031: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:44:50.309264: lr: 0.000626
2022-05-29 13:44:50.311782: This epoch took 99.327962 s

2022-05-29 13:44:50.313921: 
epoch:  477
2022-05-29 13:46:22.592018: train loss : -0.8603
2022-05-29 13:46:33.890770: validation loss: -0.7320
2022-05-29 13:46:33.909854: Average global foreground Dice: [0.8035]
2022-05-29 13:46:33.923670: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:46:34.637987: lr: 0.000601
2022-05-29 13:46:34.666368: This epoch took 104.350193 s

2022-05-29 13:46:34.686370: 
epoch:  478
2022-05-29 13:48:06.296629: train loss : -0.8585
2022-05-29 13:48:14.669410: validation loss: -0.7606
2022-05-29 13:48:14.684586: Average global foreground Dice: [0.7982]
2022-05-29 13:48:14.686882: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:48:15.160862: lr: 0.000577
2022-05-29 13:48:15.163431: This epoch took 100.461023 s

2022-05-29 13:48:15.165618: 
epoch:  479
2022-05-29 13:49:48.865648: train loss : -0.8553
2022-05-29 13:49:58.936201: validation loss: -0.7501
2022-05-29 13:49:58.940333: Average global foreground Dice: [0.7974]
2022-05-29 13:49:58.942760: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:49:59.448574: lr: 0.000552
2022-05-29 13:49:59.451293: This epoch took 104.283601 s

2022-05-29 13:49:59.453773: 
epoch:  480
2022-05-29 13:51:33.510054: train loss : -0.8533
2022-05-29 13:51:45.109815: validation loss: -0.7815
2022-05-29 13:51:45.114333: Average global foreground Dice: [0.8121]
2022-05-29 13:51:45.116632: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:51:45.592126: lr: 0.000527
2022-05-29 13:51:45.595281: This epoch took 106.139105 s

2022-05-29 13:51:45.597621: 
epoch:  481
2022-05-29 13:53:19.969182: train loss : -0.8552
2022-05-29 13:53:31.063279: validation loss: -0.7352
2022-05-29 13:53:31.070578: Average global foreground Dice: [0.783]
2022-05-29 13:53:31.072954: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:53:31.609853: lr: 0.000502
2022-05-29 13:53:31.628281: This epoch took 106.028182 s

2022-05-29 13:53:31.631621: 
epoch:  482
2022-05-29 13:55:02.652173: train loss : -0.8536
2022-05-29 13:55:14.355510: validation loss: -0.7633
2022-05-29 13:55:14.400261: Average global foreground Dice: [0.8089]
2022-05-29 13:55:14.402550: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:55:15.204176: lr: 0.000477
2022-05-29 13:55:15.230314: This epoch took 103.597264 s

2022-05-29 13:55:15.240622: 
epoch:  483
2022-05-29 13:56:54.733851: train loss : -0.8556
2022-05-29 13:57:02.863481: validation loss: -0.7415
2022-05-29 13:57:02.893198: Average global foreground Dice: [0.7946]
2022-05-29 13:57:02.907293: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:57:03.496562: lr: 0.000451
2022-05-29 13:57:03.502135: This epoch took 108.241044 s

2022-05-29 13:57:03.526288: 
epoch:  484
2022-05-29 13:58:45.223438: train loss : -0.8488
2022-05-29 13:58:54.535165: validation loss: -0.7548
2022-05-29 13:58:54.557988: Average global foreground Dice: [0.8061]
2022-05-29 13:58:54.573038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 13:58:55.204630: lr: 0.000426
2022-05-29 13:58:55.206983: This epoch took 111.671227 s

2022-05-29 13:58:55.208936: 
epoch:  485
2022-05-29 14:00:25.352057: train loss : -0.8575
2022-05-29 14:00:31.198719: validation loss: -0.7489
2022-05-29 14:00:31.203471: Average global foreground Dice: [0.8049]
2022-05-29 14:00:31.205373: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:00:31.662392: lr: 0.0004
2022-05-29 14:00:31.664819: This epoch took 96.453818 s

2022-05-29 14:00:31.666623: 
epoch:  486
2022-05-29 14:02:03.051375: train loss : -0.8572
2022-05-29 14:02:08.907204: validation loss: -0.7527
2022-05-29 14:02:08.910470: Average global foreground Dice: [0.8018]
2022-05-29 14:02:08.913100: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:02:09.453435: lr: 0.000375
2022-05-29 14:02:09.455798: This epoch took 97.787390 s

2022-05-29 14:02:09.457952: 
epoch:  487
2022-05-29 14:03:40.519595: train loss : -0.8628
2022-05-29 14:03:47.966946: validation loss: -0.7598
2022-05-29 14:03:47.972334: Average global foreground Dice: [0.802]
2022-05-29 14:03:47.974514: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:03:48.453150: lr: 0.000348
2022-05-29 14:03:48.463486: This epoch took 99.003398 s

2022-05-29 14:03:48.466650: 
epoch:  488
2022-05-29 14:05:23.442410: train loss : -0.8615
2022-05-29 14:05:32.032752: validation loss: -0.7559
2022-05-29 14:05:32.036268: Average global foreground Dice: [0.8045]
2022-05-29 14:05:32.038402: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:05:32.521920: lr: 0.000322
2022-05-29 14:05:32.524225: This epoch took 104.055435 s

2022-05-29 14:05:32.526634: 
epoch:  489
2022-05-29 14:07:03.798220: train loss : -0.8600
2022-05-29 14:07:10.271663: validation loss: -0.7510
2022-05-29 14:07:10.275522: Average global foreground Dice: [0.7927]
2022-05-29 14:07:10.277610: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:07:10.729111: lr: 0.000296
2022-05-29 14:07:10.731320: This epoch took 98.202395 s

2022-05-29 14:07:10.734302: 
epoch:  490
2022-05-29 14:08:44.975985: train loss : -0.8600
2022-05-29 14:08:52.689376: validation loss: -0.7457
2022-05-29 14:08:52.693029: Average global foreground Dice: [0.8121]
2022-05-29 14:08:52.695373: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:08:53.158914: lr: 0.000269
2022-05-29 14:08:53.174010: This epoch took 102.436718 s

2022-05-29 14:08:53.183786: 
epoch:  491
2022-05-29 14:10:24.237042: train loss : -0.8404
2022-05-29 14:10:33.424929: validation loss: -0.7662
2022-05-29 14:10:33.428486: Average global foreground Dice: [0.801]
2022-05-29 14:10:33.430595: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:10:33.889705: lr: 0.000242
2022-05-29 14:10:33.891975: This epoch took 100.693745 s

2022-05-29 14:10:33.893900: 
epoch:  492
2022-05-29 14:12:07.839583: train loss : -0.8550
2022-05-29 14:12:14.299586: validation loss: -0.7573
2022-05-29 14:12:14.314270: Average global foreground Dice: [0.7996]
2022-05-29 14:12:14.316597: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:12:14.806031: lr: 0.000215
2022-05-29 14:12:14.808823: This epoch took 100.909757 s

2022-05-29 14:12:14.810982: 
epoch:  493
2022-05-29 14:13:46.149668: train loss : -0.8509
2022-05-29 14:13:55.474962: validation loss: -0.7652
2022-05-29 14:13:55.500674: Average global foreground Dice: [0.7948]
2022-05-29 14:13:55.536258: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:13:56.039039: lr: 0.000187
2022-05-29 14:13:56.045978: This epoch took 101.232775 s

2022-05-29 14:13:56.061833: 
epoch:  494
2022-05-29 14:15:34.257857: train loss : -0.8558
2022-05-29 14:15:41.356108: validation loss: -0.7581
2022-05-29 14:15:41.360025: Average global foreground Dice: [0.7954]
2022-05-29 14:15:41.362340: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:15:41.829501: lr: 0.000158
2022-05-29 14:15:41.832029: This epoch took 105.762540 s

2022-05-29 14:15:41.834301: 
epoch:  495
2022-05-29 14:17:13.265749: train loss : -0.8627
2022-05-29 14:17:22.001973: validation loss: -0.7571
2022-05-29 14:17:22.029821: Average global foreground Dice: [0.8119]
2022-05-29 14:17:22.052295: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:17:22.728194: lr: 0.00013
2022-05-29 14:17:22.743339: This epoch took 100.906761 s

2022-05-29 14:17:22.756108: 
epoch:  496
2022-05-29 14:18:57.858523: train loss : -0.8626
2022-05-29 14:19:07.524220: validation loss: -0.7750
2022-05-29 14:19:07.529776: Average global foreground Dice: [0.8075]
2022-05-29 14:19:07.531905: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:19:08.000100: lr: 0.0001
2022-05-29 14:19:08.003034: This epoch took 105.244869 s

2022-05-29 14:19:08.005011: 
epoch:  497
2022-05-29 14:20:38.384947: train loss : -0.8624
2022-05-29 14:20:45.052112: validation loss: -0.7557
2022-05-29 14:20:45.061996: Average global foreground Dice: [0.7989]
2022-05-29 14:20:45.067490: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:20:45.548225: lr: 6.9e-05
2022-05-29 14:20:45.550526: This epoch took 97.543229 s

2022-05-29 14:20:45.552569: 
epoch:  498
2022-05-29 14:22:16.059320: train loss : -0.8540
2022-05-29 14:22:22.695005: validation loss: -0.7616
2022-05-29 14:22:22.703037: Average global foreground Dice: [0.8129]
2022-05-29 14:22:22.705219: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:22:23.199273: lr: 3.7e-05
2022-05-29 14:22:23.201604: This epoch took 97.647049 s

2022-05-29 14:22:23.203632: 
epoch:  499
2022-05-29 14:23:54.705860: train loss : -0.8651
2022-05-29 14:24:03.223758: validation loss: -0.7448
2022-05-29 14:24:03.236504: Average global foreground Dice: [0.7964]
2022-05-29 14:24:03.238820: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-05-29 14:24:03.713402: lr: 0.0
2022-05-29 14:24:03.715728: saving scheduled checkpoint file...
2022-05-29 14:24:03.751088: saving checkpoint...
2022-05-29 14:24:04.728948: done, saving took 1.01 seconds
2022-05-29 14:24:04.746542: done
2022-05-29 14:24:04.749265: This epoch took 101.543512 s

2022-05-29 14:24:04.782914: saving checkpoint...
2022-05-29 14:24:05.700140: done, saving took 0.95 seconds
panc_004 (2, 104, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 51, 102], [0, 51, 102]]
number of tiles: 27
computing Gaussian
done
prediction done
panc_019 (2, 83, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_028 (2, 81, 315, 315)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 315, 315)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 62, 123], [0, 62, 123]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_051 (2, 96, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_066 (2, 186, 322, 322)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 322, 322)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 65, 130], [0, 65, 130]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_069 (2, 188, 312, 312)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 188, 312, 312)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 62, 93, 124], [0, 60, 120], [0, 60, 120]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_077 (2, 79, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_080 (2, 95, 319, 319)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 319, 319)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 64, 127], [0, 64, 127]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_093 (2, 113, 369, 369)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 113, 369, 369)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49], [0, 88, 177], [0, 88, 177]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_122 (2, 94, 313, 313)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 313, 313)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 60, 121], [0, 60, 121]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_129 (2, 85, 289, 289)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 289, 289)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 48, 97], [0, 48, 97]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_159 (2, 87, 260, 260)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 260, 260)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 68], [0, 68]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_165 (2, 83, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_170 (2, 100, 318, 318)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 63, 126], [0, 63, 126]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_180 (2, 92, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_186 (2, 99, 280, 280)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 88], [0, 88]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_197 (2, 71, 337, 337)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 337, 337)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 72, 145], [0, 72, 145]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_201 (2, 74, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_209 (2, 101, 380, 380)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 380, 380)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 94, 188], [0, 94, 188]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_226 (2, 101, 328, 328)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 328, 328)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 68, 136], [0, 68, 136]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_228 (2, 110, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_234 (2, 79, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_235 (2, 82, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_243 (2, 99, 301, 301)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_246 (2, 104, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_253 (2, 91, 304, 304)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 91, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_255 (2, 96, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_261 (2, 94, 277, 277)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 277, 277)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85], [0, 85]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_268 (2, 65, 291, 291)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 65, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 1], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_275 (2, 102, 297, 297)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 297, 297)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 52, 105], [0, 52, 105]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_276 (2, 86, 338, 338)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 338, 338)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 73, 146], [0, 73, 146]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_304 (2, 90, 286, 286)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_308 (2, 110, 381, 381)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 381, 381)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 94, 189], [0, 94, 189]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_311 (2, 84, 303, 303)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_333 (2, 94, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_336 (2, 89, 340, 340)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 74, 148], [0, 74, 148]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_345 (2, 82, 332, 332)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_365 (2, 182, 346, 346)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 182, 346, 346)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 59, 88, 118], [0, 77, 154], [0, 77, 154]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_375 (2, 114, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_377 (2, 107, 342, 342)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 75, 150], [0, 75, 150]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_398 (2, 100, 368, 368)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 368, 368)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 88, 176], [0, 88, 176]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_400 (2, 104, 382, 382)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 382, 382)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 95, 190], [0, 95, 190]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_402 (2, 156, 287, 287)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 156, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 61, 92], [0, 95], [0, 95]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_404 (2, 102, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_406 (2, 84, 353, 353)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 353, 353)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 80, 161], [0, 80, 161]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_418 (2, 85, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_419 (2, 85, 371, 371)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 90, 179], [0, 90, 179]]
number of tiles: 18
using precomputed Gaussian
prediction done
2022-05-29 14:32:20.823961: finished prediction
2022-05-29 14:32:20.828553: evaluation of raw predictions
2022-05-29 14:32:41.711555: determining postprocessing
Foreground vs background
before: 0.8049775560505139
after:  0.8049749287518766
Only one class present, no need to do each class separately as this is covered in fg vs bg
done
for which classes:
[]
min_object_sizes
None
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
done
predicting segmentations for the next stage of the cascade
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
panc_004
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 51, 102], [0, 51, 102]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_019
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_028
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 315, 315)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 62, 123], [0, 62, 123]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_051
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_066
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 322, 322)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 65, 130], [0, 65, 130]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_069
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 188, 312, 312)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 62, 93, 124], [0, 60, 120], [0, 60, 120]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_077
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_080
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 319, 319)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 64, 127], [0, 64, 127]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_093
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 113, 369, 369)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49], [0, 88, 177], [0, 88, 177]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_122
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 313, 313)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 60, 121], [0, 60, 121]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_129
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 289, 289)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 48, 97], [0, 48, 97]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_159
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 260, 260)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 68], [0, 68]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_165
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_170
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 63, 126], [0, 63, 126]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_180
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_186
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 88], [0, 88]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_197
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 337, 337)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 72, 145], [0, 72, 145]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_201
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_209
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 380, 380)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 94, 188], [0, 94, 188]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_226
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 328, 328)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 68, 136], [0, 68, 136]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_228
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_234
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_235
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_243
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_246
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_253
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 91, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_255
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_261
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 277, 277)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85], [0, 85]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_268
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 65, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 1], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_275
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 297, 297)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 52, 105], [0, 52, 105]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_276
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 338, 338)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 73, 146], [0, 73, 146]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_304
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_308
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 381, 381)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 94, 189], [0, 94, 189]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_311
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_333
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_336
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 74, 148], [0, 74, 148]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_345
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_365
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 182, 346, 346)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 59, 88, 118], [0, 77, 154], [0, 77, 154]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_375
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_377
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 75, 150], [0, 75, 150]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_398
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 368, 368)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 88, 176], [0, 88, 176]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_400
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 382, 382)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 95, 190], [0, 95, 190]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_402
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 156, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 61, 92], [0, 95], [0, 95]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_404
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_406
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 353, 353)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 80, 161], [0, 80, 161]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_418
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_419
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 90, 179], [0, 90, 179]]
number of tiles: 18
using precomputed Gaussian
prediction done
Done training all the folds! Now we do the same command but with continue option, to generate log files.


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_lowres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 93, 318, 318]), 'current_spacing': array([2.5757525 , 1.29418872, 1.29418872]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 40, 224, 224]), 'median_patient_size_in_voxels': array([ 96, 512, 512]), 'current_spacing': array([2.5       , 0.80273402, 0.80273402]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-05-29 14:42:38.331273: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/splits_final.pkl
2022-05-29 14:42:38.370468: The split file contains 5 splits.
2022-05-29 14:42:38.372798: Desired fold for training: 0
2022-05-29 14:42:38.374779: This split has 191 training and 48 validation cases.
unpacking dataset
done
Susy hier
Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 14:42:41.964233: loading checkpoint /exports/lkeb-hpc/smaijer/results/nnUNet/3d_lowres/Task510/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model train= True
2022-05-29 14:42:51.699086: lr: 0.0
using pin_memory on device 0
using pin_memory on device 0
2022-05-29 14:42:58.704802: Unable to plot network architecture:
2022-05-29 14:42:58.746486: No module named 'hiddenlayer'
2022-05-29 14:42:58.767541: 
printing the network instead:

2022-05-29 14:42:58.782498: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 14:42:58.808031: 

2022-05-29 14:42:59.116371: saving checkpoint...
2022-05-29 14:43:00.494166: done, saving took 1.67 seconds
panc_024 (2, 102, 314, 314)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 314, 314)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 61, 122], [0, 61, 122]]
number of tiles: 27
computing Gaussian
done
prediction done
panc_040 (2, 87, 326, 326)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 326, 326)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 67, 134], [0, 67, 134]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_048 (2, 117, 384, 384)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 384, 384)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 96, 192], [0, 96, 192]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_058 (2, 177, 376, 376)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 177, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 85, 113], [0, 92, 184], [0, 92, 184]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_067 (2, 100, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 66, 133], [0, 66, 133]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_075 (2, 59, 323, 323)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 66, 131], [0, 66, 131]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_086 (2, 50, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 82, 163], [0, 82, 163]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_101 (2, 190, 298, 298)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 190, 298, 298)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 63, 94, 126], [0, 53, 106], [0, 53, 106]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_105 (2, 190, 304, 304)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 190, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 63, 94, 126], [0, 56, 112], [0, 56, 112]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_107 (2, 99, 309, 309)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 58, 117], [0, 58, 117]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_113 (2, 97, 273, 273)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 273, 273)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 81], [0, 81]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_119 (2, 83, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_131 (2, 57, 318, 318)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 63, 126], [0, 63, 126]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_137 (2, 83, 332, 332)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_148 (2, 82, 301, 301)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 54, 109], [0, 54, 109]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_157 (2, 75, 309, 309)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_182 (2, 77, 267, 267)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 77, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 13], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_191 (2, 55, 292, 292)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 292, 292)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 50, 100], [0, 50, 100]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_193 (2, 110, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 58, 116], [0, 58, 116]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_194 (2, 95, 289, 289)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 289, 289)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 48, 97], [0, 48, 97]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_204 (2, 71, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_207 (2, 79, 291, 291)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_211 (2, 117, 362, 362)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 85, 170], [0, 85, 170]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_215 (2, 96, 300, 300)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 300, 300)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 54, 108], [0, 54, 108]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_219 (2, 186, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 80
using precomputed Gaussian
prediction done
panc_224 (2, 90, 342, 342)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 75, 150], [0, 75, 150]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_236 (2, 79, 340, 340)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 74, 148], [0, 74, 148]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_241 (2, 96, 316, 316)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 62, 124], [0, 62, 124]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_256 (2, 86, 306, 306)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 306, 306)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 57, 114], [0, 57, 114]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_285 (2, 110, 329, 329)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 329, 329)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 68, 137], [0, 68, 137]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_286 (2, 90, 304, 304)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_294 (2, 94, 321, 321)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_296 (2, 83, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_302 (2, 81, 375, 375)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 375, 375)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 92, 183], [0, 92, 183]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_305 (2, 71, 293, 293)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 293, 293)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 50, 101], [0, 50, 101]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_321 (2, 114, 354, 354)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 354, 354)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 81, 162], [0, 81, 162]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_325 (2, 90, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_364 (2, 86, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_367 (2, 101, 342, 342)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 75, 150], [0, 75, 150]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_369 (2, 94, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_374 (2, 133, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 133, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46, 69], [0, 51, 102], [0, 51, 102]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_386 (2, 79, 301, 301)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 54, 109], [0, 54, 109]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_393 (2, 116, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 116, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_399 (2, 113, 371, 371)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 113, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49], [0, 90, 179], [0, 90, 179]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_410 (2, 98, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_412 (2, 191, 362, 362)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 191, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 64, 95, 127], [0, 85, 170], [0, 85, 170]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_413 (2, 83, 309, 309)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_415 (2, 118, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 118, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27, 54], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done
2022-05-29 14:52:01.543831: finished prediction
2022-05-29 14:52:01.548479: evaluation of raw predictions
2022-05-29 14:52:08.715770: determining postprocessing
Foreground vs background
before: 0.8236101016852149
after:  0.8240245791239561
Removing all but the largest foreground region improved results!
for_which_classes [1]
min_valid_object_sizes None
Only one class present, no need to do each class separately as this is covered in fg vs bg
done
for which classes:
[[1]]
min_object_sizes
None
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
done
predicting segmentations for the next stage of the cascade
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
panc_024
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 314, 314)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 61, 122], [0, 61, 122]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_040
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 326, 326)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 67, 134], [0, 67, 134]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_048
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 384, 384)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 96, 192], [0, 96, 192]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_058
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 177, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 85, 113], [0, 92, 184], [0, 92, 184]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_067
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 66, 133], [0, 66, 133]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_075
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 66, 131], [0, 66, 131]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_086
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 82, 163], [0, 82, 163]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_101
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 190, 298, 298)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 63, 94, 126], [0, 53, 106], [0, 53, 106]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_105
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 190, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 63, 94, 126], [0, 56, 112], [0, 56, 112]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_107
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 58, 117], [0, 58, 117]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_113
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 273, 273)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 81], [0, 81]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_119
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_131
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 63, 126], [0, 63, 126]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_137
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_148
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 54, 109], [0, 54, 109]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_157
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_182
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 77, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 13], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_191
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 64, 292, 292)
patch size: [ 64 192 192]
steps (x, y, and z): [[0], [0, 50, 100], [0, 50, 100]]
number of tiles: 9
using precomputed Gaussian
prediction done
panc_193
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 58, 116], [0, 58, 116]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_194
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 289, 289)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 48, 97], [0, 48, 97]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_204
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_207
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_211
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 85, 170], [0, 85, 170]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_215
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 300, 300)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 54, 108], [0, 54, 108]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_219
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 80
using precomputed Gaussian
prediction done
panc_224
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 75, 150], [0, 75, 150]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_236
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 74, 148], [0, 74, 148]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_241
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 62, 124], [0, 62, 124]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_256
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 306, 306)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 57, 114], [0, 57, 114]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_285
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 329, 329)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 68, 137], [0, 68, 137]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_286
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_294
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_296
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_302
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 375, 375)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 92, 183], [0, 92, 183]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_305
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 293, 293)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 50, 101], [0, 50, 101]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_321
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 354, 354)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 81, 162], [0, 81, 162]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_325
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_364
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_367
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 75, 150], [0, 75, 150]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_369
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_374
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 133, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46, 69], [0, 51, 102], [0, 51, 102]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_386
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 54, 109], [0, 54, 109]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_393
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 116, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_399
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 113, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49], [0, 90, 179], [0, 90, 179]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_410
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_412
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 191, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 64, 95, 127], [0, 85, 170], [0, 85, 170]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_413
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_415
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 118, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27, 54], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_lowres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 93, 318, 318]), 'current_spacing': array([2.5757525 , 1.29418872, 1.29418872]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 40, 224, 224]), 'median_patient_size_in_voxels': array([ 96, 512, 512]), 'current_spacing': array([2.5       , 0.80273402, 0.80273402]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-05-29 15:02:37.579608: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/splits_final.pkl
2022-05-29 15:02:37.608085: The split file contains 5 splits.
2022-05-29 15:02:37.610501: Desired fold for training: 1
2022-05-29 15:02:37.612504: This split has 191 training and 48 validation cases.
unpacking dataset
done
Susy hier
Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 15:02:41.331510: loading checkpoint /exports/lkeb-hpc/smaijer/results/nnUNet/3d_lowres/Task510/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_final_checkpoint.model train= True
2022-05-29 15:02:49.575858: lr: 0.0
using pin_memory on device 0
using pin_memory on device 0
2022-05-29 15:02:57.481030: Unable to plot network architecture:
2022-05-29 15:02:57.521277: No module named 'hiddenlayer'
2022-05-29 15:02:57.538292: 
printing the network instead:

2022-05-29 15:02:57.565652: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 15:02:57.580143: 

2022-05-29 15:02:57.682132: saving checkpoint...
2022-05-29 15:02:59.228530: done, saving took 1.63 seconds
panc_025 (2, 73, 277, 277)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 277, 277)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 85], [0, 85]]
number of tiles: 8
computing Gaussian
done
prediction done
panc_035 (2, 71, 243, 243)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 243, 243)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 51], [0, 51]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_041 (2, 80, 316, 316)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 62, 124], [0, 62, 124]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_045 (2, 80, 323, 323)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 66, 131], [0, 66, 131]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_052 (2, 86, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_056 (2, 82, 303, 303)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_078 (2, 74, 280, 280)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 88], [0, 88]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_091 (2, 69, 323, 323)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 69, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 5], [0, 66, 131], [0, 66, 131]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_103 (2, 87, 262, 262)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 262, 262)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 70], [0, 70]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_106 (2, 80, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_114 (2, 95, 280, 280)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 88], [0, 88]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_117 (2, 156, 261, 261)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 156, 261, 261)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 61, 92], [0, 69], [0, 69]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_125 (2, 99, 369, 369)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 369, 369)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 88, 177], [0, 88, 177]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_135 (2, 116, 286, 286)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 116, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52], [0, 94], [0, 94]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_140 (2, 109, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 109, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 45], [0, 66, 133], [0, 66, 133]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_166 (2, 92, 366, 366)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 366, 366)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 87, 174], [0, 87, 174]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_178 (2, 107, 317, 317)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 317, 317)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 62, 125], [0, 62, 125]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_187 (2, 92, 332, 332)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_199 (2, 92, 318, 318)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 63, 126], [0, 63, 126]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_200 (2, 86, 372, 372)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 372, 372)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 90, 180], [0, 90, 180]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_249 (2, 119, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 119, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 55], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_262 (2, 74, 297, 297)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 297, 297)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 52, 105], [0, 52, 105]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_264 (2, 106, 331, 331)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 331, 331)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 70, 139], [0, 70, 139]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_266 (2, 94, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_269 (2, 110, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 58, 116], [0, 58, 116]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_280 (2, 94, 367, 367)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 88, 175], [0, 88, 175]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_283 (2, 104, 280, 280)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 88], [0, 88]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_293 (2, 104, 354, 354)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 354, 354)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 81, 162], [0, 81, 162]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_301 (2, 81, 330, 330)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 330, 330)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 69, 138], [0, 69, 138]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_310 (2, 79, 365, 365)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 365, 365)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 86, 173], [0, 86, 173]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_312 (2, 73, 367, 367)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 88, 175], [0, 88, 175]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_313 (2, 92, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_323 (2, 92, 379, 379)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 379, 379)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 94, 187], [0, 94, 187]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_329 (2, 77, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 77, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 13], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_342 (2, 114, 324, 324)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 324, 324)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 66, 132], [0, 66, 132]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_343 (2, 83, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_351 (2, 85, 267, 267)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_354 (2, 157, 328, 328)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 157, 328, 328)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 62, 93], [0, 68, 136], [0, 68, 136]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_358 (2, 173, 288, 288)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 173, 288, 288)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27, 54, 82, 109], [0, 96], [0, 96]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_361 (2, 132, 247, 247)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 132, 247, 247)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 45, 68], [0, 55], [0, 55]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_366 (2, 117, 349, 349)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 349, 349)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 78, 157], [0, 78, 157]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_370 (2, 177, 267, 267)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 177, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 85, 113], [0, 75], [0, 75]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_380 (2, 122, 353, 353)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 122, 353, 353)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58], [0, 80, 161], [0, 80, 161]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_388 (2, 111, 352, 352)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 111, 352, 352)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 47], [0, 80, 160], [0, 80, 160]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_389 (2, 115, 337, 337)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 115, 337, 337)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 51], [0, 72, 145], [0, 72, 145]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_405 (2, 86, 321, 321)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_414 (2, 82, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_421 (2, 102, 385, 385)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 385, 385)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 64, 129, 193], [0, 64, 129, 193]]
number of tiles: 48
using precomputed Gaussian
prediction done
2022-05-29 15:10:48.856842: finished prediction
2022-05-29 15:10:48.860945: evaluation of raw predictions
2022-05-29 15:10:56.373874: determining postprocessing
Foreground vs background
before: 0.8120529740109464
after:  0.8120923291769743
Removing all but the largest foreground region improved results!
for_which_classes [1]
min_valid_object_sizes None
Only one class present, no need to do each class separately as this is covered in fg vs bg
done
for which classes:
[[1]]
min_object_sizes
None
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
done
predicting segmentations for the next stage of the cascade
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
panc_025
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 277, 277)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 85], [0, 85]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_035
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 243, 243)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 51], [0, 51]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_041
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 62, 124], [0, 62, 124]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_045
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 66, 131], [0, 66, 131]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_052
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_056
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_078
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 88], [0, 88]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_091
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 69, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 5], [0, 66, 131], [0, 66, 131]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_103
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 262, 262)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 70], [0, 70]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_106
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_114
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 88], [0, 88]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_117
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 156, 261, 261)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 61, 92], [0, 69], [0, 69]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_125
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 369, 369)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 88, 177], [0, 88, 177]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_135
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 116, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52], [0, 94], [0, 94]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_140
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 109, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 45], [0, 66, 133], [0, 66, 133]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_166
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 366, 366)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 87, 174], [0, 87, 174]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_178
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 317, 317)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 62, 125], [0, 62, 125]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_187
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_199
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 63, 126], [0, 63, 126]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_200
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 372, 372)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 90, 180], [0, 90, 180]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_249
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 119, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 55], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_262
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 297, 297)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 52, 105], [0, 52, 105]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_264
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 331, 331)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 70, 139], [0, 70, 139]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_266
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_269
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 58, 116], [0, 58, 116]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_280
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 88, 175], [0, 88, 175]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_283
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 88], [0, 88]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_293
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 354, 354)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 81, 162], [0, 81, 162]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_301
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 330, 330)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 69, 138], [0, 69, 138]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_310
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 365, 365)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 86, 173], [0, 86, 173]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_312
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 88, 175], [0, 88, 175]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_313
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_323
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 379, 379)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 94, 187], [0, 94, 187]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_329
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 77, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 13], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_342
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 324, 324)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 66, 132], [0, 66, 132]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_343
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_351
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_354
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 157, 328, 328)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 62, 93], [0, 68, 136], [0, 68, 136]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_358
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 173, 288, 288)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27, 54, 82, 109], [0, 96], [0, 96]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_361
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 132, 247, 247)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 45, 68], [0, 55], [0, 55]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_366
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 117, 349, 349)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53], [0, 78, 157], [0, 78, 157]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_370
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 177, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 85, 113], [0, 75], [0, 75]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_380
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 122, 353, 353)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58], [0, 80, 161], [0, 80, 161]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_388
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 111, 352, 352)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 47], [0, 80, 160], [0, 80, 160]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_389
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 115, 337, 337)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 51], [0, 72, 145], [0, 72, 145]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_405
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_414
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_421
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 385, 385)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 64, 129, 193], [0, 64, 129, 193]]
number of tiles: 48
using precomputed Gaussian
prediction done


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_lowres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 93, 318, 318]), 'current_spacing': array([2.5757525 , 1.29418872, 1.29418872]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 40, 224, 224]), 'median_patient_size_in_voxels': array([ 96, 512, 512]), 'current_spacing': array([2.5       , 0.80273402, 0.80273402]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-05-29 15:20:07.662183: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/splits_final.pkl
2022-05-29 15:20:07.672707: The split file contains 5 splits.
2022-05-29 15:20:07.674934: Desired fold for training: 2
2022-05-29 15:20:07.677068: This split has 191 training and 48 validation cases.
unpacking dataset
done
Susy hier
Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 15:20:11.381957: loading checkpoint /exports/lkeb-hpc/smaijer/results/nnUNet/3d_lowres/Task510/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_final_checkpoint.model train= True
2022-05-29 15:20:20.817028: lr: 0.0
using pin_memory on device 0
using pin_memory on device 0
2022-05-29 15:20:27.391790: Unable to plot network architecture:
2022-05-29 15:20:27.434411: No module named 'hiddenlayer'
2022-05-29 15:20:27.455394: 
printing the network instead:

2022-05-29 15:20:27.477456: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 15:20:27.500154: 

2022-05-29 15:20:27.609941: saving checkpoint...
2022-05-29 15:20:29.012820: done, saving took 1.48 seconds
panc_005 (2, 101, 363, 363)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 363, 363)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 86, 171], [0, 86, 171]]
number of tiles: 27
computing Gaussian
done
prediction done
panc_015 (2, 84, 290, 290)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 290, 290)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 49, 98], [0, 49, 98]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_021 (2, 90, 342, 342)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 75, 150], [0, 75, 150]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_032 (2, 86, 365, 365)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 365, 365)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 86, 173], [0, 86, 173]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_037 (2, 69, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 69, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 5], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_043 (2, 76, 295, 295)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 76, 295, 295)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 12], [0, 52, 103], [0, 52, 103]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_055 (2, 93, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_061 (2, 90, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_084 (2, 80, 288, 288)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 288, 288)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 96], [0, 96]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_094 (2, 82, 286, 286)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_096 (2, 105, 366, 366)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 105, 366, 366)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 41], [0, 87, 174], [0, 87, 174]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_102 (2, 89, 314, 314)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 314, 314)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 61, 122], [0, 61, 122]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_124 (2, 80, 376, 376)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 92, 184], [0, 92, 184]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_138 (2, 92, 371, 371)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 90, 179], [0, 90, 179]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_167 (2, 98, 301, 301)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_175 (2, 88, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 88, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_179 (2, 86, 311, 311)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 311, 311)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 60, 119], [0, 60, 119]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_183 (2, 74, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_196 (2, 89, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_198 (2, 108, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 108, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 44], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_203 (2, 103, 301, 301)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 103, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 39], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_222 (2, 75, 240, 240)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 240, 240)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 48], [0, 48]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_230 (2, 93, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_231 (2, 90, 313, 313)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 313, 313)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 60, 121], [0, 60, 121]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_239 (2, 89, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_244 (2, 100, 359, 359)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 359, 359)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 84, 167], [0, 84, 167]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_247 (2, 86, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_254 (2, 98, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_267 (2, 86, 269, 269)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 269, 269)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 77], [0, 77]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_270 (2, 84, 317, 317)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 317, 317)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 62, 125], [0, 62, 125]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_274 (2, 112, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 112, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 48], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_277 (2, 106, 376, 376)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 92, 184], [0, 92, 184]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_278 (2, 97, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_289 (2, 93, 272, 272)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 272, 272)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 80], [0, 80]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_290 (2, 94, 362, 362)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85, 170], [0, 85, 170]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_291 (2, 94, 362, 362)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85, 170], [0, 85, 170]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_297 (2, 98, 357, 357)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 357, 357)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 82, 165], [0, 82, 165]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_299 (2, 81, 270, 270)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 270, 270)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 78], [0, 78]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_303 (2, 110, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_320 (2, 88, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 88, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_328 (2, 92, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_331 (2, 98, 316, 316)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 62, 124], [0, 62, 124]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_339 (2, 102, 367, 367)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 88, 175], [0, 88, 175]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_344 (2, 109, 305, 305)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 109, 305, 305)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 45], [0, 56, 113], [0, 56, 113]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_355 (2, 167, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 167, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52, 77, 103], [0, 86], [0, 86]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_387 (2, 97, 309, 309)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 58, 117], [0, 58, 117]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_392 (2, 111, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 111, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 47], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_395 (2, 165, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 165, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50, 76, 101], [0, 58, 116], [0, 58, 116]]
number of tiles: 45
using precomputed Gaussian
prediction done
2022-05-29 15:28:21.189128: finished prediction
2022-05-29 15:28:21.192876: evaluation of raw predictions
2022-05-29 15:28:28.160474: determining postprocessing
Foreground vs background
before: 0.8282338621091835
after:  0.8282329790385455
Only one class present, no need to do each class separately as this is covered in fg vs bg
done
for which classes:
[]
min_object_sizes
None
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
done
predicting segmentations for the next stage of the cascade
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
panc_005
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 363, 363)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 86, 171], [0, 86, 171]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_015
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 290, 290)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 49, 98], [0, 49, 98]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_021
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 75, 150], [0, 75, 150]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_032
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 365, 365)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 86, 173], [0, 86, 173]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_037
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 69, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 5], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_043
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 76, 295, 295)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 12], [0, 52, 103], [0, 52, 103]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_055
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_061
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_084
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 288, 288)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 96], [0, 96]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_094
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_096
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 105, 366, 366)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 41], [0, 87, 174], [0, 87, 174]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_102
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 314, 314)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 61, 122], [0, 61, 122]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_124
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 80, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16], [0, 92, 184], [0, 92, 184]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_138
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 90, 179], [0, 90, 179]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_167
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_175
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 88, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_179
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 311, 311)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 60, 119], [0, 60, 119]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_183
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_196
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_198
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 108, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 44], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_203
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 103, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 39], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_222
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 240, 240)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 48], [0, 48]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_230
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_231
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 313, 313)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 60, 121], [0, 60, 121]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_239
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_244
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 359, 359)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 84, 167], [0, 84, 167]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_247
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_254
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_267
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 269, 269)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 77], [0, 77]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_270
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 317, 317)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 62, 125], [0, 62, 125]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_274
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 112, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 48], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_277
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 92, 184], [0, 92, 184]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_278
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_289
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 93, 272, 272)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29], [0, 80], [0, 80]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_290
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85, 170], [0, 85, 170]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_291
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 362, 362)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85, 170], [0, 85, 170]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_297
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 357, 357)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 82, 165], [0, 82, 165]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_299
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 270, 270)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 78], [0, 78]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_303
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_320
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 88, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_328
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_331
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 316, 316)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 62, 124], [0, 62, 124]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_339
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 88, 175], [0, 88, 175]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_344
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 109, 305, 305)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 45], [0, 56, 113], [0, 56, 113]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_355
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 167, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 52, 77, 103], [0, 86], [0, 86]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_387
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 97, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 16, 33], [0, 58, 117], [0, 58, 117]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_392
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 111, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 47], [0, 86], [0, 86]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_395
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 165, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50, 76, 101], [0, 58, 116], [0, 58, 116]]
number of tiles: 45
using precomputed Gaussian
prediction done


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_lowres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 93, 318, 318]), 'current_spacing': array([2.5757525 , 1.29418872, 1.29418872]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 40, 224, 224]), 'median_patient_size_in_voxels': array([ 96, 512, 512]), 'current_spacing': array([2.5       , 0.80273402, 0.80273402]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-05-29 15:37:28.327662: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/splits_final.pkl
2022-05-29 15:37:28.337984: The split file contains 5 splits.
2022-05-29 15:37:28.340259: Desired fold for training: 3
2022-05-29 15:37:28.342311: This split has 191 training and 48 validation cases.
unpacking dataset
done
Susy hier
Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 15:37:32.048825: loading checkpoint /exports/lkeb-hpc/smaijer/results/nnUNet/3d_lowres/Task510/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_final_checkpoint.model train= True
2022-05-29 15:37:40.224705: lr: 0.0
using pin_memory on device 0
using pin_memory on device 0
2022-05-29 15:37:46.739192: Unable to plot network architecture:
2022-05-29 15:37:46.792286: No module named 'hiddenlayer'
2022-05-29 15:37:46.817301: 
printing the network instead:

2022-05-29 15:37:46.847288: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 15:37:46.871049: 

2022-05-29 15:37:47.074679: saving checkpoint...
2022-05-29 15:37:48.921472: done, saving took 2.02 seconds
panc_001 (2, 107, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 63], [0, 63]]
number of tiles: 12
computing Gaussian
done
prediction done
panc_010 (2, 101, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_016 (2, 83, 306, 306)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 306, 306)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 57, 114], [0, 57, 114]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_018 (2, 84, 267, 267)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_029 (2, 96, 309, 309)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_049 (2, 84, 319, 319)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 319, 319)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 64, 127], [0, 64, 127]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_050 (2, 83, 286, 286)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_070 (2, 103, 345, 345)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 103, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 39], [0, 76, 153], [0, 76, 153]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_081 (2, 91, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 91, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_083 (2, 81, 304, 304)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_087 (2, 149, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 149, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 57, 85], [0, 63], [0, 63]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_098 (2, 143, 367, 367)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 143, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53, 79], [0, 88, 175], [0, 88, 175]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_110 (2, 95, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_120 (2, 162, 270, 270)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 162, 270, 270)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49, 74, 98], [0, 78], [0, 78]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_126 (2, 71, 291, 291)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_127 (2, 122, 344, 344)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 122, 344, 344)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58], [0, 76, 152], [0, 76, 152]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_130 (2, 151, 260, 260)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 151, 260, 260)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58, 87], [0, 68], [0, 68]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_149 (2, 75, 303, 303)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_158 (2, 128, 376, 376)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 128, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 64], [0, 92, 184], [0, 92, 184]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_160 (2, 73, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_169 (2, 84, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_172 (2, 92, 293, 293)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 293, 293)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 50, 101], [0, 50, 101]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_173 (2, 79, 274, 274)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 274, 274)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82], [0, 82]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_181 (2, 84, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_212 (2, 94, 345, 345)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 76, 153], [0, 76, 153]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_214 (2, 106, 336, 336)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 336, 336)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 72, 144], [0, 72, 144]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_229 (2, 84, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_242 (2, 98, 345, 345)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 76, 153], [0, 76, 153]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_279 (2, 78, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 78, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 14], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_284 (2, 83, 298, 298)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 298, 298)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 53, 106], [0, 53, 106]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_292 (2, 90, 331, 331)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 331, 331)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 70, 139], [0, 70, 139]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_309 (2, 92, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_316 (2, 86, 287, 287)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 95], [0, 95]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_326 (2, 86, 376, 376)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 92, 184], [0, 92, 184]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_327 (2, 96, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_330 (2, 86, 321, 321)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_347 (2, 86, 292, 292)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 292, 292)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 50, 100], [0, 50, 100]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_348 (2, 86, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_350 (2, 86, 287, 287)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 95], [0, 95]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_356 (2, 163, 268, 268)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 163, 268, 268)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50, 74, 99], [0, 76], [0, 76]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_357 (2, 85, 250, 250)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 250, 250)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 58], [0, 58]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_372 (2, 90, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_376 (2, 106, 340, 340)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 74, 148], [0, 74, 148]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_379 (2, 186, 275, 275)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 275, 275)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 83], [0, 83]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_382 (2, 108, 323, 323)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 108, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 44], [0, 66, 131], [0, 66, 131]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_385 (2, 95, 332, 332)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_401 (2, 175, 286, 286)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 175, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 83, 111], [0, 94], [0, 94]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_409 (2, 204, 311, 311)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 204, 311, 311)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 84, 112, 140], [0, 60, 119], [0, 60, 119]]
number of tiles: 54
using precomputed Gaussian
prediction done
2022-05-29 15:46:07.622196: finished prediction
2022-05-29 15:46:07.626563: evaluation of raw predictions
2022-05-29 15:46:19.489918: determining postprocessing
Foreground vs background
before: 0.7963701519828376
after:  0.7923558041444111
Only one class present, no need to do each class separately as this is covered in fg vs bg
done
for which classes:
[]
min_object_sizes
None
done
predicting segmentations for the next stage of the cascade
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
panc_001
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 63], [0, 63]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_010
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 48
using precomputed Gaussian
prediction done
panc_016
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 306, 306)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 57, 114], [0, 57, 114]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_018
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 267, 267)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 75], [0, 75]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_029
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 309, 309)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 58, 117], [0, 58, 117]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_049
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 319, 319)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 64, 127], [0, 64, 127]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_050
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_070
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 103, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 39], [0, 76, 153], [0, 76, 153]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_081
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 91, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_083
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_087
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 149, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 57, 85], [0, 63], [0, 63]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_098
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 143, 367, 367)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26, 53, 79], [0, 88, 175], [0, 88, 175]]
number of tiles: 36
using precomputed Gaussian
prediction done
panc_110
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_120
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 162, 270, 270)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49, 74, 98], [0, 78], [0, 78]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_126
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_127
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 122, 344, 344)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58], [0, 76, 152], [0, 76, 152]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_130
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 151, 260, 260)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 29, 58, 87], [0, 68], [0, 68]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_149
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 75, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 11], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_158
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 128, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32, 64], [0, 92, 184], [0, 92, 184]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_160
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 73, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 9], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_169
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_172
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 293, 293)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 50, 101], [0, 50, 101]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_173
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 274, 274)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82], [0, 82]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_181
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_212
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 76, 153], [0, 76, 153]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_214
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 336, 336)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 72, 144], [0, 72, 144]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_229
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_242
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 98, 345, 345)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17, 34], [0, 76, 153], [0, 76, 153]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_279
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 78, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 14], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_284
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 298, 298)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 53, 106], [0, 53, 106]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_292
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 331, 331)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 70, 139], [0, 70, 139]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_309
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_316
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 95], [0, 95]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_326
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 376, 376)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 92, 184], [0, 92, 184]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_327
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_330
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 321, 321)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 64, 129], [0, 64, 129]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_347
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 292, 292)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 50, 100], [0, 50, 100]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_348
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_350
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 95], [0, 95]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_356
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 163, 268, 268)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50, 74, 99], [0, 76], [0, 76]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_357
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 250, 250)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 58], [0, 58]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_372
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_376
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 106, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21, 42], [0, 74, 148], [0, 74, 148]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_379
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 275, 275)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 83], [0, 83]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_382
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 108, 323, 323)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 44], [0, 66, 131], [0, 66, 131]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_385
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_401
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 175, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 83, 111], [0, 94], [0, 94]]
number of tiles: 20
using precomputed Gaussian
prediction done
panc_409
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 204, 311, 311)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28, 56, 84, 112, 140], [0, 60, 119], [0, 60, 119]]
number of tiles: 54
using precomputed Gaussian
prediction done


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_lowres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 93, 318, 318]), 'current_spacing': array([2.5757525 , 1.29418872, 1.29418872]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 40, 224, 224]), 'median_patient_size_in_voxels': array([ 96, 512, 512]), 'current_spacing': array([2.5       , 0.80273402, 0.80273402]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-05-29 15:55:51.129791: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/splits_final.pkl
2022-05-29 15:55:51.141135: The split file contains 5 splits.
2022-05-29 15:55:51.143404: Desired fold for training: 4
2022-05-29 15:55:51.145348: This split has 192 training and 47 validation cases.
unpacking dataset
done
Susy hier
Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 15:55:54.739372: loading checkpoint /exports/lkeb-hpc/smaijer/results/nnUNet/3d_lowres/Task510/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_final_checkpoint.model train= True
2022-05-29 15:56:04.252671: lr: 0.0
using pin_memory on device 0
using pin_memory on device 0
2022-05-29 15:56:12.203067: Unable to plot network architecture:
2022-05-29 15:56:12.242276: No module named 'hiddenlayer'
2022-05-29 15:56:12.265271: 
printing the network instead:

2022-05-29 15:56:12.287272: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-05-29 15:56:12.310992: 

2022-05-29 15:56:12.518563: saving checkpoint...
2022-05-29 15:56:14.406463: done, saving took 2.05 seconds
panc_004 (2, 104, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 51, 102], [0, 51, 102]]
number of tiles: 27
computing Gaussian
done
prediction done
panc_019 (2, 83, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_028 (2, 81, 315, 315)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 315, 315)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 62, 123], [0, 62, 123]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_051 (2, 96, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_066 (2, 186, 322, 322)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 322, 322)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 65, 130], [0, 65, 130]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_069 (2, 188, 312, 312)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 188, 312, 312)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 62, 93, 124], [0, 60, 120], [0, 60, 120]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_077 (2, 79, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_080 (2, 95, 319, 319)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 319, 319)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 64, 127], [0, 64, 127]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_093 (2, 113, 369, 369)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 113, 369, 369)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49], [0, 88, 177], [0, 88, 177]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_122 (2, 94, 313, 313)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 313, 313)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 60, 121], [0, 60, 121]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_129 (2, 85, 289, 289)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 289, 289)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 48, 97], [0, 48, 97]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_159 (2, 87, 260, 260)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 260, 260)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 68], [0, 68]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_165 (2, 83, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_170 (2, 100, 318, 318)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 63, 126], [0, 63, 126]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_180 (2, 92, 294, 294)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_186 (2, 99, 280, 280)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 88], [0, 88]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_197 (2, 71, 337, 337)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 337, 337)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 72, 145], [0, 72, 145]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_201 (2, 74, 255, 255)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_209 (2, 101, 380, 380)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 380, 380)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 94, 188], [0, 94, 188]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_226 (2, 101, 328, 328)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 328, 328)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 68, 136], [0, 68, 136]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_228 (2, 110, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_234 (2, 79, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_235 (2, 82, 308, 308)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_243 (2, 99, 301, 301)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_246 (2, 104, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_253 (2, 91, 304, 304)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 91, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_255 (2, 96, 325, 325)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_261 (2, 94, 277, 277)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 277, 277)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85], [0, 85]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_268 (2, 65, 291, 291)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 65, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 1], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_275 (2, 102, 297, 297)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 297, 297)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 52, 105], [0, 52, 105]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_276 (2, 86, 338, 338)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 338, 338)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 73, 146], [0, 73, 146]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_304 (2, 90, 286, 286)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_308 (2, 110, 381, 381)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 381, 381)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 94, 189], [0, 94, 189]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_311 (2, 84, 303, 303)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_333 (2, 94, 386, 386)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_336 (2, 89, 340, 340)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 74, 148], [0, 74, 148]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_345 (2, 82, 332, 332)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_365 (2, 182, 346, 346)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 182, 346, 346)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 59, 88, 118], [0, 77, 154], [0, 77, 154]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_375 (2, 114, 355, 355)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_377 (2, 107, 342, 342)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 75, 150], [0, 75, 150]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_398 (2, 100, 368, 368)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 368, 368)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 88, 176], [0, 88, 176]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_400 (2, 104, 382, 382)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 382, 382)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 95, 190], [0, 95, 190]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_402 (2, 156, 287, 287)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 156, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 61, 92], [0, 95], [0, 95]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_404 (2, 102, 348, 348)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_406 (2, 84, 353, 353)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 353, 353)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 80, 161], [0, 80, 161]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_418 (2, 85, 278, 278)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_419 (2, 85, 371, 371)
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 90, 179], [0, 90, 179]]
number of tiles: 18
using precomputed Gaussian
prediction done
2022-05-29 16:04:27.794613: finished prediction
2022-05-29 16:04:27.798530: evaluation of raw predictions
2022-05-29 16:04:34.767969: determining postprocessing
Foreground vs background
before: 0.8049775560505139
after:  0.8049749287518766
Only one class present, no need to do each class separately as this is covered in fg vs bg
done
for which classes:
[]
min_object_sizes
None
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: True lowres axis [0]
separate z, order in z is 0 order inplane is 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
done
predicting segmentations for the next stage of the cascade
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
no separate z, order 1
panc_004
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 51, 102], [0, 51, 102]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_019
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 78, 156], [0, 78, 156]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_028
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 81, 315, 315)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 17], [0, 62, 123], [0, 62, 123]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_051
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_066
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 186, 322, 322)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 61, 92, 122], [0, 65, 130], [0, 65, 130]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_069
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 188, 312, 312)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 62, 93, 124], [0, 60, 120], [0, 60, 120]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_077
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_080
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 95, 319, 319)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31], [0, 64, 127], [0, 64, 127]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_093
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 113, 369, 369)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 24, 49], [0, 88, 177], [0, 88, 177]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_122
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 313, 313)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 60, 121], [0, 60, 121]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_129
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 289, 289)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 48, 97], [0, 48, 97]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_159
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 87, 260, 260)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23], [0, 68], [0, 68]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_165
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 83, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_170
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 318, 318)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 63, 126], [0, 63, 126]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_180
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 92, 294, 294)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 28], [0, 51, 102], [0, 51, 102]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_186
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 280, 280)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 88], [0, 88]]
number of tiles: 12
using precomputed Gaussian
prediction done
panc_197
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 71, 337, 337)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 7], [0, 72, 145], [0, 72, 145]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_201
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 74, 255, 255)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 10], [0, 63], [0, 63]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_209
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 380, 380)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 94, 188], [0, 94, 188]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_226
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 101, 328, 328)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 37], [0, 68, 136], [0, 68, 136]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_228
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_234
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 79, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 15], [0, 82, 163], [0, 82, 163]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_235
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 308, 308)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 58, 116], [0, 58, 116]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_243
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 99, 301, 301)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 35], [0, 54, 109], [0, 54, 109]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_246
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_253
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 91, 304, 304)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 27], [0, 56, 112], [0, 56, 112]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_255
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 96, 325, 325)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 32], [0, 66, 133], [0, 66, 133]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_261
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 277, 277)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 85], [0, 85]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_268
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 65, 291, 291)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 1], [0, 50, 99], [0, 50, 99]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_275
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 297, 297)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 52, 105], [0, 52, 105]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_276
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 86, 338, 338)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22], [0, 73, 146], [0, 73, 146]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_304
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 90, 286, 286)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 26], [0, 94], [0, 94]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_308
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 110, 381, 381)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 23, 46], [0, 94, 189], [0, 94, 189]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_311
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 303, 303)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 56, 111], [0, 56, 111]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_333
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 94, 386, 386)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30], [0, 65, 129, 194], [0, 65, 129, 194]]
number of tiles: 32
using precomputed Gaussian
prediction done
panc_336
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 89, 340, 340)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25], [0, 74, 148], [0, 74, 148]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_345
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 82, 332, 332)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18], [0, 70, 140], [0, 70, 140]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_365
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 182, 346, 346)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 30, 59, 88, 118], [0, 77, 154], [0, 77, 154]]
number of tiles: 45
using precomputed Gaussian
prediction done
panc_375
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 114, 355, 355)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 25, 50], [0, 82, 163], [0, 82, 163]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_377
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 107, 342, 342)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 22, 43], [0, 75, 150], [0, 75, 150]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_398
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 100, 368, 368)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 18, 36], [0, 88, 176], [0, 88, 176]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_400
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 104, 382, 382)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20, 40], [0, 95, 190], [0, 95, 190]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_402
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 156, 287, 287)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 31, 61, 92], [0, 95], [0, 95]]
number of tiles: 16
using precomputed Gaussian
prediction done
panc_404
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 102, 348, 348)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 19, 38], [0, 78, 156], [0, 78, 156]]
number of tiles: 27
using precomputed Gaussian
prediction done
panc_406
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 84, 353, 353)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 20], [0, 80, 161], [0, 80, 161]]
number of tiles: 18
using precomputed Gaussian
prediction done
panc_418
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 278, 278)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 86], [0, 86]]
number of tiles: 8
using precomputed Gaussian
prediction done
panc_419
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 85, 371, 371)
patch size: [ 64 192 192]
steps (x, y, and z): [[0, 21], [0, 90, 179], [0, 90, 179]]
number of tiles: 18
using precomputed Gaussian
prediction done
Program finished with exit code 0 at: Thu May 26 11:07:49 CEST 2022
