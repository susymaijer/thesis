Starting at Mon Jun  6 10:43:06 CEST 2022
Running on hosts: res-hpc-lkeb05
Running on 1 nodes.
Running 1 tasks.
CPUs on node: 8.
Account: div2-lkeb
Job ID: 10424342
Job name: PancreasTrain
Node running script: res-hpc-lkeb05
Submit host: res-hpc-lo02.researchlumc.nl
GPUS: 0 or 
Mon Jun  6 10:43:08 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     Off  | 00000000:3B:00.0 Off |                  Off |
| 33%   39C    P0    66W / 260W |      0MiB / 24220MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Current working directory is /home/smaijer
Load all modules..
Done with loading all modules. Modules:
Activate conda env nnunet..
Verifying environment variables:
nnUNet_raw_data_base = /exports/lkeb-hpc/smaijer/data/nnUNet_raw_data_base
nnUNet_preprocessed = /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed
RESULTS_FOLDER = /exports/lkeb-hpc/smaijer/results
OUTPUT = /exports/lkeb-hpc/smaijer/output
Installing hidden layer..
Collecting hiddenlayer
  Cloning https://github.com/FabianIsensee/hiddenlayer.git (to revision more_plotted_details) to /tmp/pip-install-n3qzayly/hiddenlayer_59dd17c7d3cc436f9d083d219f866c20
  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit 4b98f9e5cccebac67368f02b95f4700b522345b1
Installing nnU-net..
Obtaining file:///home/smaijer/code/nnUNet
Requirement already satisfied: torch>1.10.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.11.0)
Requirement already satisfied: tqdm in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (4.64.0)
Requirement already satisfied: dicom2nifti in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2.3.2)
Requirement already satisfied: scikit-image>=0.14 in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.19.2)
Requirement already satisfied: medpy in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.4.0)
Requirement already satisfied: scipy in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.8.0)
Requirement already satisfied: batchgenerators>=0.23 in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.23)
Requirement already satisfied: numpy in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.21.2)
Requirement already satisfied: sklearn in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.0)
Requirement already satisfied: SimpleITK in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2.1.1)
Requirement already satisfied: pandas in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.4.2)
Requirement already satisfied: requests in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2.27.1)
Requirement already satisfied: nibabel in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (3.2.2)
Requirement already satisfied: tifffile in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2022.4.8)
Requirement already satisfied: matplotlib in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (3.5.1)
Requirement already satisfied: scikit-learn in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.0.2)
Requirement already satisfied: pillow>=7.1.2 in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (9.0.1)
Requirement already satisfied: threadpoolctl in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (3.1.0)
Requirement already satisfied: future in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (0.18.2)
Requirement already satisfied: unittest2 in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)
Requirement already satisfied: imageio>=2.4.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.16.2)
Requirement already satisfied: packaging>=20.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (21.3)
Requirement already satisfied: networkx>=2.2 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.8)
Requirement already satisfied: PyWavelets>=1.1.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (1.3.0)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.conda/envs/nn/lib/python3.9/site-packages (from packaging>=20.0->scikit-image>=0.14->nnunet==1.7.0) (3.0.8)
Requirement already satisfied: typing_extensions in ./.conda/envs/nn/lib/python3.9/site-packages (from torch>1.10.0->nnunet==1.7.0) (4.1.1)
Requirement already satisfied: pydicom>=1.3.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from dicom2nifti->nnunet==1.7.0) (2.3.0)
Requirement already satisfied: python-dateutil>=2.7 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (2.8.2)
Requirement already satisfied: kiwisolver>=1.0.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (1.4.2)
Requirement already satisfied: cycler>=0.10 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (0.11.0)
Requirement already satisfied: fonttools>=4.22.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (4.32.0)
Requirement already satisfied: six>=1.5 in ./.conda/envs/nn/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->nnunet==1.7.0) (1.16.0)
Requirement already satisfied: setuptools in ./.conda/envs/nn/lib/python3.9/site-packages (from nibabel->nnunet==1.7.0) (58.0.4)
Requirement already satisfied: pytz>=2020.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from pandas->nnunet==1.7.0) (2022.1)
Requirement already satisfied: charset-normalizer~=2.0.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (2.0.4)
Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (2021.10.8)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (1.26.8)
Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (3.3)
Requirement already satisfied: joblib>=0.11 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-learn->batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)
Requirement already satisfied: traceback2 in ./.conda/envs/nn/lib/python3.9/site-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.4.0)
Collecting argparse
  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)
Requirement already satisfied: linecache2 in ./.conda/envs/nn/lib/python3.9/site-packages (from traceback2->unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.0.0)
Installing collected packages: argparse, nnunet
  Attempting uninstall: nnunet
    Found existing installation: nnunet 1.7.0
    Uninstalling nnunet-1.7.0:
      Successfully uninstalled nnunet-1.7.0
  Running setup.py develop for nnunet
Successfully installed argparse-1.4.0 nnunet-1.7.0


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_cascade_fullres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2_CascadeFullRes.nnUNetTrainerV2CascadeFullRes'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 192, 192]), 'median_patient_size_in_voxels': array([ 93, 318, 318]), 'current_spacing': array([2.5757525 , 1.29418872, 1.29418872]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [3, 5, 5], 'patch_size': array([ 40, 224, 224]), 'median_patient_size_in_voxels': array([ 96, 512, 512]), 'current_spacing': array([2.5       , 0.80273402, 0.80273402]), 'original_spacing': array([2.5       , 0.80273402, 0.80273402]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 1 from these plans
I am using batch dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/nnUNetData_plans_v2.1
###############################################
2022-06-06 10:43:43.717586: Using dummy2d data augmentation
loading dataset
loading all case properties
2022-06-06 10:43:57.534452: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task510/splits_final.pkl
2022-06-06 10:43:57.550053: The split file contains 5 splits.
2022-06-06 10:43:57.552337: Desired fold for training: 4
2022-06-06 10:43:57.554338: This split has 192 training and 47 validation cases.
unpacking dataset
done
2022-06-06 10:44:02.003026: loading checkpoint /exports/lkeb-hpc/smaijer/results/nnUNet/3d_cascade_fullres/Task510/nnUNetTrainerV2CascadeFullRes__nnUNetPlansv2.1/fold_4/model_latest.model train= True
2022-06-06 10:44:10.501690: lr: 0.002349
using pin_memory on device 0
using pin_memory on device 0
2022-06-06 10:44:30.147049: Unable to plot network architecture:
2022-06-06 10:44:30.151648: No module named 'IPython'
2022-06-06 10:44:30.154266: 
printing the network instead:

2022-06-06 10:44:30.156725: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(2, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-06-06 10:44:30.160931: 

2022-06-06 10:44:30.163370: 
epoch:  400
2022-06-06 10:47:24.022073: train loss : -0.8095
2022-06-06 10:47:58.906782: validation loss: -0.7935
2022-06-06 10:47:58.910738: Average global foreground Dice: [0.8234]
2022-06-06 10:47:58.913161: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 10:47:59.815180: lr: 0.002328
2022-06-06 10:47:59.901462: saving checkpoint...
2022-06-06 10:48:01.038910: done, saving took 1.22 seconds
2022-06-06 10:48:01.054764: This epoch took 210.889136 s

2022-06-06 10:48:01.057512: 
epoch:  401
2022-06-06 10:49:48.136303: train loss : -0.8071
2022-06-06 10:50:09.299980: validation loss: -0.7823
2022-06-06 10:50:09.303427: Average global foreground Dice: [0.814]
2022-06-06 10:50:09.305562: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 10:50:09.927904: lr: 0.002307
2022-06-06 10:50:09.930209: This epoch took 128.870142 s

2022-06-06 10:50:09.932138: 
epoch:  402
2022-06-06 10:51:46.956353: train loss : -0.8133
2022-06-06 10:52:07.440956: validation loss: -0.7796
2022-06-06 10:52:07.445117: Average global foreground Dice: [0.814]
2022-06-06 10:52:07.447264: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 10:52:07.973350: lr: 0.002286
2022-06-06 10:52:07.975528: This epoch took 118.041505 s

2022-06-06 10:52:07.977471: 
epoch:  403
2022-06-06 10:53:41.669292: train loss : -0.8101
2022-06-06 10:53:58.746054: validation loss: -0.7835
2022-06-06 10:53:58.750203: Average global foreground Dice: [0.8098]
2022-06-06 10:53:58.752158: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 10:53:59.297647: lr: 0.002264
2022-06-06 10:53:59.299861: This epoch took 111.320481 s

2022-06-06 10:53:59.302003: 
epoch:  404
2022-06-06 10:55:33.184158: train loss : -0.8090
2022-06-06 10:55:46.492708: validation loss: -0.7798
2022-06-06 10:55:46.495914: Average global foreground Dice: [0.816]
2022-06-06 10:55:46.498194: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 10:55:47.059156: lr: 0.002243
2022-06-06 10:55:47.061225: This epoch took 107.757218 s

2022-06-06 10:55:47.063317: 
epoch:  405
2022-06-06 10:57:21.173461: train loss : -0.8085
2022-06-06 10:57:31.164041: validation loss: -0.7732
2022-06-06 10:57:31.167026: Average global foreground Dice: [0.8089]
2022-06-06 10:57:31.169053: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 10:57:31.695534: lr: 0.002222
2022-06-06 10:57:31.698182: This epoch took 104.632938 s

2022-06-06 10:57:31.700158: 
epoch:  406
2022-06-06 10:59:05.706726: train loss : -0.7915
2022-06-06 10:59:16.513647: validation loss: -0.7977
2022-06-06 10:59:16.517127: Average global foreground Dice: [0.8294]
2022-06-06 10:59:16.519212: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 10:59:17.077124: lr: 0.002201
2022-06-06 10:59:17.079769: This epoch took 105.377766 s

2022-06-06 10:59:17.082009: 
epoch:  407
2022-06-06 11:00:51.113056: train loss : -0.8099
2022-06-06 11:00:59.354173: validation loss: -0.7752
2022-06-06 11:00:59.358201: Average global foreground Dice: [0.8134]
2022-06-06 11:00:59.361043: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:00:59.956130: lr: 0.002179
2022-06-06 11:00:59.958624: This epoch took 102.873559 s

2022-06-06 11:00:59.961017: 
epoch:  408
2022-06-06 11:02:33.965078: train loss : -0.8109
2022-06-06 11:02:40.652853: validation loss: -0.7628
2022-06-06 11:02:40.656404: Average global foreground Dice: [0.7989]
2022-06-06 11:02:40.658551: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:02:41.237215: lr: 0.002158
2022-06-06 11:02:41.240043: This epoch took 101.276741 s

2022-06-06 11:02:41.246289: 
epoch:  409
2022-06-06 11:04:14.824119: train loss : -0.8129
2022-06-06 11:04:22.745267: validation loss: -0.7209
2022-06-06 11:04:22.748655: Average global foreground Dice: [0.7609]
2022-06-06 11:04:22.750931: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:04:23.261259: lr: 0.002137
2022-06-06 11:04:23.263690: This epoch took 102.014602 s

2022-06-06 11:04:23.265616: 
epoch:  410
2022-06-06 11:05:56.680723: train loss : -0.7952
2022-06-06 11:06:05.083139: validation loss: -0.7695
2022-06-06 11:06:05.085918: Average global foreground Dice: [0.7982]
2022-06-06 11:06:05.087870: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:06:05.597126: lr: 0.002115
2022-06-06 11:06:05.600391: This epoch took 102.332793 s

2022-06-06 11:06:05.603358: 
epoch:  411
2022-06-06 11:07:38.803976: train loss : -0.8098
2022-06-06 11:07:46.951140: validation loss: -0.7754
2022-06-06 11:07:46.954597: Average global foreground Dice: [0.8149]
2022-06-06 11:07:46.956759: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:07:47.463105: lr: 0.002094
2022-06-06 11:07:47.465556: This epoch took 101.860383 s

2022-06-06 11:07:47.467742: 
epoch:  412
2022-06-06 11:09:20.637135: train loss : -0.8049
2022-06-06 11:09:29.583657: validation loss: -0.7819
2022-06-06 11:09:29.586529: Average global foreground Dice: [0.8126]
2022-06-06 11:09:29.588569: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:09:30.109061: lr: 0.002072
2022-06-06 11:09:30.162159: This epoch took 102.692140 s

2022-06-06 11:09:30.192512: 
epoch:  413
2022-06-06 11:11:03.219499: train loss : -0.8059
2022-06-06 11:11:13.668804: validation loss: -0.7736
2022-06-06 11:11:13.672069: Average global foreground Dice: [0.8076]
2022-06-06 11:11:13.674515: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:11:14.182751: lr: 0.002051
2022-06-06 11:11:14.185019: This epoch took 103.987185 s

2022-06-06 11:11:14.186943: 
epoch:  414
2022-06-06 11:12:47.060298: train loss : -0.8107
2022-06-06 11:12:55.058847: validation loss: -0.7504
2022-06-06 11:12:55.062567: Average global foreground Dice: [0.7894]
2022-06-06 11:12:55.064684: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:12:55.584608: lr: 0.00203
2022-06-06 11:12:55.586953: This epoch took 101.397803 s

2022-06-06 11:12:55.588842: 
epoch:  415
2022-06-06 11:14:28.767005: train loss : -0.8087
2022-06-06 11:14:36.976579: validation loss: -0.7835
2022-06-06 11:14:36.980808: Average global foreground Dice: [0.8218]
2022-06-06 11:14:36.983300: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:14:37.483861: lr: 0.002008
2022-06-06 11:14:37.486159: This epoch took 101.895500 s

2022-06-06 11:14:37.488035: 
epoch:  416
2022-06-06 11:16:10.589990: train loss : -0.8121
2022-06-06 11:16:21.414832: validation loss: -0.7985
2022-06-06 11:16:21.418001: Average global foreground Dice: [0.8312]
2022-06-06 11:16:21.420465: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:16:21.932857: lr: 0.001987
2022-06-06 11:16:21.935260: This epoch took 104.445280 s

2022-06-06 11:16:21.937800: 
epoch:  417
2022-06-06 11:17:54.873620: train loss : -0.8169
2022-06-06 11:18:06.842411: validation loss: -0.7753
2022-06-06 11:18:06.845325: Average global foreground Dice: [0.816]
2022-06-06 11:18:06.847236: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:18:07.377084: lr: 0.001965
2022-06-06 11:18:07.379513: This epoch took 105.439666 s

2022-06-06 11:18:07.381498: 
epoch:  418
2022-06-06 11:19:40.402882: train loss : -0.8043
2022-06-06 11:19:52.328741: validation loss: -0.7402
2022-06-06 11:19:52.332493: Average global foreground Dice: [0.778]
2022-06-06 11:19:52.334429: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:19:52.850983: lr: 0.001943
2022-06-06 11:19:52.853405: This epoch took 105.469810 s

2022-06-06 11:19:52.855280: 
epoch:  419
2022-06-06 11:21:26.176273: train loss : -0.8141
2022-06-06 11:21:35.623775: validation loss: -0.7620
2022-06-06 11:21:35.627457: Average global foreground Dice: [0.7969]
2022-06-06 11:21:35.629921: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:21:36.164370: lr: 0.001922
2022-06-06 11:21:36.166919: This epoch took 103.309768 s

2022-06-06 11:21:36.169105: 
epoch:  420
2022-06-06 11:23:09.553832: train loss : -0.8104
2022-06-06 11:23:20.932052: validation loss: -0.7586
2022-06-06 11:23:20.934953: Average global foreground Dice: [0.7887]
2022-06-06 11:23:20.937073: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:23:21.445440: lr: 0.0019
2022-06-06 11:23:21.448272: This epoch took 105.276967 s

2022-06-06 11:23:21.450720: 
epoch:  421
2022-06-06 11:24:54.822301: train loss : -0.8151
2022-06-06 11:25:04.176329: validation loss: -0.7979
2022-06-06 11:25:04.180102: Average global foreground Dice: [0.8317]
2022-06-06 11:25:04.182271: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:25:04.689542: lr: 0.001879
2022-06-06 11:25:04.691927: This epoch took 103.238961 s

2022-06-06 11:25:04.694707: 
epoch:  422
2022-06-06 11:26:38.161652: train loss : -0.8198
2022-06-06 11:26:47.279102: validation loss: -0.7736
2022-06-06 11:26:47.282186: Average global foreground Dice: [0.8114]
2022-06-06 11:26:47.284563: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:26:47.834774: lr: 0.001857
2022-06-06 11:26:47.836971: This epoch took 103.140006 s

2022-06-06 11:26:47.838994: 
epoch:  423
2022-06-06 11:28:21.296684: train loss : -0.8178
2022-06-06 11:28:30.189969: validation loss: -0.7709
2022-06-06 11:28:30.193645: Average global foreground Dice: [0.8073]
2022-06-06 11:28:30.196001: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:28:30.705541: lr: 0.001835
2022-06-06 11:28:30.708023: This epoch took 102.867046 s

2022-06-06 11:28:30.710113: 
epoch:  424
2022-06-06 11:30:04.042679: train loss : -0.8071
2022-06-06 11:30:13.384015: validation loss: -0.7831
2022-06-06 11:30:13.387695: Average global foreground Dice: [0.8126]
2022-06-06 11:30:13.389998: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:30:13.911665: lr: 0.001813
2022-06-06 11:30:13.914474: This epoch took 103.202429 s

2022-06-06 11:30:13.916678: 
epoch:  425
2022-06-06 11:31:47.373590: train loss : -0.8185
2022-06-06 11:31:56.741649: validation loss: -0.7710
2022-06-06 11:31:56.745098: Average global foreground Dice: [0.8032]
2022-06-06 11:31:56.747272: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:31:57.311176: lr: 0.001792
2022-06-06 11:31:57.313358: This epoch took 103.394603 s

2022-06-06 11:31:57.315418: 
epoch:  426
2022-06-06 11:33:30.747049: train loss : -0.8120
2022-06-06 11:33:38.369936: validation loss: -0.7693
2022-06-06 11:33:38.373662: Average global foreground Dice: [0.8056]
2022-06-06 11:33:38.376042: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:33:38.883789: lr: 0.00177
2022-06-06 11:33:38.886028: This epoch took 101.568677 s

2022-06-06 11:33:38.887385: 
epoch:  427
2022-06-06 11:35:12.388667: train loss : -0.8133
2022-06-06 11:35:22.396278: validation loss: -0.7781
2022-06-06 11:35:22.399855: Average global foreground Dice: [0.8138]
2022-06-06 11:35:22.402235: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:35:22.960446: lr: 0.001748
2022-06-06 11:35:22.963323: This epoch took 104.073263 s

2022-06-06 11:35:22.965838: 
epoch:  428
2022-06-06 11:36:56.543433: train loss : -0.8063
2022-06-06 11:37:04.245531: validation loss: -0.7821
2022-06-06 11:37:04.248844: Average global foreground Dice: [0.8141]
2022-06-06 11:37:04.250809: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:37:04.776028: lr: 0.001726
2022-06-06 11:37:04.778610: This epoch took 101.810030 s

2022-06-06 11:37:04.781008: 
epoch:  429
2022-06-06 11:38:38.382430: train loss : -0.8107
2022-06-06 11:38:47.366659: validation loss: -0.7770
2022-06-06 11:38:47.369555: Average global foreground Dice: [0.8099]
2022-06-06 11:38:47.371541: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:38:47.913416: lr: 0.001704
2022-06-06 11:38:47.916052: This epoch took 103.132521 s

2022-06-06 11:38:47.918115: 
epoch:  430
2022-06-06 11:40:21.362519: train loss : -0.8174
2022-06-06 11:40:32.851747: validation loss: -0.7693
2022-06-06 11:40:32.854919: Average global foreground Dice: [0.8094]
2022-06-06 11:40:32.857364: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:40:33.371304: lr: 0.001682
2022-06-06 11:40:33.373545: This epoch took 105.453506 s

2022-06-06 11:40:33.375449: 
epoch:  431
2022-06-06 11:42:06.752807: train loss : -0.8212
2022-06-06 11:42:16.236676: validation loss: -0.7742
2022-06-06 11:42:16.240327: Average global foreground Dice: [0.8064]
2022-06-06 11:42:16.242559: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:42:16.754813: lr: 0.00166
2022-06-06 11:42:16.757529: This epoch took 103.380175 s

2022-06-06 11:42:16.760462: 
epoch:  432
2022-06-06 11:43:50.248588: train loss : -0.8251
2022-06-06 11:43:58.908389: validation loss: -0.7864
2022-06-06 11:43:58.911433: Average global foreground Dice: [0.8161]
2022-06-06 11:43:58.914054: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:43:59.437942: lr: 0.001638
2022-06-06 11:43:59.440601: This epoch took 102.677996 s

2022-06-06 11:43:59.443771: 
epoch:  433
2022-06-06 11:45:32.889565: train loss : -0.8186
2022-06-06 11:45:39.724565: validation loss: -0.7543
2022-06-06 11:45:39.727717: Average global foreground Dice: [0.7974]
2022-06-06 11:45:39.729961: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:45:40.263446: lr: 0.001616
2022-06-06 11:45:40.265749: This epoch took 100.816916 s

2022-06-06 11:45:40.267631: 
epoch:  434
2022-06-06 11:47:13.784658: train loss : -0.8189
2022-06-06 11:47:20.803312: validation loss: -0.7779
2022-06-06 11:47:20.806488: Average global foreground Dice: [0.8125]
2022-06-06 11:47:20.808075: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:47:21.331061: lr: 0.001594
2022-06-06 11:47:21.333960: This epoch took 101.064385 s

2022-06-06 11:47:21.336890: 
epoch:  435
2022-06-06 11:48:54.877898: train loss : -0.8205
2022-06-06 11:49:05.818850: validation loss: -0.7593
2022-06-06 11:49:05.822133: Average global foreground Dice: [0.802]
2022-06-06 11:49:05.824539: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:49:06.355803: lr: 0.001572
2022-06-06 11:49:06.358278: This epoch took 105.018780 s

2022-06-06 11:49:06.359598: 
epoch:  436
2022-06-06 11:50:39.768310: train loss : -0.8141
2022-06-06 11:50:47.307103: validation loss: -0.7947
2022-06-06 11:50:47.310522: Average global foreground Dice: [0.8243]
2022-06-06 11:50:47.312462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:50:47.829306: lr: 0.00155
2022-06-06 11:50:47.831711: This epoch took 101.469725 s

2022-06-06 11:50:47.833979: 
epoch:  437
2022-06-06 11:52:21.345282: train loss : -0.8208
2022-06-06 11:52:27.623446: validation loss: -0.7614
2022-06-06 11:52:27.626340: Average global foreground Dice: [0.7988]
2022-06-06 11:52:27.628511: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:52:28.153412: lr: 0.001528
2022-06-06 11:52:28.156436: This epoch took 100.319977 s

2022-06-06 11:52:28.158765: 
epoch:  438
2022-06-06 11:54:01.702467: train loss : -0.8244
2022-06-06 11:54:12.795075: validation loss: -0.7844
2022-06-06 11:54:12.797951: Average global foreground Dice: [0.8181]
2022-06-06 11:54:12.800038: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:54:13.316501: lr: 0.001506
2022-06-06 11:54:13.318667: This epoch took 105.157716 s

2022-06-06 11:54:13.320727: 
epoch:  439
2022-06-06 11:55:46.712227: train loss : -0.8259
2022-06-06 11:55:55.699478: validation loss: -0.7683
2022-06-06 11:55:55.702437: Average global foreground Dice: [0.8022]
2022-06-06 11:55:55.704806: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:55:56.239542: lr: 0.001483
2022-06-06 11:55:56.241845: This epoch took 102.918936 s

2022-06-06 11:55:56.244013: 
epoch:  440
2022-06-06 11:57:29.694126: train loss : -0.8221
2022-06-06 11:57:39.703158: validation loss: -0.7673
2022-06-06 11:57:39.706150: Average global foreground Dice: [0.8113]
2022-06-06 11:57:39.708198: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:57:40.232613: lr: 0.001461
2022-06-06 11:57:40.234888: This epoch took 103.988558 s

2022-06-06 11:57:40.236823: 
epoch:  441
2022-06-06 11:59:13.635827: train loss : -0.8185
2022-06-06 11:59:23.737605: validation loss: -0.7689
2022-06-06 11:59:23.740620: Average global foreground Dice: [0.8034]
2022-06-06 11:59:23.742584: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 11:59:24.256189: lr: 0.001439
2022-06-06 11:59:24.258573: This epoch took 104.019794 s

2022-06-06 11:59:24.260741: 
epoch:  442
2022-06-06 12:00:57.595167: train loss : -0.8186
2022-06-06 12:01:08.846957: validation loss: -0.7681
2022-06-06 12:01:08.850333: Average global foreground Dice: [0.8069]
2022-06-06 12:01:08.852888: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:01:09.364037: lr: 0.001416
2022-06-06 12:01:09.366349: This epoch took 105.103385 s

2022-06-06 12:01:09.368473: 
epoch:  443
2022-06-06 12:02:42.825041: train loss : -0.8275
2022-06-06 12:02:52.382232: validation loss: -0.7632
2022-06-06 12:02:52.385223: Average global foreground Dice: [0.7993]
2022-06-06 12:02:52.386833: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:02:52.903601: lr: 0.001394
2022-06-06 12:02:52.905864: This epoch took 103.535389 s

2022-06-06 12:02:52.908313: 
epoch:  444
2022-06-06 12:04:26.259551: train loss : -0.8248
2022-06-06 12:04:38.059999: validation loss: -0.7698
2022-06-06 12:04:38.065304: Average global foreground Dice: [0.8053]
2022-06-06 12:04:38.071553: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:04:38.589555: lr: 0.001372
2022-06-06 12:04:38.591845: This epoch took 105.681126 s

2022-06-06 12:04:38.593817: 
epoch:  445
2022-06-06 12:06:11.873230: train loss : -0.8262
2022-06-06 12:06:21.510810: validation loss: -0.7833
2022-06-06 12:06:21.513799: Average global foreground Dice: [0.8153]
2022-06-06 12:06:21.522837: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:06:22.051237: lr: 0.001349
2022-06-06 12:06:22.053935: This epoch took 103.458257 s

2022-06-06 12:06:22.056054: 
epoch:  446
2022-06-06 12:07:55.675940: train loss : -0.8199
2022-06-06 12:08:04.643385: validation loss: -0.7730
2022-06-06 12:08:04.646827: Average global foreground Dice: [0.8134]
2022-06-06 12:08:04.649423: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:08:05.180946: lr: 0.001327
2022-06-06 12:08:05.183681: This epoch took 103.125436 s

2022-06-06 12:08:05.185781: 
epoch:  447
2022-06-06 12:09:38.575905: train loss : -0.8296
2022-06-06 12:09:46.213259: validation loss: -0.7591
2022-06-06 12:09:46.216358: Average global foreground Dice: [0.7974]
2022-06-06 12:09:46.218503: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:09:46.750269: lr: 0.001304
2022-06-06 12:09:46.752683: This epoch took 101.564597 s

2022-06-06 12:09:46.754721: 
epoch:  448
2022-06-06 12:11:20.216203: train loss : -0.8245
2022-06-06 12:11:28.511534: validation loss: -0.7868
2022-06-06 12:11:28.520278: Average global foreground Dice: [0.817]
2022-06-06 12:11:28.522721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:11:29.037417: lr: 0.001282
2022-06-06 12:11:29.040061: This epoch took 102.283350 s

2022-06-06 12:11:29.042403: 
epoch:  449
2022-06-06 12:13:02.468148: train loss : -0.8241
2022-06-06 12:13:11.635164: validation loss: -0.7709
2022-06-06 12:13:11.638131: Average global foreground Dice: [0.7966]
2022-06-06 12:13:11.640199: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:13:12.171056: lr: 0.001259
2022-06-06 12:13:12.173528: saving scheduled checkpoint file...
2022-06-06 12:13:12.210396: saving checkpoint...
2022-06-06 12:13:13.266078: done, saving took 1.09 seconds
2022-06-06 12:13:13.285590: done
2022-06-06 12:13:13.288598: This epoch took 104.243694 s

2022-06-06 12:13:13.290962: 
epoch:  450
2022-06-06 12:14:46.669223: train loss : -0.8247
2022-06-06 12:14:57.300023: validation loss: -0.7741
2022-06-06 12:14:57.303505: Average global foreground Dice: [0.8147]
2022-06-06 12:14:57.306170: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:14:57.876322: lr: 0.001236
2022-06-06 12:14:57.878844: This epoch took 104.585695 s

2022-06-06 12:14:57.880965: 
epoch:  451
2022-06-06 12:16:31.427490: train loss : -0.8307
2022-06-06 12:16:41.481781: validation loss: -0.7945
2022-06-06 12:16:41.484631: Average global foreground Dice: [0.822]
2022-06-06 12:16:41.486725: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:16:42.046886: lr: 0.001214
2022-06-06 12:16:42.049191: This epoch took 104.165872 s

2022-06-06 12:16:42.051101: 
epoch:  452
2022-06-06 12:18:15.356946: train loss : -0.8310
2022-06-06 12:18:23.401700: validation loss: -0.7784
2022-06-06 12:18:23.404666: Average global foreground Dice: [0.8076]
2022-06-06 12:18:23.406873: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:18:23.931110: lr: 0.001191
2022-06-06 12:18:23.933383: This epoch took 101.880436 s

2022-06-06 12:18:23.935346: 
epoch:  453
2022-06-06 12:19:57.459469: train loss : -0.8271
2022-06-06 12:20:05.159001: validation loss: -0.7531
2022-06-06 12:20:05.161890: Average global foreground Dice: [0.794]
2022-06-06 12:20:05.164041: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:20:05.682029: lr: 0.001168
2022-06-06 12:20:05.684374: This epoch took 101.746911 s

2022-06-06 12:20:05.686598: 
epoch:  454
2022-06-06 12:21:39.122214: train loss : -0.8227
2022-06-06 12:21:46.942320: validation loss: -0.7608
2022-06-06 12:21:46.945584: Average global foreground Dice: [0.8014]
2022-06-06 12:21:46.947812: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:21:47.486762: lr: 0.001145
2022-06-06 12:21:47.489030: This epoch took 101.800387 s

2022-06-06 12:21:47.491047: 
epoch:  455
2022-06-06 12:23:20.925332: train loss : -0.8383
2022-06-06 12:23:29.021038: validation loss: -0.7744
2022-06-06 12:23:29.024738: Average global foreground Dice: [0.802]
2022-06-06 12:23:29.027003: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:23:29.569386: lr: 0.001122
2022-06-06 12:23:29.571800: This epoch took 102.078843 s

2022-06-06 12:23:29.573878: 
epoch:  456
2022-06-06 12:25:02.968904: train loss : -0.8259
2022-06-06 12:25:14.216585: validation loss: -0.7705
2022-06-06 12:25:14.220194: Average global foreground Dice: [0.8042]
2022-06-06 12:25:14.224548: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:25:14.768142: lr: 0.001099
2022-06-06 12:25:14.770747: This epoch took 105.194622 s

2022-06-06 12:25:14.773074: 
epoch:  457
2022-06-06 12:26:48.496872: train loss : -0.8323
2022-06-06 12:26:55.865061: validation loss: -0.7590
2022-06-06 12:26:55.874699: Average global foreground Dice: [0.7935]
2022-06-06 12:26:55.876941: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:26:56.442616: lr: 0.001076
2022-06-06 12:26:56.445190: This epoch took 101.669868 s

2022-06-06 12:26:56.447181: 
epoch:  458
2022-06-06 12:28:29.997767: train loss : -0.8298
2022-06-06 12:28:37.288376: validation loss: -0.7640
2022-06-06 12:28:37.291385: Average global foreground Dice: [0.7955]
2022-06-06 12:28:37.293887: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:28:37.893464: lr: 0.001053
2022-06-06 12:28:37.895764: This epoch took 101.446511 s

2022-06-06 12:28:37.897914: 
epoch:  459
2022-06-06 12:30:11.475034: train loss : -0.8331
2022-06-06 12:30:19.293284: validation loss: -0.7798
2022-06-06 12:30:19.296825: Average global foreground Dice: [0.8134]
2022-06-06 12:30:19.298881: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:30:19.819296: lr: 0.00103
2022-06-06 12:30:19.821584: This epoch took 101.921561 s

2022-06-06 12:30:19.823575: 
epoch:  460
2022-06-06 12:31:53.410667: train loss : -0.8345
2022-06-06 12:32:02.494695: validation loss: -0.7727
2022-06-06 12:32:02.498200: Average global foreground Dice: [0.8128]
2022-06-06 12:32:02.500323: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:32:03.028661: lr: 0.001007
2022-06-06 12:32:03.031039: This epoch took 103.205523 s

2022-06-06 12:32:03.033224: 
epoch:  461
2022-06-06 12:33:36.541426: train loss : -0.8318
2022-06-06 12:33:43.411350: validation loss: -0.7679
2022-06-06 12:33:43.414574: Average global foreground Dice: [0.812]
2022-06-06 12:33:43.417383: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:33:43.945379: lr: 0.000983
2022-06-06 12:33:43.948124: This epoch took 100.912964 s

2022-06-06 12:33:43.950669: 
epoch:  462
2022-06-06 12:35:17.613752: train loss : -0.8320
2022-06-06 12:35:25.079422: validation loss: -0.7714
2022-06-06 12:35:25.082231: Average global foreground Dice: [0.806]
2022-06-06 12:35:25.084393: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:35:25.627423: lr: 0.00096
2022-06-06 12:35:25.629840: This epoch took 101.677092 s

2022-06-06 12:35:25.632039: 
epoch:  463
2022-06-06 12:36:59.307540: train loss : -0.8274
2022-06-06 12:37:06.726371: validation loss: -0.7861
2022-06-06 12:37:06.729626: Average global foreground Dice: [0.819]
2022-06-06 12:37:06.732059: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:37:07.261603: lr: 0.000937
2022-06-06 12:37:07.263804: This epoch took 101.629701 s

2022-06-06 12:37:07.266190: 
epoch:  464
2022-06-06 12:38:40.812588: train loss : -0.8402
2022-06-06 12:38:47.585804: validation loss: -0.7716
2022-06-06 12:38:47.588819: Average global foreground Dice: [0.8149]
2022-06-06 12:38:47.591235: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:38:48.149837: lr: 0.000913
2022-06-06 12:38:48.152175: This epoch took 100.883747 s

2022-06-06 12:38:48.154350: 
epoch:  465
2022-06-06 12:40:21.654149: train loss : -0.8337
2022-06-06 12:40:28.504492: validation loss: -0.7833
2022-06-06 12:40:28.507850: Average global foreground Dice: [0.8161]
2022-06-06 12:40:28.509906: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:40:29.035801: lr: 0.00089
2022-06-06 12:40:29.037977: This epoch took 100.881221 s

2022-06-06 12:40:29.040352: 
epoch:  466
2022-06-06 12:42:02.578208: train loss : -0.8407
2022-06-06 12:42:10.647573: validation loss: -0.7750
2022-06-06 12:42:10.650948: Average global foreground Dice: [0.8046]
2022-06-06 12:42:10.653253: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:42:11.176738: lr: 0.000866
2022-06-06 12:42:11.179216: This epoch took 102.136567 s

2022-06-06 12:42:11.181716: 
epoch:  467
2022-06-06 12:43:44.671772: train loss : -0.8321
2022-06-06 12:43:51.115084: validation loss: -0.7932
2022-06-06 12:43:51.117853: Average global foreground Dice: [0.826]
2022-06-06 12:43:51.120069: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:43:51.647612: lr: 0.000842
2022-06-06 12:43:51.650100: This epoch took 100.466009 s

2022-06-06 12:43:51.652357: 
epoch:  468
2022-06-06 12:45:25.103004: train loss : -0.8306
2022-06-06 12:45:32.088743: validation loss: -0.7668
2022-06-06 12:45:32.092119: Average global foreground Dice: [0.8044]
2022-06-06 12:45:32.094792: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:45:32.630249: lr: 0.000819
2022-06-06 12:45:32.632884: This epoch took 100.978358 s

2022-06-06 12:45:32.635191: 
epoch:  469
2022-06-06 12:47:06.238081: train loss : -0.8304
2022-06-06 12:47:15.273626: validation loss: -0.7824
2022-06-06 12:47:15.277045: Average global foreground Dice: [0.8193]
2022-06-06 12:47:15.279449: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:47:15.820791: lr: 0.000795
2022-06-06 12:47:15.823145: This epoch took 103.185120 s

2022-06-06 12:47:15.825186: 
epoch:  470
2022-06-06 12:48:49.289301: train loss : -0.8330
2022-06-06 12:48:56.784839: validation loss: -0.7833
2022-06-06 12:48:56.787863: Average global foreground Dice: [0.8143]
2022-06-06 12:48:56.790189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:48:57.355259: lr: 0.000771
2022-06-06 12:48:57.357924: This epoch took 101.530912 s

2022-06-06 12:48:57.360328: 
epoch:  471
2022-06-06 12:50:30.900269: train loss : -0.8373
2022-06-06 12:50:38.409947: validation loss: -0.7817
2022-06-06 12:50:38.413679: Average global foreground Dice: [0.8117]
2022-06-06 12:50:38.416229: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:50:38.956112: lr: 0.000747
2022-06-06 12:50:38.963979: This epoch took 101.601256 s

2022-06-06 12:50:38.966158: 
epoch:  472
2022-06-06 12:52:12.489613: train loss : -0.8467
2022-06-06 12:52:20.425664: validation loss: -0.7766
2022-06-06 12:52:20.428764: Average global foreground Dice: [0.8171]
2022-06-06 12:52:20.430913: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:52:20.953315: lr: 0.000723
2022-06-06 12:52:20.960282: This epoch took 101.991925 s

2022-06-06 12:52:20.962466: 
epoch:  473
2022-06-06 12:53:54.309489: train loss : -0.8390
2022-06-06 12:54:01.329017: validation loss: -0.7918
2022-06-06 12:54:01.332146: Average global foreground Dice: [0.8256]
2022-06-06 12:54:01.334236: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:54:01.860321: lr: 0.000699
2022-06-06 12:54:01.862666: This epoch took 100.898336 s

2022-06-06 12:54:01.864595: 
epoch:  474
2022-06-06 12:55:35.435644: train loss : -0.8315
2022-06-06 12:55:43.674518: validation loss: -0.7722
2022-06-06 12:55:43.678038: Average global foreground Dice: [0.807]
2022-06-06 12:55:43.679942: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:55:44.222452: lr: 0.000675
2022-06-06 12:55:44.225077: This epoch took 102.358693 s

2022-06-06 12:55:44.227354: 
epoch:  475
2022-06-06 12:57:17.718665: train loss : -0.8358
2022-06-06 12:57:24.010205: validation loss: -0.7746
2022-06-06 12:57:24.013283: Average global foreground Dice: [0.8043]
2022-06-06 12:57:24.015549: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:57:24.542980: lr: 0.00065
2022-06-06 12:57:24.545905: This epoch took 100.316225 s

2022-06-06 12:57:24.548274: 
epoch:  476
2022-06-06 12:58:58.078612: train loss : -0.8459
2022-06-06 12:59:04.875882: validation loss: -0.7859
2022-06-06 12:59:04.879083: Average global foreground Dice: [0.817]
2022-06-06 12:59:04.881491: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 12:59:05.444372: lr: 0.000626
2022-06-06 12:59:05.447579: This epoch took 100.897077 s

2022-06-06 12:59:05.450156: 
epoch:  477
2022-06-06 13:00:38.978274: train loss : -0.8412
2022-06-06 13:00:45.705840: validation loss: -0.7591
2022-06-06 13:00:45.709324: Average global foreground Dice: [0.7918]
2022-06-06 13:00:45.711583: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:00:46.293878: lr: 0.000601
2022-06-06 13:00:46.297024: This epoch took 100.844085 s

2022-06-06 13:00:46.300272: 
epoch:  478
2022-06-06 13:02:19.795136: train loss : -0.8397
2022-06-06 13:02:26.156062: validation loss: -0.7628
2022-06-06 13:02:26.159956: Average global foreground Dice: [0.8004]
2022-06-06 13:02:26.162529: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:02:26.723819: lr: 0.000577
2022-06-06 13:02:26.726087: This epoch took 100.423602 s

2022-06-06 13:02:26.728068: 
epoch:  479
2022-06-06 13:04:00.166971: train loss : -0.8373
2022-06-06 13:04:08.256323: validation loss: -0.7696
2022-06-06 13:04:08.259263: Average global foreground Dice: [0.8009]
2022-06-06 13:04:08.261523: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:04:08.796843: lr: 0.000552
2022-06-06 13:04:08.799503: This epoch took 102.069104 s

2022-06-06 13:04:08.801641: 
epoch:  480
2022-06-06 13:05:42.264858: train loss : -0.8411
2022-06-06 13:05:48.597335: validation loss: -0.7454
2022-06-06 13:05:48.600487: Average global foreground Dice: [0.7813]
2022-06-06 13:05:48.602888: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:05:49.137572: lr: 0.000527
2022-06-06 13:05:49.140256: This epoch took 100.336568 s

2022-06-06 13:05:49.142619: 
epoch:  481
2022-06-06 13:07:22.660401: train loss : -0.8403
2022-06-06 13:07:29.567433: validation loss: -0.7748
2022-06-06 13:07:29.570860: Average global foreground Dice: [0.8152]
2022-06-06 13:07:29.573434: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:07:30.103528: lr: 0.000502
2022-06-06 13:07:30.106004: This epoch took 100.961394 s

2022-06-06 13:07:30.108249: 
epoch:  482
2022-06-06 13:09:03.520748: train loss : -0.8396
2022-06-06 13:09:10.151998: validation loss: -0.7520
2022-06-06 13:09:10.155137: Average global foreground Dice: [0.7929]
2022-06-06 13:09:10.157440: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:09:10.743500: lr: 0.000477
2022-06-06 13:09:10.745584: This epoch took 100.635312 s

2022-06-06 13:09:10.747599: 
epoch:  483
2022-06-06 13:10:44.161703: train loss : -0.8409
2022-06-06 13:10:50.456466: validation loss: -0.7755
2022-06-06 13:10:50.461198: Average global foreground Dice: [0.8048]
2022-06-06 13:10:50.467741: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:10:50.994018: lr: 0.000451
2022-06-06 13:10:50.996634: This epoch took 100.247025 s

2022-06-06 13:10:50.998837: 
epoch:  484
2022-06-06 13:12:24.517177: train loss : -0.8444
2022-06-06 13:12:31.651083: validation loss: -0.7776
2022-06-06 13:12:31.654372: Average global foreground Dice: [0.8166]
2022-06-06 13:12:31.656741: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:12:32.229799: lr: 0.000426
2022-06-06 13:12:32.232133: This epoch took 101.231007 s

2022-06-06 13:12:32.234050: 
epoch:  485
2022-06-06 13:14:05.713942: train loss : -0.8406
2022-06-06 13:14:12.794655: validation loss: -0.7626
2022-06-06 13:14:12.797709: Average global foreground Dice: [0.8044]
2022-06-06 13:14:12.801189: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:14:13.336549: lr: 0.0004
2022-06-06 13:14:13.338751: This epoch took 101.102699 s

2022-06-06 13:14:13.340712: 
epoch:  486
2022-06-06 13:15:46.691863: train loss : -0.8522
2022-06-06 13:15:53.017331: validation loss: -0.7683
2022-06-06 13:15:53.021541: Average global foreground Dice: [0.8051]
2022-06-06 13:15:53.023866: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:15:53.546055: lr: 0.000375
2022-06-06 13:15:53.548572: This epoch took 100.205889 s

2022-06-06 13:15:53.550778: 
epoch:  487
2022-06-06 13:17:26.938043: train loss : -0.8445
2022-06-06 13:17:33.273217: validation loss: -0.7763
2022-06-06 13:17:33.276254: Average global foreground Dice: [0.8143]
2022-06-06 13:17:33.278530: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:17:33.842602: lr: 0.000348
2022-06-06 13:17:33.845087: This epoch took 100.292038 s

2022-06-06 13:17:33.847185: 
epoch:  488
2022-06-06 13:19:07.353048: train loss : -0.8467
2022-06-06 13:19:13.671437: validation loss: -0.7690
2022-06-06 13:19:13.675046: Average global foreground Dice: [0.8086]
2022-06-06 13:19:13.677321: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:19:14.215845: lr: 0.000322
2022-06-06 13:19:14.218351: This epoch took 100.369169 s

2022-06-06 13:19:14.220644: 
epoch:  489
2022-06-06 13:20:47.720967: train loss : -0.8483
2022-06-06 13:20:55.174944: validation loss: -0.7662
2022-06-06 13:20:55.178464: Average global foreground Dice: [0.8063]
2022-06-06 13:20:55.182777: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:20:55.806986: lr: 0.000296
2022-06-06 13:20:55.813424: This epoch took 101.589959 s

2022-06-06 13:20:55.815592: 
epoch:  490
2022-06-06 13:22:29.112608: train loss : -0.8458
2022-06-06 13:22:36.028766: validation loss: -0.7766
2022-06-06 13:22:36.033116: Average global foreground Dice: [0.8116]
2022-06-06 13:22:36.035126: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:22:36.584570: lr: 0.000269
2022-06-06 13:22:36.587172: This epoch took 100.769397 s

2022-06-06 13:22:36.589760: 
epoch:  491
2022-06-06 13:24:09.898143: train loss : -0.8465
2022-06-06 13:24:16.292037: validation loss: -0.7665
2022-06-06 13:24:16.295030: Average global foreground Dice: [0.8023]
2022-06-06 13:24:16.297118: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:24:16.825150: lr: 0.000242
2022-06-06 13:24:16.827410: This epoch took 100.235110 s

2022-06-06 13:24:16.829473: 
epoch:  492
2022-06-06 13:25:50.283767: train loss : -0.8443
2022-06-06 13:25:56.718002: validation loss: -0.7811
2022-06-06 13:25:56.720841: Average global foreground Dice: [0.8141]
2022-06-06 13:25:56.722895: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:25:57.256078: lr: 0.000215
2022-06-06 13:25:57.260128: This epoch took 100.428612 s

2022-06-06 13:25:57.263203: 
epoch:  493
2022-06-06 13:27:30.630961: train loss : -0.8526
2022-06-06 13:27:36.960258: validation loss: -0.7582
2022-06-06 13:27:36.964851: Average global foreground Dice: [0.7954]
2022-06-06 13:27:36.967056: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:27:37.488355: lr: 0.000187
2022-06-06 13:27:37.491390: This epoch took 100.226136 s

2022-06-06 13:27:37.505282: 
epoch:  494
2022-06-06 13:29:10.924990: train loss : -0.8468
2022-06-06 13:29:17.470750: validation loss: -0.7744
2022-06-06 13:29:17.474287: Average global foreground Dice: [0.8032]
2022-06-06 13:29:17.476892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:29:18.028395: lr: 0.000158
2022-06-06 13:29:18.033332: This epoch took 100.525088 s

2022-06-06 13:29:18.039190: 
epoch:  495
2022-06-06 13:30:51.440376: train loss : -0.8474
2022-06-06 13:30:57.914135: validation loss: -0.7938
2022-06-06 13:30:57.917693: Average global foreground Dice: [0.8264]
2022-06-06 13:30:57.920354: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:30:58.511279: lr: 0.00013
2022-06-06 13:30:58.516198: This epoch took 100.471225 s

2022-06-06 13:30:58.522390: 
epoch:  496
2022-06-06 13:32:31.849727: train loss : -0.8479
2022-06-06 13:32:38.942484: validation loss: -0.7726
2022-06-06 13:32:38.946831: Average global foreground Dice: [0.8057]
2022-06-06 13:32:38.949113: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:32:39.671781: lr: 0.0001
2022-06-06 13:32:39.674248: This epoch took 101.149261 s

2022-06-06 13:32:39.676571: 
epoch:  497
2022-06-06 13:34:13.022190: train loss : -0.8459
2022-06-06 13:34:19.497943: validation loss: -0.7404
2022-06-06 13:34:19.501590: Average global foreground Dice: [0.7815]
2022-06-06 13:34:19.503701: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:34:20.048254: lr: 6.9e-05
2022-06-06 13:34:20.050895: This epoch took 100.372044 s

2022-06-06 13:34:20.053421: 
epoch:  498
2022-06-06 13:35:53.571505: train loss : -0.8528
2022-06-06 13:36:00.923497: validation loss: -0.7897
2022-06-06 13:36:00.926892: Average global foreground Dice: [0.8254]
2022-06-06 13:36:00.929099: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:36:01.485770: lr: 3.7e-05
2022-06-06 13:36:01.488868: This epoch took 101.433221 s

2022-06-06 13:36:01.491203: 
epoch:  499
2022-06-06 13:37:34.944820: train loss : -0.8470
2022-06-06 13:37:41.696934: validation loss: -0.7721
2022-06-06 13:37:41.699984: Average global foreground Dice: [0.8137]
2022-06-06 13:37:41.702044: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-06 13:37:42.245531: lr: 0.0
2022-06-06 13:37:42.248140: saving scheduled checkpoint file...
2022-06-06 13:37:42.287268: saving checkpoint...
2022-06-06 13:37:43.368896: done, saving took 1.12 seconds
2022-06-06 13:37:43.384340: done
2022-06-06 13:37:43.386615: This epoch took 101.892536 s

2022-06-06 13:37:43.415452: saving checkpoint...
2022-06-06 13:37:44.565164: done, saving took 1.18 seconds
