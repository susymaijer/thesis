Starting at Wed Jun 29 23:43:00 CEST 2022
Running on hosts: res-hpc-lkeb06
Running on 1 nodes.
Running 1 tasks.
CPUs on node: 4.
Account: div2-lkeb
Job ID: 10587631
Job name: PancreasTrain
Node running script: res-hpc-lkeb06
Submit host: res-hpc-lo02.researchlumc.nl
GPUS: 0 or 
Wed Jun 29 23:45:20 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     On   | 00000000:AF:00.0 Off |                  Off |
| 33%   25C    P8    17W / 260W |      0MiB / 24220MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Current working directory is /home/smaijer
Load all modules..
Done with loading all modules. Modules:
Activate conda env nnunet..
Verifying environment variables:
Installing hidden layer and nnUnet..
Collecting hiddenlayer
  Cloning https://github.com/FabianIsensee/hiddenlayer.git (to revision more_plotted_details) to /tmp/pip-install-8605hg7n/hiddenlayer_c96c229c3f684cc2a7645478544bfe6f
  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit 4b98f9e5cccebac67368f02b95f4700b522345b1
Obtaining file:///home/smaijer/code/nnUNet
Requirement already satisfied: torch>1.10.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (1.12.0)
Requirement already satisfied: tqdm in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (4.64.0)
Requirement already satisfied: dicom2nifti in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (2.4.2)
Requirement already satisfied: scikit-image>=0.14 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.19.3)
Requirement already satisfied: medpy in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.4.0)
Requirement already satisfied: scipy in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (1.8.1)
Requirement already satisfied: batchgenerators>=0.23 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.24)
Requirement already satisfied: numpy in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (1.23.0)
Requirement already satisfied: sklearn in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.0)
Requirement already satisfied: SimpleITK in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (2.1.1.2)
Requirement already satisfied: pandas in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (1.4.3)
Requirement already satisfied: requests in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (2.28.0)
Requirement already satisfied: nibabel in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (4.0.1)
Requirement already satisfied: tifffile in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (2022.5.4)
Requirement already satisfied: matplotlib in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (3.5.2)
Requirement already satisfied: monai in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.9.0)
Requirement already satisfied: einops in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.4.1)
Requirement already satisfied: ipython in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (8.4.0)
Requirement already satisfied: graphviz in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.20)
Requirement already satisfied: unittest2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)
Requirement already satisfied: pillow>=7.1.2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (9.1.1)
Requirement already satisfied: scikit-learn in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.1.1)
Requirement already satisfied: future in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (0.18.2)
Requirement already satisfied: threadpoolctl in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (3.1.0)
Requirement already satisfied: imageio>=2.4.1 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.19.3)
Requirement already satisfied: PyWavelets>=1.1.1 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (1.3.0)
Requirement already satisfied: networkx>=2.2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.8.4)
Requirement already satisfied: packaging>=20.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (21.3)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from packaging>=20.0->scikit-image>=0.14->nnunet==1.7.0) (3.0.9)
Requirement already satisfied: typing-extensions in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from torch>1.10.0->nnunet==1.7.0) (4.2.0)
Requirement already satisfied: pydicom>=2.2.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from dicom2nifti->nnunet==1.7.0) (2.3.0)
Requirement already satisfied: python-gdcm in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from dicom2nifti->nnunet==1.7.0) (3.0.14)
Requirement already satisfied: setuptools>=18.5 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (58.1.0)
Requirement already satisfied: decorator in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (5.1.1)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (3.0.30)
Requirement already satisfied: pygments>=2.4.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (2.12.0)
Requirement already satisfied: backcall in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (0.2.0)
Requirement already satisfied: stack-data in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (0.3.0)
Requirement already satisfied: jedi>=0.16 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (0.18.1)
Requirement already satisfied: traitlets>=5 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (5.3.0)
Requirement already satisfied: pickleshare in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (0.7.5)
Requirement already satisfied: pexpect>4.3 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (4.8.0)
Requirement already satisfied: matplotlib-inline in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (0.1.3)
Requirement already satisfied: parso<0.9.0,>=0.8.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from jedi>=0.16->ipython->nnunet==1.7.0) (0.8.3)
Requirement already satisfied: ptyprocess>=0.5 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from pexpect>4.3->ipython->nnunet==1.7.0) (0.7.0)
Requirement already satisfied: wcwidth in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->nnunet==1.7.0) (0.2.5)
Requirement already satisfied: python-dateutil>=2.7 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from matplotlib->nnunet==1.7.0) (2.8.2)
Requirement already satisfied: fonttools>=4.22.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from matplotlib->nnunet==1.7.0) (4.33.3)
Requirement already satisfied: cycler>=0.10 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from matplotlib->nnunet==1.7.0) (0.11.0)
Requirement already satisfied: kiwisolver>=1.0.1 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from matplotlib->nnunet==1.7.0) (1.4.3)
Requirement already satisfied: six>=1.5 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->nnunet==1.7.0) (1.16.0)
Requirement already satisfied: pytz>=2020.1 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from pandas->nnunet==1.7.0) (2022.1)
Requirement already satisfied: charset-normalizer~=2.0.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from requests->nnunet==1.7.0) (2.0.12)
Requirement already satisfied: certifi>=2017.4.17 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from requests->nnunet==1.7.0) (2022.6.15)
Requirement already satisfied: idna<4,>=2.5 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from requests->nnunet==1.7.0) (3.3)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from requests->nnunet==1.7.0) (1.26.9)
Requirement already satisfied: joblib>=1.0.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from scikit-learn->batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)
Requirement already satisfied: asttokens in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from stack-data->ipython->nnunet==1.7.0) (2.0.5)
Requirement already satisfied: executing in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from stack-data->ipython->nnunet==1.7.0) (0.8.3)
Requirement already satisfied: pure-eval in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from stack-data->ipython->nnunet==1.7.0) (0.2.2)
Collecting argparse
  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)
Requirement already satisfied: traceback2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.4.0)
Requirement already satisfied: linecache2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from traceback2->unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.0.0)
Installing collected packages: argparse, nnunet
  Attempting uninstall: nnunet
    Found existing installation: nnunet 1.7.0
    Uninstalling nnunet-1.7.0:
      Successfully uninstalled nnunet-1.7.0
  Running setup.py develop for nnunet
Successfully installed argparse-1.4.0 nnunet-1.7.0


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

Suus0 - run_training. Args:
Namespace(network='3d_fullres', network_trainer='nnUNetTrainerV2', task='535', fold='1', validation_only=False, continue_training=True, p='nnUNetPlansv2.1', use_compressed_data=False, deterministic=False, npz=False, find_lr=False, valbest=False, fp32=False, val_folder='validation_raw', disable_saving=False, disable_postprocessing_on_folds=False, val_disable_overwrite=False, disable_next_stage_pred=False, pretrained_weights=None)
###############################################
I am running the following nnUNet: 3d_fullres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  15
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 160, 160]), 'median_patient_size_in_voxels': array([141, 240, 240]), 'current_spacing': array([3.32215628, 1.6685856 , 1.6685856 ]), 'original_spacing': array([2.        , 0.68825001, 0.68825001]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 160, 160]), 'median_patient_size_in_voxels': array([235, 582, 582]), 'current_spacing': array([2.        , 0.68825001, 0.68825001]), 'original_spacing': array([2.        , 0.68825001, 0.68825001]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 1 from these plans
I am using batch dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task535/nnUNetData_plans_v2.1
###############################################
Suus1 - Initialise de NetworkTrainer
Suus2 - Initialise de nnUNetTrainer
Suus3 - Initialise de nnUNetTrainerV2
Suus4 - Initialise de trainer echt
Suus5 - zet de plans properties
Suus6 - Zet de data augmentation params
Suus7 - zet deep supervision weights die de meerdere outputs prioriteit geven
loading dataset
loading all case properties
2022-06-29 23:46:05.610156: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task535/splits_final.pkl
2022-06-29 23:46:05.624429: The split file contains 5 splits.
2022-06-29 23:46:05.626956: Desired fold for training: 1
2022-06-29 23:46:05.629112: This split has 160 training and 40 validation cases.
unpacking dataset
done
Suus8 - Maak network aan (BELANGRIJK!)
SuusB - first stride 
Suus10 - StackedConvLayers, input: 1 en output: 32, first_stride: None, num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [1, 3, 3], 'padding': [0, 1, 1]}
SuusA - first_stride [1, 2, 2]
Suus10 - StackedConvLayers, input: 32 en output: 64, first_stride: [1, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
SuusA - first_stride [2, 2, 2]
Suus10 - StackedConvLayers, input: 64 en output: 128, first_stride: [2, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
SuusA - first_stride [2, 2, 2]
Suus10 - StackedConvLayers, input: 128 en output: 256, first_stride: [2, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
SuusA - first_stride [2, 2, 2]
Suus10 - StackedConvLayers, input: 256 en output: 320, first_stride: [2, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 320 en output: 320, first_stride: [2, 2, 2], num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 320 en output: 320, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 640 en output: 320, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 320 en output: 320, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 512 en output: 256, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 256 en output: 256, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 256 en output: 128, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 128 en output: 128, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 128 en output: 64, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 64 en output: 64, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 64 en output: 32, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 32 en output: 32, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Generic_UNet(
  (encoder): Generic_UNETEncoder()
  (decoder): Generic_UNETDecoder()
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
SuusA - Load checkpoint (final, latest, best)
2022-06-29 23:46:08.292389: loading checkpoint /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task535/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_latest.model train= True
SuusB run_training - zet learning rate als  
2022-06-29 23:46:17.065537: Suus1 maybe_update_lr lr: 0.009095
SuusC - run_training!
using pin_memory on device 0
using pin_memory on device 0
Suus for now disable cause it breaks the logs
2022-06-29 23:46:58.178344: Unable to plot network architecture:
2022-06-29 23:46:58.183839: local variable 'g' referenced before assignment
2022-06-29 23:46:58.186788: 
printing the network instead:

2022-06-29 23:46:58.189083: Generic_UNet(
  (encoder): Generic_UNETEncoder()
  (decoder): Generic_UNETDecoder()
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-06-29 23:46:58.193123: 

2022-06-29 23:46:58.196051: 
epoch:  50
2022-06-29 23:53:53.852646: train loss : 0.0211
2022-06-29 23:54:35.665486: validation loss: -0.0385
2022-06-29 23:54:35.669400: Average global foreground Dice: [0.7726, 0.7395, 0.6902, 0.5067, 0.5843, 0.9239, 0.5787, 0.8316, 0.6499, 0.5817, 0.0, 0.0, 0.4191, 0.8439, 0.6559]
2022-06-29 23:54:35.671768: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-29 23:54:36.174010: Suus1 maybe_update_lr lr: 0.009077
2022-06-29 23:54:36.176724: saving best epoch checkpoint...
2022-06-29 23:54:36.240713: saving checkpoint...
2022-06-29 23:54:37.386828: done, saving took 1.21 seconds
2022-06-29 23:54:37.403875: This epoch took 459.205749 s

2022-06-29 23:54:37.406430: 
epoch:  51
2022-06-29 23:59:58.646297: train loss : 0.0427
2022-06-30 00:00:24.043265: validation loss: 0.0310
2022-06-30 00:00:24.048106: Average global foreground Dice: [0.5461, 0.6711, 0.6706, 0.5875, 0.6163, 0.8344, 0.381, 0.8737, 0.7171, 0.5585, 0.0, 0.0, 0.417, 0.523, 0.6273]
2022-06-30 00:00:24.050387: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 00:00:24.458971: Suus1 maybe_update_lr lr: 0.009059
2022-06-30 00:00:24.461458: This epoch took 347.052633 s

2022-06-30 00:00:24.463588: 
epoch:  52
2022-06-30 00:05:45.328042: train loss : 0.0199
2022-06-30 00:06:11.351128: validation loss: 0.0149
2022-06-30 00:06:11.356050: Average global foreground Dice: [0.8058, 0.8092, 0.5646, 0.5217, 0.4796, 0.8606, 0.5919, 0.8183, 0.747, 0.5909, 0.0, 0.0, 0.4156, 0.622, 0.5068]
2022-06-30 00:06:11.358281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 00:06:11.766179: Suus1 maybe_update_lr lr: 0.009041
2022-06-30 00:06:11.768517: This epoch took 347.302105 s

2022-06-30 00:06:11.770867: 
epoch:  53
2022-06-30 00:11:32.810051: train loss : 0.0176
2022-06-30 00:11:57.214310: validation loss: -0.0364
2022-06-30 00:11:57.223958: Average global foreground Dice: [0.7366, 0.7653, 0.6984, 0.4475, 0.5667, 0.8761, 0.5376, 0.825, 0.7598, 0.6084, 0.0, 0.0, 0.4889, 0.7028, 0.5866]
2022-06-30 00:11:57.227579: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 00:11:57.641330: Suus1 maybe_update_lr lr: 0.009023
2022-06-30 00:11:57.643661: This epoch took 345.870592 s

2022-06-30 00:11:57.645918: 
epoch:  54
2022-06-30 00:17:18.376211: train loss : -0.0028
2022-06-30 00:17:36.752118: validation loss: -0.0359
2022-06-30 00:17:36.755882: Average global foreground Dice: [0.7927, 0.7105, 0.7696, 0.6645, 0.5292, 0.8752, 0.6242, 0.789, 0.7396, 0.5736, 0.0, 0.0, 0.4787, 0.7299, 0.5515]
2022-06-30 00:17:36.758602: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 00:17:37.190454: Suus1 maybe_update_lr lr: 0.009004
2022-06-30 00:17:37.192795: This epoch took 339.544752 s

2022-06-30 00:17:37.194911: 
epoch:  55
2022-06-30 00:22:58.010277: train loss : -0.0151
2022-06-30 00:23:19.843754: validation loss: -0.0318
2022-06-30 00:23:19.848196: Average global foreground Dice: [0.7651, 0.8161, 0.7697, 0.4142, 0.6253, 0.88, 0.6543, 0.8727, 0.7403, 0.6088, 0.0, 0.0, 0.4014, 0.6759, 0.4572]
2022-06-30 00:23:19.851079: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 00:23:20.266401: Suus1 maybe_update_lr lr: 0.008986
2022-06-30 00:23:20.268787: This epoch took 343.071304 s

2022-06-30 00:23:20.270961: 
epoch:  56
2022-06-30 00:28:40.812902: train loss : -0.0353
2022-06-30 00:28:59.043883: validation loss: -0.0543
2022-06-30 00:28:59.048202: Average global foreground Dice: [0.7327, 0.6629, 0.7219, 0.7377, 0.59, 0.8425, 0.5531, 0.8591, 0.7375, 0.6268, 0.0, 0.0, 0.4545, 0.6696, 0.6006]
2022-06-30 00:28:59.050756: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 00:28:59.481555: Suus1 maybe_update_lr lr: 0.008968
2022-06-30 00:28:59.484081: This epoch took 339.210473 s

2022-06-30 00:28:59.486112: 
epoch:  57
2022-06-30 00:34:20.292348: train loss : -0.0009
2022-06-30 00:34:38.529581: validation loss: 0.0565
2022-06-30 00:34:38.533795: Average global foreground Dice: [0.6331, 0.6969, 0.7253, 0.3091, 0.6539, 0.7983, 0.6026, 0.8628, 0.6555, 0.616, 0.0, 0.0, 0.3833, 0.652, 0.5708]
2022-06-30 00:34:38.536220: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 00:34:38.967443: Suus1 maybe_update_lr lr: 0.00895
2022-06-30 00:34:38.970072: This epoch took 339.481817 s

2022-06-30 00:34:38.972208: 
epoch:  58
2022-06-30 00:39:59.716932: train loss : -0.0179
2022-06-30 00:40:20.915641: validation loss: -0.0783
2022-06-30 00:40:20.919879: Average global foreground Dice: [0.8408, 0.707, 0.629, 0.5876, 0.6197, 0.9084, 0.7025, 0.8694, 0.7695, 0.6315, 0.0, 0.0, 0.5271, 0.7848, 0.6344]
2022-06-30 00:40:20.922755: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 00:40:21.344286: Suus1 maybe_update_lr lr: 0.008931
2022-06-30 00:40:21.347069: This epoch took 342.372725 s

2022-06-30 00:40:21.349380: 
epoch:  59
2022-06-30 00:45:42.139867: train loss : -0.0154
2022-06-30 00:46:02.145019: validation loss: -0.0626
2022-06-30 00:46:02.148611: Average global foreground Dice: [0.714, 0.5914, 0.668, 0.578, 0.6189, 0.8259, 0.7387, 0.8233, 0.7845, 0.6893, 0.0, 0.0, 0.5531, 0.8173, 0.6482]
2022-06-30 00:46:02.150964: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 00:46:02.580665: Suus1 maybe_update_lr lr: 0.008913
2022-06-30 00:46:02.583219: This epoch took 341.231583 s

2022-06-30 00:46:02.585579: 
epoch:  60
2022-06-30 00:51:23.198212: train loss : -0.0237
2022-06-30 00:51:41.419353: validation loss: -0.0366
2022-06-30 00:51:41.423377: Average global foreground Dice: [0.8333, 0.7261, 0.7196, 0.5448, 0.5641, 0.8781, 0.6798, 0.7754, 0.7186, 0.6379, 0.0, 0.0, 0.4803, 0.623, 0.524]
2022-06-30 00:51:41.426006: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 00:51:41.850189: Suus1 maybe_update_lr lr: 0.008895
2022-06-30 00:51:41.852980: This epoch took 339.264895 s

2022-06-30 00:51:41.855506: 
epoch:  61
2022-06-30 00:57:02.586789: train loss : -0.0095
2022-06-30 00:57:24.662343: validation loss: -0.0072
2022-06-30 00:57:24.665934: Average global foreground Dice: [0.5484, 0.8045, 0.6858, 0.6401, 0.5983, 0.8589, 0.5723, 0.8737, 0.743, 0.5992, 0.0, 0.0, 0.4775, 0.6711, 0.433]
2022-06-30 00:57:24.668462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 00:57:25.088062: Suus1 maybe_update_lr lr: 0.008877
2022-06-30 00:57:25.090608: This epoch took 343.232464 s

2022-06-30 00:57:25.093033: 
epoch:  62
2022-06-30 01:02:45.895807: train loss : -0.0469
2022-06-30 01:03:04.145492: validation loss: -0.0213
2022-06-30 01:03:04.151671: Average global foreground Dice: [0.7768, 0.8064, 0.5548, 0.6032, 0.5906, 0.8392, 0.7082, 0.8911, 0.7983, 0.7079, 0.0006, 0.0, 0.4795, 0.7272, 0.4803]
2022-06-30 01:03:04.155707: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 01:03:04.626997: Suus1 maybe_update_lr lr: 0.008859
2022-06-30 01:03:04.629265: This epoch took 339.534008 s

2022-06-30 01:03:04.631344: 
epoch:  63
2022-06-30 01:08:25.561611: train loss : -0.0413
2022-06-30 01:08:43.799933: validation loss: -0.0690
2022-06-30 01:08:43.804443: Average global foreground Dice: [0.682, 0.7275, 0.5786, 0.4206, 0.6767, 0.8761, 0.6861, 0.8552, 0.7927, 0.6929, 0.343, 0.0, 0.569, 0.7167, 0.3588]
2022-06-30 01:08:43.807094: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 01:08:44.223441: Suus1 maybe_update_lr lr: 0.00884
2022-06-30 01:08:44.226610: This epoch took 339.593233 s

2022-06-30 01:08:44.229217: 
epoch:  64
2022-06-30 01:14:05.073834: train loss : -0.0641
2022-06-30 01:14:23.464526: validation loss: -0.1215
2022-06-30 01:14:23.469739: Average global foreground Dice: [0.8102, 0.7668, 0.7696, 0.7604, 0.694, 0.8883, 0.6889, 0.9057, 0.7713, 0.7002, 0.3728, 0.0, 0.5454, 0.0766, 0.8184]
2022-06-30 01:14:23.472593: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 01:14:23.889907: Suus1 maybe_update_lr lr: 0.008822
2022-06-30 01:14:23.892288: saving best epoch checkpoint...
2022-06-30 01:14:23.966580: saving checkpoint...
2022-06-30 01:14:24.984448: done, saving took 1.09 seconds
2022-06-30 01:14:25.005570: This epoch took 340.771460 s

2022-06-30 01:14:25.007790: 
epoch:  65
2022-06-30 01:19:46.168622: train loss : -0.0288
2022-06-30 01:20:04.402974: validation loss: -0.1222
2022-06-30 01:20:04.406591: Average global foreground Dice: [0.7601, 0.6971, 0.7605, 0.4498, 0.6672, 0.8983, 0.7656, 0.8816, 0.7615, 0.6923, 0.3558, 0.1393, 0.5169, 0.6979, 0.6206]
2022-06-30 01:20:04.408980: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 01:20:04.867307: Suus1 maybe_update_lr lr: 0.008804
2022-06-30 01:20:04.871149: saving best epoch checkpoint...
2022-06-30 01:20:04.945748: saving checkpoint...
2022-06-30 01:20:06.044078: done, saving took 1.17 seconds
2022-06-30 01:20:06.064078: This epoch took 341.054193 s

2022-06-30 01:20:06.066425: 
epoch:  66
2022-06-30 01:25:27.041006: train loss : -0.0718
2022-06-30 01:25:45.304255: validation loss: -0.1339
2022-06-30 01:25:45.309340: Average global foreground Dice: [0.729, 0.859, 0.7386, 0.6587, 0.7197, 0.9212, 0.7426, 0.8619, 0.7968, 0.6556, 0.487, 0.2504, 0.4694, 0.7009, 0.6436]
2022-06-30 01:25:45.312892: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 01:25:45.773135: Suus1 maybe_update_lr lr: 0.008785
2022-06-30 01:25:45.775381: saving best epoch checkpoint...
2022-06-30 01:25:45.851939: saving checkpoint...
2022-06-30 01:25:46.960217: done, saving took 1.18 seconds
2022-06-30 01:25:46.973259: This epoch took 340.904467 s

2022-06-30 01:25:46.975191: 
epoch:  67
2022-06-30 01:31:08.018240: train loss : -0.0956
2022-06-30 01:31:26.266634: validation loss: -0.1428
2022-06-30 01:31:26.270926: Average global foreground Dice: [0.8067, 0.8232, 0.8136, 0.7021, 0.561, 0.9073, 0.6847, 0.8336, 0.7751, 0.6883, 0.4592, 0.3169, 0.5562, 0.6286, 0.5762]
2022-06-30 01:31:26.273320: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 01:31:26.692648: Suus1 maybe_update_lr lr: 0.008767
2022-06-30 01:31:26.695510: saving best epoch checkpoint...
2022-06-30 01:31:26.777012: saving checkpoint...
2022-06-30 01:31:27.866153: done, saving took 1.17 seconds
2022-06-30 01:31:27.884932: This epoch took 340.907631 s

2022-06-30 01:31:27.887200: 
epoch:  68
2022-06-30 01:36:48.932599: train loss : -0.0563
2022-06-30 01:37:07.227461: validation loss: -0.0655
2022-06-30 01:37:07.231672: Average global foreground Dice: [0.8428, 0.7777, 0.6312, 0.5325, 0.6746, 0.8574, 0.632, 0.8583, 0.7599, 0.664, 0.3438, 0.3731, 0.5286, 0.6627, 0.6374]
2022-06-30 01:37:07.235036: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 01:37:07.712581: Suus1 maybe_update_lr lr: 0.008749
2022-06-30 01:37:07.715380: saving best epoch checkpoint...
2022-06-30 01:37:07.797165: saving checkpoint...
2022-06-30 01:37:08.864827: done, saving took 1.14 seconds
2022-06-30 01:37:08.878760: This epoch took 340.989398 s

2022-06-30 01:37:08.882016: 
epoch:  69
2022-06-30 01:42:29.863077: train loss : -0.1063
2022-06-30 01:42:48.138767: validation loss: -0.1173
2022-06-30 01:42:48.142897: Average global foreground Dice: [0.8522, 0.7164, 0.7321, 0.6187, 0.6725, 0.9147, 0.6615, 0.8765, 0.7363, 0.6613, 0.3489, 0.3807, 0.5191, 0.8294, 0.6656]
2022-06-30 01:42:48.145501: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 01:42:48.569600: Suus1 maybe_update_lr lr: 0.008731
2022-06-30 01:42:48.571888: saving best epoch checkpoint...
2022-06-30 01:42:48.647343: saving checkpoint...
2022-06-30 01:42:49.688408: done, saving took 1.11 seconds
2022-06-30 01:42:49.706777: This epoch took 340.821425 s

2022-06-30 01:42:49.709030: 
epoch:  70
2022-06-30 01:48:11.076104: train loss : -0.0984
2022-06-30 01:48:29.325613: validation loss: -0.1289
2022-06-30 01:48:29.329515: Average global foreground Dice: [0.8072, 0.7872, 0.7536, 0.689, 0.7048, 0.8974, 0.6488, 0.8719, 0.7717, 0.6942, 0.4316, 0.3289, 0.5106, 0.7437, 0.6632]
2022-06-30 01:48:29.332417: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 01:48:29.756696: Suus1 maybe_update_lr lr: 0.008712
2022-06-30 01:48:29.759177: saving best epoch checkpoint...
2022-06-30 01:48:29.823454: saving checkpoint...
2022-06-30 01:48:30.953481: done, saving took 1.19 seconds
2022-06-30 01:48:30.971622: This epoch took 341.260489 s

2022-06-30 01:48:30.974105: 
epoch:  71
2022-06-30 01:53:52.249350: train loss : -0.0896
2022-06-30 01:54:10.501402: validation loss: -0.0826
2022-06-30 01:54:10.505408: Average global foreground Dice: [0.6304, 0.8213, 0.7553, 0.4252, 0.644, 0.8567, 0.6952, 0.8621, 0.8031, 0.588, 0.5096, 0.3275, 0.5119, 0.6892, 0.633]
2022-06-30 01:54:10.507653: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 01:54:11.036617: Suus1 maybe_update_lr lr: 0.008694
2022-06-30 01:54:11.039536: saving best epoch checkpoint...
2022-06-30 01:54:11.088633: saving checkpoint...
2022-06-30 01:54:12.127408: done, saving took 1.09 seconds
2022-06-30 01:54:12.148885: This epoch took 341.172383 s

2022-06-30 01:54:12.154842: 
epoch:  72
2022-06-30 01:59:33.385465: train loss : -0.0653
2022-06-30 01:59:51.621132: validation loss: -0.0638
2022-06-30 01:59:51.625405: Average global foreground Dice: [0.7149, 0.7459, 0.7182, 0.6922, 0.631, 0.8301, 0.681, 0.9057, 0.812, 0.6596, 0.5241, 0.3959, 0.4993, 0.5755, 0.608]
2022-06-30 01:59:51.627795: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 01:59:52.040440: Suus1 maybe_update_lr lr: 0.008676
2022-06-30 01:59:52.042899: saving best epoch checkpoint...
2022-06-30 01:59:52.091421: saving checkpoint...
2022-06-30 01:59:53.196516: done, saving took 1.15 seconds
2022-06-30 01:59:53.210775: This epoch took 341.052626 s

2022-06-30 01:59:53.213179: 
epoch:  73
2022-06-30 02:05:14.563484: train loss : -0.1074
2022-06-30 02:05:32.927941: validation loss: -0.0740
2022-06-30 02:05:32.932149: Average global foreground Dice: [0.8451, 0.8217, 0.6938, 0.5992, 0.6662, 0.8294, 0.7397, 0.8691, 0.7996, 0.6194, 0.4372, 0.492, 0.5228, 0.7601, 0.7137]
2022-06-30 02:05:32.934849: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 02:05:33.351774: Suus1 maybe_update_lr lr: 0.008658
2022-06-30 02:05:33.354545: saving best epoch checkpoint...
2022-06-30 02:05:33.398704: saving checkpoint...
2022-06-30 02:05:34.422792: done, saving took 1.07 seconds
2022-06-30 02:05:34.436224: This epoch took 341.220809 s

2022-06-30 02:05:34.438529: 
epoch:  74
2022-06-30 02:10:55.581818: train loss : -0.1187
2022-06-30 02:11:13.831553: validation loss: -0.1170
2022-06-30 02:11:13.835470: Average global foreground Dice: [0.7528, 0.719, 0.6223, 0.612, 0.7163, 0.9066, 0.7169, 0.8822, 0.8144, 0.6463, 0.5597, 0.3658, 0.5753, 0.7313, 0.5874]
2022-06-30 02:11:13.837815: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-06-30 02:11:14.273272: Suus1 maybe_update_lr lr: 0.008639
2022-06-30 02:11:14.276091: saving best epoch checkpoint...
2022-06-30 02:11:14.321661: saving checkpoint...
2022-06-30 02:11:15.354747: done, saving took 1.08 seconds
2022-06-30 02:11:15.367373: This epoch took 340.926335 s

2022-06-30 02:11:15.369598: 
epoch:  75
2022-06-30 02:16:36.311069: train loss : -0.1029
2022-06-30 02:16:54.573177: validation loss: -0.1285
2022-06-30 02:16:54.577866: Average global foreground Dice: [0.7702, 0.8763, 0.8055, 0.5852, 0.648, 0.9227, 0.7425, 0.8639, 0.8102, 0.7095, 0.5184, 0.5131, 0.5457, 0.7683, 0.6164]
2022-06-30 02:16:54.581316: 