Starting at Tue Apr 26 17:44:47 CEST 2022
Running on hosts: res-hpc-lkeb06
Running on 1 nodes.
Running 1 tasks.
CPUs on node: 8.
Account: div2-lkeb
Job ID: 10037825
Job name: NIHPancreasTrain
Node running script: res-hpc-lkeb06
Submit host: res-hpc-lo02.researchlumc.nl
GPUS: 0 or 
Tue Apr 26 21:44:26 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     Off  | 00000000:AF:00.0 Off |                  Off |
| 34%   52C    P0    67W / 260W |      0MiB / 24220MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Current working directory is /home/smaijer
Load all modules..
Done with loading all modules. Modules:
Activate conda env nnunet..
Verifying environment variables:
nnUNet_raw_data_base = /exports/lkeb-hpc/smaijer/data/nnUNet_raw_data_base
nnUNet_preprocessed = /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed
RESULTS_FOLDER = /exports/lkeb-hpc/smaijer/results
Installing nnU-net..
Obtaining file:///home/smaijer/code/nnUNet
Requirement already satisfied: torch>1.10.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.11.0)
Requirement already satisfied: tqdm in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (4.64.0)
Requirement already satisfied: dicom2nifti in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2.3.2)
Requirement already satisfied: scikit-image>=0.14 in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.19.2)
Requirement already satisfied: medpy in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.4.0)
Requirement already satisfied: scipy in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.8.0)
Requirement already satisfied: batchgenerators>=0.23 in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.23)
Requirement already satisfied: numpy in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.21.2)
Requirement already satisfied: sklearn in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (0.0)
Requirement already satisfied: SimpleITK in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2.1.1)
Requirement already satisfied: pandas in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (1.4.2)
Requirement already satisfied: requests in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2.27.1)
Requirement already satisfied: nibabel in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (3.2.2)
Requirement already satisfied: tifffile in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (2022.4.8)
Requirement already satisfied: matplotlib in ./.conda/envs/nn/lib/python3.9/site-packages (from nnunet==1.7.0) (3.5.1)
Requirement already satisfied: future in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (0.18.2)
Requirement already satisfied: pillow>=7.1.2 in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (9.0.1)
Requirement already satisfied: scikit-learn in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.0.2)
Requirement already satisfied: unittest2 in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)
Requirement already satisfied: threadpoolctl in ./.conda/envs/nn/lib/python3.9/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (3.1.0)
Requirement already satisfied: networkx>=2.2 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.8)
Requirement already satisfied: packaging>=20.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (21.3)
Requirement already satisfied: imageio>=2.4.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.16.2)
Requirement already satisfied: PyWavelets>=1.1.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (1.3.0)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.conda/envs/nn/lib/python3.9/site-packages (from packaging>=20.0->scikit-image>=0.14->nnunet==1.7.0) (3.0.8)
Requirement already satisfied: typing_extensions in ./.conda/envs/nn/lib/python3.9/site-packages (from torch>1.10.0->nnunet==1.7.0) (4.1.1)
Requirement already satisfied: pydicom>=1.3.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from dicom2nifti->nnunet==1.7.0) (2.3.0)
Requirement already satisfied: kiwisolver>=1.0.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (1.4.2)
Requirement already satisfied: python-dateutil>=2.7 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (2.8.2)
Requirement already satisfied: fonttools>=4.22.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (4.32.0)
Requirement already satisfied: cycler>=0.10 in ./.conda/envs/nn/lib/python3.9/site-packages (from matplotlib->nnunet==1.7.0) (0.11.0)
Requirement already satisfied: six>=1.5 in ./.conda/envs/nn/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->nnunet==1.7.0) (1.16.0)
Requirement already satisfied: setuptools in ./.conda/envs/nn/lib/python3.9/site-packages (from nibabel->nnunet==1.7.0) (58.0.4)
Requirement already satisfied: pytz>=2020.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from pandas->nnunet==1.7.0) (2022.1)
Requirement already satisfied: charset-normalizer~=2.0.0 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (2.0.4)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (1.26.8)
Requirement already satisfied: idna<4,>=2.5 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (3.3)
Requirement already satisfied: certifi>=2017.4.17 in ./.conda/envs/nn/lib/python3.9/site-packages (from requests->nnunet==1.7.0) (2021.10.8)
Requirement already satisfied: joblib>=0.11 in ./.conda/envs/nn/lib/python3.9/site-packages (from scikit-learn->batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)
Requirement already satisfied: traceback2 in ./.conda/envs/nn/lib/python3.9/site-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.4.0)
Collecting argparse
  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)
Requirement already satisfied: linecache2 in ./.conda/envs/nn/lib/python3.9/site-packages (from traceback2->unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.0.0)
Installing collected packages: argparse, nnunet
  Attempting uninstall: nnunet
    Found existing installation: nnunet 1.7.0
    Uninstalling nnunet-1.7.0:
      Successfully uninstalled nnunet-1.7.0
  Running setup.py develop for nnunet
Successfully installed argparse-1.4.0 nnunet-1.7.0


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_lowres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  1
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 192, 160]), 'median_patient_size_in_voxels': array([120, 285, 285]), 'current_spacing': array([1.7987096 , 1.54576606, 1.54576606]), 'original_spacing': array([1.      , 0.859375, 0.859375]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 192, 160]), 'median_patient_size_in_voxels': array([216, 512, 512]), 'current_spacing': array([1.      , 0.859375, 0.859375]), 'original_spacing': array([1.      , 0.859375, 0.859375]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 0 from these plans
I am using sample dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task500_NIH_Pancreas/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-04-26 21:45:18.808659: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task500_NIH_Pancreas/splits_final.pkl
2022-04-26 21:45:18.818660: The split file contains 5 splits.
2022-04-26 21:45:18.820745: Desired fold for training: 2
2022-04-26 21:45:18.822651: This split has 64 training and 16 validation cases.
unpacking dataset
done
2022-04-26 21:45:22.536784: loading checkpoint /exports/lkeb-hpc/smaijer/results/nnUNet/3d_lowres/Task500_NIH_Pancreas/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_latest.model train= True
2022-04-26 21:45:31.474891: lr: 0.003384
using pin_memory on device 0
using pin_memory on device 0
2022-04-26 21:45:40.957801: Unable to plot network architecture:
2022-04-26 21:45:40.972598: No module named 'hiddenlayer'
2022-04-26 21:45:40.989201: 
printing the network instead:

2022-04-26 21:45:41.011144: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-04-26 21:45:41.066247: 

2022-04-26 21:45:41.068804: 
epoch:  350
2022-04-26 21:47:32.979413: train loss : -0.8831
2022-04-26 21:47:40.431302: validation loss: -0.8333
2022-04-26 21:47:40.458855: Average global foreground Dice: [0.8598]
2022-04-26 21:47:40.478169: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 21:47:41.618760: lr: 0.003364
2022-04-26 21:47:41.621648: This epoch took 120.528710 s

2022-04-26 21:47:41.623976: 
epoch:  351
2022-04-26 21:49:16.050392: train loss : -0.8814
2022-04-26 21:49:22.973751: validation loss: -0.8383
2022-04-26 21:49:23.010721: Average global foreground Dice: [0.8572]
2022-04-26 21:49:23.029385: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 21:49:23.592671: lr: 0.003343
2022-04-26 21:49:23.619907: This epoch took 101.993918 s

2022-04-26 21:49:23.639232: 
epoch:  352
2022-04-26 21:50:57.693987: train loss : -0.8899
2022-04-26 21:51:04.548182: validation loss: -0.8482
2022-04-26 21:51:04.568482: Average global foreground Dice: [0.8663]
2022-04-26 21:51:04.595209: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 21:51:05.502708: lr: 0.003323
2022-04-26 21:51:05.524272: This epoch took 101.868115 s

2022-04-26 21:51:05.548172: 
epoch:  353
2022-04-26 21:52:40.252010: train loss : -0.8898
2022-04-26 21:52:47.733554: validation loss: -0.8432
2022-04-26 21:52:47.785795: Average global foreground Dice: [0.8644]
2022-04-26 21:52:47.798161: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 21:52:48.747453: lr: 0.003303
2022-04-26 21:52:48.771214: This epoch took 103.214494 s

2022-04-26 21:52:48.795164: 
epoch:  354
2022-04-26 21:54:26.283724: train loss : -0.8769
2022-04-26 21:54:33.473373: validation loss: -0.8425
2022-04-26 21:54:33.538633: Average global foreground Dice: [0.8622]
2022-04-26 21:54:33.591426: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 21:54:34.355174: lr: 0.003282
2022-04-26 21:54:34.390189: This epoch took 105.538871 s

2022-04-26 21:54:34.420627: 
epoch:  355
2022-04-26 21:56:16.342521: train loss : -0.8814
2022-04-26 21:56:24.433099: validation loss: -0.8493
2022-04-26 21:56:24.487555: Average global foreground Dice: [0.8695]
2022-04-26 21:56:24.512382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 21:56:25.240093: lr: 0.003262
2022-04-26 21:56:25.278185: This epoch took 110.842201 s

2022-04-26 21:56:25.312652: 
epoch:  356
2022-04-26 21:58:08.675404: train loss : -0.8850
2022-04-26 21:58:15.808898: validation loss: -0.8396
2022-04-26 21:58:15.820958: Average global foreground Dice: [0.8605]
2022-04-26 21:58:15.860862: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 21:58:16.332985: lr: 0.003241
2022-04-26 21:58:16.338243: This epoch took 110.972081 s

2022-04-26 21:58:16.340270: 
epoch:  357
2022-04-26 21:59:50.979990: train loss : -0.8887
2022-04-26 21:59:58.123403: validation loss: -0.8428
2022-04-26 21:59:58.142611: Average global foreground Dice: [0.8629]
2022-04-26 21:59:58.145634: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 21:59:58.831320: lr: 0.003221
2022-04-26 21:59:58.851329: This epoch took 102.509169 s

2022-04-26 21:59:58.871001: 
epoch:  358
2022-04-26 22:01:43.503743: train loss : -0.8913
2022-04-26 22:01:50.658041: validation loss: -0.8454
2022-04-26 22:01:50.691553: Average global foreground Dice: [0.8672]
2022-04-26 22:01:50.714165: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:01:51.304850: lr: 0.003201
2022-04-26 22:01:51.326171: This epoch took 112.425684 s

2022-04-26 22:01:51.349149: 
epoch:  359
2022-04-26 22:03:29.023482: train loss : -0.8912
2022-04-26 22:03:36.545684: validation loss: -0.8441
2022-04-26 22:03:36.590996: Average global foreground Dice: [0.8668]
2022-04-26 22:03:36.613144: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:03:37.561379: lr: 0.00318
2022-04-26 22:03:37.600017: This epoch took 106.226848 s

2022-04-26 22:03:37.615433: 
epoch:  360
2022-04-26 22:05:14.003782: train loss : -0.8903
2022-04-26 22:05:21.567397: validation loss: -0.8371
2022-04-26 22:05:21.601591: Average global foreground Dice: [0.8563]
2022-04-26 22:05:21.608827: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:05:22.268785: lr: 0.00316
2022-04-26 22:05:22.291179: This epoch took 104.665256 s

2022-04-26 22:05:22.313188: 
epoch:  361
2022-04-26 22:06:56.865143: train loss : -0.8917
2022-04-26 22:07:03.311900: validation loss: -0.8394
2022-04-26 22:07:03.336845: Average global foreground Dice: [0.8606]
2022-04-26 22:07:03.360643: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:07:04.010540: lr: 0.003139
2022-04-26 22:07:04.029186: This epoch took 101.682046 s

2022-04-26 22:07:04.050163: 
epoch:  362
2022-04-26 22:08:45.510095: train loss : -0.8911
2022-04-26 22:08:52.625464: validation loss: -0.8338
2022-04-26 22:08:52.658500: Average global foreground Dice: [0.856]
2022-04-26 22:08:52.691141: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:08:53.232579: lr: 0.003119
2022-04-26 22:08:53.255177: This epoch took 109.181014 s

2022-04-26 22:08:53.278136: 
epoch:  363
2022-04-26 22:10:28.597743: train loss : -0.8905
2022-04-26 22:10:36.740962: validation loss: -0.8484
2022-04-26 22:10:36.756073: Average global foreground Dice: [0.8681]
2022-04-26 22:10:36.786311: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:10:37.356938: lr: 0.003098
2022-04-26 22:10:37.377199: This epoch took 104.076059 s

2022-04-26 22:10:37.386838: 
epoch:  364
2022-04-26 22:12:13.052847: train loss : -0.8898
2022-04-26 22:12:20.980278: validation loss: -0.8390
2022-04-26 22:12:20.997560: Average global foreground Dice: [0.8638]
2022-04-26 22:12:21.030147: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:12:21.720242: lr: 0.003078
2022-04-26 22:12:21.733196: This epoch took 104.324363 s

2022-04-26 22:12:21.742127: 
epoch:  365
2022-04-26 22:13:58.073986: train loss : -0.8942
2022-04-26 22:14:05.765307: validation loss: -0.8453
2022-04-26 22:14:05.802609: Average global foreground Dice: [0.87]
2022-04-26 22:14:05.822157: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:14:06.419403: lr: 0.003057
2022-04-26 22:14:06.597080: saving checkpoint...
2022-04-26 22:14:07.811829: done, saving took 1.36 seconds
2022-04-26 22:14:07.827347: This epoch took 106.052199 s

2022-04-26 22:14:07.830315: 
epoch:  366
2022-04-26 22:15:42.074527: train loss : -0.8934
2022-04-26 22:15:49.122133: validation loss: -0.8428
2022-04-26 22:15:49.139724: Average global foreground Dice: [0.8625]
2022-04-26 22:15:49.169476: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:15:50.268941: lr: 0.003037
2022-04-26 22:15:50.271378: This epoch took 102.438649 s

2022-04-26 22:15:50.288515: 
epoch:  367
2022-04-26 22:17:26.634604: train loss : -0.8921
2022-04-26 22:17:33.535806: validation loss: -0.8473
2022-04-26 22:17:33.573942: Average global foreground Dice: [0.8661]
2022-04-26 22:17:33.595202: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:17:34.204057: lr: 0.003016
2022-04-26 22:17:34.279889: saving checkpoint...
2022-04-26 22:17:35.472326: done, saving took 1.25 seconds
2022-04-26 22:17:35.512476: This epoch took 105.207345 s

2022-04-26 22:17:35.531231: 
epoch:  368
2022-04-26 22:19:13.344545: train loss : -0.8905
2022-04-26 22:19:20.105335: validation loss: -0.8407
2022-04-26 22:19:20.145736: Average global foreground Dice: [0.8604]
2022-04-26 22:19:20.148140: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:19:20.971547: lr: 0.002996
2022-04-26 22:19:20.997180: This epoch took 105.463537 s

2022-04-26 22:19:21.012156: 
epoch:  369
2022-04-26 22:20:58.185624: train loss : -0.8884
2022-04-26 22:21:06.209825: validation loss: -0.8442
2022-04-26 22:21:06.233710: Average global foreground Dice: [0.8652]
2022-04-26 22:21:06.266121: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:21:06.906868: lr: 0.002975
2022-04-26 22:21:06.927186: This epoch took 105.893037 s

2022-04-26 22:21:06.943529: 
epoch:  370
2022-04-26 22:22:49.784221: train loss : -0.8919
2022-04-26 22:22:57.151645: validation loss: -0.8517
2022-04-26 22:22:57.178648: Average global foreground Dice: [0.8686]
2022-04-26 22:22:57.209879: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:22:57.717952: lr: 0.002954
2022-04-26 22:22:57.827216: saving checkpoint...
2022-04-26 22:22:58.975446: done, saving took 1.24 seconds
2022-04-26 22:22:58.985964: This epoch took 112.039805 s

2022-04-26 22:22:58.988763: 
epoch:  371
2022-04-26 22:24:33.420568: train loss : -0.8909
2022-04-26 22:24:41.589249: validation loss: -0.8264
2022-04-26 22:24:41.620675: Average global foreground Dice: [0.8519]
2022-04-26 22:24:41.640185: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:24:42.158376: lr: 0.002934
2022-04-26 22:24:42.161471: This epoch took 103.170466 s

2022-04-26 22:24:42.163850: 
epoch:  372
2022-04-26 22:26:16.248019: train loss : -0.8902
2022-04-26 22:26:23.896605: validation loss: -0.8494
2022-04-26 22:26:23.928570: Average global foreground Dice: [0.8684]
2022-04-26 22:26:23.950945: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:26:24.771696: lr: 0.002913
2022-04-26 22:26:24.811165: This epoch took 102.645148 s

2022-04-26 22:26:24.833155: 
epoch:  373
2022-04-26 22:28:01.343765: train loss : -0.8887
2022-04-26 22:28:08.425364: validation loss: -0.8396
2022-04-26 22:28:08.449537: Average global foreground Dice: [0.8596]
2022-04-26 22:28:08.485382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:28:09.422242: lr: 0.002892
2022-04-26 22:28:09.431605: This epoch took 104.577373 s

2022-04-26 22:28:09.436094: 
epoch:  374
2022-04-26 22:29:42.682107: train loss : -0.8920
2022-04-26 22:29:50.350180: validation loss: -0.8367
2022-04-26 22:29:50.369669: Average global foreground Dice: [0.8606]
2022-04-26 22:29:50.395177: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:29:51.107473: lr: 0.002872
2022-04-26 22:29:51.137835: This epoch took 101.695040 s

2022-04-26 22:29:51.140468: 
epoch:  375
2022-04-26 22:31:25.042143: train loss : -0.8953
2022-04-26 22:31:31.544029: validation loss: -0.8382
2022-04-26 22:31:31.554482: Average global foreground Dice: [0.8623]
2022-04-26 22:31:31.580122: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:31:32.073380: lr: 0.002851
2022-04-26 22:31:32.075646: This epoch took 100.932729 s

2022-04-26 22:31:32.077944: 
epoch:  376
2022-04-26 22:33:07.564853: train loss : -0.8922
2022-04-26 22:33:15.695700: validation loss: -0.8381
2022-04-26 22:33:15.711597: Average global foreground Dice: [0.8607]
2022-04-26 22:33:15.737153: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:33:16.255312: lr: 0.00283
2022-04-26 22:33:16.283913: This epoch took 104.203866 s

2022-04-26 22:33:16.304021: 
epoch:  377
2022-04-26 22:34:53.845095: train loss : -0.8892
2022-04-26 22:35:01.014750: validation loss: -0.8326
2022-04-26 22:35:01.031626: Average global foreground Dice: [0.8573]
2022-04-26 22:35:01.056152: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:35:01.750986: lr: 0.00281
2022-04-26 22:35:01.771271: This epoch took 105.446110 s

2022-04-26 22:35:01.781350: 
epoch:  378
2022-04-26 22:36:38.504491: train loss : -0.8896
2022-04-26 22:36:45.863566: validation loss: -0.8387
2022-04-26 22:36:45.892802: Average global foreground Dice: [0.8617]
2022-04-26 22:36:45.909173: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:36:46.518608: lr: 0.002789
2022-04-26 22:36:46.538287: This epoch took 104.746831 s

2022-04-26 22:36:46.560158: 
epoch:  379
2022-04-26 22:38:22.859041: train loss : -0.8842
2022-04-26 22:38:29.040806: validation loss: -0.8302
2022-04-26 22:38:29.069738: Average global foreground Dice: [0.8556]
2022-04-26 22:38:29.089121: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:38:29.942861: lr: 0.002768
2022-04-26 22:38:29.963192: This epoch took 103.394471 s

2022-04-26 22:38:29.982162: 
epoch:  380
2022-04-26 22:40:07.142462: train loss : -0.8900
2022-04-26 22:40:13.603194: validation loss: -0.8415
2022-04-26 22:40:13.633805: Average global foreground Dice: [0.8626]
2022-04-26 22:40:13.653175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:40:14.273813: lr: 0.002747
2022-04-26 22:40:14.305194: This epoch took 104.292042 s

2022-04-26 22:40:14.331148: 
epoch:  381
2022-04-26 22:41:48.499525: train loss : -0.8863
2022-04-26 22:41:57.328195: validation loss: -0.8469
2022-04-26 22:41:57.343209: Average global foreground Dice: [0.8673]
2022-04-26 22:41:57.364179: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:41:57.902473: lr: 0.002727
2022-04-26 22:41:57.932232: This epoch took 103.579865 s

2022-04-26 22:41:57.964215: 
epoch:  382
2022-04-26 22:43:36.718827: train loss : -0.8909
2022-04-26 22:43:44.201269: validation loss: -0.8449
2022-04-26 22:43:44.215410: Average global foreground Dice: [0.8663]
2022-04-26 22:43:44.266117: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:43:44.784617: lr: 0.002706
2022-04-26 22:43:44.806065: This epoch took 106.828919 s

2022-04-26 22:43:44.824179: 
epoch:  383
2022-04-26 22:45:19.553212: train loss : -0.8827
2022-04-26 22:45:26.131672: validation loss: -0.8387
2022-04-26 22:45:26.161306: Average global foreground Dice: [0.8635]
2022-04-26 22:45:26.179864: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:45:26.633046: lr: 0.002685
2022-04-26 22:45:26.662267: This epoch took 101.825837 s

2022-04-26 22:45:26.676015: 
epoch:  384
2022-04-26 22:47:00.520683: train loss : -0.8853
2022-04-26 22:47:07.223212: validation loss: -0.8507
2022-04-26 22:47:07.257553: Average global foreground Dice: [0.8692]
2022-04-26 22:47:07.270784: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:47:07.717021: lr: 0.002664
2022-04-26 22:47:07.719321: This epoch took 101.026811 s

2022-04-26 22:47:07.721394: 
epoch:  385
2022-04-26 22:48:41.630929: train loss : -0.8878
2022-04-26 22:48:49.498644: validation loss: -0.8398
2022-04-26 22:48:49.541611: Average global foreground Dice: [0.8575]
2022-04-26 22:48:49.570229: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:48:50.340079: lr: 0.002643
2022-04-26 22:48:50.362189: This epoch took 102.638733 s

2022-04-26 22:48:50.394167: 
epoch:  386
2022-04-26 22:50:25.083175: train loss : -0.8890
2022-04-26 22:50:32.585814: validation loss: -0.8398
2022-04-26 22:50:32.615578: Average global foreground Dice: [0.8624]
2022-04-26 22:50:32.644158: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:50:33.331583: lr: 0.002622
2022-04-26 22:50:33.333843: This epoch took 102.919584 s

2022-04-26 22:50:33.335948: 
epoch:  387
2022-04-26 22:52:16.348795: train loss : -0.8919
2022-04-26 22:52:23.268738: validation loss: -0.8316
2022-04-26 22:52:23.314536: Average global foreground Dice: [0.8542]
2022-04-26 22:52:23.360733: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:52:24.062410: lr: 0.002601
2022-04-26 22:52:24.084289: This epoch took 110.737054 s

2022-04-26 22:52:24.104339: 
epoch:  388
2022-04-26 22:53:57.903644: train loss : -0.8887
2022-04-26 22:54:04.371120: validation loss: -0.8333
2022-04-26 22:54:04.376452: Average global foreground Dice: [0.8539]
2022-04-26 22:54:04.396696: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:54:04.864877: lr: 0.002581
2022-04-26 22:54:04.867687: This epoch took 100.746517 s

2022-04-26 22:54:04.870580: 
epoch:  389
2022-04-26 22:55:39.044709: train loss : -0.8910
2022-04-26 22:55:45.660016: validation loss: -0.8264
2022-04-26 22:55:45.696545: Average global foreground Dice: [0.8513]
2022-04-26 22:55:45.710333: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:55:46.167621: lr: 0.00256
2022-04-26 22:55:46.170047: This epoch took 101.295572 s

2022-04-26 22:55:46.171991: 
epoch:  390
2022-04-26 22:57:23.823085: train loss : -0.8935
2022-04-26 22:57:30.888504: validation loss: -0.8394
2022-04-26 22:57:30.923259: Average global foreground Dice: [0.8609]
2022-04-26 22:57:30.942163: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:57:31.875666: lr: 0.002539
2022-04-26 22:57:31.897288: This epoch took 105.723248 s

2022-04-26 22:57:31.917336: 
epoch:  391
2022-04-26 22:59:06.420257: train loss : -0.8922
2022-04-26 22:59:13.263835: validation loss: -0.8461
2022-04-26 22:59:13.284538: Average global foreground Dice: [0.8668]
2022-04-26 22:59:13.290333: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 22:59:14.103750: lr: 0.002518
2022-04-26 22:59:14.124174: This epoch took 102.186678 s

2022-04-26 22:59:14.151166: 
epoch:  392
2022-04-26 23:00:47.936229: train loss : -0.8854
2022-04-26 23:00:55.162564: validation loss: -0.8347
2022-04-26 23:00:55.182973: Average global foreground Dice: [0.8561]
2022-04-26 23:00:55.213166: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:00:55.951991: lr: 0.002497
2022-04-26 23:00:55.972173: This epoch took 101.807921 s

2022-04-26 23:00:55.990527: 
epoch:  393
2022-04-26 23:02:30.852433: train loss : -0.8884
2022-04-26 23:02:37.031766: validation loss: -0.8461
2022-04-26 23:02:37.034653: Average global foreground Dice: [0.8656]
2022-04-26 23:02:37.036657: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:02:37.437253: lr: 0.002476
2022-04-26 23:02:37.439834: This epoch took 101.412666 s

2022-04-26 23:02:37.442159: 
epoch:  394
2022-04-26 23:04:12.275564: train loss : -0.8944
2022-04-26 23:04:19.411354: validation loss: -0.8475
2022-04-26 23:04:19.442324: Average global foreground Dice: [0.8655]
2022-04-26 23:04:19.464155: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:04:19.938643: lr: 0.002455
2022-04-26 23:04:19.952039: This epoch took 102.507742 s

2022-04-26 23:04:19.981138: 
epoch:  395
2022-04-26 23:05:54.528807: train loss : -0.8918
2022-04-26 23:06:01.205265: validation loss: -0.8458
2022-04-26 23:06:01.225855: Average global foreground Dice: [0.8657]
2022-04-26 23:06:01.268687: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:06:02.268770: lr: 0.002434
2022-04-26 23:06:02.289178: This epoch took 102.287836 s

2022-04-26 23:06:02.302789: 
epoch:  396
2022-04-26 23:07:35.049373: train loss : -0.8904
2022-04-26 23:07:41.858583: validation loss: -0.8505
2022-04-26 23:07:41.879918: Average global foreground Dice: [0.8698]
2022-04-26 23:07:41.900178: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:07:42.450074: lr: 0.002413
2022-04-26 23:07:42.452603: This epoch took 100.134074 s

2022-04-26 23:07:42.454771: 
epoch:  397
2022-04-26 23:09:17.290918: train loss : -0.8904
2022-04-26 23:09:24.286685: validation loss: -0.8429
2022-04-26 23:09:24.316514: Average global foreground Dice: [0.8633]
2022-04-26 23:09:24.336863: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:09:24.998588: lr: 0.002391
2022-04-26 23:09:25.031223: This epoch took 102.573840 s

2022-04-26 23:09:25.054164: 
epoch:  398
2022-04-26 23:10:58.836117: train loss : -0.8944
2022-04-26 23:11:05.907347: validation loss: -0.8493
2022-04-26 23:11:05.936529: Average global foreground Dice: [0.8679]
2022-04-26 23:11:05.958178: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:11:06.832372: lr: 0.00237
2022-04-26 23:11:06.877183: This epoch took 101.797019 s

2022-04-26 23:11:06.899143: 
epoch:  399
2022-04-26 23:12:39.892236: train loss : -0.8885
2022-04-26 23:12:46.300215: validation loss: -0.8332
2022-04-26 23:12:46.329477: Average global foreground Dice: [0.8563]
2022-04-26 23:12:46.351403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:12:46.777132: lr: 0.002349
2022-04-26 23:12:46.779534: saving scheduled checkpoint file...
2022-04-26 23:12:46.818116: saving checkpoint...
2022-04-26 23:12:48.007757: done, saving took 1.23 seconds
2022-04-26 23:12:48.020498: done
2022-04-26 23:12:48.023645: This epoch took 101.101502 s

2022-04-26 23:12:48.026110: 
epoch:  400
2022-04-26 23:14:22.724136: train loss : -0.8927
2022-04-26 23:14:29.334391: validation loss: -0.8474
2022-04-26 23:14:29.348360: Average global foreground Dice: [0.869]
2022-04-26 23:14:29.374120: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:14:30.015416: lr: 0.002328
2022-04-26 23:14:30.066405: This epoch took 102.038067 s

2022-04-26 23:14:30.089157: 
epoch:  401
2022-04-26 23:16:02.800641: train loss : -0.8942
2022-04-26 23:16:08.863058: validation loss: -0.8523
2022-04-26 23:16:08.866170: Average global foreground Dice: [0.8699]
2022-04-26 23:16:08.868173: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:16:09.281461: lr: 0.002307
2022-04-26 23:16:09.336415: saving checkpoint...
2022-04-26 23:16:10.290720: done, saving took 1.01 seconds
2022-04-26 23:16:10.304889: This epoch took 100.193741 s

2022-04-26 23:16:10.307059: 
epoch:  402
2022-04-26 23:17:44.746385: train loss : -0.8939
2022-04-26 23:17:51.738667: validation loss: -0.8481
2022-04-26 23:17:51.752541: Average global foreground Dice: [0.8667]
2022-04-26 23:17:51.773174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:17:52.453531: lr: 0.002286
2022-04-26 23:17:52.534149: saving checkpoint...
2022-04-26 23:17:53.683931: done, saving took 1.20 seconds
2022-04-26 23:17:53.700013: This epoch took 103.390737 s

2022-04-26 23:17:53.702284: 
epoch:  403
2022-04-26 23:19:28.356386: train loss : -0.8941
2022-04-26 23:19:35.262534: validation loss: -0.8524
2022-04-26 23:19:35.308489: Average global foreground Dice: [0.87]
2022-04-26 23:19:35.324165: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:19:35.870242: lr: 0.002264
2022-04-26 23:19:35.941333: saving checkpoint...
2022-04-26 23:19:37.206232: done, saving took 1.31 seconds
2022-04-26 23:19:37.215235: This epoch took 103.510880 s

2022-04-26 23:19:37.217245: 
epoch:  404
2022-04-26 23:21:10.551304: train loss : -0.8922
2022-04-26 23:21:17.450320: validation loss: -0.8429
2022-04-26 23:21:17.472343: Average global foreground Dice: [0.8629]
2022-04-26 23:21:17.492693: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:21:18.231965: lr: 0.002243
2022-04-26 23:21:18.271231: This epoch took 101.051826 s

2022-04-26 23:21:18.297465: 
epoch:  405
2022-04-26 23:22:52.528440: train loss : -0.8932
2022-04-26 23:22:59.239584: validation loss: -0.8420
2022-04-26 23:22:59.261835: Average global foreground Dice: [0.8615]
2022-04-26 23:22:59.265083: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:22:59.704092: lr: 0.002222
2022-04-26 23:22:59.706482: This epoch took 101.353330 s

2022-04-26 23:22:59.708649: 
epoch:  406
2022-04-26 23:24:32.089478: train loss : -0.8945
2022-04-26 23:24:38.557358: validation loss: -0.8442
2022-04-26 23:24:38.560458: Average global foreground Dice: [0.8661]
2022-04-26 23:24:38.562071: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:24:38.971063: lr: 0.002201
2022-04-26 23:24:38.973432: This epoch took 99.262780 s

2022-04-26 23:24:38.975359: 
epoch:  407
2022-04-26 23:26:13.011950: train loss : -0.8924
2022-04-26 23:26:19.283108: validation loss: -0.8413
2022-04-26 23:26:19.288090: Average global foreground Dice: [0.862]
2022-04-26 23:26:19.290446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:26:19.781641: lr: 0.002179
2022-04-26 23:26:19.784151: This epoch took 100.806959 s

2022-04-26 23:26:19.786098: 
epoch:  408
2022-04-26 23:27:53.210969: train loss : -0.8970
2022-04-26 23:28:00.376000: validation loss: -0.8433
2022-04-26 23:28:00.406518: Average global foreground Dice: [0.8632]
2022-04-26 23:28:00.427158: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:28:01.317290: lr: 0.002158
2022-04-26 23:28:01.354167: This epoch took 101.566081 s

2022-04-26 23:28:01.373144: 
epoch:  409
2022-04-26 23:29:41.167714: train loss : -0.8922
2022-04-26 23:29:48.006626: validation loss: -0.8389
2022-04-26 23:29:48.029692: Average global foreground Dice: [0.8597]
2022-04-26 23:29:48.049136: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:29:48.864520: lr: 0.002137
2022-04-26 23:29:48.884194: This epoch took 107.496027 s

2022-04-26 23:29:48.918151: 
epoch:  410
2022-04-26 23:31:24.661646: train loss : -0.8941
2022-04-26 23:31:32.502237: validation loss: -0.8357
2022-04-26 23:31:32.540004: Average global foreground Dice: [0.857]
2022-04-26 23:31:32.573119: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:31:33.897498: lr: 0.002115
2022-04-26 23:31:33.918353: This epoch took 104.980596 s

2022-04-26 23:31:33.936157: 
epoch:  411
2022-04-26 23:33:08.973088: train loss : -0.8928
2022-04-26 23:33:15.074956: validation loss: -0.8402
2022-04-26 23:33:15.080305: Average global foreground Dice: [0.8584]
2022-04-26 23:33:15.082411: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:33:15.516685: lr: 0.002094
2022-04-26 23:33:15.519093: This epoch took 101.566917 s

2022-04-26 23:33:15.521245: 
epoch:  412
2022-04-26 23:34:47.795793: train loss : -0.8964
2022-04-26 23:34:54.130027: validation loss: -0.8461
2022-04-26 23:34:54.133010: Average global foreground Dice: [0.8631]
2022-04-26 23:34:54.134959: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:34:54.536098: lr: 0.002072
2022-04-26 23:34:54.538615: This epoch took 99.015353 s

2022-04-26 23:34:54.540804: 
epoch:  413
2022-04-26 23:36:28.859120: train loss : -0.8966
2022-04-26 23:36:35.066710: validation loss: -0.8328
2022-04-26 23:36:35.069756: Average global foreground Dice: [0.8587]
2022-04-26 23:36:35.071983: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:36:35.482985: lr: 0.002051
2022-04-26 23:36:35.485736: This epoch took 100.942846 s

2022-04-26 23:36:35.487833: 
epoch:  414
2022-04-26 23:38:08.325682: train loss : -0.8944
2022-04-26 23:38:14.716556: validation loss: -0.8498
2022-04-26 23:38:14.719611: Average global foreground Dice: [0.8688]
2022-04-26 23:38:14.723952: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:38:15.131459: lr: 0.00203
2022-04-26 23:38:15.133891: This epoch took 99.643905 s

2022-04-26 23:38:15.135990: 
epoch:  415
2022-04-26 23:39:49.179998: train loss : -0.8990
2022-04-26 23:39:55.801835: validation loss: -0.8379
2022-04-26 23:39:55.818025: Average global foreground Dice: [0.8584]
2022-04-26 23:39:55.839365: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:39:56.316885: lr: 0.002008
2022-04-26 23:39:56.318882: This epoch took 101.180847 s

2022-04-26 23:39:56.322215: 
epoch:  416
2022-04-26 23:41:29.536971: train loss : -0.8907
2022-04-26 23:41:36.349956: validation loss: -0.8445
2022-04-26 23:41:36.387572: Average global foreground Dice: [0.8643]
2022-04-26 23:41:36.412181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:41:37.047041: lr: 0.001987
2022-04-26 23:41:37.049441: This epoch took 100.723428 s

2022-04-26 23:41:37.051465: 
epoch:  417
2022-04-26 23:43:10.561866: train loss : -0.8944
2022-04-26 23:43:16.405730: validation loss: -0.8483
2022-04-26 23:43:16.408966: Average global foreground Dice: [0.8692]
2022-04-26 23:43:16.411215: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:43:16.807759: lr: 0.001965
2022-04-26 23:43:16.810258: This epoch took 99.756777 s

2022-04-26 23:43:16.812402: 
epoch:  418
2022-04-26 23:44:51.187433: train loss : -0.8932
2022-04-26 23:44:57.879338: validation loss: -0.8464
2022-04-26 23:44:57.902814: Average global foreground Dice: [0.8637]
2022-04-26 23:44:57.908137: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:44:58.416051: lr: 0.001943
2022-04-26 23:44:58.418586: This epoch took 101.603942 s

2022-04-26 23:44:58.420739: 
epoch:  419
2022-04-26 23:46:32.354323: train loss : -0.8956
2022-04-26 23:46:38.944352: validation loss: -0.8461
2022-04-26 23:46:38.968674: Average global foreground Dice: [0.8639]
2022-04-26 23:46:38.971076: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:46:39.458820: lr: 0.001922
2022-04-26 23:46:39.461359: This epoch took 101.038606 s

2022-04-26 23:46:39.463727: 
epoch:  420
2022-04-26 23:48:13.101259: train loss : -0.8954
2022-04-26 23:48:20.290178: validation loss: -0.8440
2022-04-26 23:48:20.317569: Average global foreground Dice: [0.863]
2022-04-26 23:48:20.333182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:48:20.873635: lr: 0.0019
2022-04-26 23:48:20.876171: This epoch took 101.410348 s

2022-04-26 23:48:20.878253: 
epoch:  421
2022-04-26 23:49:55.656414: train loss : -0.8928
2022-04-26 23:50:02.121061: validation loss: -0.8446
2022-04-26 23:50:02.145634: Average global foreground Dice: [0.8647]
2022-04-26 23:50:02.170151: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:50:02.827666: lr: 0.001879
2022-04-26 23:50:02.830372: This epoch took 101.950051 s

2022-04-26 23:50:02.832599: 
epoch:  422
2022-04-26 23:51:37.452901: train loss : -0.8927
2022-04-26 23:51:43.828671: validation loss: -0.8506
2022-04-26 23:51:43.836107: Average global foreground Dice: [0.869]
2022-04-26 23:51:43.859652: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:51:44.422757: lr: 0.001857
2022-04-26 23:51:44.428131: This epoch took 101.593327 s

2022-04-26 23:51:44.430447: 
epoch:  423
2022-04-26 23:53:19.086736: train loss : -0.8913
2022-04-26 23:53:25.450040: validation loss: -0.8465
2022-04-26 23:53:25.453957: Average global foreground Dice: [0.865]
2022-04-26 23:53:25.456174: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:53:25.855241: lr: 0.001835
2022-04-26 23:53:25.857593: This epoch took 101.424901 s

2022-04-26 23:53:25.859729: 
epoch:  424
2022-04-26 23:54:59.768609: train loss : -0.8970
2022-04-26 23:55:05.870719: validation loss: -0.8499
2022-04-26 23:55:05.873875: Average global foreground Dice: [0.8712]
2022-04-26 23:55:05.876223: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:55:06.274798: lr: 0.001813
2022-04-26 23:55:06.323548: saving checkpoint...
2022-04-26 23:55:07.281716: done, saving took 1.00 seconds
2022-04-26 23:55:07.294022: This epoch took 101.430897 s

2022-04-26 23:55:07.296667: 
epoch:  425
2022-04-26 23:56:43.789192: train loss : -0.8959
2022-04-26 23:56:51.702885: validation loss: -0.8451
2022-04-26 23:56:51.749672: Average global foreground Dice: [0.8632]
2022-04-26 23:56:51.774148: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:56:52.467725: lr: 0.001792
2022-04-26 23:56:52.501079: This epoch took 105.201991 s

2022-04-26 23:56:52.522146: 
epoch:  426
2022-04-26 23:58:27.937451: train loss : -0.8909
2022-04-26 23:58:35.174927: validation loss: -0.8482
2022-04-26 23:58:35.206441: Average global foreground Dice: [0.8694]
2022-04-26 23:58:35.234181: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-26 23:58:35.844818: lr: 0.00177
2022-04-26 23:58:35.966990: saving checkpoint...
2022-04-26 23:58:37.117236: done, saving took 1.24 seconds
2022-04-26 23:58:37.177644: This epoch took 104.640698 s

2022-04-26 23:58:37.197716: 
epoch:  427
2022-04-27 00:00:11.902739: train loss : -0.8943
2022-04-27 00:00:19.116127: validation loss: -0.8403
2022-04-27 00:00:19.142621: Average global foreground Dice: [0.8631]
2022-04-27 00:00:19.157159: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:00:20.052348: lr: 0.001748
2022-04-27 00:00:20.055076: This epoch took 102.838930 s

2022-04-27 00:00:20.073141: 
epoch:  428
2022-04-27 00:01:55.410447: train loss : -0.8971
2022-04-27 00:02:02.162872: validation loss: -0.8446
2022-04-27 00:02:02.209595: Average global foreground Dice: [0.8646]
2022-04-27 00:02:02.226238: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:02:02.693396: lr: 0.001726
2022-04-27 00:02:02.705414: This epoch took 102.610267 s

2022-04-27 00:02:02.707957: 
epoch:  429
2022-04-27 00:03:36.728992: train loss : -0.8990
2022-04-27 00:03:42.821144: validation loss: -0.8477
2022-04-27 00:03:42.824859: Average global foreground Dice: [0.8679]
2022-04-27 00:03:42.827333: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:03:43.224286: lr: 0.001704
2022-04-27 00:03:43.258823: saving checkpoint...
2022-04-27 00:03:44.225133: done, saving took 1.00 seconds
2022-04-27 00:03:44.235416: This epoch took 101.525170 s

2022-04-27 00:03:44.237753: 
epoch:  430
2022-04-27 00:05:17.758543: train loss : -0.8940
2022-04-27 00:05:23.735413: validation loss: -0.8313
2022-04-27 00:05:23.739586: Average global foreground Dice: [0.8531]
2022-04-27 00:05:23.741886: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:05:24.181009: lr: 0.001682
2022-04-27 00:05:24.183658: This epoch took 99.943536 s

2022-04-27 00:05:24.186061: 
epoch:  431
2022-04-27 00:06:58.318978: train loss : -0.8968
2022-04-27 00:07:05.267209: validation loss: -0.8409
2022-04-27 00:07:05.292560: Average global foreground Dice: [0.8619]
2022-04-27 00:07:05.344815: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:07:05.983598: lr: 0.00166
2022-04-27 00:07:05.998291: This epoch took 101.810093 s

2022-04-27 00:07:06.016915: 
epoch:  432
2022-04-27 00:08:42.108514: train loss : -0.8947
2022-04-27 00:08:48.910603: validation loss: -0.8480
2022-04-27 00:08:48.946264: Average global foreground Dice: [0.865]
2022-04-27 00:08:48.960164: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:08:49.843588: lr: 0.001638
2022-04-27 00:08:49.860200: This epoch took 103.841023 s

2022-04-27 00:08:49.870518: 
epoch:  433
2022-04-27 00:10:24.790797: train loss : -0.8949
2022-04-27 00:10:31.524928: validation loss: -0.8500
2022-04-27 00:10:31.550962: Average global foreground Dice: [0.8667]
2022-04-27 00:10:31.584182: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:10:32.138814: lr: 0.001616
2022-04-27 00:10:32.159240: This epoch took 102.272726 s

2022-04-27 00:10:32.180367: 
epoch:  434
2022-04-27 00:12:04.247748: train loss : -0.8973
2022-04-27 00:12:10.417317: validation loss: -0.8399
2022-04-27 00:12:10.420741: Average global foreground Dice: [0.8603]
2022-04-27 00:12:10.422956: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:12:10.824733: lr: 0.001594
2022-04-27 00:12:10.827091: This epoch took 98.634905 s

2022-04-27 00:12:10.829201: 
epoch:  435
2022-04-27 00:13:45.358384: train loss : -0.8975
2022-04-27 00:13:53.109303: validation loss: -0.8333
2022-04-27 00:13:53.134750: Average global foreground Dice: [0.8555]
2022-04-27 00:13:53.162167: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:13:54.290525: lr: 0.001572
2022-04-27 00:13:54.303168: This epoch took 103.471879 s

2022-04-27 00:13:54.331186: 
epoch:  436
2022-04-27 00:15:28.910122: train loss : -0.8962
2022-04-27 00:15:35.753719: validation loss: -0.8457
2022-04-27 00:15:35.769929: Average global foreground Dice: [0.8655]
2022-04-27 00:15:35.788043: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:15:36.265768: lr: 0.00155
2022-04-27 00:15:36.268442: This epoch took 101.914292 s

2022-04-27 00:15:36.270559: 
epoch:  437
2022-04-27 00:17:10.406789: train loss : -0.8910
2022-04-27 00:17:17.029030: validation loss: -0.8467
2022-04-27 00:17:17.053622: Average global foreground Dice: [0.866]
2022-04-27 00:17:17.073233: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:17:17.796404: lr: 0.001528
2022-04-27 00:17:17.818711: This epoch took 101.545839 s

2022-04-27 00:17:17.846147: 
epoch:  438
2022-04-27 00:18:52.453997: train loss : -0.8961
2022-04-27 00:18:58.881270: validation loss: -0.8355
2022-04-27 00:18:58.893265: Average global foreground Dice: [0.8606]
2022-04-27 00:18:58.901462: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:18:59.362060: lr: 0.001506
2022-04-27 00:18:59.365177: This epoch took 101.505043 s

2022-04-27 00:18:59.367514: 
epoch:  439
2022-04-27 00:20:33.633087: train loss : -0.9002
2022-04-27 00:20:40.414816: validation loss: -0.8407
2022-04-27 00:20:40.417596: Average global foreground Dice: [0.8625]
2022-04-27 00:20:40.419500: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:20:40.936970: lr: 0.001483
2022-04-27 00:20:40.939399: This epoch took 101.569321 s

2022-04-27 00:20:40.941634: 
epoch:  440
2022-04-27 00:22:14.949122: train loss : -0.8959
2022-04-27 00:22:21.420395: validation loss: -0.8470
2022-04-27 00:22:21.451651: Average global foreground Dice: [0.8639]
2022-04-27 00:22:21.476541: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:22:21.915057: lr: 0.001461
2022-04-27 00:22:21.917565: This epoch took 100.973804 s

2022-04-27 00:22:21.919655: 
epoch:  441
2022-04-27 00:23:56.418694: train loss : -0.8980
2022-04-27 00:24:02.542119: validation loss: -0.8506
2022-04-27 00:24:02.545193: Average global foreground Dice: [0.8678]
2022-04-27 00:24:02.547197: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:24:02.945096: lr: 0.001439
2022-04-27 00:24:02.947536: This epoch took 101.025838 s

2022-04-27 00:24:02.949622: 
epoch:  442
2022-04-27 00:25:36.181226: train loss : -0.8907
2022-04-27 00:25:42.092385: validation loss: -0.8440
2022-04-27 00:25:42.095646: Average global foreground Dice: [0.8633]
2022-04-27 00:25:42.097903: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:25:42.501624: lr: 0.001416
2022-04-27 00:25:42.504151: This epoch took 99.552115 s

2022-04-27 00:25:42.506285: 
epoch:  443
2022-04-27 00:27:15.470745: train loss : -0.8980
2022-04-27 00:27:21.774805: validation loss: -0.8516
2022-04-27 00:27:21.782422: Average global foreground Dice: [0.8694]
2022-04-27 00:27:21.794324: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:27:22.211016: lr: 0.001394
2022-04-27 00:27:22.213469: This epoch took 99.704975 s

2022-04-27 00:27:22.215935: 
epoch:  444
2022-04-27 00:28:55.967721: train loss : -0.8969
2022-04-27 00:29:02.450395: validation loss: -0.8458
2022-04-27 00:29:02.474536: Average global foreground Dice: [0.8662]
2022-04-27 00:29:02.495172: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:29:03.006158: lr: 0.001372
2022-04-27 00:29:03.008615: This epoch took 100.790455 s

2022-04-27 00:29:03.011211: 
epoch:  445
2022-04-27 00:30:37.212457: train loss : -0.8987
2022-04-27 00:30:43.813108: validation loss: -0.8438
2022-04-27 00:30:43.816045: Average global foreground Dice: [0.8602]
2022-04-27 00:30:43.818244: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:30:44.228898: lr: 0.001349
2022-04-27 00:30:44.231460: This epoch took 101.217998 s

2022-04-27 00:30:44.233573: 
epoch:  446
2022-04-27 00:32:18.585073: train loss : -0.8962
2022-04-27 00:32:25.143483: validation loss: -0.8447
2022-04-27 00:32:25.146375: Average global foreground Dice: [0.8634]
2022-04-27 00:32:25.148450: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:32:25.550043: lr: 0.001327
2022-04-27 00:32:25.553099: This epoch took 101.317311 s

2022-04-27 00:32:25.555758: 
epoch:  447
2022-04-27 00:34:00.136755: train loss : -0.8980
2022-04-27 00:34:06.637939: validation loss: -0.8506
2022-04-27 00:34:06.641233: Average global foreground Dice: [0.8676]
2022-04-27 00:34:06.643438: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:34:07.044477: lr: 0.001304
2022-04-27 00:34:07.047047: This epoch took 101.488774 s

2022-04-27 00:34:07.049428: 
epoch:  448
2022-04-27 00:35:40.085512: train loss : -0.8983
2022-04-27 00:35:46.656888: validation loss: -0.8353
2022-04-27 00:35:46.659788: Average global foreground Dice: [0.8566]
2022-04-27 00:35:46.662047: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:35:47.169633: lr: 0.001282
2022-04-27 00:35:47.171949: This epoch took 100.120163 s

2022-04-27 00:35:47.175295: 
epoch:  449
2022-04-27 00:37:20.881466: train loss : -0.9015
2022-04-27 00:37:27.399653: validation loss: -0.8458
2022-04-27 00:37:27.428557: Average global foreground Dice: [0.869]
2022-04-27 00:37:27.447156: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:37:28.047881: lr: 0.001259
2022-04-27 00:37:28.061915: saving scheduled checkpoint file...
2022-04-27 00:37:28.102683: saving checkpoint...
2022-04-27 00:37:29.134442: done, saving took 1.07 seconds
2022-04-27 00:37:29.145836: done
2022-04-27 00:37:29.148034: This epoch took 101.969610 s

2022-04-27 00:37:29.150186: 
epoch:  450
2022-04-27 00:39:02.475298: train loss : -0.8986
2022-04-27 00:39:08.985491: validation loss: -0.8468
2022-04-27 00:39:08.988372: Average global foreground Dice: [0.8653]
2022-04-27 00:39:08.990513: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:39:09.394791: lr: 0.001236
2022-04-27 00:39:09.397298: This epoch took 100.244843 s

2022-04-27 00:39:09.399529: 
epoch:  451
2022-04-27 00:40:42.053307: train loss : -0.8985
2022-04-27 00:40:48.073861: validation loss: -0.8432
2022-04-27 00:40:48.076805: Average global foreground Dice: [0.8642]
2022-04-27 00:40:48.078917: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:40:48.478255: lr: 0.001214
2022-04-27 00:40:48.480513: This epoch took 99.078939 s

2022-04-27 00:40:48.482404: 
epoch:  452
2022-04-27 00:42:21.387173: train loss : -0.9012
2022-04-27 00:42:27.803080: validation loss: -0.8505
2022-04-27 00:42:27.806238: Average global foreground Dice: [0.8678]
2022-04-27 00:42:27.808237: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:42:28.209273: lr: 0.001191
2022-04-27 00:42:28.211431: This epoch took 99.727148 s

2022-04-27 00:42:28.213671: 
epoch:  453
2022-04-27 00:44:01.623793: train loss : -0.9003
2022-04-27 00:44:08.140934: validation loss: -0.8394
2022-04-27 00:44:08.144060: Average global foreground Dice: [0.8586]
2022-04-27 00:44:08.146403: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:44:08.593773: lr: 0.001168
2022-04-27 00:44:08.615221: This epoch took 100.399266 s

2022-04-27 00:44:08.622746: 
epoch:  454
2022-04-27 00:45:43.794747: train loss : -0.8991
2022-04-27 00:45:50.095458: validation loss: -0.8472
2022-04-27 00:45:50.111770: Average global foreground Dice: [0.8656]
2022-04-27 00:45:50.124186: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:45:50.668188: lr: 0.001145
2022-04-27 00:45:50.670738: This epoch took 102.044374 s

2022-04-27 00:45:50.673047: 
epoch:  455
2022-04-27 00:47:24.343994: train loss : -0.8976
2022-04-27 00:47:31.324020: validation loss: -0.8502
2022-04-27 00:47:31.331386: Average global foreground Dice: [0.8694]
2022-04-27 00:47:31.349133: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:47:31.860128: lr: 0.001122
2022-04-27 00:47:31.878996: This epoch took 101.203674 s

2022-04-27 00:47:31.890270: 
epoch:  456
2022-04-27 00:49:05.597886: train loss : -0.8974
2022-04-27 00:49:12.587606: validation loss: -0.8506
2022-04-27 00:49:12.601515: Average global foreground Dice: [0.8707]
2022-04-27 00:49:12.623175: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:49:13.288769: lr: 0.001099
2022-04-27 00:49:13.377805: saving checkpoint...
2022-04-27 00:49:14.474768: done, saving took 1.16 seconds
2022-04-27 00:49:14.487431: This epoch took 102.591148 s

2022-04-27 00:49:14.489628: 
epoch:  457
2022-04-27 00:50:47.760263: train loss : -0.8911
2022-04-27 00:50:54.642824: validation loss: -0.8414
2022-04-27 00:50:54.682379: Average global foreground Dice: [0.8624]
2022-04-27 00:50:54.707224: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:50:55.481368: lr: 0.001076
2022-04-27 00:50:55.503244: This epoch took 101.011334 s

2022-04-27 00:50:55.523467: 
epoch:  458
2022-04-27 00:52:31.345667: train loss : -0.8969
2022-04-27 00:52:39.056354: validation loss: -0.8457
2022-04-27 00:52:39.077326: Average global foreground Dice: [0.8694]
2022-04-27 00:52:39.079802: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:52:39.859901: lr: 0.001053
2022-04-27 00:52:39.940227: saving checkpoint...
2022-04-27 00:52:40.974378: done, saving took 1.09 seconds
2022-04-27 00:52:41.039156: This epoch took 105.504005 s

2022-04-27 00:52:41.057135: 
epoch:  459
2022-04-27 00:54:15.724515: train loss : -0.8982
2022-04-27 00:54:23.156435: validation loss: -0.8445
2022-04-27 00:54:23.203562: Average global foreground Dice: [0.8653]
2022-04-27 00:54:23.224382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-04-27 00:54:23.783849: lr: 0.00103
2022-04-27 00:54:23.791021: This epoch took 102.715849 s

2022-04-27 00:54:23.793278: 
epoch:  460
2022-04-27 00:55:56.833820: train loss : -0.8963
2022-04-27 00:56:03.854679: validation loss: -0.8421
2022-04-27 00:56:03.895641: Average global foreground Dice: [0.8648]
2022-04-27 00:56:03.912863: 