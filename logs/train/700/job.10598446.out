Starting at Fri Jul  1 00:32:13 CEST 2022
Running on hosts: res-hpc-lkeb05
Running on 1 nodes.
Running 1 tasks.
CPUs on node: 4.
Account: div2-lkeb
Job ID: 10598446
Job name: PancreasTrain
Node running script: res-hpc-lkeb05
Submit host: res-hpc-lo02.researchlumc.nl
GPUS: 0 or 
Fri Jul  1 00:32:14 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     Off  | 00000000:D8:00.0 Off |                  Off |
| 34%   36C    P0    54W / 260W |      0MiB / 24220MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Current working directory is /home/smaijer
Load all modules..
Done with loading all modules. Modules:
Activate conda env nnunet..
Verifying environment variables:
Installing hidden layer and nnUnet..
Collecting hiddenlayer
  Cloning https://github.com/FabianIsensee/hiddenlayer.git (to revision more_plotted_details) to /tmp/pip-install-rm66hgk_/hiddenlayer_07c1df50759f461c849c0ada11d71761
  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit 4b98f9e5cccebac67368f02b95f4700b522345b1
Obtaining file:///home/smaijer/code/nnUNet
Requirement already satisfied: torch>1.10.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (1.12.0)
Requirement already satisfied: tqdm in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (4.64.0)
Requirement already satisfied: dicom2nifti in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (2.4.2)
Requirement already satisfied: scikit-image>=0.14 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.19.3)
Requirement already satisfied: medpy in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.4.0)
Requirement already satisfied: scipy in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (1.8.1)
Requirement already satisfied: batchgenerators>=0.23 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.24)
Requirement already satisfied: numpy in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (1.23.0)
Requirement already satisfied: sklearn in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.0)
Requirement already satisfied: SimpleITK in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (2.1.1.2)
Requirement already satisfied: pandas in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (1.4.3)
Requirement already satisfied: requests in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (2.28.0)
Requirement already satisfied: nibabel in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (4.0.1)
Requirement already satisfied: tifffile in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (2022.5.4)
Requirement already satisfied: matplotlib in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (3.5.2)
Requirement already satisfied: monai in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.9.0)
Requirement already satisfied: einops in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.4.1)
Requirement already satisfied: ipython in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (8.4.0)
Requirement already satisfied: graphviz in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from nnunet==1.7.0) (0.20)
Requirement already satisfied: threadpoolctl in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (3.1.0)
Requirement already satisfied: unittest2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)
Requirement already satisfied: future in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (0.18.2)
Requirement already satisfied: pillow>=7.1.2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (9.1.1)
Requirement already satisfied: scikit-learn in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from batchgenerators>=0.23->nnunet==1.7.0) (1.1.1)
Requirement already satisfied: networkx>=2.2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.8.4)
Requirement already satisfied: imageio>=2.4.1 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (2.19.3)
Requirement already satisfied: packaging>=20.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (21.3)
Requirement already satisfied: PyWavelets>=1.1.1 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from scikit-image>=0.14->nnunet==1.7.0) (1.3.0)
Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from packaging>=20.0->scikit-image>=0.14->nnunet==1.7.0) (3.0.9)
Requirement already satisfied: typing-extensions in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from torch>1.10.0->nnunet==1.7.0) (4.2.0)
Requirement already satisfied: pydicom>=2.2.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from dicom2nifti->nnunet==1.7.0) (2.3.0)
Requirement already satisfied: python-gdcm in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from dicom2nifti->nnunet==1.7.0) (3.0.14)
Requirement already satisfied: pickleshare in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (0.7.5)
Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (3.0.30)
Requirement already satisfied: jedi>=0.16 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (0.18.1)
Requirement already satisfied: setuptools>=18.5 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (58.1.0)
Requirement already satisfied: traitlets>=5 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (5.3.0)
Requirement already satisfied: stack-data in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (0.3.0)
Requirement already satisfied: pexpect>4.3 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (4.8.0)
Requirement already satisfied: pygments>=2.4.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (2.12.0)
Requirement already satisfied: decorator in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (5.1.1)
Requirement already satisfied: matplotlib-inline in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (0.1.3)
Requirement already satisfied: backcall in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from ipython->nnunet==1.7.0) (0.2.0)
Requirement already satisfied: parso<0.9.0,>=0.8.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from jedi>=0.16->ipython->nnunet==1.7.0) (0.8.3)
Requirement already satisfied: ptyprocess>=0.5 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from pexpect>4.3->ipython->nnunet==1.7.0) (0.7.0)
Requirement already satisfied: wcwidth in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->nnunet==1.7.0) (0.2.5)
Requirement already satisfied: kiwisolver>=1.0.1 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from matplotlib->nnunet==1.7.0) (1.4.3)
Requirement already satisfied: cycler>=0.10 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from matplotlib->nnunet==1.7.0) (0.11.0)
Requirement already satisfied: python-dateutil>=2.7 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from matplotlib->nnunet==1.7.0) (2.8.2)
Requirement already satisfied: fonttools>=4.22.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from matplotlib->nnunet==1.7.0) (4.33.3)
Requirement already satisfied: six>=1.5 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->nnunet==1.7.0) (1.16.0)
Requirement already satisfied: pytz>=2020.1 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from pandas->nnunet==1.7.0) (2022.1)
Requirement already satisfied: idna<4,>=2.5 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from requests->nnunet==1.7.0) (3.3)
Requirement already satisfied: certifi>=2017.4.17 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from requests->nnunet==1.7.0) (2022.6.15)
Requirement already satisfied: charset-normalizer~=2.0.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from requests->nnunet==1.7.0) (2.0.12)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from requests->nnunet==1.7.0) (1.26.9)
Requirement already satisfied: joblib>=1.0.0 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from scikit-learn->batchgenerators>=0.23->nnunet==1.7.0) (1.1.0)
Requirement already satisfied: executing in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from stack-data->ipython->nnunet==1.7.0) (0.8.3)
Requirement already satisfied: asttokens in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from stack-data->ipython->nnunet==1.7.0) (2.0.5)
Requirement already satisfied: pure-eval in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from stack-data->ipython->nnunet==1.7.0) (0.2.2)
Collecting argparse
  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)
Requirement already satisfied: traceback2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.4.0)
Requirement already satisfied: linecache2 in /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/lib/python3.10/site-packages (from traceback2->unittest2->batchgenerators>=0.23->nnunet==1.7.0) (1.0.0)
Installing collected packages: argparse, nnunet
  Attempting uninstall: nnunet
    Found existing installation: nnunet 1.7.0
    Uninstalling nnunet-1.7.0:
      Successfully uninstalled nnunet-1.7.0
  Running setup.py develop for nnunet
Successfully installed argparse-1.4.0 nnunet-1.7.0


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

Suus0 - run_training. Args:
Namespace(network='3d_fullres', network_trainer='nnUNetTrainerV2', task='700', fold='2', validation_only=False, continue_training=True, p='nnUNetPlansv2.1', use_compressed_data=False, deterministic=False, npz=False, find_lr=False, valbest=False, fp32=False, val_folder='validation_raw', disable_saving=False, disable_postprocessing_on_folds=False, val_disable_overwrite=False, disable_next_stage_pred=False, pretrained_weights=None)
###############################################
I am running the following nnUNet: 3d_fullres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  15
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 160, 160]), 'median_patient_size_in_voxels': array([138, 243, 243]), 'current_spacing': array([3.28926364, 1.64543342, 1.64543342]), 'original_spacing': array([2.        , 0.78014851, 0.78014851]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 160, 160]), 'median_patient_size_in_voxels': array([228, 513, 513]), 'current_spacing': array([2.        , 0.78014851, 0.78014851]), 'original_spacing': array([2.        , 0.78014851, 0.78014851]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 1 from these plans
I am using batch dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task700/nnUNetData_plans_v2.1
###############################################
Suus1 - Initialise de NetworkTrainer
Suus2 - Initialise de nnUNetTrainer
Suus3 - Initialise de nnUNetTrainerV2
Suus4 - Initialise de trainer echt
Suus5 - zet de plans properties
Suus6 - Zet de data augmentation params
Suus7 - zet deep supervision weights die de meerdere outputs prioriteit geven
loading dataset
loading all case properties
2022-07-01 00:32:50.189204: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task700/splits_final.pkl
2022-07-01 00:32:50.200009: The split file contains 5 splits.
2022-07-01 00:32:50.202397: Desired fold for training: 2
2022-07-01 00:32:50.204727: This split has 192 training and 48 validation cases.
unpacking dataset
done
Suus8 - Maak network aan (BELANGRIJK!)
SuusB - first stride 
Suus10 - StackedConvLayers, input: 1 en output: 32, first_stride: None, num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [1, 3, 3], 'padding': [0, 1, 1]}
SuusA - first_stride [1, 2, 2]
Suus10 - StackedConvLayers, input: 32 en output: 64, first_stride: [1, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
SuusA - first_stride [2, 2, 2]
Suus10 - StackedConvLayers, input: 64 en output: 128, first_stride: [2, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
SuusA - first_stride [2, 2, 2]
Suus10 - StackedConvLayers, input: 128 en output: 256, first_stride: [2, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
SuusA - first_stride [2, 2, 2]
Suus10 - StackedConvLayers, input: 256 en output: 320, first_stride: [2, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 320 en output: 320, first_stride: [2, 2, 2], num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 320 en output: 320, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 640 en output: 320, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 320 en output: 320, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 512 en output: 256, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 256 en output: 256, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 256 en output: 128, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 128 en output: 128, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 128 en output: 64, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 64 en output: 64, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 64 en output: 32, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 32 en output: 32, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Generic_UNet(
  (encoder): Generic_UNETEncoder()
  (decoder): Generic_UNETDecoder()
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
SuusA - Load checkpoint (final, latest, best)
2022-07-01 00:32:53.121095: loading checkpoint /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task700/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_latest.model train= True
SuusB run_training - zet learning rate als  
2022-07-01 00:33:03.926142: Suus1 maybe_update_lr lr: 0.001259
SuusC - run_training!
using pin_memory on device 0
using pin_memory on device 0
Suus for now disable cause it breaks the logs
2022-07-01 00:33:31.307987: Unable to plot network architecture:
2022-07-01 00:33:31.313265: local variable 'g' referenced before assignment
2022-07-01 00:33:31.315887: 
printing the network instead:

2022-07-01 00:33:31.318611: Generic_UNet(
  (encoder): Generic_UNETEncoder()
  (decoder): Generic_UNETDecoder()
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-07-01 00:33:31.323041: 

2022-07-01 00:33:31.325490: 
epoch:  450
2022-07-01 00:39:15.167925: train loss : -0.3627
2022-07-01 00:39:34.552632: validation loss: -0.3993
2022-07-01 00:39:34.557030: Average global foreground Dice: [0.9243, 0.9375, 0.9095, 0.7835, 0.7671, 0.9456, 0.8645, 0.9374, 0.8632, 0.8396, 0.7177, 0.7172, 0.6721, 0.8869, 0.8269]
2022-07-01 00:39:34.559398: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 00:39:35.137590: Suus1 maybe_update_lr lr: 0.001236
2022-07-01 00:39:35.140179: saving best epoch checkpoint...
2022-07-01 00:39:35.205447: saving checkpoint...
2022-07-01 00:39:36.256576: done, saving took 1.11 seconds
2022-07-01 00:39:36.275877: This epoch took 364.947893 s

2022-07-01 00:39:36.278843: 
epoch:  451
2022-07-01 00:45:04.846566: train loss : -0.3467
2022-07-01 00:45:23.382240: validation loss: -0.3932
2022-07-01 00:45:23.386792: Average global foreground Dice: [0.9342, 0.899, 0.8478, 0.7812, 0.743, 0.96, 0.879, 0.9248, 0.8725, 0.8125, 0.6949, 0.7153, 0.6794, 0.9214, 0.8259]
2022-07-01 00:45:23.389444: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 00:45:23.842511: Suus1 maybe_update_lr lr: 0.001214
2022-07-01 00:45:23.845070: This epoch took 347.563642 s

2022-07-01 00:45:23.847274: 
epoch:  452
2022-07-01 00:50:52.118526: train loss : -0.3674
2022-07-01 00:51:10.618880: validation loss: -0.3763
2022-07-01 00:51:10.623072: Average global foreground Dice: [0.915, 0.9245, 0.9286, 0.8085, 0.7276, 0.9507, 0.85, 0.927, 0.8655, 0.8447, 0.7655, 0.7411, 0.7168, 0.9062, 0.7881]
2022-07-01 00:51:10.625597: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 00:51:11.082722: Suus1 maybe_update_lr lr: 0.001191
2022-07-01 00:51:11.085101: This epoch took 347.235758 s

2022-07-01 00:51:11.087500: 
epoch:  453
2022-07-01 00:56:39.106488: train loss : -0.3515
2022-07-01 00:56:57.614677: validation loss: -0.3953
2022-07-01 00:56:57.619970: Average global foreground Dice: [0.9497, 0.9494, 0.8938, 0.7823, 0.6955, 0.9605, 0.8743, 0.9287, 0.8584, 0.8331, 0.7339, 0.7246, 0.725, 0.8664, 0.8349]
2022-07-01 00:56:57.622505: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 00:56:58.109181: Suus1 maybe_update_lr lr: 0.001168
2022-07-01 00:56:58.111443: This epoch took 347.021839 s

2022-07-01 00:56:58.113468: 
epoch:  454
2022-07-01 01:02:26.081927: train loss : -0.3386
2022-07-01 01:02:44.626072: validation loss: -0.3309
2022-07-01 01:02:44.630787: Average global foreground Dice: [0.918, 0.9147, 0.7425, 0.8453, 0.6429, 0.9392, 0.8498, 0.9274, 0.8527, 0.7727, 0.7265, 0.6435, 0.6204, 0.9363, 0.7134]
2022-07-01 01:02:44.632922: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 01:02:45.091017: Suus1 maybe_update_lr lr: 0.001145
2022-07-01 01:02:45.093485: This epoch took 346.977414 s

2022-07-01 01:02:45.095738: 
epoch:  455
2022-07-01 01:08:13.114417: train loss : -0.3512
2022-07-01 01:08:31.821941: validation loss: -0.3707
2022-07-01 01:08:31.826399: Average global foreground Dice: [0.9161, 0.9349, 0.8381, 0.7954, 0.7357, 0.953, 0.8318, 0.9363, 0.89, 0.8305, 0.7263, 0.7368, 0.6927, 0.9014, 0.9181]
2022-07-01 01:08:31.828687: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 01:08:32.280624: Suus1 maybe_update_lr lr: 0.001122
2022-07-01 01:08:32.283516: This epoch took 347.185573 s

2022-07-01 01:08:32.285992: 
epoch:  456
2022-07-01 01:14:00.236586: train loss : -0.3536
2022-07-01 01:14:18.757163: validation loss: -0.4045
2022-07-01 01:14:18.761714: Average global foreground Dice: [0.9634, 0.9338, 0.9423, 0.7633, 0.7694, 0.9574, 0.8565, 0.9323, 0.8536, 0.8426, 0.7184, 0.7213, 0.7071, 0.8793, 0.8489]
2022-07-01 01:14:18.763972: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 01:14:19.282013: Suus1 maybe_update_lr lr: 0.001099
2022-07-01 01:14:19.284883: This epoch took 346.996290 s

2022-07-01 01:14:19.287145: 
epoch:  457
2022-07-01 01:19:47.507340: train loss : -0.3547
2022-07-01 01:20:06.037303: validation loss: -0.4174
2022-07-01 01:20:06.041225: Average global foreground Dice: [0.9493, 0.9407, 0.9481, 0.8698, 0.7296, 0.9683, 0.884, 0.9282, 0.8394, 0.8464, 0.7673, 0.7401, 0.7443, 0.9114, 0.7987]
2022-07-01 01:20:06.043443: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 01:20:06.505022: Suus1 maybe_update_lr lr: 0.001076
2022-07-01 01:20:06.507404: This epoch took 347.218218 s

2022-07-01 01:20:06.509422: 
epoch:  458
2022-07-01 01:25:35.066808: train loss : -0.3579
2022-07-01 01:25:53.587441: validation loss: -0.4150
2022-07-01 01:25:53.604227: Average global foreground Dice: [0.9364, 0.9519, 0.8971, 0.821, 0.7647, 0.9648, 0.9044, 0.9335, 0.8722, 0.8199, 0.736, 0.6711, 0.7428, 0.8859, 0.8713]
2022-07-01 01:25:53.620575: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 01:25:54.121122: Suus1 maybe_update_lr lr: 0.001053
2022-07-01 01:25:54.136891: saving best epoch checkpoint...
2022-07-01 01:25:54.235865: saving checkpoint...
2022-07-01 01:25:55.894559: done, saving took 1.74 seconds
2022-07-01 01:25:55.960048: This epoch took 349.448600 s

2022-07-01 01:25:55.973372: 
epoch:  459
2022-07-01 01:31:23.936181: train loss : -0.3494
2022-07-01 01:31:42.422167: validation loss: -0.3752
2022-07-01 01:31:42.427984: Average global foreground Dice: [0.9492, 0.9452, 0.9427, 0.8675, 0.7066, 0.9672, 0.8595, 0.9351, 0.872, 0.8484, 0.7583, 0.7375, 0.7561, 0.9144, 0.7753]
2022-07-01 01:31:42.430333: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 01:31:42.978977: Suus1 maybe_update_lr lr: 0.00103
2022-07-01 01:31:42.981558: saving best epoch checkpoint...
2022-07-01 01:31:43.062592: saving checkpoint...
2022-07-01 01:31:44.055278: done, saving took 1.07 seconds
2022-07-01 01:31:44.070043: This epoch took 348.085650 s

2022-07-01 01:31:44.072459: 
epoch:  460
2022-07-01 01:37:12.225690: train loss : -0.3672
2022-07-01 01:37:30.831838: validation loss: -0.4395
2022-07-01 01:37:30.836515: Average global foreground Dice: [0.9629, 0.9121, 0.9307, 0.8087, 0.703, 0.9593, 0.8808, 0.9405, 0.8632, 0.8281, 0.7277, 0.7359, 0.6902, 0.9556, 0.8252]
2022-07-01 01:37:30.839004: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 01:37:31.331207: Suus1 maybe_update_lr lr: 0.001007
2022-07-01 01:37:31.333784: saving best epoch checkpoint...
2022-07-01 01:37:31.424294: saving checkpoint...
2022-07-01 01:37:32.460351: done, saving took 1.12 seconds
2022-07-01 01:37:32.502641: This epoch took 348.428028 s

2022-07-01 01:37:32.504806: 
epoch:  461
2022-07-01 01:43:00.586321: train loss : -0.3566
2022-07-01 01:43:19.099783: validation loss: -0.4179
2022-07-01 01:43:19.104261: Average global foreground Dice: [0.9465, 0.9149, 0.9211, 0.8197, 0.7468, 0.9475, 0.9108, 0.9325, 0.8564, 0.8303, 0.7472, 0.7332, 0.6914, 0.9133, 0.8351]
2022-07-01 01:43:19.106725: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 01:43:19.568224: Suus1 maybe_update_lr lr: 0.000983
2022-07-01 01:43:19.570875: saving best epoch checkpoint...
2022-07-01 01:43:19.650059: saving checkpoint...
2022-07-01 01:43:20.707629: done, saving took 1.13 seconds
2022-07-01 01:43:20.729059: This epoch took 348.222203 s

2022-07-01 01:43:20.731179: 
epoch:  462
2022-07-01 01:48:48.829659: train loss : -0.3698
2022-07-01 01:49:07.406631: validation loss: -0.4455
2022-07-01 01:49:07.412026: Average global foreground Dice: [0.9415, 0.9424, 0.9396, 0.8446, 0.7519, 0.9612, 0.8885, 0.9223, 0.8824, 0.841, 0.7257, 0.7403, 0.7089, 0.9082, 0.81]
2022-07-01 01:49:07.414322: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 01:49:08.027312: Suus1 maybe_update_lr lr: 0.00096
2022-07-01 01:49:08.029923: saving best epoch checkpoint...
2022-07-01 01:49:08.079801: saving checkpoint...
2022-07-01 01:49:09.105016: done, saving took 1.07 seconds
2022-07-01 01:49:09.119503: This epoch took 348.386224 s

2022-07-01 01:49:09.121629: 
epoch:  463
2022-07-01 01:54:37.300549: train loss : -0.3590
2022-07-01 01:54:55.802978: validation loss: -0.3926
2022-07-01 01:54:55.807165: Average global foreground Dice: [0.9666, 0.9122, 0.9467, 0.8751, 0.7468, 0.9632, 0.9045, 0.9318, 0.8755, 0.8802, 0.7692, 0.781, 0.7567, 0.9308, 0.8449]
2022-07-01 01:54:55.809434: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 01:54:56.275873: Suus1 maybe_update_lr lr: 0.000937
2022-07-01 01:54:56.278419: saving best epoch checkpoint...
2022-07-01 01:54:56.325543: saving checkpoint...
2022-07-01 01:54:57.334505: done, saving took 1.05 seconds
2022-07-01 01:54:57.348558: This epoch took 348.224839 s

2022-07-01 01:54:57.350680: 
epoch:  464
2022-07-01 02:00:25.336007: train loss : -0.3359
2022-07-01 02:00:43.848168: validation loss: -0.3955
2022-07-01 02:00:43.852128: Average global foreground Dice: [0.9476, 0.9347, 0.7993, 0.8523, 0.6723, 0.9499, 0.8856, 0.9307, 0.8848, 0.8492, 0.7526, 0.704, 0.7635, 0.9187, 0.7854]
2022-07-01 02:00:43.854392: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 02:00:44.315442: Suus1 maybe_update_lr lr: 0.000913
2022-07-01 02:00:44.318010: This epoch took 346.965281 s

2022-07-01 02:00:44.320047: 
epoch:  465
2022-07-01 02:06:12.584324: train loss : -0.3541
2022-07-01 02:06:31.088800: validation loss: -0.4224
2022-07-01 02:06:31.121030: Average global foreground Dice: [0.9508, 0.9344, 0.9437, 0.7839, 0.7267, 0.9616, 0.8942, 0.9362, 0.876, 0.8423, 0.6929, 0.7377, 0.734, 0.9299, 0.9003]
2022-07-01 02:06:31.146336: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 02:06:31.733464: Suus1 maybe_update_lr lr: 0.00089
2022-07-01 02:06:31.742935: saving best epoch checkpoint...
2022-07-01 02:06:31.799896: saving checkpoint...
2022-07-01 02:06:33.438362: done, saving took 1.69 seconds
2022-07-01 02:06:33.479276: This epoch took 349.157291 s

2022-07-01 02:06:33.493439: 
epoch:  466
2022-07-01 02:12:01.795029: train loss : -0.3687
2022-07-01 02:12:20.309331: validation loss: -0.3752
2022-07-01 02:12:20.313852: Average global foreground Dice: [0.9498, 0.9403, 0.8079, 0.8074, 0.6587, 0.9569, 0.8486, 0.9338, 0.8895, 0.8201, 0.7409, 0.6887, 0.7285, 0.8737, 0.6613]
2022-07-01 02:12:20.316389: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 02:12:20.792841: Suus1 maybe_update_lr lr: 0.000866
2022-07-01 02:12:20.795482: This epoch took 347.287682 s

2022-07-01 02:12:20.797566: 
epoch:  467
2022-07-01 02:17:49.251654: train loss : -0.3506
2022-07-01 02:18:07.777184: validation loss: -0.3369
2022-07-01 02:18:07.781359: Average global foreground Dice: [0.9516, 0.9201, 0.9148, 0.8232, 0.6532, 0.9459, 0.8423, 0.9268, 0.8511, 0.8077, 0.7091, 0.7196, 0.6251, 0.8873, 0.7739]
2022-07-01 02:18:07.783868: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 02:18:08.235394: Suus1 maybe_update_lr lr: 0.000842
2022-07-01 02:18:08.238352: This epoch took 347.438848 s

2022-07-01 02:18:08.240851: 
epoch:  468
2022-07-01 02:23:36.545349: train loss : -0.3772
2022-07-01 02:23:55.056417: validation loss: -0.4371
2022-07-01 02:23:55.060562: Average global foreground Dice: [0.953, 0.9403, 0.9503, 0.7921, 0.7812, 0.9557, 0.8892, 0.9371, 0.8669, 0.8454, 0.7287, 0.7675, 0.6705, 0.8577, 0.83]
2022-07-01 02:23:55.062910: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 02:23:55.520030: Suus1 maybe_update_lr lr: 0.000819
2022-07-01 02:23:55.522339: This epoch took 347.279026 s

2022-07-01 02:23:55.524353: 
epoch:  469
2022-07-01 02:29:23.956945: train loss : -0.3586
2022-07-01 02:29:42.469635: validation loss: -0.4025
2022-07-01 02:29:42.473861: Average global foreground Dice: [0.9435, 0.924, 0.9248, 0.8285, 0.7392, 0.9591, 0.8876, 0.9306, 0.8782, 0.8211, 0.7548, 0.771, 0.7484, 0.8819, 0.8076]
2022-07-01 02:29:42.476084: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 02:29:42.928801: Suus1 maybe_update_lr lr: 0.000795
2022-07-01 02:29:42.933212: This epoch took 347.406931 s

2022-07-01 02:29:42.935656: 
epoch:  470
2022-07-01 02:35:11.557381: train loss : -0.3612
2022-07-01 02:35:30.075762: validation loss: -0.3571
2022-07-01 02:35:30.080255: Average global foreground Dice: [0.943, 0.9348, 0.7574, 0.8302, 0.7493, 0.9481, 0.8956, 0.9185, 0.8625, 0.859, 0.729, 0.7321, 0.728, 0.8179, 0.7865]
2022-07-01 02:35:30.082526: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 02:35:30.541701: Suus1 maybe_update_lr lr: 0.000771
2022-07-01 02:35:30.544101: This epoch took 347.606064 s

2022-07-01 02:35:30.546110: 
epoch:  471
2022-07-01 02:40:59.024233: train loss : -0.3691
2022-07-01 02:41:17.540637: validation loss: -0.4296
2022-07-01 02:41:17.563203: Average global foreground Dice: [0.9445, 0.9178, 0.9181, 0.8138, 0.7463, 0.9589, 0.8719, 0.9384, 0.8745, 0.8326, 0.7353, 0.732, 0.7083, 0.9547, 0.8338]
2022-07-01 02:41:17.581446: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 02:41:18.077187: Suus1 maybe_update_lr lr: 0.000747
2022-07-01 02:41:18.086613: This epoch took 347.538056 s

2022-07-01 02:41:18.099760: 
epoch:  472
2022-07-01 02:46:46.549604: train loss : -0.3632
2022-07-01 02:47:05.076924: validation loss: -0.4005
2022-07-01 02:47:05.080871: Average global foreground Dice: [0.9441, 0.9436, 0.8998, 0.7594, 0.7105, 0.9474, 0.842, 0.936, 0.8472, 0.8495, 0.7405, 0.7457, 0.6836, 0.9232, 0.8532]
2022-07-01 02:47:05.083145: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 02:47:05.546055: Suus1 maybe_update_lr lr: 0.000723
2022-07-01 02:47:05.548423: This epoch took 347.434513 s

2022-07-01 02:47:05.550438: 
epoch:  473
2022-07-01 02:52:33.969322: train loss : -0.3683
2022-07-01 02:52:52.482348: validation loss: -0.4258
2022-07-01 02:52:52.487626: Average global foreground Dice: [0.9419, 0.9171, 0.9224, 0.8678, 0.7726, 0.9623, 0.8902, 0.9412, 0.8703, 0.8558, 0.7573, 0.7481, 0.7595, 0.9269, 0.8392]
2022-07-01 02:52:52.490041: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 02:52:52.938317: Suus1 maybe_update_lr lr: 0.000699
2022-07-01 02:52:52.941166: This epoch took 347.387532 s

2022-07-01 02:52:52.943529: 
epoch:  474
2022-07-01 02:58:21.230130: train loss : -0.3576
2022-07-01 02:58:39.770790: validation loss: -0.4308
2022-07-01 02:58:39.774531: Average global foreground Dice: [0.9322, 0.9226, 0.9067, 0.8246, 0.747, 0.9642, 0.877, 0.9435, 0.8779, 0.8407, 0.7324, 0.7675, 0.7272, 0.8981, 0.8277]
2022-07-01 02:58:39.776721: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 02:58:40.235923: Suus1 maybe_update_lr lr: 0.000675
2022-07-01 02:58:40.238235: This epoch took 347.292413 s

2022-07-01 02:58:40.240362: 
epoch:  475
2022-07-01 03:04:08.955550: train loss : -0.3720
2022-07-01 03:04:27.503184: validation loss: -0.4149
2022-07-01 03:04:27.507319: Average global foreground Dice: [0.9604, 0.9205, 0.9568, 0.8203, 0.758, 0.9685, 0.8936, 0.9383, 0.8954, 0.8452, 0.711, 0.7731, 0.7781, 0.9037, 0.8126]
2022-07-01 03:04:27.509758: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 03:04:27.958437: Suus1 maybe_update_lr lr: 0.00065
2022-07-01 03:04:27.960755: saving best epoch checkpoint...
2022-07-01 03:04:28.036701: saving checkpoint...
2022-07-01 03:04:29.057279: done, saving took 1.09 seconds
2022-07-01 03:04:29.079845: This epoch took 348.837320 s

2022-07-01 03:04:29.082165: 
epoch:  476
2022-07-01 03:09:57.386549: train loss : -0.3941
2022-07-01 03:10:15.938703: validation loss: -0.3888
2022-07-01 03:10:15.942983: Average global foreground Dice: [0.9262, 0.944, 0.9301, 0.8125, 0.7178, 0.9574, 0.8369, 0.9281, 0.8634, 0.8197, 0.7332, 0.7231, 0.7388, 0.8031, 0.8411]
2022-07-01 03:10:15.945520: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 03:10:16.392875: Suus1 maybe_update_lr lr: 0.000626
2022-07-01 03:10:16.395182: This epoch took 347.310814 s

2022-07-01 03:10:16.397398: 
epoch:  477
2022-07-01 03:15:44.615407: train loss : -0.3760
2022-07-01 03:16:03.142927: validation loss: -0.4122
2022-07-01 03:16:03.147062: Average global foreground Dice: [0.9519, 0.9168, 0.9313, 0.893, 0.7706, 0.969, 0.9252, 0.9407, 0.8771, 0.8415, 0.765, 0.7401, 0.751, 0.8987, 0.8443]
2022-07-01 03:16:03.149391: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 03:16:03.607160: Suus1 maybe_update_lr lr: 0.000601
2022-07-01 03:16:03.609504: saving best epoch checkpoint...
2022-07-01 03:16:03.690780: saving checkpoint...
2022-07-01 03:16:04.676562: done, saving took 1.06 seconds
2022-07-01 03:16:04.697341: This epoch took 348.297806 s

2022-07-01 03:16:04.699775: 
epoch:  478
2022-07-01 03:21:32.863668: train loss : -0.3716
2022-07-01 03:21:51.405078: validation loss: -0.4565
2022-07-01 03:21:51.408952: Average global foreground Dice: [0.9655, 0.9442, 0.9395, 0.8037, 0.778, 0.9662, 0.9067, 0.94, 0.8775, 0.8571, 0.7094, 0.7684, 0.7399, 0.9304, 0.8746]
2022-07-01 03:21:51.411418: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 03:21:51.865615: Suus1 maybe_update_lr lr: 0.000577
2022-07-01 03:21:51.868033: saving best epoch checkpoint...
2022-07-01 03:21:51.942815: saving checkpoint...
2022-07-01 03:21:52.958032: done, saving took 1.09 seconds
2022-07-01 03:21:52.979169: This epoch took 348.277209 s

2022-07-01 03:21:52.981439: 
epoch:  479
2022-07-01 03:27:21.307684: train loss : -0.3674
2022-07-01 03:27:39.810403: validation loss: -0.4287
2022-07-01 03:27:39.814425: Average global foreground Dice: [0.9529, 0.9279, 0.9526, 0.7486, 0.7732, 0.9638, 0.916, 0.9274, 0.8835, 0.8545, 0.7526, 0.7158, 0.7207, 0.9171, 0.8219]
2022-07-01 03:27:39.816674: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 03:27:40.397704: Suus1 maybe_update_lr lr: 0.000552
2022-07-01 03:27:40.400179: saving best epoch checkpoint...
2022-07-01 03:27:40.448171: saving checkpoint...
2022-07-01 03:27:41.492195: done, saving took 1.09 seconds
2022-07-01 03:27:41.506550: This epoch took 348.522938 s

2022-07-01 03:27:41.508698: 
epoch:  480
2022-07-01 03:33:09.915630: train loss : -0.3289
2022-07-01 03:33:28.786366: validation loss: -0.3578
2022-07-01 03:33:28.790931: Average global foreground Dice: [0.9563, 0.9403, 0.8916, 0.8611, 0.7415, 0.9556, 0.825, 0.9387, 0.8726, 0.8703, 0.7329, 0.7241, 0.7517, 0.8405, 0.7249]
2022-07-01 03:33:28.793301: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 03:33:29.250711: Suus1 maybe_update_lr lr: 0.000527
2022-07-01 03:33:29.253248: This epoch took 347.742292 s

2022-07-01 03:33:29.255507: 
epoch:  481
2022-07-01 03:38:57.493633: train loss : -0.3630
2022-07-01 03:39:17.088945: validation loss: -0.3941
2022-07-01 03:39:17.094480: Average global foreground Dice: [0.8875, 0.9143, 0.9159, 0.8724, 0.7081, 0.9369, 0.8519, 0.9396, 0.876, 0.8426, 0.7585, 0.7364, 0.7156, 0.8866, 0.8564]
2022-07-01 03:39:17.097560: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 03:39:17.567624: Suus1 maybe_update_lr lr: 0.000502
2022-07-01 03:39:17.570876: This epoch took 348.313085 s

2022-07-01 03:39:17.573460: 
epoch:  482
2022-07-01 03:44:45.706023: train loss : -0.3677
2022-07-01 03:45:04.205680: validation loss: -0.3831
2022-07-01 03:45:04.210119: Average global foreground Dice: [0.9387, 0.9271, 0.9322, 0.8372, 0.7672, 0.9606, 0.8731, 0.9362, 0.8566, 0.8083, 0.7036, 0.6951, 0.6914, 0.9, 0.7596]
2022-07-01 03:45:04.212468: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 03:45:04.666328: Suus1 maybe_update_lr lr: 0.000477
2022-07-01 03:45:04.669221: This epoch took 347.093160 s

2022-07-01 03:45:04.671607: 
epoch:  483
2022-07-01 03:50:32.422311: train loss : -0.3727
2022-07-01 03:50:50.929833: validation loss: -0.4273
2022-07-01 03:50:50.933750: Average global foreground Dice: [0.9558, 0.9472, 0.9044, 0.8473, 0.7427, 0.9592, 0.8717, 0.934, 0.8705, 0.8435, 0.7131, 0.7214, 0.7207, 0.9397, 0.8676]
2022-07-01 03:50:50.935862: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 03:50:51.424770: Suus1 maybe_update_lr lr: 0.000451
2022-07-01 03:50:51.427006: This epoch took 346.753078 s

2022-07-01 03:50:51.429003: 
epoch:  484
2022-07-01 03:56:19.509361: train loss : -0.3714
2022-07-01 03:56:38.042228: validation loss: -0.3836
2022-07-01 03:56:38.045966: Average global foreground Dice: [0.9464, 0.937, 0.8021, 0.8711, 0.7164, 0.9622, 0.8435, 0.9136, 0.87, 0.8201, 0.7412, 0.6892, 0.7366, 0.919, 0.8586]
2022-07-01 03:56:38.048281: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 03:56:38.505795: Suus1 maybe_update_lr lr: 0.000426
2022-07-01 03:56:38.508065: This epoch took 347.077085 s

2022-07-01 03:56:38.510123: 
epoch:  485
2022-07-01 04:02:06.560494: train loss : -0.3794
2022-07-01 04:02:25.048839: validation loss: -0.4218
2022-07-01 04:02:25.052750: Average global foreground Dice: [0.9419, 0.9178, 0.8419, 0.8318, 0.7468, 0.9631, 0.8824, 0.9322, 0.8703, 0.8248, 0.75, 0.7622, 0.7453, 0.9441, 0.9189]
2022-07-01 04:02:25.055139: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 04:02:25.562125: Suus1 maybe_update_lr lr: 0.0004
2022-07-01 04:02:25.564664: This epoch took 347.052350 s

2022-07-01 04:02:25.566741: 
epoch:  486
2022-07-01 04:07:53.771523: train loss : -0.3724
2022-07-01 04:08:12.263648: validation loss: -0.3896
2022-07-01 04:08:12.267805: Average global foreground Dice: [0.9368, 0.9396, 0.7695, 0.8003, 0.7346, 0.9413, 0.8963, 0.9299, 0.8849, 0.8246, 0.7414, 0.7239, 0.75, 0.8996, 0.8376]
2022-07-01 04:08:12.270014: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 04:08:12.730175: Suus1 maybe_update_lr lr: 0.000375
2022-07-01 04:08:12.732640: This epoch took 347.163810 s

2022-07-01 04:08:12.734842: 
epoch:  487
2022-07-01 04:13:40.752803: train loss : -0.3837
2022-07-01 04:13:59.334621: validation loss: -0.4020
2022-07-01 04:13:59.338649: Average global foreground Dice: [0.9442, 0.9443, 0.883, 0.8192, 0.7661, 0.9699, 0.8895, 0.9367, 0.8954, 0.8261, 0.7688, 0.7464, 0.7264, 0.8987, 0.8962]
2022-07-01 04:13:59.341112: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 04:13:59.835716: Suus1 maybe_update_lr lr: 0.000348
2022-07-01 04:13:59.838043: This epoch took 347.100855 s

2022-07-01 04:13:59.840354: 
epoch:  488
2022-07-01 04:19:27.675676: train loss : -0.3676
2022-07-01 04:19:46.193733: validation loss: -0.3805
2022-07-01 04:19:46.197671: Average global foreground Dice: [0.9576, 0.9538, 0.9396, 0.829, 0.7637, 0.967, 0.8995, 0.9249, 0.888, 0.838, 0.7542, 0.7292, 0.7318, 0.8762, 0.785]
2022-07-01 04:19:46.200108: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 04:19:46.675328: Suus1 maybe_update_lr lr: 0.000322
2022-07-01 04:19:46.677771: This epoch took 346.835234 s

2022-07-01 04:19:46.679850: 
epoch:  489
2022-07-01 04:25:14.934568: train loss : -0.3563
2022-07-01 04:25:33.612916: validation loss: -0.4498
2022-07-01 04:25:33.617311: Average global foreground Dice: [0.9541, 0.9486, 0.9477, 0.8127, 0.7946, 0.9655, 0.9001, 0.9226, 0.8798, 0.8478, 0.7755, 0.7493, 0.7267, 0.9342, 0.8681]
2022-07-01 04:25:33.619660: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 04:25:34.126921: Suus1 maybe_update_lr lr: 0.000296
2022-07-01 04:25:34.129792: saving best epoch checkpoint...
2022-07-01 04:25:34.179142: saving checkpoint...
2022-07-01 04:25:35.189701: done, saving took 1.06 seconds
2022-07-01 04:25:35.205262: This epoch took 348.523287 s

2022-07-01 04:25:35.207545: 
epoch:  490
2022-07-01 04:31:03.350173: train loss : -0.3607
2022-07-01 04:31:21.860174: validation loss: -0.4174
2022-07-01 04:31:21.864312: Average global foreground Dice: [0.9671, 0.9211, 0.9003, 0.7704, 0.8121, 0.9649, 0.9106, 0.9298, 0.863, 0.833, 0.7422, 0.7499, 0.7083, 0.8466, 0.7827]
2022-07-01 04:31:21.866929: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 04:31:22.325528: Suus1 maybe_update_lr lr: 0.000269
2022-07-01 04:31:22.328270: This epoch took 347.118465 s

2022-07-01 04:31:22.330620: 
epoch:  491
2022-07-01 04:36:50.550754: train loss : -0.3862
2022-07-01 04:37:09.062593: validation loss: -0.4034
2022-07-01 04:37:09.068616: Average global foreground Dice: [0.9272, 0.9239, 0.9412, 0.8599, 0.7738, 0.964, 0.8971, 0.9274, 0.8556, 0.8234, 0.7366, 0.7525, 0.7333, 0.9394, 0.8395]
2022-07-01 04:37:09.071070: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 04:37:09.526599: Suus1 maybe_update_lr lr: 0.000242
2022-07-01 04:37:09.529467: saving best epoch checkpoint...
2022-07-01 04:37:09.583506: saving checkpoint...
2022-07-01 04:37:10.599509: done, saving took 1.07 seconds
2022-07-01 04:37:10.614929: This epoch took 348.281937 s

2022-07-01 04:37:10.617265: 
epoch:  492
2022-07-01 04:42:39.068191: train loss : -0.3634
2022-07-01 04:42:57.584266: validation loss: -0.3588
2022-07-01 04:42:57.589358: Average global foreground Dice: [0.9503, 0.9057, 0.8356, 0.8631, 0.7986, 0.9527, 0.8789, 0.9394, 0.8786, 0.8331, 0.7538, 0.7566, 0.7014, 0.909, 0.8846]
2022-07-01 04:42:57.591637: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 04:42:58.055494: Suus1 maybe_update_lr lr: 0.000215
2022-07-01 04:42:58.057836: saving best epoch checkpoint...
2022-07-01 04:42:58.110275: saving checkpoint...
2022-07-01 04:42:59.102570: done, saving took 1.04 seconds
2022-07-01 04:42:59.121336: This epoch took 348.501885 s

2022-07-01 04:42:59.123490: 
epoch:  493
2022-07-01 04:48:27.507361: train loss : -0.3642
2022-07-01 04:48:46.071830: validation loss: -0.4665
2022-07-01 04:48:46.075687: Average global foreground Dice: [0.9495, 0.9476, 0.9498, 0.7894, 0.7365, 0.9661, 0.9096, 0.94, 0.8881, 0.8582, 0.7457, 0.7314, 0.7725, 0.8972, 0.8906]
2022-07-01 04:48:46.078000: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 04:48:46.530888: Suus1 maybe_update_lr lr: 0.000187
2022-07-01 04:48:46.533408: saving best epoch checkpoint...
2022-07-01 04:48:46.609648: saving checkpoint...
2022-07-01 04:48:47.621088: done, saving took 1.09 seconds
2022-07-01 04:48:47.642139: This epoch took 348.516500 s

2022-07-01 04:48:47.644443: 
epoch:  494
2022-07-01 04:54:16.240582: train loss : -0.3665
2022-07-01 04:54:34.766191: validation loss: -0.4418
2022-07-01 04:54:34.770340: Average global foreground Dice: [0.9499, 0.9542, 0.9212, 0.8641, 0.7632, 0.971, 0.914, 0.9437, 0.8903, 0.8507, 0.7611, 0.7646, 0.7882, 0.9068, 0.8757]
2022-07-01 04:54:34.772703: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 04:54:35.224274: Suus1 maybe_update_lr lr: 0.000158
2022-07-01 04:54:35.226627: saving best epoch checkpoint...
2022-07-01 04:54:35.306999: saving checkpoint...
2022-07-01 04:54:36.292929: done, saving took 1.06 seconds
2022-07-01 04:54:36.315677: This epoch took 348.669152 s

2022-07-01 04:54:36.318231: 
epoch:  495
2022-07-01 05:00:04.914895: train loss : -0.3831
2022-07-01 05:00:23.684501: validation loss: -0.4403
2022-07-01 05:00:23.689041: Average global foreground Dice: [0.9487, 0.9393, 0.9347, 0.819, 0.7565, 0.9646, 0.9168, 0.9205, 0.8643, 0.8462, 0.7387, 0.6989, 0.6997, 0.9269, 0.8691]
2022-07-01 05:00:23.691745: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 05:00:24.153602: Suus1 maybe_update_lr lr: 0.00013
2022-07-01 05:00:24.156579: saving best epoch checkpoint...
2022-07-01 05:00:24.237625: saving checkpoint...
2022-07-01 05:00:25.494034: done, saving took 1.33 seconds
2022-07-01 05:00:25.509420: This epoch took 349.188962 s

2022-07-01 05:00:25.511769: 
epoch:  496
2022-07-01 05:05:54.266835: train loss : -0.3564
2022-07-01 05:06:12.790399: validation loss: -0.3863
2022-07-01 05:06:12.794985: Average global foreground Dice: [0.937, 0.9458, 0.8433, 0.7748, 0.7231, 0.9599, 0.8359, 0.9326, 0.8627, 0.821, 0.7325, 0.7236, 0.6636, 0.8002, 0.7819]
2022-07-01 05:06:12.797420: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 05:06:13.380312: Suus1 maybe_update_lr lr: 0.0001
2022-07-01 05:06:13.382833: This epoch took 347.868796 s

2022-07-01 05:06:13.384985: 
epoch:  497
2022-07-01 05:11:42.122448: train loss : -0.3788
2022-07-01 05:12:00.788082: validation loss: -0.4122
2022-07-01 05:12:00.792712: Average global foreground Dice: [0.9465, 0.9361, 0.9293, 0.8663, 0.7847, 0.9439, 0.8732, 0.9406, 0.8821, 0.8562, 0.7618, 0.7526, 0.7395, 0.911, 0.8603]
2022-07-01 05:12:00.795382: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 05:12:01.250549: Suus1 maybe_update_lr lr: 6.9e-05
2022-07-01 05:12:01.252991: This epoch took 347.865826 s

2022-07-01 05:12:01.255200: 
epoch:  498
2022-07-01 05:17:30.092438: train loss : -0.3885
2022-07-01 05:17:52.791343: validation loss: -0.4180
2022-07-01 05:17:52.796288: Average global foreground Dice: [0.9588, 0.9396, 0.9542, 0.7815, 0.7106, 0.9645, 0.8831, 0.9251, 0.8854, 0.8691, 0.762, 0.7722, 0.7426, 0.9038, 0.6144]
2022-07-01 05:17:52.799545: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 05:17:53.297060: Suus1 maybe_update_lr lr: 3.7e-05
2022-07-01 05:17:53.299672: This epoch took 352.042300 s

2022-07-01 05:17:53.301983: 
epoch:  499
2022-07-01 05:23:21.940069: train loss : -0.3768
2022-07-01 05:23:40.473803: validation loss: -0.4348
2022-07-01 05:23:40.478281: Average global foreground Dice: [0.9474, 0.9473, 0.9418, 0.8262, 0.744, 0.9597, 0.9246, 0.9278, 0.8732, 0.8281, 0.7111, 0.7877, 0.7399, 0.9417, 0.8627]
2022-07-01 05:23:40.480763: (interpret this as an estimate for the Dice of the different classes. This is not exact.)
2022-07-01 05:23:40.940358: Suus1 maybe_update_lr lr: 0.0
2022-07-01 05:23:40.942903: saving scheduled checkpoint file...
2022-07-01 05:23:40.991129: saving checkpoint...
2022-07-01 05:23:41.952579: done, saving took 1.01 seconds
2022-07-01 05:23:41.995040: done
2022-07-01 05:23:41.997896: This epoch took 348.693638 s

2022-07-01 05:23:42.027498: saving checkpoint...
2022-07-01 05:23:42.984140: done, saving took 0.98 seconds
