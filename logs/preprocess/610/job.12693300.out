Starting at Tue Oct 25 15:55:32 CEST 2022
Running on hosts: res-hpc-lkeb06
Running on 1 nodes.
Running 1 tasks.
CPUs on node: 6.
Account: div2-lkeb
Job ID: 12693300
Job name: PancreasPreprocess
Node running script: res-hpc-lkeb06
Submit host: res-hpc-lo02.researchlumc.nl
GPUS: 0 or 
Fri Oct 28 15:35:09 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     Off  | 00000000:3B:00.0 Off |                  Off |
| 31%   33C    P0    65W / 260W |      0MiB / 24220MiB |      3%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Current working directory is /home/smaijer
Load all modules..
Done with loading all modules. Modules:
Activate conda env nnunet..
Verifying environment variables:
Installing hidden layer and nnUnet..
Collecting hiddenlayer
  Cloning https://github.com/FabianIsensee/hiddenlayer.git (to revision more_plotted_details) to /tmp/pip-install-j90b35_0/hiddenlayer_2947a1ae423f411c8346ad8a65ffc5b8
  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit 4b98f9e5cccebac67368f02b95f4700b522345b1
Using legacy 'setup.py install' for hiddenlayer, since package 'wheel' is not installed.
Installing collected packages: hiddenlayer
    Running setup.py install for hiddenlayer: started
    Running setup.py install for hiddenlayer: finished with status 'done'
Successfully installed hiddenlayer-0.2
Obtaining file:///home/smaijer/code/nnUNet
Collecting torch==1.12.0
  Using cached torch-1.12.0-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)
Collecting tqdm
  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)
Collecting dicom2nifti
  Using cached dicom2nifti-2.4.5-py3-none-any.whl (43 kB)
Collecting scikit-image>=0.14
  Using cached scikit_image-0.19.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)
Collecting medpy
  Using cached MedPy-0.4.0.tar.gz (151 kB)
Collecting scipy
  Using cached scipy-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.7 MB)
Collecting batchgenerators>=0.23
  Using cached batchgenerators-0.24.tar.gz (61 kB)
Collecting numpy
  Using cached numpy-1.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)
Collecting sklearn
  Using cached sklearn-0.0.tar.gz (1.1 kB)
Collecting SimpleITK
  Using cached SimpleITK-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.8 MB)
Collecting pandas
  Using cached pandas-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)
Collecting requests
  Using cached requests-2.28.1-py3-none-any.whl (62 kB)
Collecting nibabel
  Using cached nibabel-4.0.2-py3-none-any.whl (3.3 MB)
Collecting tifffile
  Using cached tifffile-2022.10.10-py3-none-any.whl (210 kB)
Collecting matplotlib
  Using cached matplotlib-3.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)
Collecting monai
  Using cached monai-1.0.1-202210241233-py3-none-any.whl (1.1 MB)
Collecting einops
  Using cached einops-0.5.0-py3-none-any.whl (36 kB)
Collecting ipython
  Using cached ipython-8.5.0-py3-none-any.whl (752 kB)
Collecting graphviz
  Using cached graphviz-0.20.1-py3-none-any.whl (47 kB)
Collecting typing-extensions
  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)
Collecting pillow>=7.1.2
  Using cached Pillow-9.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.2 MB)
Collecting scikit-learn
  Using cached scikit_learn-1.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)
Collecting future
  Using cached future-0.18.2.tar.gz (829 kB)
Collecting unittest2
  Using cached unittest2-1.1.0-py2.py3-none-any.whl (96 kB)
Collecting threadpoolctl
  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)
Collecting imageio>=2.4.1
  Using cached imageio-2.22.2-py3-none-any.whl (3.4 MB)
Collecting packaging>=20.0
  Using cached packaging-21.3-py3-none-any.whl (40 kB)
Collecting PyWavelets>=1.1.1
  Using cached PyWavelets-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.8 MB)
Collecting networkx>=2.2
  Using cached networkx-2.8.7-py3-none-any.whl (2.0 MB)
Collecting pyparsing!=3.0.5,>=2.0.2
  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)
Collecting python-gdcm
  Using cached python_gdcm-3.0.19-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)
Collecting pydicom>=2.2.0
  Using cached pydicom-2.3.0-py3-none-any.whl (2.0 MB)
Collecting prompt-toolkit<3.1.0,>3.0.1
  Using cached prompt_toolkit-3.0.31-py3-none-any.whl (382 kB)
Collecting traitlets>=5
  Using cached traitlets-5.5.0-py3-none-any.whl (107 kB)
Collecting stack-data
  Using cached stack_data-0.5.1-py3-none-any.whl (24 kB)
Collecting decorator
  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)
Collecting pickleshare
  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)
Collecting pygments>=2.4.0
  Using cached Pygments-2.13.0-py3-none-any.whl (1.1 MB)
Collecting pexpect>4.3
  Using cached pexpect-4.8.0-py2.py3-none-any.whl (59 kB)
Collecting matplotlib-inline
  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)
Collecting jedi>=0.16
  Using cached jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)
Collecting backcall
  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)
Collecting parso<0.9.0,>=0.8.0
  Using cached parso-0.8.3-py2.py3-none-any.whl (100 kB)
Collecting ptyprocess>=0.5
  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)
Collecting wcwidth
  Using cached wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)
Collecting kiwisolver>=1.0.1
  Using cached kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
Collecting fonttools>=4.22.0
  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)
Collecting python-dateutil>=2.7
  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
Collecting contourpy>=1.0.1
  Using cached contourpy-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (295 kB)
Collecting cycler>=0.10
  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)
Collecting six>=1.5
  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)
Collecting setuptools
  Using cached setuptools-65.5.0-py3-none-any.whl (1.2 MB)
Collecting pytz>=2020.1
  Using cached pytz-2022.5-py2.py3-none-any.whl (500 kB)
Collecting idna<4,>=2.5
  Using cached idna-3.4-py3-none-any.whl (61 kB)
Collecting urllib3<1.27,>=1.21.1
  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)
Collecting certifi>=2017.4.17
  Using cached certifi-2022.9.24-py3-none-any.whl (161 kB)
Collecting charset-normalizer<3,>=2
  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)
Collecting joblib>=1.0.0
  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)
Collecting executing
  Using cached executing-1.1.1-py2.py3-none-any.whl (22 kB)
Collecting pure-eval
  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)
Collecting asttokens
  Using cached asttokens-2.0.8-py2.py3-none-any.whl (23 kB)
Collecting traceback2
  Using cached traceback2-1.4.0-py2.py3-none-any.whl (16 kB)
Collecting argparse
  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)
Collecting linecache2
  Using cached linecache2-1.0.0-py2.py3-none-any.whl (12 kB)
Using legacy 'setup.py install' for batchgenerators, since package 'wheel' is not installed.
Using legacy 'setup.py install' for future, since package 'wheel' is not installed.
Using legacy 'setup.py install' for medpy, since package 'wheel' is not installed.
Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.
Installing collected packages: six, pyparsing, pillow, numpy, linecache2, wcwidth, typing-extensions, traitlets, traceback2, tifffile, threadpoolctl, setuptools, scipy, PyWavelets, pure-eval, ptyprocess, parso, packaging, networkx, joblib, imageio, executing, asttokens, argparse, urllib3, unittest2, torch, stack-data, SimpleITK, scikit-learn, scikit-image, pytz, python-gdcm, python-dateutil, pygments, pydicom, prompt-toolkit, pickleshare, pexpect, nibabel, matplotlib-inline, kiwisolver, jedi, idna, future, fonttools, decorator, cycler, contourpy, charset-normalizer, certifi, backcall, tqdm, sklearn, requests, pandas, monai, medpy, matplotlib, ipython, graphviz, einops, dicom2nifti, batchgenerators, nnunet
    Running setup.py install for future: started
    Running setup.py install for future: finished with status 'done'
    Running setup.py install for sklearn: started
    Running setup.py install for sklearn: finished with status 'done'
    Running setup.py install for medpy: started
    Running setup.py install for medpy: finished with status 'done'
    Running setup.py install for batchgenerators: started
    Running setup.py install for batchgenerators: finished with status 'done'
  Running setup.py develop for nnunet
Successfully installed PyWavelets-1.4.1 SimpleITK-2.2.0 argparse-1.4.0 asttokens-2.0.8 backcall-0.2.0 batchgenerators-0.24 certifi-2022.9.24 charset-normalizer-2.1.1 contourpy-1.0.5 cycler-0.11.0 decorator-5.1.1 dicom2nifti-2.4.5 einops-0.5.0 executing-1.1.1 fonttools-4.38.0 future-0.18.2 graphviz-0.20.1 idna-3.4 imageio-2.22.2 ipython-8.5.0 jedi-0.18.1 joblib-1.2.0 kiwisolver-1.4.4 linecache2-1.0.0 matplotlib-3.6.1 matplotlib-inline-0.1.6 medpy-0.4.0 monai-1.0.1 networkx-2.8.7 nibabel-4.0.2 nnunet numpy-1.23.4 packaging-21.3 pandas-1.5.1 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.2.0 prompt-toolkit-3.0.31 ptyprocess-0.7.0 pure-eval-0.2.2 pydicom-2.3.0 pygments-2.13.0 pyparsing-3.0.9 python-dateutil-2.8.2 python-gdcm-3.0.19 pytz-2022.5 requests-2.28.1 scikit-image-0.19.3 scikit-learn-1.1.3 scipy-1.9.3 setuptools-65.5.0 six-1.16.0 sklearn-0.0 stack-data-0.5.1 threadpoolctl-3.1.0 tifffile-2022.10.10 torch-1.12.0 tqdm-4.64.1 traceback2-1.4.0 traitlets-5.5.0 typing-extensions-4.4.0 unittest2-1.1.0 urllib3-1.26.12 wcwidth-0.2.5


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

Verifying training set
checking case panc_00001
checking case panc_00000
checking case panc_00004
checking case panc_00007
checking case panc_00003
checking case panc_00006
checking case panc_00002
checking case panc_00005
Verifying label values
Expected label values are [0, 1]
Labels OK
Dataset OK
panc_00006
[Timing] Loading took 0.37457871437072754 seconds
before crop: (1, 42, 320, 320) after crop: (1, 42, 300, 320) spacing: [3.         0.66666669 0.66666669] 

panc_00000
[Timing] Loading took 0.3588216304779053 seconds
before crop: (1, 40, 320, 320) after crop: (1, 40, 318, 320) spacing: [3.     0.6875 0.6875] 

panc_00001
[Timing] Loading took 0.2133471965789795 seconds
before crop: (1, 40, 320, 320) after crop: (1, 40, 320, 320) spacing: [3.     0.6875 0.6875] 

panc_00003
[Timing] Loading took 0.34650516510009766 seconds
before crop: (1, 40, 320, 320) after crop: (1, 40, 320, 320) spacing: [3.     0.6875 0.6875] 

panc_00002
[Timing] Loading took 0.1943674087524414 seconds
before crop: (1, 40, 320, 320) after crop: (1, 40, 320, 320) spacing: [3.     0.6875 0.6875] 

panc_00004
[Timing] Loading took 0.31014013290405273 seconds
before crop: (1, 35, 512, 512) after crop: (1, 35, 438, 512) spacing: [4.4000001 0.78125   0.78125  ] 

panc_00007
[Timing] Loading took 0.3736386299133301 seconds
before crop: (1, 42, 320, 320) after crop: (1, 42, 292, 320) spacing: [3.         0.68493152 0.68493152] 

panc_00005
[Timing] Loading took 0.2311878204345703 seconds
before crop: (1, 42, 320, 320) after crop: (1, 42, 292, 320) spacing: [3.         0.68493152 0.68493152] 




 Task610
number of threads:  (6, 6) 

not using nonzero mask for normalization
Are we using the nonzero mask for normalization? OrderedDict([(0, False)])
the median shape of the dataset is  [ 41. 319. 320.]
the max shape in the dataset is  [ 51.33333445 497.72727273 581.81818182]
the min shape in the dataset is  [ 40.         290.90909507 310.30303955]
we don't want feature maps smaller than  4  in the bottleneck
the transposed median shape of the dataset is  [ 41. 319. 320.]
generating configuration for 3d_fullres
{0: {'batch_size': 2, 'num_pool_per_axis': [3, 5, 6], 'patch_size': array([ 32, 224, 256]), 'median_patient_size_in_voxels': array([ 41, 319, 320]), 'current_spacing': array([3.    , 0.6875, 0.6875]), 'original_spacing': array([3.    , 0.6875, 0.6875]), 'do_dummy_2D_data_aug': True, 'pool_op_kernel_sizes': [[1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 1, 2]], 'conv_kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}
transpose forward [0, 1, 2]
transpose backward [0, 1, 2]
Initializing to run preprocessing
npz folder: /exports/lkeb-hpc/smaijer/data/nnUNet_raw_data_base/nnUNet_cropped_data/Task610
output_folder: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610
no resampling necessary
no resampling necessary
before: {'spacing': array([3.    , 0.6875, 0.6875]), 'spacing_transposed': array([3.    , 0.6875, 0.6875]), 'data.shape (data is transposed)': (1, 40, 318, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 40, 318, 320)} 

1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_stage0/panc_00000.npz
no resampling necessary
no resampling necessary
before: {'spacing': array([3.    , 0.6875, 0.6875]), 'spacing_transposed': array([3.    , 0.6875, 0.6875]), 'data.shape (data is transposed)': (1, 40, 320, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 40, 320, 320)} 

1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_stage0/panc_00001.npz
separate z, order in z is 0 order inplane is 3
separate z, order in z is 0 order inplane is 1
before: {'spacing': array([3.        , 0.68493152, 0.68493152]), 'spacing_transposed': array([3.        , 0.68493152, 0.68493152]), 'data.shape (data is transposed)': (1, 42, 292, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 42, 291, 319)} 

1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_stage0/panc_00005.npz
no resampling necessary
no resampling necessary
before: {'spacing': array([3.    , 0.6875, 0.6875]), 'spacing_transposed': array([3.    , 0.6875, 0.6875]), 'data.shape (data is transposed)': (1, 40, 320, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 40, 320, 320)} 

1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_stage0/panc_00003.npz
separate z, order in z is 0 order inplane is 3
separate z, order in z is 0 order inplane is 1
before: {'spacing': array([3.        , 0.66666669, 0.66666669]), 'spacing_transposed': array([3.        , 0.66666669, 0.66666669]), 'data.shape (data is transposed)': (1, 42, 300, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 42, 291, 310)} 

1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_stage0/panc_00006.npz
no resampling necessary
no resampling necessary
before: {'spacing': array([3.    , 0.6875, 0.6875]), 'spacing_transposed': array([3.    , 0.6875, 0.6875]), 'data.shape (data is transposed)': (1, 40, 320, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 40, 320, 320)} 

1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_stage0/panc_00002.npz
separate z, order in z is 0 order inplane is 3
separate z, order in z is 0 order inplane is 1
before: {'spacing': array([3.        , 0.68493152, 0.68493152]), 'spacing_transposed': array([3.        , 0.68493152, 0.68493152]), 'data.shape (data is transposed)': (1, 42, 292, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 42, 291, 319)} 

1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_stage0/panc_00007.npz
separate z, order in z is 0 order inplane is 3
separate z, order in z is 0 order inplane is 1
before: {'spacing': array([4.4000001, 0.78125  , 0.78125  ]), 'spacing_transposed': array([4.4000001, 0.78125  , 0.78125  ]), 'data.shape (data is transposed)': (1, 35, 438, 512)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 51, 498, 582)} 

1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_stage0/panc_00004.npz
not using nonzero mask for normalization
Are we using the nonzero mask for normalization? OrderedDict([(0, False)])
the median shape of the dataset is  [ 41. 319. 320.]
the max shape in the dataset is  [ 51.33333445 497.72727273 581.81818182]
the min shape in the dataset is  [ 40.         290.90909507 310.30303955]
we don't want feature maps smaller than  4  in the bottleneck
the transposed median shape of the dataset is  [ 41. 319. 320.]
[{'batch_size': 16, 'num_pool_per_axis': [6, 6], 'patch_size': array([320, 320]), 'median_patient_size_in_voxels': array([ 41, 319, 320]), 'current_spacing': array([3.    , 0.6875, 0.6875]), 'original_spacing': array([3.    , 0.6875, 0.6875]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]
Initializing to run preprocessing
npz folder: /exports/lkeb-hpc/smaijer/data/nnUNet_raw_data_base/nnUNet_cropped_data/Task610
output_folder: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610
no resampling necessary
no resampling necessary
before: {'spacing': array([3.    , 0.6875, 0.6875]), 'spacing_transposed': array([3.    , 0.6875, 0.6875]), 'data.shape (data is transposed)': (1, 40, 318, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 40, 318, 320)} 

normalization...
normalization done
1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_2D_stage0/panc_00000.npz
no resampling necessary
no resampling necessary
before: {'spacing': array([3.    , 0.6875, 0.6875]), 'spacing_transposed': array([3.    , 0.6875, 0.6875]), 'data.shape (data is transposed)': (1, 40, 320, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 40, 320, 320)} 

normalization...
normalization done
1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_2D_stage0/panc_00001.npz
separate z, order in z is 0 order inplane is 3
separate z, order in z is 0 order inplane is 1
before: {'spacing': array([3.        , 0.68493152, 0.68493152]), 'spacing_transposed': array([3.        , 0.68493152, 0.68493152]), 'data.shape (data is transposed)': (1, 42, 292, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 42, 291, 319)} 

normalization...
normalization done
1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_2D_stage0/panc_00005.npz
no resampling necessary
no resampling necessary
before: {'spacing': array([3.    , 0.6875, 0.6875]), 'spacing_transposed': array([3.    , 0.6875, 0.6875]), 'data.shape (data is transposed)': (1, 40, 320, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 40, 320, 320)} 

normalization...
normalization done
1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_2D_stage0/panc_00003.npz
separate z, order in z is 0 order inplane is 3
separate z, order in z is 0 order inplane is 1
before: {'spacing': array([3.        , 0.66666669, 0.66666669]), 'spacing_transposed': array([3.        , 0.66666669, 0.66666669]), 'data.shape (data is transposed)': (1, 42, 300, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 42, 291, 310)} 

normalization...
normalization done
1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_2D_stage0/panc_00006.npz
no resampling necessary
no resampling necessary
before: {'spacing': array([3.    , 0.6875, 0.6875]), 'spacing_transposed': array([3.    , 0.6875, 0.6875]), 'data.shape (data is transposed)': (1, 40, 320, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 40, 320, 320)} 

normalization...
normalization done
1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_2D_stage0/panc_00002.npz
separate z, order in z is 0 order inplane is 3
separate z, order in z is 0 order inplane is 1
before: {'spacing': array([3.        , 0.68493152, 0.68493152]), 'spacing_transposed': array([3.        , 0.68493152, 0.68493152]), 'data.shape (data is transposed)': (1, 42, 292, 320)} 
after:  {'spacing': array([3.    , 0.6875, 0.6875]), 'data.shape (data is resampled)': (1, 42, 291, 319)} 

normalization...
normalization done
1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_2D_stage0/panc_00007.npz
separate z, order in z is 0 order inplane is 3
separate z, order in z is 0 order inplane is 1
before: {'spacing': array([4.4000001, 0.78125  , 0.78125  ]), 'spacing_transposed': array([4.4000001, 0.78125  , 0.78125  ]), 'data.shape (data is transposed)': (1, 35, 438, 512)} 
after:  {'spacing': array([4.4000001, 0.6875   , 0.6875   ]), 'data.shape (data is resampled)': (1, 35, 498, 582)} 

normalization...
normalization done
1 10000
saving:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task610/nnUNetData_plans_v2.1_2D_stage0/panc_00004.npz
Program finished with exit code 0 at: Tue Oct 25 15:55:32 CEST 2022
