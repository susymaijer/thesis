Starting at Mon Jun 20 02:24:17 CEST 2022
Running on hosts: res-hpc-lkeb06
Running on 1 nodes.
Running 1 tasks.
CPUs on node: 8.
Account: div2-lkeb
Job ID: 10579869
Job name: PancreasAll
Node running script: res-hpc-lkeb06
Submit host: res-hpc-lo02.researchlumc.nl
GPUS: 0 or 
Mon Jun 27 14:25:24 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     On   | 00000000:D8:00.0 Off |                  Off |
| 33%   24C    P8     4W / 260W |      0MiB / 24220MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Current working directory is /home/smaijer
Load all modules..
Done with loading all modules. Modules:
Activate conda env nnunet..
Verifying environment variables:
Installing hidden layer and nnUnet..
Collecting hiddenlayer
  Cloning https://github.com/FabianIsensee/hiddenlayer.git (to revision more_plotted_details) to /tmp/pip-install-emmxqshh/hiddenlayer_6d372777d8644d6f9b66b125702fbea5
  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit 4b98f9e5cccebac67368f02b95f4700b522345b1
Using legacy 'setup.py install' for hiddenlayer, since package 'wheel' is not installed.
Installing collected packages: hiddenlayer
    Running setup.py install for hiddenlayer: started
    Running setup.py install for hiddenlayer: finished with status 'done'
Successfully installed hiddenlayer-0.2
Start preprocessing..
Done preprocessing! Start training all the folds..


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

###############################################
I am running the following nnUNet: 3d_fullres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  15
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 160, 160]), 'median_patient_size_in_voxels': array([138, 243, 243]), 'current_spacing': array([3.28926364, 1.64543342, 1.64543342]), 'original_spacing': array([2.        , 0.78014851, 0.78014851]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 160, 160]), 'median_patient_size_in_voxels': array([228, 513, 513]), 'current_spacing': array([2.        , 0.78014851, 0.78014851]), 'original_spacing': array([2.        , 0.78014851, 0.78014851]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 1 from these plans
I am using batch dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task700/nnUNetData_plans_v2.1
###############################################
loading dataset
loading all case properties
2022-06-27 14:25:45.896281: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task700/splits_final.pkl
2022-06-27 14:25:45.906020: The split file contains 5 splits.
2022-06-27 14:25:45.908351: Desired fold for training: 2
2022-06-27 14:25:45.910288: This split has 192 training and 48 validation cases.
unpacking dataset
