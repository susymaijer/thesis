Starting at Sat Jun 18 17:37:25 CEST 2022
Running on hosts: res-hpc-lkeb06
Running on 1 nodes.
Running 1 tasks.
CPUs on node: 6.
Account: div2-lkeb
Job ID: 10579499
Job name: PancreasAll
Node running script: res-hpc-lkeb06
Submit host: res-hpc-lo02.researchlumc.nl
GPUS: 0 or 
Mon Jun 27 09:49:15 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Quadro RTX 6000     On   | 00000000:D8:00.0 Off |                  Off |
| 33%   24C    P8     4W / 260W |      0MiB / 24220MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
Current working directory is /home/smaijer
Load all modules..
Done with loading all modules. Modules:
Activate conda env nnunet..
Verifying environment variables:
nnUNet_raw_data_base = /exports/lkeb-hpc/smaijer/data/nnUNet_raw_data_base
nnUNet_preprocessed = /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed
RESULTS_FOLDER = /exports/lkeb-hpc/smaijer/results
OUTPUT = /exports/lkeb-hpc/smaijer/output
Installing hidden layer and nnUnet..
Collecting hiddenlayer
  Cloning https://github.com/FabianIsensee/hiddenlayer.git (to revision more_plotted_details) to /tmp/pip-install-su19pnam/hiddenlayer_f564070b02d64359ba3227ec5c6130b1
  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit 4b98f9e5cccebac67368f02b95f4700b522345b1
Building wheels for collected packages: hiddenlayer
  Building wheel for hiddenlayer (setup.py): started
  Building wheel for hiddenlayer (setup.py): finished with status 'done'
  Created wheel for hiddenlayer: filename=hiddenlayer-0.2-py3-none-any.whl size=19803 sha256=6630e5efd82fb9057c7177bb0f75d21a78305154e18dcbd9f13493a64f4f6f10
  Stored in directory: /tmp/pip-ephem-wheel-cache-qaxbo_p9/wheels/e8/74/05/c6527f5ffdb22e1fc41a970a8ae3b62a1412a71b445ce477a2
Successfully built hiddenlayer
Installing collected packages: hiddenlayer
Successfully installed hiddenlayer-0.2
Obtaining file:///home/smaijer/nnUNet
Collecting torch>1.10.0
  Using cached torch-1.11.0-cp39-cp39-manylinux1_x86_64.whl (750.6 MB)
Collecting tqdm
  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)
Collecting dicom2nifti
  Using cached dicom2nifti-2.3.4-py3-none-any.whl
Collecting scikit-image>=0.14
  Using cached scikit_image-0.19.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)
Collecting medpy
  Using cached MedPy-0.4.0-py3-none-any.whl
Collecting scipy
  Using cached scipy-1.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.2 MB)
Collecting batchgenerators>=0.23
  Using cached batchgenerators-0.24-py3-none-any.whl
Collecting numpy
  Using cached numpy-1.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)
Collecting sklearn
  Using cached sklearn-0.0-py2.py3-none-any.whl
Collecting SimpleITK
  Using cached SimpleITK-2.1.1.2-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)
Collecting pandas
  Using cached pandas-1.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)
Collecting requests
  Using cached requests-2.28.0-py3-none-any.whl (62 kB)
Collecting nibabel
  Using cached nibabel-4.0.1-py3-none-any.whl (3.3 MB)
Collecting tifffile
  Using cached tifffile-2022.5.4-py3-none-any.whl (195 kB)
Collecting matplotlib
  Using cached matplotlib-3.5.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)
Collecting monai
  Using cached monai-0.9.0-202206131636-py3-none-any.whl (939 kB)
Collecting einops
  Using cached einops-0.4.1-py3-none-any.whl (28 kB)
Collecting pillow>=7.1.2
  Using cached Pillow-9.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)
Collecting scikit-learn
  Using cached scikit_learn-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.8 MB)
Collecting unittest2
  Using cached unittest2-1.1.0-py2.py3-none-any.whl (96 kB)
Collecting future
  Using cached future-0.18.2-py3-none-any.whl
Collecting threadpoolctl
  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)
Collecting PyWavelets>=1.1.1
  Using cached PyWavelets-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)
Collecting packaging>=20.0
  Using cached packaging-21.3-py3-none-any.whl (40 kB)
Collecting imageio>=2.4.1
  Using cached imageio-2.19.3-py3-none-any.whl (3.4 MB)
Collecting networkx>=2.2
  Using cached networkx-2.8.4-py3-none-any.whl (2.0 MB)
Collecting pyparsing!=3.0.5,>=2.0.2
  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)
Collecting typing-extensions
  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)
Collecting pydicom>=1.3.0
  Using cached pydicom-2.3.0-py3-none-any.whl (2.0 MB)
Collecting python-dateutil>=2.7
  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
Collecting fonttools>=4.22.0
  Using cached fonttools-4.33.3-py3-none-any.whl (930 kB)
Collecting cycler>=0.10
  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)
Collecting kiwisolver>=1.0.1
  Using cached kiwisolver-1.4.3-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
Collecting six>=1.5
  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)
Collecting setuptools
  Using cached setuptools-62.6.0-py3-none-any.whl (1.2 MB)
Collecting pytz>=2020.1
  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)
Collecting certifi>=2017.4.17
  Using cached certifi-2022.6.15-py3-none-any.whl (160 kB)
Collecting idna<4,>=2.5
  Using cached idna-3.3-py3-none-any.whl (61 kB)
Collecting charset-normalizer~=2.0.0
  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)
Collecting urllib3<1.27,>=1.21.1
  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)
Collecting joblib>=1.0.0
  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)
Collecting traceback2
  Using cached traceback2-1.4.0-py2.py3-none-any.whl (16 kB)
Collecting argparse
  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)
Collecting linecache2
  Using cached linecache2-1.0.0-py2.py3-none-any.whl (12 kB)
Installing collected packages: pyparsing, pillow, numpy, linecache2, typing-extensions, traceback2, tifffile, threadpoolctl, six, setuptools, scipy, PyWavelets, packaging, networkx, joblib, imageio, argparse, urllib3, unittest2, torch, SimpleITK, scikit-learn, scikit-image, pytz, python-dateutil, pydicom, nibabel, kiwisolver, idna, future, fonttools, cycler, charset-normalizer, certifi, tqdm, sklearn, requests, pandas, monai, medpy, matplotlib, einops, dicom2nifti, batchgenerators, nnunet
  Running setup.py develop for nnunet
Successfully installed PyWavelets-1.3.0 SimpleITK-2.1.1.2 argparse-1.4.0 batchgenerators-0.24 certifi-2022.6.15 charset-normalizer-2.0.12 cycler-0.11.0 dicom2nifti-2.3.4 einops-0.4.1 fonttools-4.33.3 future-0.18.2 idna-3.3 imageio-2.19.3 joblib-1.1.0 kiwisolver-1.4.3 linecache2-1.0.0 matplotlib-3.5.2 medpy-0.4.0 monai-0.9.0 networkx-2.8.4 nibabel-4.0.1 nnunet numpy-1.23.0 packaging-21.3 pandas-1.4.3 pillow-9.1.1 pydicom-2.3.0 pyparsing-3.0.9 python-dateutil-2.8.2 pytz-2022.1 requests-2.28.0 scikit-image-0.19.3 scikit-learn-1.1.1 scipy-1.8.1 setuptools-62.6.0 six-1.16.0 sklearn-0.0 threadpoolctl-3.1.0 tifffile-2022.5.4 torch-1.11.0 tqdm-4.64.0 traceback2-1.4.0 typing-extensions-4.2.0 unittest2-1.1.0 urllib3-1.26.9
Start preprocessing..
Done preprocessing! Start training all the folds..


Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet



Please cite the following paper when using nnUNet:

Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation." Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z


If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet

Suus0 - run_training. Args:
Namespace(network='3d_fullres', network_trainer='nnUNetTrainerV2', task='535', fold='2', validation_only=False, continue_training=False, p='nnUNetPlansv2.1', use_compressed_data=False, deterministic=False, npz=False, find_lr=False, valbest=False, fp32=False, val_folder='validation_raw', disable_saving=False, disable_postprocessing_on_folds=False, val_disable_overwrite=True, disable_next_stage_pred=False, pretrained_weights=None)
###############################################
I am running the following nnUNet: 3d_fullres
My trainer class is:  <class 'nnunet.training.network_training.nnUNetTrainerV2.nnUNetTrainerV2'>
For that I will be using the following configuration:
num_classes:  15
modalities:  {0: 'CT'}
use_mask_for_norm OrderedDict([(0, False)])
keep_only_largest_region None
min_region_size_per_class None
min_size_per_class None
normalization_schemes OrderedDict([(0, 'CT')])
stages...

stage:  0
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 80, 160, 160]), 'median_patient_size_in_voxels': array([141, 240, 240]), 'current_spacing': array([3.32215628, 1.6685856 , 1.6685856 ]), 'original_spacing': array([2.        , 0.68825001, 0.68825001]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

stage:  1
{'batch_size': 2, 'num_pool_per_axis': [4, 5, 5], 'patch_size': array([ 64, 160, 160]), 'median_patient_size_in_voxels': array([235, 582, 582]), 'current_spacing': array([2.        , 0.68825001, 0.68825001]), 'original_spacing': array([2.        , 0.68825001, 0.68825001]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}

I am using stage 1 from these plans
I am using batch dice + CE loss

I am using data from this folder:  /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task535/nnUNetData_plans_v2.1
###############################################
Suus1 - Initialise de NetworkTrainer
Suus2 - Initialise de nnUNetTrainer
Suus3 - Initialise de nnUNetTrainerV2
Suus4 - Initialise de trainer echt
Suus5 - zet de plans properties
Suus6 - Zet de data augmentation params
Suus7 - zet deep supervision weights die de meerdere outputs prioriteit geven
loading dataset
loading all case properties
2022-06-27 09:50:26.671284: Using splits from existing split file: /exports/lkeb-hpc/smaijer/data/nnUNet_preprocessed/Task535/splits_final.pkl
2022-06-27 09:50:26.683041: The split file contains 5 splits.
2022-06-27 09:50:26.686123: Desired fold for training: 2
2022-06-27 09:50:26.688246: This split has 160 training and 40 validation cases.
unpacking dataset
done
Suus8 - Maak network aan (BELANGRIJK!)
Suus9 - Maak alle convolutional layrs aan (conv_blocks_context
SuusB - first stride 
Suus10 - StackedConvLayers, input: 1 en output: 32, first_stride: None, num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [1, 3, 3], 'padding': [0, 1, 1]}
SuusA - first_stride [1, 2, 2]
Suus10 - StackedConvLayers, input: 32 en output: 64, first_stride: [1, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
SuusA - first_stride [2, 2, 2]
Suus10 - StackedConvLayers, input: 64 en output: 128, first_stride: [2, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
SuusA - first_stride [2, 2, 2]
Suus10 - StackedConvLayers, input: 128 en output: 256, first_stride: [2, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
SuusA - first_stride [2, 2, 2]
Suus10 - StackedConvLayers, input: 256 en output: 320, first_stride: [2, 2, 2], num_convs: 2, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus11 - Maak laatste convolutional layers aam
Suus10 - StackedConvLayers, input: 320 en output: 320, first_stride: [2, 2, 2], num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 320 en output: 320, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - Maak alle decoding layrs aan (conv_blocks_context
Suus10 - StackedConvLayers, input: 640 en output: 320, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 320 en output: 320, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 512 en output: 256, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 256 en output: 256, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 256 en output: 128, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 128 en output: 128, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 128 en output: 64, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 64 en output: 64, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 64 en output: 32, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Suus10 - StackedConvLayers, input: 32 en output: 32, first_stride: None, num_convs: 1, conv_kwargs: {'stride': 1, 'dilation': 1, 'bias': True, 'kernel_size': [3, 3, 3], 'padding': [1, 1, 1]}
Generic_UNet(
  (encoder): Generic_UNETEncoder()
  (decoder): Generic_UNETDecoder()
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
SuusB run_training - zet learning rate als  
2022-06-27 09:50:33.494881: Suus1 maybe_update_lr lr: 0.01
SuusC - run_training!
using pin_memory on device 0
using pin_memory on device 0
2022-06-27 09:51:13.177997: Unable to plot network architecture:
2022-06-27 09:51:13.182719: No module named 'IPython'
2022-06-27 09:51:13.184813: 
printing the network instead:

2022-06-27 09:51:13.188543: Generic_UNet(
  (encoder): Generic_UNETEncoder()
  (decoder): Generic_UNETDecoder()
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
)
2022-06-27 09:51:13.193299: 

2022-06-27 09:51:13.195871: 
epoch:  0
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
x.shape after conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
Downsample 3
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 128, 32, 40, 40])
x.shape after conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
Downsample 4
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 256, 16, 20, 20])
x.shape after conv_blocks_context: torch.Size([2, 320, 8, 10, 10])
Suus12b - Decoder.
Upsample 0
ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 4, 5, 5])
x.shape after self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after concat skips: torch.Size([2, 640, 8, 10, 10])
x.shape after conv_blocks_localization: torch.Size([2, 320, 8, 10, 10])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 8, 10, 10])
Upsample 1
ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 320, 8, 10, 10])
x.shape after self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after concat skips: torch.Size([2, 512, 16, 20, 20])
x.shape after conv_blocks_localization: torch.Size([2, 256, 16, 20, 20])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 16, 20, 20])
Upsample 2
ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 256, 16, 20, 20])
x.shape after self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after concat skips: torch.Size([2, 256, 32, 40, 40])
x.shape after conv_blocks_localization: torch.Size([2, 128, 32, 40, 40])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 32, 40, 40])
Upsample 3
ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 128, 32, 40, 40])
x.shape after self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after concat skips: torch.Size([2, 128, 64, 80, 80])
x.shape after conv_blocks_localization: torch.Size([2, 64, 64, 80, 80])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 80, 80])
Upsample 4
ConvTranspose3d(64, 32, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
x.shape before self.tu[u].x: torch.Size([2, 64, 64, 80, 80])
x.shape after self.tu[u].x: torch.Size([2, 32, 64, 160, 160])
x.shape after concat skips: torch.Size([2, 64, 64, 160, 160])
x.shape after conv_blocks_localization: torch.Size([2, 32, 64, 160, 160])
De final result wordt nog door een seg_outputs convolutional 3d layer gehaald, en nonlinear: torch.Size([2, 16, 64, 160, 160])
Final shape seg_outputs (pre deep supervision), length 5 and contains: torch.Size([2, 16, 64, 160, 160])
Suus 12c We doen deep supervision dingen
torch.Size([2, 16, 64, 160, 160])
torch.Size([2, 1, 64, 160, 160])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 160, 160])
huh gaat goed?
torch.Size([2, 16, 64, 80, 80])
torch.Size([2, 1, 64, 80, 80])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 64, 80, 80])
huh gaat goed?
torch.Size([2, 16, 32, 40, 40])
torch.Size([2, 1, 32, 40, 40])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 32, 40, 40])
huh gaat goed?
torch.Size([2, 16, 16, 20, 20])
torch.Size([2, 1, 16, 20, 20])
[0, 2, 3, 4]
x na nonlin: torch.Size([2, 16, 16, 20, 20])
huh gaat goed?
Suus12a - Forward! Eerst doen we 5x convolutional blocks. We slaan deze op in skips. 
Downsample 0
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(1, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))
      (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 1, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
Downsample 1
StackedConvLayers(
  (blocks): Sequential(
    (0): ConvDropoutNormNonlin(
      (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
    (1): ConvDropoutNormNonlin(
      (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
    )
  )
)
x.shape before conv_blocks_context: torch.Size([2, 32, 64, 160, 160])
x.shape after conv_blocks_context: torch.Size([2, 64, 64, 80, 80])
Downsample 2
