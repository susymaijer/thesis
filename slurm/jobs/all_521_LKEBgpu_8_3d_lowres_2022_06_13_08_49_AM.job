#!/bin/bash
#SBATCH -J PancreasAll
#SBATCH -p LKEBgpu
#SBATCH -N 1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=32GB
#SBATCH --gres=gpu:RTX6000:1
#SBATCH --error=/home/smaijer/logs/all/521/job.%J.err
#SBATCH --output=/home/smaijer/logs/all/521/job.%J.out
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=susy.maijer@lumc.nl

# Prepare nnUnet
echo "Starting at Mon Jun 13 08:49:10 CEST 2022"

echo "Running on hosts: $SLURM_JOB_NODELIST"
echo "Running on $SLURM_JOB_NUM_NODES nodes."
echo "Running $SLURM_NTASKS tasks."
echo "CPUs on node: $SLURM_CPUS_ON_NODE."
echo "Account: $SLURM_JOB_ACCOUNT"
echo "Job ID: $SLURM_JOB_ID"
echo "Job name: $SLURM_JOB_NAME"
echo "Node running script: $SLURMD_NODENAME"
echo "Submit host: $SLURM_SUBMIT_HOST"
echo "GPUS: $CUDA_VISIBLE_DEVICES or $SLURM_STEP_GPUS"
nvidia-smi
echo "Current working directory is /home/smaijer"

echo "Load all modules.."
module purge
module add tools/miniconda/python3.8/4.9.2
echo "Done with loading all modules. Modules:"
module li
echo "Activate conda env nnunet.."
conda activate nn
echo "Verifying environment variables:"
conda env config vars list
echo "Installing nnU-net.."
pip install -e /home/smaijer/code/nnUNet

echo Start preprocessing..
nnUNet_plan_and_preprocess -t 521 --verify_dataset_integrity

echo Done preprocessing! Start training all the folds..
nnUNet_train 3d_lowres nnUNetTrainerV2 521 0
nnUNet_train 3d_lowres nnUNetTrainerV2 521 1
nnUNet_train 3d_lowres nnUNetTrainerV2 521 2
nnUNet_train 3d_lowres nnUNetTrainerV2 521 3
nnUNet_train 3d_lowres nnUNetTrainerV2 521 4

echo Done training all the folds! Now start the same command but with continue option, to generate log files
nnUNet_train 3d_lowres nnUNetTrainerV2 521 0 -c
nnUNet_train 3d_lowres nnUNetTrainerV2 521 1 -c
nnUNet_train 3d_lowres nnUNetTrainerV2 521 2 -c
nnUNet_train 3d_lowres nnUNetTrainerV2 521 3 -c
nnUNet_train 3d_lowres nnUNetTrainerV2 521 4 -c

echo Start postprocessing..
nnUNet_determine_postprocessing -t 521 -m 3d_lowres

echo Done postprocessing! Now start inferencing its own train and test files.
mkdir -p /exports/lkeb-hpc/smaijer/output/521/3d_lowres/521/imagesTr
mkdir -p /exports/lkeb-hpc/smaijer/output/521/3d_lowres/521/imagesTs
nnUNet_predict -i /exports/lkeb-hpc/smaijer/data/nnUNet_raw_data_base/nnUNet_raw_data/Task521/imagesTr -o /exports/lkeb-hpc/smaijer/output/521/3d_lowres/521/imagesTr -t 521 -m 3d_lowres
nnUNet_predict -i /exports/lkeb-hpc/smaijer/data/nnUNet_raw_data_base/nnUNet_raw_data/Task521/imagesTs -o /exports/lkeb-hpc/smaijer/output/521/3d_lowres/521/imagesTs -t 521 -m 3d_lowres

echo Done inferencing! Now start the evaluation.
nnUNet_evaluate_folder -ref /exports/lkeb-hpc/smaijer/data/nnUNet_raw_data_base/nnUNet_raw_data/Task521/labelsTr -pred /exports/lkeb-hpc/smaijer/output/521/3d_lowres/521/imagesTr -l 1
nnUNet_evaluate_folder -ref /exports/lkeb-hpc/smaijer/data/nnUNet_raw_data_base/nnUNet_raw_data/Task521/labelsTs -pred /exports/lkeb-hpc/smaijer/output/521/3d_lowres/521/imagesTs -l 1

echo "Program finished with exit code 0 at: Mon Jun 13 08:49:10 CEST 2022"
