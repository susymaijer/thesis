#!/bin/bash
#SBATCH -J P16panc_inference
#SBATCH -p LKEBgpu
#SBATCH -N 1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --time=02:00:00
#SBATCH --mem=85GB
#SBATCH --gres=gpu:RTX6000:1
#SBATCH --error=/home/smaijer/logs/p16/job.%J.inference.err
#SBATCH --output=/home/smaijer/logs/p16/job.%J.inference.out

echo "Starting at `\date`"
echo "Running on hosts: \$SLURM_JOB_NODELIST"
echo "Running on \$SLURM_JOB_NUM_NODES nodes."
echo "Running \$SLURM_NTASKS tasks."
echo "CPUs on node: \$SLURM_CPUS_ON_NODE."
echo "Account: \$SLURM_JOB_ACCOUNT"
echo "Job ID: \$SLURM_JOB_ID"
echo "Job name: \$SLURM_JOB_NAME"
echo "Node running script: \$SLURMD_NODENAME"
echo "Submit host: \$SLURM_SUBMIT_HOST"
echo "GPUS: \$CUDA_VISIBLE_DEVICES or \$SLURM_STEP_GPUS"
nvidia-smi
echo "Current working directory is `\pwd`"

echo "Load all modules.."
module purge
module add system/python/3.10.2
echo "Done with loading all modules. Modules:"
module li
echo "Activate conda env nnUNet"
source /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/bin/activate
echo "Verifying environment variables:"
conda env config vars list
echo "Installing hidden layer and nnUnet"

python -m pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git@more_plotted_details#egg=hiddenlayer
python -m pip install --editable /home/smaijer/code/nnUNet
mkdir -p $nnUNet_raw_data_base/p16/batch1/segmentations/Task610
nnUNet_predict -i $nnUNet_raw_data_base/p16/batch1/niftis -o $nnUNet_raw_data_base/p16/batch1/segmentations/Task610  -t 610 -m 3d_fullres -tr nnUNetTrainerV2 -f 0 1 2 3 4
echo "Program finished with exit code $? at: `\date`"