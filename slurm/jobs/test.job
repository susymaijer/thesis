#!/bin/bash
#SBATCH -J P16panc_inference#SBATCH -p LKEBgpu#SBATCH -N 1#SBATCH --ntasks=1#SBATCH --cpus-per-task=6#SBATCH --time=02:00:00#SBATCH --mem=85GB#SBATCH --gres=gpu:RTX6000:1#SBATCH --error=/home/smaijer/logs/p16/job.%J.err#SBATCH --output={shared.log_dir}/job.%J.outecho "Starting at `\date`"echo "Running on hosts: \$SLURM_JOB_NODELIST"echo "Running on \$SLURM_JOB_NUM_NODES nodes."echo "Running \$SLURM_NTASKS tasks."echo "CPUs on node: \$SLURM_CPUS_ON_NODE."echo "Account: \$SLURM_JOB_ACCOUNT"echo "Job ID: \$SLURM_JOB_ID"echo "Job name: \$SLURM_JOB_NAME"echo "Node running script: \$SLURMD_NODENAME"echo "Submit host: \$SLURM_SUBMIT_HOST"echo "GPUS: \$CUDA_VISIBLE_DEVICES or \$SLURM_STEP_GPUS"nvidia-smiecho "Current working directory is `\pwd`"echo "Load all modules.."module purgemodule add system/python/3.10.2echo "Done with loading all modules. Modules:"module liecho "Activate conda env nnunet"source /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/bin/activateecho "Verifying environment variables:"conda env config vars listecho "Installing hidden layer and nnUnet"python -m pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git@more_plotted_details#egg=hiddenlayerpython -m pip install --editable /home/smaijer/code/nnUNetmkdir -p $nnUNet_raw_data_base/nnUNet_raw_data/p16/batch$batch/segmentationsnnUNet_predict -i $nnUNet_raw_data_base/nnUNet_raw_data/p16/batch$batch/niftis -o $nnUNet_raw_data_base/nnUNet_raw_data/p16/batch$batch/segmentations  -t $task -m 3d_fullres -tr nnUNetTrainerV2 -f 0 1 2 3 4echo "Program finished with exit code $? at: `\date`"