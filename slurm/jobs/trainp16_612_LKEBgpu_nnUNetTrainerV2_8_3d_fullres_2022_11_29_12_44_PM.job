#!/bin/bash
#SBATCH -J PancreasTrain
#SBATCH -p LKEBgpu
#SBATCH -N 1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=64GB
#SBATCH --gres=gpu:RTX6000:1
#SBATCH --error=/home/smaijer/logs/p16/job_train_612.%J.err
#SBATCH --output=/home/smaijer/logs/p16/job_train_612.%J.out
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=susy.maijer@lumc.nl

# Prepare nnUnet
echo "Starting at Tue Nov 29 12:44:26 CET 2022"

echo "Running on hosts: $SLURM_JOB_NODELIST"
echo "Running on $SLURM_JOB_NUM_NODES nodes."
echo "Running $SLURM_NTASKS tasks."
echo "CPUs on node: $SLURM_CPUS_ON_NODE."
echo "Account: $SLURM_JOB_ACCOUNT"
echo "Job ID: $SLURM_JOB_ID"
echo "Job name: $SLURM_JOB_NAME"
echo "Node running script: $SLURMD_NODENAME"
echo "Submit host: $SLURM_SUBMIT_HOST"
echo "GPUS: $CUDA_VISIBLE_DEVICES or $SLURM_STEP_GPUS"
nvidia-smi
echo "Current working directory is /home/smaijer/p16"

echo Load all modules..
module purge
module add system/python/3.10.2
echo Done with loading all modules. Modules:
module li
echo Activate conda env nnunet..
source /exports/lkeb-hpc/smaijer/venv_environments/pancreasThesis/bin/activate
echo Verifying environment variables:
conda env config vars list
echo Installing hidden layer and nnUnet..
python -m pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git@more_plotted_details#egg=hiddenlayer
python -m pip install -editable /home/smaijer/code/nnUNet


echo Start preprocessing..
if [  == y ];
then
   nnUNet_plan_and_preprocess -t 612 --verify_dataset_integrity -tl 4 -tf 4
fi

echo Done preprocessing! Start training all the folds..
if [ -z /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task611/nnUNetTrainerV2__nnUNetPlansv2.1 ];
then

    if [ ! -z task611 ];
    then
         echo Run with specific identifier task611
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 0 -p task611
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 1 -p task611
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 2 -p task611
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 3 -p task611
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 4 -p task611
    else
        nnUNet_train 3d_fullres nnUNetTrainerV2 612 0
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 1
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 2
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 3
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 4 
    fi

    echo Done training all the folds! Now start the same command but with continue option, to generate log files
    
    if [ ! -z task611 ];
    then
	 nnUNet_train 3d_fullres nnUNetTrainerV2 612 0 -p task611 -c --val_disable_overwrite
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 1 -p task611 -c --val_disable_overwrite
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 2 -p task611 -c --val_disable_overwrite
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 3 -p task611 -c --val_disable_overwrite
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 4 -p task611 -c --val_disable_overwrite
    else
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 0 -c --val_disable_overwrite
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 1 -c --val_disable_overwrite
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 2 -c --val_disable_overwrite
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 3 -c --val_disable_overwrite
         nnUNet_train 3d_fullres nnUNetTrainerV2 612 4 -c --val_disable_overwrite
    fi

else
    echo Use pretrained!
    nnUNet_train 3d_fullres nnUNetTrainerV2 612 0 -pretrained_weights /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task611/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_best.model
    nnUNet_train 3d_fullres nnUNetTrainerV2 612 1 -pretrained_weights /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task611/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_best.model
    nnUNet_train 3d_fullres nnUNetTrainerV2 612 2 -pretrained_weights /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task611/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_best.model
    nnUNet_train 3d_fullres nnUNetTrainerV2 612 3 -pretrained_weights /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task611/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_best.model
    nnUNet_train 3d_fullres nnUNetTrainerV2 612 4 -pretrained_weights /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task611/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_best.model

    echo Done training all the folds! Now start the same command but with continue option, to generate log files
    nnUNet_train 3d_fullres nnUNetTrainerV2 612 0 -c -pretrained_weights /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task611/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/model_best.model --val_disable_overwrite
    nnUNet_train 3d_fullres nnUNetTrainerV2 612 1 -c -pretrained_weights /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task611/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/model_best.model --val_disable_overwrite
    nnUNet_train 3d_fullres nnUNetTrainerV2 612 2 -c -pretrained_weights /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task611/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/model_best.model --val_disable_overwrite
    nnUNet_train 3d_fullres nnUNetTrainerV2 612 3 -c -pretrained_weights /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task611/nnUNetTrainerV2__nnUNetPlansv2.1/fold_3/model_best.model --val_disable_overwrite
    nnUNet_train 3d_fullres nnUNetTrainerV2 612 4 -c -pretrained_weights /exports/lkeb-hpc/smaijer/results/nnUNet/3d_fullres/Task611/nnUNetTrainerV2__nnUNetPlansv2.1/fold_4/model_best.model --val_disable_overwrite
fi

echo Start postprocessing..
if [ -z task611 ];
then
    echo Postprocessing with default plans
    nnUNet_determine_postprocessing -t 612 -m 3d_fullres -tr nnUNetTrainerV2
else
    echo Postprocessing with pretrained
    nnUNet_determine_postprocessing -t 612 -m 3d_fullres -tr nnUNetTrainerV2 -p task611
fi

echo "Program finished with exit code 0 at: Tue Nov 29 12:44:26 CET 2022"
